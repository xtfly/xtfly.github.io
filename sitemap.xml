<search>
    
     <entry>
        <title>程序员编码技术栈</title>
        <url>http://lanlingzi.cn/post/technical/2020/1114_tech_stack/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 写在前面 偶尔会有同学来问我：&amp;ldquo;飞哥，我在学校是学java，来公司却安排搞c&#43;&#43;，我不喜欢，怎么办？&amp;rdquo;
让人信服地回答这个问题其实很难。我的理解是无论什么语言，本质是要服务业务，无论是java还是c&#43;&#43;，他们都是实现业务软件的工具。在工作中，我们要尽可能多的去掌握一些固化不变的基础，越基础的知识点越具有通用性，掌握会让自己变得更有竞争力。各种编程语言在语法上可能有着相同又有不同的地方，有着他们各自最佳适合的场景。透过语法层面来看，似乎我们总是能找到一些共同的基础知识体系。当你了解并熟悉这些知识点之后，可能不会再纠结是选java还是其它了。
当然并不是语言层面的知识不再需要深入掌握，而是当工作选择需要你掌握哪种语言时，就去学习了解哪种语言。有了一些公共基础，也会触类旁通，学习起来更轻松。
本文试图抛开具体的语言，列出提纲梳理背后共同的技术栈，希望能给正在处于纠结选择语言的同学一些帮助。由于笔者能力、精力都有限，部分内容也是从网上收集整理，其中可能存在理解上偏差与错误。
数据结构与算法 曾有人总结，程序=数据结构&#43;算法。毫无疑问，他们是基础，是根本。
学习他们最好的方法之一是刷LeetCode题。我之前比较反感刷题，因为觉得编程语言的体系都实现大多数的数据结构和多种算法，大部分算法也在实际工作中使用不到。在某一次的软件教练聚餐上，意识到优秀的人往往越爱学习。其中一位知名教练说他会每周刷一两道题，目的是锻炼解决问题的思考能力。
下面以应用的视角来看数据结构与算法，是不是觉得他们既陌生又熟悉？不经意间发现我们从未离开他们。
 数据结构  集合：链表，栈，队列，编码时可能就是不停地与他们打交道 二叉树  红黑树：应用在Java/C&#43;&#43; STL的tree set/map，Linux虚拟内存管理 霍夫曼树：常应用在无损压缩编码 B树：分B-树，B&#43;树，B&#43;-树，用在磁盘文件组织，数据索引和数据库索引 AVL树：平衡二叉搜索树，Win系统对进程地址空间的管理 字典树：用在统计和排序大量字符串   图  二分图：有两顶点集且图中每条边的的两个顶点分别位于两个顶点集中，每个顶点集中没有边直接相连接。如应用在匈牙利算法，解决指派任务 有向无环图：如果一个有向图无法从某个顶点出发经过若干条边回到该点则这个图是一个有向无环图。如应用在流程编排，Spark的DAG图 欧拉图：通过图（无向图或有向图）中所有边且每边仅通过一次通路，相应的回路称为欧拉回路，如应用在判断定理，邮路问题 哈密顿图：图的一个回路，通过图的每一个节点一次且仅一次，就是哈密顿回路，存在哈密顿回路的图就是哈密顿图。可以解决旅行售货员，排座位问题等     算法  贪心：局部最优策略能导致产生全局最优解 动态规划：将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解 深度优先搜索：解决连通性问题，通常采用递归 广度优先搜索：解决最短路径问题，通常采用栈 最大流最小割：网络流基础，网络流的最大流等于其最小割 均摊分析：少量昂贵操作的成本均摊到所有的操作上    离散数学 昨天刷手机刷到我司交付的瑞士5G网络优化项目荣获2020 GLOTEL最佳交付奖。前一段时间GTS的创新论坛，正好有一位教授演讲的Topic与之相关，听完不得不感慨数学太重要了。因为这个获奖的背后并不是传统的工程化，而是通过数学建模来解决复杂网络的优化场景，数学公式是复杂事物的抽象。
不过大多数程序员不是数学科班出身，过多的数学理论对我们来说太难了。编程的基础是计算机科学，而计算机科学的基础是数学。学习数学有助于巩固编程的基础，写出更健壮的程序。
计算机只能懂得离散，作为程序员就有必要了解一些离散数学知识。离散数学是数学和计算机之间的桥梁。算法的基础都是离散数学，加密的理论基础也是离散数学，编码中很多奇怪而又高效的小技巧核心也是离散数学。
笔者去年偶然刷手机发现一本日本人写的《程序员的数学》，一读就停不下来，其中不少也与离散数学相关，写得太有意思了：
 0的故事：无即是有，其意义更多的是空、占位符 逻辑：真与假的二元世界，写代码需注意边界值，也需要兼顾完整性和排他性 余数：大问题通过余数规律简化为小问题 归纳法：一条腿可以往前迈一步，另一条腿若也能迈出一步，那就能够行进到无限的远方 排列组合：计数的关键就在于注意“遗漏”和“重复” 递归：从一般性前提推出个别性结论 指数爆炸：极力求解，变相求解，近似求解，概率求解 不可解问题：不可数的集合，用对角论证法和反证法  数学如何解决问题：
 认清模式，进行抽象化：用简单的数字进行规则的探寻，对问题进行抽象化的思考 由不擅长催生出的智慧：处理大规模数字、复杂判断，复杂问题可以找到规律简化为小问题 幻想法则：把问题换一种思考方式，不按套路去出牌  语言理论 以前看软件工程的材料，会看到形式化建模、形式化验证与形式化方法。由于非CS科班出身，对形式化这一词难以理解。一搜索才发现还有形式语言，自动机理念，进程代数等。它们是形式化方法基础，也是程序语言(PL)理论基础。
程序语言理论就是编程语言各自特征的设计、实现、分析、表征和分类。而形式语言是经过数学定义的语言，从数学方法的严谨性解决各类计算问题。解决这些问题需要多少资源，存储的空间与花费的时间要达到怎样程度。
公司iLearning上有一门南大教授讲《程序设计语言概念》的课程，或许你听完成之后有种上帝的视角，选择什么编程语言那不再是事儿。
下面关于PL的知识点，感兴趣的同学可以搜索相关材料。
 形式语言理论  自动机理论  下推自动机 有限状态自动机 线性有界自动机 图灵机   文法  正则文法 上下文无关文法 无限制文法   形式系统  形式证明     形式语义学  操作语义 指称语义 代数语义 公理语义   编译原理  中间代码(IR) 编译器前端 编译器后端 编译方式  实时编译(JIT) 预先编译(AOT)      编程范式 编程语言有上百种，能归纳如下编程范式：
 指令式：使用流程化语句和过程直接控制程序的运行与状态数据  过程式：核心在于模块化，在实现过程中使用了状态，依赖了外部变量，导致很容易影响附近的代码，可读性较差，后期维护成本也较高。 面向对象：核心在于事物抽象，提供清晰的对象边界。结合封装、集成、多态特性，降低了代码的耦合度，提升了系统的可维护性。   声明式：定义计算的逻辑而不是定义具体的流程控制  函数式：核心在于“避免副作用”，不改变也不依赖当前函数外的数据。结合不可变数据、函数是第一等公民等特性，使函数带有自描述性，可读性较高。 逻辑式：核心在于强调的是我们事先知道一系列事实，然后通过这些事实自动推出合理的结果 数据流式：核心在于将数据视作数据流的形式，并用pipeline的形式做处理。典型代表是响应式编程   元编程：用代码生成代码  静态元编程：在编译期展开生成或者执行代码  宏：分为基于文本替换的宏(C/C&#43;&#43;)，基于语法的宏(Rust) 泛型：在强类型程序设计语言中编写代码时使用一些以后才指定的类型，在实例化时作为参数指明这些类型。Java叫泛型，C&#43;&#43;叫模板。   动态元编程：  反射式：在运行时可以访问、检测和修改它本身状态或行为的一种能力      并发编程 软件的性能提升是一个永恒话题，并发编程是提升性能常见有效的方式。现有计算资源都是多核，从早期的多进程，到多线程，再到现在流行的协程，并发调度的粒度越来越细，为的是更有效地发挥多核的价值。但并发编程需要面对的问题是：并发实体之间的如何协同，资源竞争时如何同步？个人觉得并发编程是编码中最不好掌握且容易引发问题的点。
多进程编程主涉及到进程间通讯，在单体系统中应用较多，多与操作系统相关。协程可以理解微线程，近几年已逐渐普及。多线程编程是各种语言并发基础，下面是对多线程的知识点梳理：
 并发模型  CSP：独立的并发实体间通过共享的通讯channel(管道)进行通信，注重的是消息传送方式（channel），不关心发送的人和接收的人是谁 Actor：独立的并发实体间通过消息传递避免数据竞争，注重的处理单元，也就是Actor，而不是消息传送方式，发送消息时，都需要知道对方是谁   协作方式  Semaphone：信号量，维护了一组许可证，以约束访问被限制资源的线程数 Monitor：管程，使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作 CountDownLatch：计数器，通过倒计数器控制线程是否要等待 CyclicBarrier：循环屏障，用于一组固定数目的线程互相等待 Phaser：相位器，一种同步器能够让多个线程分别在不同阶段进行同步 Exchanger：交换器，提供了线程之间能够交换对象的同步点   设计模式  Single Threaded Execution模式：同一时刻只允许一个线程操作 Immutable模式：变量赋值一次后只能读取，不能改变 Fork/Join：单机版的MapReduce Feature：给您一张提货单，下午来取 Producer-Consumer模式：你生产蛋榚我来吃 Balking模式：有人在做了？太好了，我就不过去了 Guarded Suspension模式：要等到我准备好，没准备好就在门口等着，准备好了再叫你 Thread per Message模式：一任务一线程 Worker thread模式：工作没来就一直等，工作来了就干活 Thread-Specific Storage模式：线程私有物品保管箱 Two-Phase Termination模式：优雅安全的关闭线程   互斥锁  同步资源决策方式  悲观锁: 认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改 乐观锁: 认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据   同步资源表现方式  阻塞锁 非阻塞锁  自旋锁: 指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁 适应性自旋锁：自适应意味着自旋的时间（次数）不再固定，由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定     资源竞争方式  公平锁：排队，多个线程按照申请锁的顺序来获取锁 非公平锁：插队，多个线程获取锁的顺序并不是按照申请锁的顺序   资源竞争结果：  无锁：不锁住资源，多个线程只有一个锁能修改资源，其它线程重试 偏向锁：同一线程执行同步资源时自动获取资源 轻量级锁：多个线程竞争同步资源时，没有获得资源的线程自旋等待释放 重量级锁：多个线程竞争同步资源时，没有获得资源的线程阻塞等待唤醒   锁是否多线程持有  共享锁：锁可被多个线程所持有 独享锁：锁一次只能被一个线程所持有   锁是否可重入  可重入锁：递归锁，锁支持一个线程对资源的重复加锁 不可重入锁：锁不支持一个线程 对资源的重复加锁，同一线程重入会导致死锁      设计模式 设计模式是从许多优秀系统中总结出的成功、可复用的经验，提供一套通用的设计词汇与形式来描述。
设计模式的六大原则：
 开闭原则：对扩展开放，对修改关闭 里氏替换原则：任何基类可以出现的地方，子类一定可以出现 依赖倒置原则：针对接口编程，依赖于抽象而不依赖于具体 接口隔离原则：使用多个隔离的接口，比使用单个接口要好 迪米特法则：一个实体应当尽量少地与其他实体之间发生相互作用 合成复用原则：尽量使用合成/聚合的方式，而不是使用继承  面向对象设计原则:
 对接口编程而不是对实现编程 优先使用对象组合而不是继承  应对变化，正交四原则：
 消除重复：重复意味着耦合，最小化重复 分离变化：识别变化方向，并对变化预留出扩展接口 缩小依赖范围：依赖接口，不要依赖实现 向稳定的方向依赖：定义的API应该关注What，而不是How  经典 23 种设计模式：
 创建型模式：隐藏创建对象的逻辑，包括：工厂模式，抽象工厂模式，单例模式，建造者模式，原型模式 结构型模式：组合接口和定义组合对象获得新功能，包括：适配器模式，桥接模式，过滤器模式，组合模式，装饰器模式，外观模式，享元模式，代理模式 行为型模式：使对象之间的通信方式松耦、可扩展，包括： 责任链模式，命令模式，解释器模式，迭代器模式，迭代器模式，中介者模式，备忘录模式，观察者模式，状态模式，空对象模式，策略模式，模板模式，访问者模式  结语 上面的提纲仅仅是从编程语言层次来发现背后的理论、数学、范式、模型、原则来展开。整个软件开发的技术栈太广太深，这些只是冰山一角，但却是最为基础。掌握基础知识点，或许会让你切换编程语言体系不再是那么困难。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码16：函数式让数据处理更简洁</title>
        <url>http://lanlingzi.cn/post/technical/2020/1108_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 案例一，代码摘抄某外部培训材料，主要代码逻辑是打印每课成绩，并找出学生非F级别课程统计平均分数：
class CourseGrade { public String title; public char grade; } public class ReportCard { public String studentName; public ArrayList&amp;lt;CourseGrade&amp;gt; cliens; public void printReport() { System.out.println(&amp;#34;Report card for &amp;#34; &#43; studentName); System.out.println(&amp;#34;------------------------&amp;#34;); System.out.println(&amp;#34;Course Title Grade&amp;#34;); Iterator&amp;lt;CourseGrade&amp;gt; grades = cliens.iterator(); CourseGrade grade; double avg = 0.0d; while (grades.hasNext()) { grade = grades.next(); System.out.println(grade.title &#43; &amp;#34; &amp;#34; &#43; grade.grade); if (!(grade.grade == &amp;#39;F&amp;#39;)) { avg = avg &#43; grade.grade - 64; } } avg = avg / cliens.size(); System.out.println(&amp;#34;------------------------&amp;#34;); System.out.println(&amp;#34;Grade Point Average = &amp;#34; &#43; avg); } } 上面的代码有哪些问题呢:
 成员变量采用public，缺少数据封装性 没有判断cliens是否为空，可能除以0值。注：假定它不会为空，另外逻辑可能有问题，为什么统计总分是非F课程，除数却是所有课程Size，先忽略这个问题 avg这个变量多个用途，即是总分，又是平均分 cliens变量名难以理解 !(grade.grade == &#39;F&#39;) 有点反直觉 while循环干了两件事，打印每课的成绩，也统计了分数  培训材料并未给标准解题。我来尝试优化一下代码，采用Java8的Stream来简化计算过程，并对代码进行了分段：
public void printReport2() { System.out.println(&amp;#34;Report card for &amp;#34; &#43; studentName); System.out.println(&amp;#34;------------------------&amp;#34;); System.out.println(&amp;#34;Course Title Grade&amp;#34;); cliens.forEach(it -&amp;gt; System.out.println(it.title &#43; &amp;#34; &amp;#34; &#43; it.grade)); double total = cliens.stream().filter(it -&amp;gt; it.grade != &amp;#39;F&amp;#39;) .mapToDouble(it -&amp;gt; it.grade - 64).sum(); System.out.println(&amp;#34;------------------------&amp;#34;); System.out.println(&amp;#34;Grade Point Average = &amp;#34; &#43; total / cliens.size()); } 进一步优化，把各类打印抽取各自函数：
private void printHeader() { System.out.println(&amp;#34;Report card for &amp;#34; &#43; studentName); System.out.println(&amp;#34;------------------------&amp;#34;); } private void printGrade() { System.out.println(&amp;#34;Course Title Grade&amp;#34;); cliens.forEach(it -&amp;gt; System.out.println(it.title &#43; &amp;#34; &amp;#34; &#43; it.grade)); } private void printAverage() { double total = cliens.stream().filter(it -&amp;gt; it.grade != &amp;#39;F&amp;#39;) .mapToDouble(it -&amp;gt; it.grade - 64).sum(); System.out.println(&amp;#34;------------------------&amp;#34;); System.out.println(&amp;#34;Grade Point Average = &amp;#34; &#43; total / cliens.size()); } public void printReport3() { printHeader(); printGrade(); printAverage(); } 注：如果只算非F的平均分，而可以一行搞定：
double avg = cliens.stream() .filter(it -&amp;gt; it.grade != &amp;#39;F&amp;#39;) .mapToDouble(it -&amp;gt; it.grade - 64) .average() .orElse(0.0d); 案例二，再看一段代码：
List&amp;lt;Integer&amp;gt; tanscationsIds = transcations.parallelStream() .filter(it -&amp;gt; it.getType() == Transcation.GROCERY) .sorted(comparing(Transcation::getValue).resersed()) .map(Transcation::getId) .collect(Collectors::toList()); 代码非常清晰：
 过滤出类型为GROCERY的交易记录 按其value值进行倒排序 各自取其Id字段 输出Id列表  这看起来是不是像这样一条SQL语句：select t.id from tanscations t where t.type == &#39;GROCERY&#39; order by t.value desc
背后的知识 目前Java8应该在公司已广泛使用，对于Stream与Lambda应习以为常了，而不再是一种炫技。我在 跟我一起复习Java-2：集合与Stream 一文稍总结一下Stream的知识点，网上也有非常多的教程。若有同学还不熟悉他们的用法，可以多找找材料熟悉一下。
Stream正如其名，像一条数据生产流水线，逐步叠加中间操作（算法和计算），把数据源转换为另一个数据集。
笔者很早以前学过C#，接触过LINQ(Language Integrated Query)，它比Java的Stream和Lambda用法更为清晰简洁，先给个简单示例：
var result = db.ProScheme.OrderByDescending(p =&amp;gt; p.rpId).Where(p =&amp;gt; p.rpId &amp;gt; 10).ToList(); LINQ为数据查询而生，可以算是DSL(Domain Specific Language)了，背后也是函数式编程(FP)一套理念，先记住其中两点：
 Monad 是一种设计模式，表示将一个运算过程，通过函数拆解成互相连接的多个步骤 Lambda表达式 是一个匿名函数，Lambda表达式基于数学中的λ演算得名  FP还有其它的特性：模式匹配，柯里化，偏函数，闭包，尾递归等。对FP感觉兴趣的同学不妨找找材料学习一下。
现在的主流语言，都引入一些FP特性来提升语言在数据上的表达能力。
C&#43;&#43;11引入Lambda表达式，并提供&amp;lt;algorithm&amp;gt;，&amp;lt;functional&amp;gt;两个基础库，一个简单示例：
int foo[] = { 10, 20, 5, 15, 25 }; std::sort(foo, foo&#43;5, [](int a,int b){return a &amp;gt; b;}); Python提供functools库来简化一些函数式编程（还是相当的弱），一个简单示例：
foo = [&amp;#34;A&amp;#34;, &amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;, &amp;#34;B&amp;#34;] sorted(iterable, key=functools.cmp_to_key(locale.strcoll)) 函数式编程 当然，面向对象语言中增加lambda这类特征不能就称为函数式编程了，大部分只不过是语法糖。是采用什么编程范式不在于语言的语法，而是在于思维方式。
在上一篇 飞哥讲代码15：写代码从事物认识开始 要使用面向对象的思维对现实世界来建模。面向对象编程(OOP)在过去20多年非常成功，而函数式编程(FP)也不断地发展，他们相生相息，各自解决不同的场景问题：
 面向对象可以理解为是对数据的抽象，比如把一个事物抽象成一个对象，关注的是数据。 函数式编程是一种过程抽象的思维，就是对当前的动作去进行抽象，关注的是动作。  上一篇博文也提到现实业务需求往往体现为业务活动，它是面向过程的，即先输入数据源，在一定条件下，进行一系列的交互，再输出结果。那面向过程与函数式的的区别是什么：
 面向过程可以理解是把做事情的动作进行分解多个步骤，所以有if/while这类语法支撑，走不同的分支步骤。 函数式相比面向过程式，它更加地强调执行结果而非执行过程，利用若干个简单的执行单元让计算结果不断渐近，逐层推导复杂的运算，而不是像面向过程设计出复杂的执行过程，所以纯函数式编程语言中不需要if/while这类语法，而是模式匹配，递归调用等。  在 不可变减少副作用 一文中提到：
 面向对象的编程通过封装可变的部分来构造能够让人读懂的代码，函数式编程则是通过最大程度地减少可变的部分来构造出可让人读懂的代码。
 我们从Java的Stream实现也看到函数式的另一个特点：
 函数不维护任何状态，上下文的数据是不变的，传入的参数据处理完成之后再扔出来。  结合上面的理解，我们可以先把世界事物通过OOP抽象为对象，再把事物间的联系与交互通过FP抽象为执行单元，这种结合或许是对业务活动的实现一种较好的解决方式。
避免单一范式 一提到编程范式，很容易联想到宗教的虔诚，每种宗教所表达信条都有一定合理性，但如果一直只遵循一种教条，可能也被让自己痛苦不堪。编程范式也是如此，正如Java在1.8之前是纯面向对象式，你就会觉得它非常繁琐。也如Erlang是纯函数式，你就会发现有时简单的逻辑处理会非常复杂。
近些年来，由于数据分析、科学计算和并行计算的兴起，让人认识到函数式编程解决数据领域的魅力，它也越来越受欢迎。在这些领域，程序往往比较容易用数据表达式来表达，采用函数式可以用很少代码来实现。
现实的业务软件，很多的逻辑其实也是对数据的处理，最简单是对数据的CURD，以及数据的组合、过滤与查询。所以函数式编程在许多语言中都得到支持，提升了对数据处理的表达能力。
了解新的编程范式在适当的时候使用它们，这会使你事半功倍。无论什么编程范式，他们都是工具，在你的工具箱中，可能有锤子，螺丝刀&amp;hellip;，这个工具在什么时候使用，取决待解决的问题。
结语 本文的案例只是一个引子，主要是想给你带来函数式编程的一些理念，函数式给我们解决业务问题提供了另一种思维方式：如何高效简洁地对数据查询与变换。许多语言都支持函数式一些能力，需要我们不断地学习，在合理的场景下使用他们。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码15：写代码从事物认识开始</title>
        <url>http://lanlingzi.cn/post/technical/2020/1101_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 上周参加张逸老师解构领域驱动设计培训。课上老师提到传统的设计是贫血模型类&#43;事务脚本（逻辑过程），并给出一个贫血类设计的案例代码。凭记忆记录如下，有三个类：
 Customer: 顾客 Wallet: 顾客的钱包 Paperboy: 收银员  实现的主体逻辑是，收银员向顾客收钱。
代码如下：
public class Wallet { private float value; // 省略构造方法  public float getTotalMoney() { return value; } public void addMoney(float deposit) { value &#43;= deposit; } public void subtractMoney(float debit) { value -= debit; } } public class Customer { private String firstName; private String lastName; private Wallet myWallet; // 省略构造方法，与Getter } public class Paperboy { public void charge(Customer myCustomer, float payment) { Wallet theWallet = myCustomer.getWallet(); if (theWallet.getTotalMoney() &amp;gt; payment) { theWallet.subtractMoney(payment); } else { throw new NotEnoughMoneyException(); } } } 显然，案例中的Wallet与Customer类从直观上在太单薄了，而Paperboy是直接操作了顾客的钱包，把整个支付流程都写到了charge方法中。
试想在现实生活中：
 假如你作为顾客，你是否愿意也把你的钱包直接给收银员，说：&amp;ldquo;这是我的钱包，你直接从钱包中拿钱吧&amp;rdquo;。 假如你作为收银员，你是否愿意直接去数顾客钱包中的钱，还要判断里面的钱是否足够。  背后的知识 我在之前的博文 类的职责单一 一文中提到了类的模型，主要有两种：
 贫血模型：是指对象只有属性（getter/setter），或者包含少量的CRUD方法，而业务逻辑都不包含在其中。 充血模型：是指对象里即有数据和状态，也有行为，行为负责维持本身的数据和状态，具有内聚性，最符合面向对象的设计，满足单一职责原则。  Martin Fowler主张这种模型，他是从领域驱动开发（DDD）中领域模型对象来分析的，领域模型（Domain Model）是一个商业建模范畴。从一个模型的封装性来说，即有状态又有行为是合理的。
注：有些资料进一步细分四种：贫血模型、失血模型、富血模型、胀血模型。
代码重构 重构的方法：采用『移』。
第一步：把Paperboy.change的逻辑移到Customer中，收银员看不到顾客的钱包，以及其中钱的数目。
public class Paperboy { public void charge(Customer myCustomer, float payment) { myCustomer.pay(payment); } } public class Customer { public void pay(float payment) { Wallet theWallet = getWallet(); if (theWallet.getTotalMoney() &amp;gt; payment) { theWallet.subtractMoney(payment); } else { throw new NotEnoughMoneyException(); } } } 第二步：对外屏蔽Wallet，去掉getWallet()，因为使用钱包只是一种支付方式，后续可能扩展为其它支付，如刷信用卡。
public class Customer { public void pay(float payment) { if (myWallet.getTotalMoney() &amp;gt; payment) { myWallet.subtractMoney(payment); } else { throw new NotEnoughMoneyException(); } } } 第三步：假定钱包也是个鲜活个体，也有自己的隐私。去掉getTotalMoney方法，不是暴露钱的数目，而提供判断是否足够的isEnough方法。
public class Customer { public void pay(float payment) { if (myWallet.isEnough(payment)) { myWallet.subtractMoney(payment); } else { throw new NotEnoughMoneyException(); } } } public class Wallet { public boolean isEnough(float payment) { return this.value &amp;gt; payment; } } 再说类模型 在DDD中，一般将领域模型通过如下三种概念表示：
 Entity：用来代表一个事物，有唯一标识，它有着自己的生命周期。 Value Object：用来描述事物的某一方面的特征，所以它是一个无状态的，且是一个没有标识符的对象，这是和Entity的本质区别。 Service：用来组合多个实体(实体间没有聚合关系)和基础设施能力，提供领域内的组合服务能力。  有些材料又把Service分为：
 Domain Service：即上面的领域模型中的Service，如果某种行为无法归类给任何实体/值对象，则就为这些行为建立相应的领域服务。如在账户管理领域中，转账服务（TransferService）需要操作借方/贷方两个账户实体，而借方/贷方又不能聚合到成一个新实体，并提供行为方法，所以转账行为可以由领域层的Service提供。 Application Service：组合领域层的领域对象行为、领域服务和基础设施层能力提供更为场景化的能力。可以根据业务场景需要包装出多变的服务，以适应外部变化并能保持领域层模型稳定。  把上面的三类领域模型都映射为类设计，则需要避免类贫血，应该是充血的，简单说类应该有数据、状态及行为。
贫血模型偏重个性化，面向过程式，逻辑与数据分离了。充血偏共性化，面向对象，类拥有其属性及对应的行为，数据与行为内聚在一个事物内，具有封装性。如果对象的某些行为在任何场景都是通用的，那么就放在领域中去，将其绑定，这是尊重“共性”的约束；如果对象的某些能力依赖于具体的场景，那么则在具体的场景中注入相应的行为，赋予对象相应的角色，这是尊重“个性”的自由。
对象的行为该不该放入“领域模型”，我们要先分析一下这些行为是对象所固有的，还是依赖于场景的。如果是固有的，即是共性的，就放入领域模型（Entity、VO，Domain Service），如果不是则延迟在具体的场景（Appliction Service）中，赋予其角色的个性。
结合DDD的思想，从案例中的代码，我们能体会类设计最好是：
 面向对象设计的本质，一个对象是拥有自己数据、状态和行为，具有完备性。 对象行为方法要内聚到各自的实体或值对象上，减少类之间数据依赖，具有独立演进性。 从面向业务流程（面向过程设计）转变为领域建模设计（面向对象设计）  事物认知 再结合DDD的概念，我们再来谈如何认识事物。
描述事物的基本方法：要素、属性和行为
 要素：就是事物的构成部分，如车由发动机，轮胎等要素组成。可以理解为DDD的Enitty，具体相关的Entity在一起形成聚合（Aggregation），聚合体即事物(车)。 属性：就是描述要素特征的维度，如轮胎的型号，大小等则是描述轮胎的特征。可以理解为DDD的Value Object。 行为：就是基于要素和属性的行为，要素和属性决定了行力能力，发动机提供动力，轮胎基于动力向前滚动。  要素、属性和方法的模型框架是数据化描述事物时使用的一种有效的方法，DDD建模则是对事物数据化的一种描述方法论。当模型概念映射为计算机编程语言时，而采用面向对象设计方式，事物分解成要素、属性即映射为『类』，类构建了计算机世界描述现实世界中事物的基本元素。
结语 由于我们的需求通常是交付某个功能，在需求分析过程中思考的是如何去达成某个条件，需要哪些步骤来实现功能，这是面向过程的解题思维方式。但现实世界又是由一切事物组成，需求可以映射到事物提供的业务能力，则我们需要思考事物是什么，事物能干什么，事物之间的关系是什么。这是面向对象的解题思维方式。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码14：好代码源自相互改进</title>
        <url>http://lanlingzi.cn/post/technical/2020/0920_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码是来自我们新构建的服务，采用Python语言开发。案例故事是这样：
开始： 某同学最先开发某功能，需要读取服务的配置文件，代码如下，是代码直接读取文件取配置项：
HOME_PATH = os.environ[&amp;#39;HOME&amp;#39;] DASK_PROPERTIES_PATH = HOME_PATH &#43; &amp;#39;/training/webapps/lodas/WEB-INF/classes/application-dask.properties&amp;#39; DASK_PROPERTIES_DICT = Properties(DASK_PROPERTIES_PATH).get_properties() CLUSTER_WORKER_THREAD_NUM = DASK_PROPERTIES_DICT[&amp;#39;lodap.dask.cluster.worker.nthreads&amp;#39;] .... # 省略其它配置项的获取代码 后续： 功能不断增加，又分配给 不同的同学来实现 ，也需要读取同目录下其它的配置文件，于是又出现 类似 上面的代码写法，但略有差别，就不再贴代码了。
问题： 经过一段时间，发现类似读取配置项的代码段 散落 到我们源码中多个地方。从功能上讲，代码也没什么问题；但从可维护角度来看，若后面对配置增加约束或者配置文件挪位置，侧需要修改多处。
重构： 对它的改进也很简单，对一个服务的多个配置文件集中管理，提供 封装 对象。改进之后代码如下，并且做了一点小的容错性增强：
 [1] 检查配置文件存在时才加入dict中，解决当文件不存在时，直接调用Properties(file)抛异常问题。 [2] 当配置项不存在时，支持默认值，解决代码中直接对Dict取下标操作时当不存在Key抛异常问题。  class TrainingCfg(object): def __init__(self): self.cfgs = {} self.cls_path = os.path.expandvars(&amp;#39;$HOME/training/webapps/lodaps/WEB-INF/classes&amp;#39;) self.add_cfg(&amp;#39;app&amp;#39;, &amp;#39;application.properties&amp;#39;) self.add_cfg(&amp;#39;extend&amp;#39;, &amp;#39;application-extend.properties&amp;#39;) self.add_cfg(&amp;#39;dask&amp;#39;, &amp;#39;application-dask.properties&amp;#39;) self.add_cfg(&amp;#39;server&amp;#39;, &amp;#39;application-server.properties&amp;#39;) def add_cfg(self, name: str, file: str): cfg_path = f&amp;#39;{self.cls_path}/{file}&amp;#39; if os.path.exists(cfg_path): # 1 self.cfgs[name] = Properties(cfg_path) else: LOG.warning(f&amp;#39;not found configuration file {cfg_path}&amp;#39;) def get(self, name: str, key: str, default_value: str = &amp;#39;&amp;#39;) -&amp;gt; str: if name in self.cfgs: return self.cfgs[name].get(key, default_value) return default_value # 2 这个问题表象，是由于不同的开发人员写了类似重复代码，缺少统一集中的封装。在 飞哥讲代码11：通过封装降低耦合 一文中已讲了封装的重要性，这次我们来换个角度来看看这个问题。
Commit机制 我司在推行Commit的代码审核机制，Committer做为代码的把关者，案例中重复的代码应该不能上库，为什么还会出现，后面又怎么整改了。
Commit机制不是万金油：
 现在强调一次Commit代码不能太多，Committer在Review代码时没有完整上下文，也只见树木，不见森林。 Committer也是普通人，让人肉记忆是否存在相似代码不太现实，不是自己写的代码记忆也不会深刻。需要Committer对代码的全盘掌控。 我们的确做得不到位，每次上库前，重复代码，Findbugs，CodeStyle等可能并没有一一去做本地检查，需要开发者养成良好开发习惯。 即使采用工具检查了，对于相似代码，工具并不能检查出来，还需要开发者不能各自扫门前雪，应该多看看多思考。  事实上案例中的代码是我在重新阅读整个代码才发现可以改进，并 立刻 着手实施的。
还有另一个小故事，由于重构了这段代码，加深了对其的印象。当后面有另一个同学提交代码给我Review时，我就很立刻能指出其类似代码。重用了TrainingCfg的使用，相应代码也从10&#43;行代码下降到3行。
所以代码的看护并非能通过Commit机制一劳永逸，需要开发人员善用工具自已主动发现问题；也需要Committer不定期的代码全局地再次Review。“像老牛吃草一样进行反刍咀嚼”，把之前积累的片断MR（MergeRequest）代码完全地消化掉。
相互改进 代码一旦写出，就已走上腐化的道路上。尤其是在多人团队开发的项目，多人协作性差也很容易加重腐化的速度。像我们家里的环境，即使你没有乱扔东西，一段时间之后也会到处布满灰尘，需要经常打扫保持房屋的干净，但问题是 谁来打扫 ？代码开发也是如此，童子军有一条军规：
 始终保持露营地比你发现它的时间还要干净。
 如果你在地上发现一点脏东西，不管是谁弄的，都清理掉它，要为了下一拨露营的人改善环境。这其实是一个我为人人的精神，代码开发也是应该是如此。事不过三，当你发现相似代码出现三处时，不管是不是你写的，都应该立即去思考重构，提取为公共能力。公共能力即可方便自己，也更能方便他人。所谓&amp;quot;众人拾柴火焰高&amp;rdquo;，只有我为人人了，人人为我才能成为可能，代码的改进才能形成良性的内循环。
我们不应该通过吹捧 重构 对现有代码的问题进行全盘革命，或者热衷于把 重构 弄成一门政治业绩。重构就是在日常开发中持续地改进代码可维护性，可读性&amp;hellip;重构发生在开发新需求时，发生在代码Review时，发生在解决问题时。重构是每个开发人员份内的事，大凡需要大的代码重构（非架构重构）时说明没有把重构融入开发活动。我们不应该经常提及 重构，而是多鼓励小进改。这让我想到公司以前的宣传：&amp;ldquo;小改进，大奖励&amp;rdquo;。
我们在写代码时通常不希望被别人打扰，不是非得要拉个espace电话，发个espace消息就是协作了。Git就是代码开发最好的协作平台。每次从仓库Pull代码时，我们可以花点时间来看看有哪些同学做哪些修改：是否改过自己写的代码，为什么这样修改，对我学习哪些可取之处？有什么新开发公共能力，这次是否我能使用上？只有用心地发现，才会有相互改时的基础。
正如上面的案例，当我们发现相似代码提取封装时，就会涉及到对他人写的代码修改。通常我们去修改他人代码的主观能动性不强，原因可能很多，最重要是怕出问题还被责问：看你把我的代码改出问题来了吧。作为原始作者可以&amp;quot;虚怀若谷，安之若素&amp;rdquo;。若你觉得再有问题，那就把它改得更好，拿代码来交流最有说服力。
结语 每天我们都在输出代码，也可能自己写的代码正被重写。不同的场景下，原先没有问题的代码也可能变成不太合适。优秀的代码绝不是一成不变的代码，源自满足新的诉求而不断地被改进，不同人的改进。目前软件开发早已不是单打独斗，团队协作开发，应该把代码的相互改进融入到个人日常开发中。我为人人，人人为我，形成良性的内循环。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码13：好代码须匠心打磨</title>
        <url>http://lanlingzi.cn/post/technical/2020/0912_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 目前写Python的同学越来越多了，但动态语言无类型约束，导致Commit时难以review。先来看一段我们的代码：
优化前的代码：
def handle(self, data, rules): rule_type = rules[&amp;#39;type&amp;#39;] # 1 rule_list = rules[&amp;#39;rules&amp;#39;] # 2 res = None if str(rule_type).lower() != RULES_MAPPING: raise ValueError(&amp;#34;type of rule should be &amp;#39;rules_mapping&amp;#39;&amp;#34;) for rule in rule_list: col_name = rule[&amp;#39;column&amp;#39;] # 2 if rule[&amp;#39;function&amp;#39;].lower() == &amp;#39;cast&amp;#39;: # 3 mapping_dict, other = self.parse_cast(rule[&amp;#39;mapping&amp;#39;]) res = data[col_name].apply(self.case_func, args=(mapping_dict, other)) elif rule[&amp;#39;function&amp;#39;].lower() == &amp;#39;in&amp;#39;: mapping_dict, other = self.parse_in(rule[&amp;#39;mapping&amp;#39;]) res = data[col_name].apply(self.in_func, args=(mapping_dict, other)) elif rule[&amp;#39;function&amp;#39;].lower() == &amp;#39;binning&amp;#39;: res = data[col_name].apply(self.binning_func, args=(rule[&amp;#39;mapping&amp;#39;])) else: raise ValueError(&amp;#39;not supported function&amp;#39;) # 4  return res 代化之后的代码：
def handle(self, data: DataFrame, rules: Rule) -&amp;gt; Series: # 1 if rules.type != MappingHandler.RULES_TYPE: raise ValueError(f&amp;#34;type of rule should be &amp;#39;{MappingHandler.RULES_TYPE}&amp;#39;&amp;#34;) # 6 rule_list = rules.nested_rules: # 8 res = None for item in rule_list: rule = Rule(item) # 2 col_name = self.get_col_name(rule.column) func_name = rule.function # 4 if func_name == MappingHandler.KEY_CAST: # 3 mapping_dict, other = self.parse_cast(rule.mapping, data[col_name].dtype) # 5 res = data[col_name].apply(self.case_func, args=(mapping_dict, other)) elif func_name == MappingHandler.KEY_IN: mapping_dict, other = self.parse_in(rule.mapping, data[col_name].dtype) res = data[col_name].apply(self.in_func, args=(mapping_dict, other)) elif func_name == MappingHandler.KEY_BINNING: res = data[col_name].apply(self.binning_func, args=(rule.mapping)) else: raise ValueError(f&amp;#39;not supported function {func_name}&amp;#39;) # 7 return res class Rule(object): # 2 KEY_TYPE = &amp;#39;type&amp;#39; # ... 省略其它的常量定义 def __init__(self, rules: Dict[str, Any]): self.rules = rules @property def type(self) -&amp;gt; str: # 2 return str(self.rules[Rule.KEY_TYPE]).lower() if Rule.KEY_TYPE in self.rules else None # ... 省略其它属性 咋一看，似乎没有什么大的变化，代码反而变多了。我来说说做了哪些改进：
优化前的存在潜在问题（数字代表问题出现的地方）：
 [1] rules实际类型为Dict，对dict的取值方式是采用rules[&amp;lsquo;type&amp;rsquo;]这种方法，在Python3之后，若无对应的Key，会抛KeyError异常。 [2] 从dict取出的值无类型推导，IDE无法联想，也无法类型检查纠错。 [3] 多次调用rule[&#39;function&#39;].lower()，最坏场景下需要三次从Dict取值与调用lower()方法。 [4] 最后的抛异常信息不完整&amp;rsquo;not supported function&amp;rsquo;，应该给出具体的function值。  优化后的改进点（数字代表改点的地方）：
 [1] 方法的入参与出参采用python typing新语法，通过对变量的类型标注，让IDE帮助你联想与纠错，增加代码的可读性。 [2] 对Dict对象进行包装为Rule对象，原有直接通过Key下标取值，变成Rule的属性，在属性方法中对是否存在做检查。 [3] 所有的字面字符串都换成了常量大写，更符合编码规范。注：Python语言上并无常量，通过约定俗成的变量名全大写来表示这是一个常量。 [4] 减少rule[&amp;lsquo;function&amp;rsquo;].lower()调用次数，先赋值给一临时变量。 [5] 通过data[col_name].dtype 取出数据实际类型，并在parse_xxx方法对支持类型做检查。 [6] 第一个ValueError的异常信息中rules_mapping采用常量替换，避免修改了常量时而没有修改异常字符串。 [7] 补充第二个ValueError的异常信息，把实际的func_name抛出，方便定位问题。 [8] 变量就近声明，可以减少作用域范围。注：此类优化并不明显，有些代码检查工具规定变量声明离它使用的地方不能超过5行。  说了这么多，有人可能会开始质疑了，优化前的代码也没有什么大问题，可读性也还行，能正常工作。你这样优化是不是有点太过于吹毛求疵了。代码就在这，代码到底要不要这样去打磨，每个人心中都有一杆称，只要哪怕你觉得其中一条优化点对你有所启发，那就采纳吧。
背后的知识 Python是动态脚本语言，不需要显示数据类型声明，缺少静态语言类型检查机制。有人戏称：动态一时爽，重构火葬场。
 优点：动态语言由于类型到运行时才确定，对于输入输出并不要一一对应，满足其调用约束即可。动态性带来了灵活性，有很多高级用法，编写的代码数量更少，看起来更加简洁，提升了开发效率。 缺点：最大问题是代码难以阅读，变量与方法的作用需要查阅大量上下文同时靠人肉去做类型推导，修改重构都很麻烦。  所以现在动态语言的发展趋势是也增加类型机制，如JavaScript之上的TypeScript，Python中的Typing标注。
Python的Typing标注是在3.5版本引入，其语法是可以归纳为两点：
 在声明变量时，变量的后面可以加一个冒号，后面再写上变量的类型，如func(x: int, y: List[str])。 在声明方法返回值的时候，可以在方法的后面加一个箭头，后面加上返回值的类型 如func() -&amp;gt; str。  其作用显然是增强类型检查，减少开发态出错的机率：
 类型检查，防止低级错误，减少运行时出现参数和返回值类型不符合。 使IDE有能力进行更智能的代码提示与检查，提升开发效率。 代码更规范化，明确的类型约束让代码也更容易阅读与理解。  案例中的几项优化点都是让代码增加类型约束，借助于IDE的联想与检查机制，减少低级错误，同时提升代码可读性与可维护性。
可读性 增强代码的可读性可能是一个老生常谈的问题，可读性也是可维护性的前提。但事实上，我们常常受限于时间，好不容易有点时间按自己的思维方式把代码写完，哪再有时间去花得精力把代码优化一点点，让他变得更容易阅读。
在我司也有很典型的错觉，越少的代码越容易让人理解与维护。很多的所谓优秀重构实践都会强调从XXX行代码降到XXX行码，似乎重构代码行数不下降就不好意思说。但是事实上，并不是代码越精简就越容易让人理解与维护。相对于追求最小化代码行数，一个更好的提高可读性方法是最小化人们理解代码所需要的时间。
减少理解代码花费的时间，有两个层次：
 代码直观上很容易理解。 IDE等工具能准确地查找代码间调用关系。  在&amp;laquo;编写可读代码的艺术&amp;raquo;一书中，对于如何提升代码的可读性总结三个层次：
 表层上的改进：在命名方法（变量名，方法名），变量声明，代码格式，注释等方面的改进。 控制流和逻辑的改进：在控制流，逻辑表达式上让代码变得更容易理解。 结构上的改进：善于抽取逻辑，借助自然语言的描述来改善代码。  回到案例本身来看，前面列出8个细小的改进，其实也在遵循着上述所讲的表层上改进原则。光代码的可读性就能写一本了，百度百科上有 编写可读代码的艺术 一书的介绍，如果你没有时间，可以看看它的目录，也可以知晓些有哪些技巧手段。
小重构 最近心声与管理优化报上有一篇谈到：写软件是一门&amp;quot;手艺活&amp;rdquo;，要写好就得熟能生巧。虽文章中论据可能会受到挑战，但我是非常赞成其立意的。写好代码需要有匠心，匠心就需要对其倾注爱心，出于爱心就会不断追求，追求中不避艰苦，是追求中自得其乐。软件的生命周期70%的时间是维护期，代码一旦写完，只是刚刚开始，代码需要匠心持续地打磨优化。
但我们写的代码却是一旦提交上库之后，可能忙于下个迭代的需求开发，再也不会回头来看自己写的代码。我们是做商品的工人，而不是做工艺品的手艺人。绝大部人的不会在写完代码来思考是否可有改进的空间，增加可读性、可维护性。及时对自己代码的小重构就是对代码不断打磨，打磨则需要有一颗匠心。
还有一个原因，我们害怕出错，因为重构可会导致问题。没有被问题折磨的程序员在技术上不会有长进的，错误可以让我们很快接近真理。每个迭代写完代码，我们应该来审视自己的代码，不是组织上行为要求，而是出于自己的追求。及时的小重构效果往往会好于被动地需求驱动重构。
重构的理由不需要什么高大上的理论支持，也不需要响天震地的口号，而是像手艺人一样不为繁华易匠心，把代码当成自己的作品，倾注对其的爱心。
结语 写代码是一个不断打磨的过程，不以善小而不为。当你发现IDE不能类型检查纠错时，那就增加类型约束；当你发现变量命名不易理解时，那就思考改个容易理解的；当你发现定位问题不能快速定位时，那就增加日志内容中的关键信息&amp;hellip;注重细节，从小事做起，慢慢就养成习惯。对自己的代码匠心打磨，倾注爱心，不断的追求，让它变得越来越好。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码12：好代码应表意直白</title>
        <url>http://lanlingzi.cn/post/technical/2020/0815_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面代码都来源于部门某一中间件产品(java)的源码，代码风格（此风格非格式风格而是逻辑思维风格）并且在整个源码中具有普遍性。
代码一：
public void run() { while(!(this.stopped.get())) { try { synchronized (this.lock) { while (this.endTime - System.currentTimeMills() &amp;gt; 0L) { try { if (this.stopped.get()) { return; } this.lock.wait(this.endTime - System.currentTimeMillis()); // 省略主要业务逻辑  } catch (IntrruptedExecption e) { // 省略日志打印  } } // 注意：这个while之后并没有其它的逻辑  } } catch(Throwable e) { // 省略日志打印  } } } 代码意思是可能在等待的最大时间内，中间可以被通知执行主逻辑，然后再进入等待下次通知。在易读性上的问题：
 双重while， 双重try/catch，增加代码嵌套层次，代码有六层，由于跨度较大，掩盖了要表达的业务逻辑，不容易看懂。 第一个while判断是 否定之否定 判断，不够直接，stoppped不需采AtomicBoolean，使用volatile变量即可。 代码有bug(嵌套太深隐藏了bug)，当超过最大时间时，若没有设置stopped标识位，空循环占CPU。  建议优化：
 由于synchronized是对lock的wait方法同步，wait后面的逻辑并不需要再同步保护，不应该锁整个while，减少锁的粒度。可以对wait逻辑单独抽取一个方法，直白表示是要waitNotify。 去掉否定之否定。把AtomicBoolean stopped变成volatile boolean running，判断更直白，running表示还得继续。  public void run () { while(this.running) { try { if ( waitNotify() ) { // 省略主要业务逻辑  } } catch(Throwable e) { // 省略日志打印  } } } // 新增方法，表意是要等通知 private boolean waitNotify() { if (this.endTime - System.currentTimeMills() &amp;lt;= 0L) { this.running = false; // 超时，避免空循环  return false; } if (!this.running) { return false; } try { synchronized (this.lock) { this.lock.wait(this.endTime - System.currentTimeMillis()); } return true; } catch (IntrruptedExecption e) { // 省略日志打印  return false; } } 代码二：
public boolean deleteFile(File file) if (file.isFile() &amp;amp;&amp;amp; file.exists()) { bool flag = file.delete() if (flag) { return true; } else { return false; } } else { return false; } } 上面的代码的问题比较明显：
 存在废话  建议优化：
public boolean deleteFile(File file) if (file.isFile() &amp;amp;&amp;amp; file.exists()) { return file.delete() } return false; // 其实这个false与上面file.delete()返回false含义不一样，本文不深究这个问题 } 代码三：
switch(getMessageResult().getStatus()) { case FOUND: { while (iter.hasNext()) { SelectMapedBufferResult selectMapedBuffer = iter.next(); try { // 省略其它业务逻辑  } finally { selectMapedBuffer.release(); } } messageList.addAll(mqMessageList); break; } case OFFSET_TOO_SMALL: // 省略其它的CASE处理逻辑  } 上面的代码问题主要是：
 switch中嵌套while，若while循环中一个break，它到底是break while还是break switch，不一小心就是产生一个bug。  解决上述问题也比较简单：
 对于switch分支，每个分支的处理逻辑应该提取函数。  建议优化：
switch(getMessageResult().getStatus()) { case FOUND: processFound(...) break; case OFFSET_TOO_SMALL: // 省略其它的CASE处理逻辑  } 背后的知识 上述代码表面上的共性问题：
 代码层次嵌套比较深，容易产生bug；也不容易读懂代码，甚至隐藏问题。 代码表达意图不够简洁，代码一写得比较绕，代码二存在废话，代码三存在break错误风险。  减少嵌套层次，降低代码复杂度是老生常谈的问题，也是大牛们经常提到的问题：
 If you need more than 3 levels of indentation, you’re screwed anyway, and should fix your program.
 Linus曾经说过：如果你的代码里需要有超过三层的缩进，那么你已经搞砸了，应该修改你的代码。
在C语言中，Linus的话应该是没有问题的，对于其它的语言要求过高。在我司的编程规范，也建议嵌套层次不要超过4层。
控制与逻辑分离 嵌套层次过深，表面上可能业务逻辑复杂，表现为控制流程太多过深；深层次可能的原因是我们思维方式引起的，正常的人思维肯定按顺序思考方式：先考虑正常情况，再考虑异常情况，依次递进地再思考。
我把嵌套过深分为四类，从代码现象来看，都是由于控制语句引起的复杂。
 if/else引嵌套。 for/while嵌套。 try/catch嵌套。 上述的组合嵌套。  总结的好处是可以给我带来新的思考，我们写代码的思维逻辑可不可以不是顺序的，而是站在更高一层来看，总体原则是否可能把控制与逻辑分离：
 控制： 即上述说的各个控制语名，它只是控制你的主要逻辑的走向。 逻辑： 才是程度真实要执行的代码，是业务主要完成的功能。  如果我们能把 控制 与 逻辑 部分有效的分开，那么代码将会变得更加容易看懂、维护和改进。
对于 控制 的优化，则方法要根据不同控制语句而论：
if/else 的优化
 使用卫语句，异常条件优先返回  if () { if () { if () { // ...  } } else if() { } } 可优化为：
if (!...) { return ; } if (...) { return ; } if (...) { .... }  把嵌套的 if 换成 if {} else if {} 语句 将 if 换成 case 语句 优先使用&amp;amp;&amp;amp;，在可以使用&amp;amp;&amp;amp;条件判断的地方要避免使用连续嵌套的if 将深层嵌套抽出来放到子函数  for/while优化
 采用使用break，continue改变控制流程  for(int a : list) { if (...) { //  } } 优化为:
for(int a : list) { if (!...) { // 反着写  continue; } } Switch优化
 不要根据类型标签进行分支，而要优先使用多态函数。 采用表驱动查找，每个类型标签分支对应一个。  try/catch优化：
 嵌套的try/catch表明你没有干净地编码，说明他们不在一个层次，肯定要把内部的try/catch的逻辑提取函数了。  对于 逻辑 的分开，最直接办法就是提取函数：
 复杂的if/else内的逻辑提取函数 for/while循环体内的逻辑提取函数 switch的分支处理逻辑提到函数  更复杂的 逻辑 分离，则需要采用一些设计手段，如状态机模式与策略模式的核心思维都是把逻辑分散化，不同的处理逻辑分布到各个子类中。
结语 干净的代码首先肯定是易读的代码，直接白了的对话大家都喜欢，同样代码不应该隐藏其所表达的意图，而是表意直白，不需要让读者太多的思考。代码嵌套非常影响易读性，还会带来退出分支过多，需要人思考的方面也就越多，稍不留神就会搞出大Bug。减少嵌套层次，降低代码复杂度，值得你去追求。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码11：通过封装降低耦合</title>
        <url>http://lanlingzi.cn/post/technical/2020/0808_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 最近在走读某一老产品的代码，发现存在一个普遍不好的实践，代码类似如下：
public class Class1 { private Map&amp;lt;String, String&amp;gt; store = new HashMap&amp;lt;&amp;gt;(); private List&amp;lt;Class2&amp;gt; queue = new ArrayList&amp;lt;&amp;gt;(); //... 省略其它的字段与其Getter/Setter方法 } 此类的特点是：只有一些集合字段与其Getter/Setter，而对字段的使用却是如下：
public void method1() { // ... 省略其它逻辑  // 在其它的类中的方法实现中，却通过Getter方法获取集合对象加锁来处理  synchronized(class1.getStore()) { String value = class1.getStore().get(key); if (value == null) { // ... 省略其它逻辑  value = createValue(); class1.getStore().put(key, value); } } // ... 省略其它逻辑 } 代码的问题是很明显：
 Class1中的成员直接被Get出去，散落在各个类中操作，缺少对其操作的方法封装，破坏了类的封装性，带来了数据的耦合。 同步加锁在Owner对象之外，其出发点是以其它方法逻辑为切入，而不是从Owner对象的数据全生命周期安全来思考，很容易造成加锁不全。  背后的知识 在面向对象设计中，会提到如下特征：
 封装性 抽象性 继承性 多态性  封装性，顾名思义，对用户隐藏其实现细节，使用该类的用户可以通过该类提供的接口来访问该类，使用户不能轻易的操作此数据结构，只能执行类允许公开的数据的一个小系统。
抽象性，就是找出一些事物的相似和共性之处，然后将这些事物归为一个类，这个类只考虑这些事物的相似和共性之处，并且会忽略与当前主题和目标无关的那些方面，将注意力集中在与当前目标有关的方面。
显然，案例中类设计违背了封装性，抽象也不够，只是一堆的数据集合，数据之间并没有共性，要说共性这个类的责职就是用来存储数据的。只不过这它承担的责职也太少太少。
在领域驱动设计中对领域模型提到如下概念：
 失血模型：模型仅仅包含数据的定义和getter/setter方法，业务逻辑和应用逻辑都放到服务层中。 贫血模型：贫血模型中包含了一些业务逻辑，但不包含依赖持久层的业务逻辑。这部分依赖于持久层的业务逻辑将会放到服务层中。 充血模型：充血模型中包含了所有的业务逻辑，包括依赖于持久层的业务逻辑。 胀血模型：胀血模型就是把和业务逻辑不想关的其他应用逻辑（如授权、事务等）都放到领域模型中。  显然，案例中的代码是失血模型的类设计。
上述案例的中代码，可反映出当时写代码的思考方式：以面向过程自顶向下的方式来解决业务流程问题，数据只是流程中的附属品。而不是以面向领域模型的设计方式，系统中存在哪些概念模型，模型以什么方式来提供能力（接口/方法），再把这此能力组织串起来，形成业务流程。
数据类 在现实开发中，的确并不是所有类都要有业务逻辑，有一种类只是数据的容器，用于聚合数据，这种类通常称为数据类（data class）。在JVM体系中，像Scala与Kotlin在语言层面都存在这种显式概念：
 Scala: 叫case class，其特性就是支持类的模式匹配，应用于数据的解构使用场景，定义如下  case class User(name: String, age: Int)  Kotlin：叫data class，与JavaBean相似，提供原生关键字，定义如下：  data class User(val name: String, val age: Int)  Java：在Java14中也坐不住了，引用叫记录类(record)的概念，定义如下：  public record User(String name, int age) {} 各种语言概念略有差别，但都是数据类，他们共同的特点：
 都会自动生成 equals、hashCode 和 toString 方法 都会自动生成 Getter 方法 强调数据的不变性，字段在构建方法中声明，Scala 与 Kotlin 可以通过指定val来标识数据只读，record类的字段隐式都是final的 Kotlin与Java的数据类不可继承  从Java的命名Record(也是抄C#的概念)，更能看见对数据类的使用场景：
 是数据记录的承载，可用数据库表结构字段的映射，如JPA/MyBatis中Entity类定义。 是数据格式的描述，可用于网络消息包的定义，如Rest接口请求/响应消息的结构体定义。  这种类对数据的使用，一个重要的特点是：
 数据一旦生成，它们是不可变的，只能只读。 类对数据透明持有，不理解数据，不需要有对数据的行为。  看完上面说明，相信大家也清楚了上述案例中的Class1并不满足数据类的要求，因为外部对数据进行了修改。
再说封装 封装是面向对象设计中的重要特征，其目标就是要实现软件部件的“高内聚、低耦合”，防止相互依赖性而带来的变动影响。封装具有黑盒性质，使得用户不用关注其内部细节，从而保证软件具有优良模块性基础。
像Java是完全面向对象的编程语言，面向对象的封装比传统语言（如C的struct）的封装更为清晰、更为有力。封装就是把描述一个对象的属性和行为的代码封装在一个“模块”中，也就是一个类中，属性用变量定义，行为用方法进行定义，方法可以直接访问同一个对象中的属性。通常情况下，让变量和访问这个变量的方法放在一起，将一个类中的成员变量全部定义成私有的，只有这个类自己的方法才可以访问到这些成员变量，这就基本上实现对象的封装。
封装设计原则：把对同一事物进行操作的方法和相关的方法放在同一个类中，把方法和它操作的数据放在同一个类中。对象封装成一个高度自治和相对封闭的个体，对象状态（属性）由这个对象自己的行为（方法）来读取和改变。
封装带来好处也是显而易见的：
 代码复用：提供对行为方法的打包，调用者在使用的时候，只需调用方法即可，提升代码的易用性。 信息隐蔽：将其成员通过Private隐蔽起来，对成员访问权限的合理控制，提高了数据的安全性。 封装变化：将对其状态的改变控制在封闭的范围，后续修改调整在可见范围内，提升了代码的可维护性。  我们再回到案例中的代码，所有散落在外部对Class1的数据操作，应该提供相应的行为方法，把对其的改变控制在自己相对封闭的范围内部。
当一个类即有行为方法，又提供某一些字段的Getter方法时，一定要考虑Getter是其数据的Copy以及必要性，把改变控制在自己手上。
结语 在面向对象编程语言中，类是最为基础的单元，设计一个类，最先要考虑是它的封装性。把对一事物操作的方法和它操作的数据放在同一个类中，将其成员通过Private隐蔽起来，对外提供相应的方法，对其成员访问权限的合理控制，并把外部引起的变化都能控制在本类的方法中。以面向对象的思维来设计模块，通过类的行为方法来组织实现业务流程，避免直接对数据的耦合，这样我们不仅可以提升代码易用性，安全性与可维护性。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码10：提升性能，表设计很重要</title>
        <url>http://lanlingzi.cn/post/technical/2020/0726_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 在这个月，我曾经分析处理两个与数据操作相关的性能问题。根因是缺少对表的严谨设计。通过搜索些资料，便有此博文分享给大家。
案例一：某服务对接Oracle，在某些场景下出现读取表数据失败。现象是日志会报如下堆栈信息：
Caused by java.sql.SQLException: Stream has already bean closed at oracle.jdbc.driver.LongAccessor.getBytesInternel(LongAccessor.java:127) at oracle.jdbc.driver.Accessor.getBytes(Accessor.java:897) at oracle.jdbc.driver.LongAccessor.getString(LongAccessor.java:154) ... 从堆栈来看，是访问Long类型的字段值(通过LongAccessor字面猜出)，获取Bytes的流强制关闭了，为什么有时会关闭，过长过大？通过Google搜索才发现，我们跳入使用Long类型坑中。
案例二：对接GaussDB，几十并发执行作业，日志报无法获取可用的数据库连接，导致后面的作业状态入库失败。
通过时间打点日志发现写某一张表很慢，导致长时间占用连接，连接池很快耗尽。这一张表有个Blob字段，把这修改Varchar2之后，问题得已解决。
背后的知识 案例一，先看一段Oracle官方对Long的描述(摘抄部分):
 Do not create tables with LONG columns. Use LOB columns (CLOB, NCLOB, BLOB) instead. LONG columns are supported only for backward compatibility.
LONG columns store variable-length character strings containing up to 2 gigabytes -1, or 231-1 bytes. LONG columns have many of the characteristics of VARCHAR2 columns. You can use LONG columns to store long text strings. The length of LONG values may be limited by the memory available on your computer. LONG literals are formed as described for &amp;ldquo;Text Literals&amp;rdquo;.
 更多Long的问题与约束参见LONG Datatype 。
Oracle不建议使用Long类型，存在也是为了向后兼容。Long并不存储整数型，而是存储字符串型数据，最大长度限制是2GB。在案例一中，即使只存储一个很短的字符串给Long字段，当查询时Oracle也可能会分配一个较大的空间，所以问题只有在一定场景下出现。
为什么会采用Long类型，这是不恰当使用hibernate造成的，我们来还原一下出现这个问题的使用过程：
 系统采用了JPA做数据访问层，JPA底层是hibernate。 某个表映射Java类型为String，指定长度4096。 开启JPA的ddl_auto，自动刷表，创建对应表结构，此字段自动声明为Long类型。 为了省事，直接把生成的表DDL拷贝出来，放在flyway的安装SQL脚本中。  hibernate为什么会对String声明为Long类型，因为在 Oracle9iDialect 中会有如下代码：
registerColumnType( Types.VARCHAR, 4000, &amp;#34;varchar2($l char)&amp;#34; ); registerColumnType( Types.VARCHAR, &amp;#34;long&amp;#34; ); 虽然我们是配置Oracle12cDialect，但他们继承关系，Oracle12cDialect-&amp;gt;Oracle10gDialect-&amp;gt;Oracle9iDialect。当String长度超过4000，则使用long类型。这就掉入坑中的根因，其实从业务场景来看，根本不需要那么长的存储要求。
案例二，是由Blob字段的性能问题引起的。无论是哪种数据库，Clob/Blob的写入性能并不高。我们也来还原一下出现这个问题的使用过程：
 使用一张表用于记录作业执行过程日志，担心日志可能过长，最开始采用Blob（文本存储为什么不采用Clob，还是JPA自动刷表映射的问题）。 后面也做了优化，日志拆成多行记录写，每一行限制长度，但表字段类型并未修改。  由于GaussDB的材料比较少，还是以Oracle为例说明一下问题。
Oracle数据库的LOB字段用于存储大数据对象的字段类型，包括BLOB、CLOB、NLOB、BFILE：
 当LOB字段大小超过4k时，数据库会单独为该LOB字段分配额外的BLOB Segments存储BLOB对象，存储在lobsegment中的lob缺省不在缓冲区缓存，对于lob的读写都是物理IO，代价非常高。 被删除或更新的BLOB字段所占用空间不会自动批量回收，当所在表有大量的删除、更新操作时，BLOB所在Segments会迅速耗尽空间，新的INSERT需要空间时，会在高水位线上加锁后，回收曾使用但已经过期的BLOB空间，由于该操作效率很低，此时数据库就会有大量的enq:HW – contention等待，相关SQL会由于该等待而串行执行。因此LOB字段不适合在有大批量删除、更新操作的并发场合使用。  对两个案例的反思：
 不要采用JPA/hibernate自动DDL创建表，自动能省事即不是最优的。 每个表结构的采用什么类型，长度是多少，应该严格设计。  数据库设计 数据库有很强的领域知识，但现实项目中几乎由开发者直接进行数据库设计。但开发者通常对数据表知识知之甚少，就会导致各种问题的发生。比较大的团队可能会有DBA专门负责表设计，评审与优化，为项目保驾护航。今年的任职也把数据库这一专项也取消掉了，可能会导致后面更为严重的问题，无任职的牵引，无人懂数据库，完全需要依赖外部专家。
从提升性能的角度来看，关系型数据库设计通常要从下面两点考虑：
 节省空间：选择合适的类型与和长度，不要浪费存储空间。 提高效率：采用合适的主键，建立合适的索引，去掉不必的依赖，切分表读写分离，存储分离。  范式 团队开发者甚少需要了解有哪些范式，才能设计出合理的表结构。下面只是简单记录一下，更详细的说明请自行搜索相关材料。
 第一范式(1NF)：无重复的列，每一列都是不可分割的基本数据项。 第二范式(2NF)：1NF基础上，每列都和主键相关，每张表一定要有个主键例。 第三范式(3NF)：每列都和主键列直接相关,而不是间接相关，非主键列变更不应引起其它列变更，应该消除传递依赖。 鲍依斯-科得范式(BCNF)：3NF基础上，某一列与复合主键中的某一列有关，而与其他主键无关，即每个表中只有一个候选键。 第四范式(4NF)：非主键列不应该有多值，没有多值依赖。 第五范式(5NF)：最终范式，满足4NF基础上，表必须可以分解为较小的表，除非那些表在逻辑上拥有与原始表相同的主键。  从实际项目中的来看，对于数据模型存在层次结构，我们不少情况没有拆分为小表，通常一张表中存在多个大字段，存储Json字符串。这样看似存储扩展性好，但它违背了第四范式或第五范式，解决方案是增加关联表。虽然增加关联表会导致一些冗余，也会导致联合查询的效率问题，但结构依赖是清晰，便于数据库维护，也可能针对性查询优化（如只查询下层结构的数据）。
一些经验 下面是个人一些经验积累，由于本人非数据库领域专家，供参考，欢迎大家补充：
节省空间：
 选择小的数据类型，如枚举类型，可以采用tinyint/bit，以便节省空间。 使用varchar而不要使用char字段，varchar使用可以减少空间占用。 不要使用BLOB/CLOB字段存放大数据，除非无性能要求。 不要使用设计器/框架缺省的字段长度，给每个字段指定最合理的长度。 不要过早考虑字段的扩展，审视空值字段存在是否有业务必要性。  提升效率：
 主键类型，建议采用bigint，因为CPU是64位，查询效率更高。 慎重使用联合主键。 不建议使用外键约束，一是影响效率，二是增加维护成本。 用关联表建立表和表之间的多对多关系，而不用一个字段解析的方式。 列无重复值，可以建索引，唯一索引和普通索引。 审视非主键唯一索引的必要性。唯一索引一定要小心，它带有唯一约束。 唯一性太差的字段不适合建立索引，比如性别，真假值。 频繁更新的字段不适合建立索引。 where条件中用不到的字段不适合建立索引。  当然上述肯定只是最为基础的优化点，对于大规模系统中的表还得考虑读写分离，分库分表，表空间分离，采用不同的存储引擎等等。我由于却少实战经验，就不敢造次了。
结语 数据库设计是一门非常高深的学问，DBA这个岗位的价值非常的大。不合理的表结构设计，极可能会导致业务性能问题。对于我们普通开发人员来说，非常有必要掌握一些数据库表设计的原则、技巧。范式为我们提供了基本的原则与规范要求。一个开发团队内，表结构设计应该拿出来内部评审，参考公司内部相关设计规范。三个臭皮匠顶个诸葛亮，充分发挥集体的经验，减少不必要的设计问题。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码9：提升性能，线程数合适就行</title>
        <url>http://lanlingzi.cn/post/technical/2020/0718_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 两周前，参与某一老产品的性能优化有如下收获：
 同事说，我配置了 1000个线程 ，但是总消耗时间还是需要 10分钟 左右，似乎没有真正的并发。 经过分析代码，狂改一通代码，结果是：只配置了 32个线程 ，总消耗时间下降至 44秒 。  这个产品已有一定的年头，采用Java开发，但Maven配置的编译source/target还是 1.6（直接把配置修改为1.8整个产品编译会有问题。对于老产品，稳定优先，维护者并没有太多的动力升级到1.8，因为一升级需要对所有历史分支都升级并验证）。 为了线程安全，代码中大量地存在如下Double-Check写法(伪代码)，无法享受Java高版本带来的红利，并不高效：
Description desc = cache.get(key); if (desc == null) { synchronized(cache) { // 这个是全局锁，极大影响并发  if (desc == null) { desc = getDescription(....); // 此方法还会调用其它类似写法的Cache，主要逻辑是查询以及反射类，以及嵌套类，效率并不高  cache = new CopyOnWriteMap(cache) // 对象Copy  cache.add(key, desc); } } } return desc; cache是自己实现的CopyOnWrite的Map，并没有使用ConcurrentHashMap，目的是提升读远远多于写的场景的性能。但这个性能问题就是写的时候。写的业务场景：
 业务中有76个Jar包，需要读取这个76个jar包中所有Class对象，每个Jar中平均约100个Class。 采用懒加载方式，通过反射获取这些Class的方法与属性等描述信息，描述信息生成之后则放入Cache中。 虽然采用多线程并发加载（每个Jar在一个线程中处理），配置1000个线程也是多余的。 多个线程并没有完全并发处理，因为都是首次加载，线程阻塞在获取cache全局锁上。 在整个流程中，上述采用Double-Check对Map操作的synchronized块有5~6个，即有5~6全局锁。  所做优化：
 把CopyOnWriteMap换成JDK自带的ConcurrentHashMap。 去掉Double-Check &#43; synchronized块，采用putIfAbsent来加入新值。  这次不再讲锁的优化（请参考飞哥讲代码3：简洁高效的线程安全 ），而是来谈谈线程模型，并不是线程配置得越多，就能提升性能。
背后的知识 笔者在我司最早曾写过C/C&#43;&#43;代码，接触的早期智能网平台产品是单线程多进程模式，即一个进程中只有一个线程在处理业务逻辑。所有的事件采用Select函数监视所有文件描述符的变化情况来处理各种请求。虽然只有一个线程在处理，性能并不差，因为线程并没有阻塞，它是满血在永不停息的干活。并发是采用多进程的方式，单个进程并绑定CPU，也避免了CPU在多进程之间的切换，效率更好。
开源项目大名鼎鼎Redis也是采用单线程模式，也类似于我们的智能网平台的机制，基于Reactor模式实现了多路 I/O 复用，由于Redis主要是对内存读写操作，单线程避免了上下文频繁切换问题，效率是出奇的高。
Java天生支持多线程，JDK也提供了多种机制来保证线程安全。JVM线程在Java 1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，而在Java 1.2中，线程模型替换为基于操作系统原生线程模型来实现。也就是说，现在的JVM中线程的本质，其实就是操作系统中的线程，Linux下是基于pthread库实现的多线程。
为了弄清楚Java的线程模型，先说几个概念：
 内核线程(Kernel-Level Thread, KLT)：由操作系统内核创建和撤销。一个内核线程由于I/O操作而阻塞，不会影响其它线程的运行。内核线程使用的资源就是内核栈和上下文切换时保存寄存器的空间。 用户线程(User Thread,UT)：指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。 轻量级进程(Light Weight Process, LWP)：是一种由内核支持的用户线程。它是基于内核线程的高级抽象，每一个进程有一个或多个LWPs，每个LWP由一个内核线程支持。在内核线程的支持下，LWP是独立的调度单元，就像普通的进程一样。  JVM中的线程在Linux下是基于pthread库实现，而pthread也存在演进：
 LWP：内核2.6以前，pthread线程库基于LWP模拟线程，并采用的“一对一”的线程模型，即一个LWP对应一个线程。这个模型最大的好处是线程调度由内核完成了，而其他线程操作（同步、取消）等都是核外的线程库函数完成的，核外不需要额外的调度管理。 NPTL：内核2.6以后，POSIX标准对线程提出很多的改进，于是glibc中有了一种新的pthread线程库(NPTL:Native POSIX Threading Library)，本质上来说，NPTL还是一个LWP的实现机制。  总结起来如下：
 JVM一个线程对应一个用户线程，此用户线程由NPTL实现。 由于NPTL是“一对一”的线程模型，则JVM一个线程对应内核中一个线程。 一个CPU通过内核调度，分配给一个内核线程。 映射关系：JVM线程(N) &amp;lt;&amp;ndash;&amp;gt; 用户线程（N） &amp;lt;&amp;ndash;&amp;gt; 内核线程(N) &amp;lt;&amp;ndash;&amp;gt; CPU(1) 。  对于线程调度，通常有两种：
 协同式调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。线程执行时间系统不可控。 抢占式调度：每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定，线程的执行时间是系统可控。  Java采用的是抢占式调度的多线程系统，理解这个，就会明白为什么 Thread.yield() 可以让出执行时间，但是要获取执行时间的话，线程本身是没有什么办法。
回到案例本身，为什么配置32个线程就可能解决问题，根据上面的线程模型，如果线程处理无阻塞，满血干活：
 初步可以得出的结论是：有多个CPU，就配置多少个线程。 但实际并不那么简单，为什么Tomcat默认要500个处理线程？我们后面再讲。  M:N模型 Go语言天生为高并发而生，可以轻松构造上万的协程(goroutine)。它的并发模型采用MPG模型：
 M(Mechine)：代表着一个内核线程，也可以称为一个工作线程。 P(Processor)：代表着处理器，它的主要用途就是用来执行goroutine的，一个P代表执行一个Go代码片段的基础（可以理解为上下文环境）,它也维护了一个可运行的goroutine队列，和自由的goroutine队列，里面存储了所有需要它来执行的goroutine。 G(Goroutine)：代表着goroutine实际的数据结构，即用户封装的要执行的方法。G维护goroutine需要的栈、程序计数器以及它所在的M等信息。 Seched：代表着一个调度器，它维护有存储空闲的M队列和空闲的P队列，可运行的G队列，自由的G队列以及调度器的一些状态信息等。  NPTL每个线程都对应内核中的一个调度实体，这种模型称为1:1模型(1个线程对应1个内核级线程)。而NGPL(Next Generation POSIX Threads)则打算实现M:N模型(M个线程对应N个内核级线程)，也就是说若干个线程可能是在同一个执行实体上实现的。但在Linux上实现这个，要处理的细节问题非常之多，目前没有任何一个Linux实现了M:N模型。Solaris系统貌似实现M:N模型（待求证）。
Go语言而不依赖于Linux系统，而是在它的Runtime上实现MPG模型，本质即在用户态实现了NGPL。Goroutine只是一个内核线程执行的一个Task，只不过Go的Runtine能帮助你恢复上下文环境，维护了栈、程序计数器等信息，在Goroute中感觉就是像一个线程调用。轻松构造上万的Goroute，因为这不是真实的内核线程，而是线程执行的一个任务(Task)。
异步 如果线程不阻塞，则1:1的模型没有任何的问题，但实际上线程会阻塞在各种I/O操作中。如访问数据库，需要等待响应回来。为了增加并发，如果增加线程，每个线程对应一个内核线程，而内核线程是重资源型，过多的线程会导致内核调度上效率低下。
所以为了高效，采用线程复用。复用则需要当线程由于I/O阻塞时，可以释放出来，让它去干其它的活，当请求响应真正回来时，则通过回调通知。在1:1的模型的多线程多任务框架，通常异步采用回调方式。
函数回调有其缺陷，当遇到多重函数回调的嵌套，代码难以维护。对于多个回调组成的嵌套耦合，业界通常叫回调地狱（Callback Hell）。解决回调地狱的方案有不少，现在常见是链式调用，Java中实现链式调用有RxJava。RxJava中通过“流”来构建链式调用结构，“流”的创建、转化与消费都需要使用到它提供的各种类和丰富的操作符，也让使用成本大大增加。
在JVM之上的Kotlin语言，也实现了协程(Coroutine)框架，通过语法糖如async/await解决了普通多任务框架的回调地狱问题。async本质返回一个Deferred对象，在异步执行结束之后，调用await()方法通知等待者。等待者调用await()则先释放线程，再得到异步回调。
而Tomcat主要是Servlet容器，Servlet在3.0之前，API并不支持异步。同步导致的问题当有阻塞时，则线程是空闲的，为了并发，则需要更多的线程来处理，配置更多的线程也带了更多的成本，比如内存的增加，CPU对多线程上下问切换的性能损耗。
合理的线程线 线程个数设置多少合适？不是越多越好，多了竞争资源反而效率低。建议配置的线程数=可用的CPU核数/(1-阻塞系数)。阻塞系统在0到1之间，所谓阻塞系数就是发生的IO操作，如读文件，读socket流，读写数据库等占程序时间的比率。这个数值每个系统肯定不一样，可以先做个估计，然后测试逐步往最佳值靠拢。如果线程不是瓶颈所在，那么大概估一个值就好了。
再回到案例本身，通过优化锁的使用，减少了阻塞系数，当阻塞系数接近为0时，则配置的线程数=可用的CPU核数，而案例中的测试机器正好是32个CPU核。而案例中的IO操作主要是加载Class文件，Class文件是存在Jar文件中，所以以Jar为粒度并发读取是合适的，再多的并发也会由于文件锁导致更多的阻塞。
结语 提升性能，我们先有必要深入了解所使用语言的线程模型及其调度方式。提高并发，并不是一味的提高线程数，而是减少阻塞时间。为了提升线程的调度效率，通常是配置与CPU对等合理的线程线，通过异步框架合理地复用线程，让线程尽可能多的干活，而不是空闲在哪。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码8：提升性能，线程级缓存复用</title>
        <url>http://lanlingzi.cn/post/technical/2020/0705_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 去年在做BCM切换进行如火如荼时，一位兄弟找到我，有如下对话：
 ■■(工号) 2019-08-27 14:50
飞哥，下午有时间吗？▲▲的性能瓶颈的问题想跟你讨论一下
◆◆◆(工号) 2019-08-27 14:51
好
■■(工号) 2019-08-28 10:39
飞哥，性能有提升， 8W8 压到了 9W7
提升了1W
 一个下午的时间，到底发生了什么，对代码做了什么优化，性能提升将近1W TPS？
出现性能瓶颈的组件是平台一个很成熟的中间件，从x86切换到arm下性能基准测试情况如下：
 组网：3 client &#43; 1 server 环境：4VM(arm 8C64G) VS 4VM(x86 8C64G） 基准测试：TPS x86 VS arm = 1 VS 0.6  首次在arm下测试，情况不容乐观。此中间件采用Java开发，底层的JVM我们无法直接优化，但应用层还是存在优化的空间，测试主要场景如下：
 业务流程关键逻辑是对消息进行序列化与反序列化，编解码采用protostuff。 网络层连接采用Netty，粘包/拆包采用不定的自定义格式LengthFieldBasedFrame。 基准测试传递的消息长度固定为1K。  接到兄弟的救助之后，我们一起通过JProfile分析了主要流程的调用栈耗时情况，再结合代码快速发现一处可优化点：
 消息的编解码内存是可以线程级复用，完全可以分配一段大于1K的内存绑定每个线程，只给此线程反复使用。  背后的知识 Java NIO框架提供了ByteBuffer机制，通常用于对数据流byte的操作，也常用于网络编程，它有两种分配方式：
 allocate(int capacity) ：从JVM的堆内存上分配。 allocateDirect(int capacity) ：从堆外内存上分配。  他们的使用场景不同，并不是一定哪个快哪个慢。
 allocate分配受垃圾回收器影响，并不太适合内存长驻使用的场景。 allocateDirect不受垃圾回收器影响，适合于不需要从OS内存到JVM内存拷贝的场景，也适合于大块内存长驻使用的场景，并不适合于频繁申请小块内存的场景。做过C/C&#43;&#43;开发的同学，可能听说过内存空洞的问题。  而Netty又在参考JDK的ByteBuffer基础之上，提供ByteBufAllocator：
public interface ByteBufAllocator { // 直接分配一块内存，是使用direct还是heap取决于子类实现  ByteBuf buffer(int initialCapacity, int maxCapacity); // 更倾向于direct方式分配  ByteBuf ioBuffer(int initialCapacity, int maxCapacity); // heap内存分配  ByteBuf heapBuffer(int initialCapacity, int maxCapacity); // direct内存分配  ByteBuf directBuffer(int initialCapacity, int maxCapacity); ... } 它有两个主要的子类：
 UnpooledByteBufAllocator： 非池化分配器。 PooledByteBufAllocator：池化分配器，并且考虑了多线程并发访问的效率问题。在多线程情况下，每个线程有一份独立的缓存管理。  PooledByteBufAllocator的实现很复杂，它涉及到多个数据结构Arena、Chunk、ChunkList、Page、SubPage。我就不敢班门弄斧了，请感兴趣的同学自行搜索Netty相应的资料。可参考：看完这篇还不清楚Netty的内存管理，那我就哭了
线程级缓存复用 任何计算机中的资源是有限的，为了效率，我们通常会采用池化复用各种资源，常见有：
 线程池 连接池 内存池  内存池化指：应用程序可以通过系统的内存分配调用预先一次性申请适当大小的内存作为一个内存池，之后应用程序自己对内存的分配和释放则可以通过这个内存池来完成。但内存池的实现相比于线程池，连接池更为复杂，因为内存池还需要对内存进一步分块分片，以满足不同的大小对象的高效使用。
从线程安全的角度来分，内存池可以分为单线程内存池和多线程内存池。单线程内存池整个生命周期只被一个线程使用，因而不需要考虑互斥访问的问题；多线程内存池有可能被多个线程共享，因此则需要在每次分配和释放内存时加锁。相对而言，单线程内存池性能更高，而多线程内存池适用范围更广。
JVM的堆内存管理，也是一种更为广义支持多线程带有内存标记整理能自动回收的内存池管理。由于越是最为复杂的东西，考虑的场景越多，效率也就不是最好的。
对于网络编程，我们对于连接，线程都是可能固定池化管理，固定的连接数，固定的处理线程数。那内存则可以直接如下：
 分配足够的内存绑定连接，只给此连接复用。 分配足够的内存绑定线程，只给此线程复用。  这样一下来，内存的管理也就简单得多，也变得效率更高，不需要池化管理的加锁保证多线程安全问题。
回到案例中的问题，虽然我们可以使用PooledByteBufAllocator来达到ByteBuff复用的效果，同样它也支持为每一个线程通过PoolThreadLocalCache来管理内存，从来避免多线程争夺的问题。它的实现还是非常高效的，只不要过要注意第一次分配的时间。来自网上的测试：
public class PooledByteBufTest { public static void main(String[] args) throws InterruptedException { for(int i=0; i&amp;lt;5; i&#43;&#43;){ long start = System.currentTimeMillis(); ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.buffer(1024*1024); long end = System.currentTimeMillis(); System.out.println(&amp;#34;初始化pooled的ByteBuf第&amp;#34;&#43;i&#43;&amp;#34;次，耗时&amp;#34;&#43;(end-start)&#43;&amp;#34;毫秒&amp;#34;); } } } 执行结果：
初始化pooled的ByteBuf第0次，耗时165毫秒 初始化pooled的ByteBuf第1次，耗时2毫秒 初始化pooled的ByteBuf第2次，耗时0毫秒 初始化pooled的ByteBuf第3次，耗时0毫秒 初始化pooled的ByteBuf第4次，耗时0毫 但我觉得还是过于复杂，其实最为简单的实现：
 考虑绝多大数的场景，假定每个请求消息98%是 1K 大小以内，则可以为每个处理线程直接预先分配 1K的 directBuffer。这个大小做成系统配置项。 当大小超过 1K 时，则可以再调整 directBuffer 内存的大小。可设置一个上限，避免对内存的溢出攻击。  结语 任何计算机的资源都是有限的，而内存则是最为重要的资源之一。现代语言的垃圾回收机制解决了手工释放内存的问题，内存池化也得解决了内存复用的问题。但多线程并发场景下，内存池可能会存在锁的争夺与分配不公平导致CPU抖动等问题，效率并不高。为了更高效，往往我们需要视使用场景返璞归真，使用最为简单的策略，固定的线程数，为每个线程独立预先分配足够的内存，做到线程级缓存复用。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码7：消除重复，需要脚本模块化</title>
        <url>http://lanlingzi.cn/post/technical/2020/0627_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 这次就不上代码了。情况是这样的，我们某一新产品，采用微服务架构，每个微服务独立的源码仓：
 每个服务都要支持手工安装，DF部署，容器部署。 每个服务都要支持修改密钥，密码等。 每个服务都要支持容灾，WatchDog等  上面的功能实现都需要采用Shell脚本，当搞定一个服务时，只需要复制到其它的服务，是最为常见的做法。但这种做法也带来了大量的重复，导致维护极其困难。真是拷贝一时爽，维护成了火葬场。主要问题表现：
 服务内重复： 同一服务内脚本不同场景下复制粘贴，如手工安装与DF部署，都需要创建OS用户，没有抽取公共函数复用 服务间重复： 不同服务间脚本复制粘贴，如同样是修改密码，只是配置文件路径不一样，配置项略有差别，没有抽取公共脚本复用。 缺少封装性： 部分脚本从头到尾没有任何函数提取，大块脚本从顶写到尾，全局变量到处飞，阅读极其困难。 健壮性不足： 脚本中的操作没有判断返回值或退出状态码，脚本没有太多的可靠性的防护。  Shell脚本重复是普遍现象 ，却又是常常习惯性被忽略:
 一是认为它是次要功能，几乎不会影响系统关键运行，在工作时间分配与测试上投入不足； 二次认为脚本没有太多的技术难度，似乎谁都可能做好似的。  但事实却一地鸡毛，大量相似与重复的脚本充斥在我们服务的代码仓中，也带来了大量重复机械的开发与测试工作量，开发效率自然好不到哪些去。
脚本模块化 像高级语言Java，Python等都支持模块化，shell本质上并不支持模块化，但通过抽取函数，分类规划好脚本文件来达到模块化的效果。
提取函数 同其它语言一样，函数具有封装性，是搭起大系统的积木。Shell的函数定义如下：
function func_name() { statements [return value] } 函数的调用方式
func_name # 不带参数 func_name param1 param2 # 带参数 函数一些最佳实践：
 函数返回值虽是可选的，默认是最后一条命令的退出码，但还是建议显示指定返回值，通常是用 0 表示成功， 非 0 表示失败。 函数内不建议调用 exit 退出执行，而是由上层调用者通过 返回值 决定是否 退出。 对于局部变量一定要采用 local 声明，因为无论在哪定义的变量默认是 global 的，其作用域从被定义的地方开始，到shell结束或被显示删除的地方为止。而 local 则只限制在函数内，则避免了对全局变量的污染。 全局变量应该是全大写（如HOME_PATH），而函数内的局部变量应该是小写(local_var)，并且当是只读变量最，建议增加 local -r 。 函数应该取了好名称，由于函数通过source生效时，具有 global 性，建议是按功能模块对函数增加 前辍， 如安装类函数，增加 install_ 前辍。 函数取参数要先赋值给 local 局部变量，不要在其它语句中直接通过 $1 $2 这种引用，因为它们可读性差，而局部变量名称增加可读性。  另外，在Github发现一个好东西，pure-sh-bible，收集汇总了编写 bash 脚本经常会使用到的一些代码片段，以帮助开发者更快的搭建好自己的脚本工具。
启动子Shell进程 把功能相对独立的函数与入口逻辑放一个独立的文件中，通过如下两种执行方式产生子Shell进程，以达到模块化的效果。
 指定Shell类型执行，如sh script.sh 通过spawnw命令执行，通常搭配expect使用，用于交互式命令，也适合于我们对于安全要求较高，脚本参数不能传递密码这类的场景。  引用Shell文件 把功能相对独立的函数放在一个独立文件中，当要使用其中的函数时，可以使用source命令，让函数在当前的Shell上下文生效。
 使用source命令 source script.sh 直接用点号 . script， 注：sh只支持点号，不支持source命令，不过现在Linux中，sh通常是bash的软链接。  通过source Shell文件，类比C中的include语句。但要注意的是shell不会判断一个shell脚本是不是被导入多次，每次source script.sh一下，都会在当前shell中执行script.sh。
能被source的Shell一些最佳实践：
 建议只包含函数定义，不要包含有入口执行逻辑，函数内不要定义全局变量。 若在Shell脚本开头定义了全局变量，一定要考虑全局变量的冲突问题，建议采用declare -r来定义只读全局变量。  当模块化Shell之后，不同功能的Shell往往不在一个目录下，Shell之间还会相互导入。但引用Shell脚本存在有一个较大的坑。
从我们实际代码来看，通用采用如下方式来获取脚本所在路径，拿到此路径再根据相对路径引用其它的Shell脚本。
declare -r CUR_PATH=$(cd &amp;#34;$(dirname $0)&amp;#34;;pwd) declare -R LIB_PATH=$(cd $CUR_PATH/../lib;pwd) source $LIB_PATH/lib_a.sh 上面的写法是有问题的，比如脚本A source了另一个目录下的脚本B、然后脚本B尝试使用此法获取路径时得到的是A的路径。获取当前执行的shell脚本路径的正确姿势应该是：
declare -r CUR_PATH=$( cd &amp;#34;$( dirname &amp;#34;${BASH_SOURCE[0]}&amp;#34; )&amp;#34; &amp;amp;&amp;amp; pwd ) 原因是$0是入口主脚本路径，并非被引用Shell的路径。对于source Shell一定要记住：
 source命令，不再产生新的shell，而是在当前Shell下执行一切命令。 source FileName，作用是在当前Shell环境下读取并执行FileName中的命令。 source在本Shell中执行的，产生的结果会影响本Shell。  模块化规划 通过上面三种脚本复用方式，我们现在大概清楚如何做脚本模块化了：
 第一步，按功能划分不同一脚本目录或文件，形成一系列的Shell Lib。 第二步，在每个Shell Lib定义公共函数，做到函数级可复用。 第三步，通过正式的姿势，source Lib文件到本Shell，调用相应的函数。 可选，当发现大部分执行逻辑相同能复用时，也可以采用启动子Shell进程方式复用。  下面给出一个目录及文件规划建议：
 shell_lib： 根目录  lib_common： 通用公共函数，如打印日志，异常退出函数，函数名建议以 common_ 开头。 lib_os：OS相关的函数，如创建用户组，用户，增加crontab任务，函数名建议以 os_ 开头。 lib_install：安装流程函数，函数名建议以 install_ 开头。 lib_unisntall：卸载流程函数，函数名建议以 unisntall_ 开头。 lib_df: DF部署特有函数，函数名建议以 df_ 开头。 &amp;hellip; libs.sh: 为了方便引用，可以提供一个汇总文件，它只source其它 lib_ 文件。    服务间引用 由于目前系统大多采用微服务的架构，为了能在多个微服务间复用，需要做到打包自动化，则依赖于服务所采用构建工具。
对于Java maven工程，给出一种参考玩法。
第一步，把脚本放在一个独立的Maven module工程中，此工程只包含公共脚本，放在src/main/resources下，子目录参考前面的目录规划建议。
第二步，把此module工程发布到Maven仓库中，以便其它的服务能通过Maven的GAV坐标下载它。
第三步，通过Maven Assambly插件打包，把依赖的脚本解压到目标包文件中，可以采用如下
&amp;lt;dependencySets&amp;gt; &amp;lt;dependencySet&amp;gt; &amp;lt;outputDirectory&amp;gt;/shell_lib&amp;lt;/outputDirectory&amp;gt; &amp;lt;useProjectArtifact&amp;gt;true&amp;lt;/useProjectArtifact&amp;gt; &amp;lt;unpack&amp;gt;true&amp;lt;/unpack&amp;gt; &amp;lt;unpackOptions&amp;gt; &amp;lt;includes&amp;gt; &amp;lt;!--也可能只解压部分需要的shell文件--&amp;gt; &amp;lt;include&amp;gt;*.sh&amp;lt;/include&amp;gt; &amp;lt;/includes&amp;gt; &amp;lt;lineEnding&amp;gt;unix&amp;lt;/lineEnding&amp;gt; &amp;lt;/unpackOptions&amp;gt; &amp;lt;includes&amp;gt; &amp;lt;!--指定公共Shell的GAV信息--&amp;gt; &amp;lt;include&amp;gt;com.huawei.aa:bb-common-shell&amp;lt;/include&amp;gt; &amp;lt;/includes&amp;gt; &amp;lt;/dependencySet&amp;gt; &amp;lt;/dependencySets&amp;gt; 结语 各个服务的Shell脚本质量也像Java/C&#43;&#43;语言同等重要，但脚本的模块化通常被人遗忘。大量相似与重复的脚本充斥在我们服务的代码仓中，也带来了大量重复机械的开发与测试工作量，对后面的维护也带来困难。消除脚本的重复，需要在设计与开发脚本时，采用模块化思维提升他们的复用，提升我们的开发效率。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码6：消除重复，需要配置代码分离</title>
        <url>http://lanlingzi.cn/post/technical/2020/0621_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一平台产品前端源码(Java语言)中：
private static Map&amp;lt;String, Map&amp;lt;String, String&amp;gt;&amp;gt; constructConstrainMap() { Map&amp;lt;String, Map&amp;lt;String, String&amp;gt;&amp;gt; typeConstrainMap = new HashMap&amp;lt;String, Map&amp;lt;String, String&amp;gt;&amp;gt;(); Map&amp;lt;String, String&amp;gt; imageConstrainPatternMap = new HashMap&amp;lt;String, String&amp;gt;(); imageConstrainPatternMap.put(&amp;#34;allowdPatten&amp;#34;, &amp;#34;^[a-zA-Z0-9_~.=@-]$&amp;#34;); imageConstrainPatternMap.put(&amp;#34;allowdMin&amp;#34;, &amp;#34;1&amp;#34;); imageConstrainPatternMap.put(&amp;#34;allowdMax&amp;#34;, &amp;#34;256&amp;#34;); imageConstrainPatternMap.put(&amp;#34;allowdValue&amp;#34;, null); imageConstrainPatternMap.put(&amp;#34;noEcho&amp;#34;, &amp;#34;false&amp;#34;); imageConstrainPatternMap.put(&amp;#34;description&amp;#34;, &amp;#34;com.huawei.....&amp;#34;); typeConstrainMap.put(TPropType.IAA_S_IMAGE_ID.value(), imageConstrainPatternMap) Map&amp;lt;String, String&amp;gt; netWorkConstrainPatternMap = new HashMap&amp;lt;String, String&amp;gt;(); // 省略 put ...  Map&amp;lt;String, String&amp;gt; containerConstrainPatternMap = new HashMap&amp;lt;String, String&amp;gt;(); // 省略 put ...  // 省略 其它的Constrain代码 ... } 上面的代码在一个方法中构造了16个Constrain，它是提供给BME控件用于输入框的校验。显然代码出现了重复（相似），也较容易想到采用外部配置文件方式来简化样板代码，但采用什么配置方式呢？
 对于较老的代码，可以选择XML，Properties。 对于基于SpringBoot框架开发的代码，有更多的选择，还可以是JSON与YAML。  无论哪种配置文件格式，解释库几乎都提供配置内容直接到Java对象的映射。比如XML，JDK1.6起提供JAXB(Java Architecture for XML Binding)来序列化与反序列化XML文件。不过由于XML技术过于古老，JDK11把JAXB从标准模块移除了，需要额外引入依赖或使用Jackson的JAXB能力。倘若使用DOM或SAX来解释XML，要写的代码有些多，也容易出错，直观感觉还不如上面一行一行代码写死配置内容来得快。而采用JAXB，定义映射结构类加上解释代码，也就20行左右代码可以搞定。那我们来尝试优化一下此案例代码：
第一步，定义XML的格式：
&amp;lt;Constrains&amp;gt; &amp;lt;Constrain id=&amp;#34;image&amp;#34; allowdPatten=&amp;#34;^[a-zA-Z0-9_~.=@-]$&amp;#34; allowdMin=&amp;#34;1&amp;#34; allowdMax=&amp;#34;256&amp;#34; noEcho=&amp;#34;false&amp;#34; description=&amp;#34;com...&amp;#34;&amp;gt; &amp;lt;Constrain id=&amp;#34;network&amp;#34; allowdPatten=&amp;#34;^[a-zA-Z0-9_]$&amp;#34; allowdMin=&amp;#34;1&amp;#34; allowdMax=&amp;#34;256&amp;#34; noEcho=&amp;#34;false&amp;#34; allowdValue=&amp;#34;local/external&amp;#34; description=&amp;#34;com...&amp;#34;&amp;gt; &amp;lt;!--省略其它的--&amp;gt; &amp;lt;/Constrains&amp;gt; 第二步，定义Java类结构：
@XmlAccessorType(XmlAccessType.FIELD) @Getter @Setter public class Constrain { @XmlAttribute(name=&amp;#34;id&amp;#34;) private String id; @XmlAttribute(name=&amp;#34;allowdPatten&amp;#34;) private String allowdPatten; @XmlAttribute(name=&amp;#34;allowdMin&amp;#34;) private int allowdMin; @XmlAttribute(name=&amp;#34;iallowdMaxd&amp;#34;) private int allowdMax; @XmlAttribute(name=&amp;#34;noEcho&amp;#34;) private boolean noEcho; @XmlAttribute(name=&amp;#34;allowdValue&amp;#34;) private String allowdValue; @XmlAttribute(name=&amp;#34;description&amp;#34;) private String description; } @XmlRootElement(name=&amp;#34;Constrains&amp;#34;) @Getter @Setter public class Constrains { @XmlElement(name = &amp;#34;Constrain&amp;#34;) protected List&amp;lt;Constrain&amp;gt; items; } 第三步，解释配置文件
try (InputStream is = new FileInputStream(&amp;#34;constrains.xml&amp;#34;)) { JAXBContext jc = JAXBContext.newInstance(Constrains.class); Unmarshaller unmarshaller = jc.createUnmarshaller(); Constrains constrains = (Constrains)unmarshaller.unmarshal(is) } 不过上面的代码有两个坑：
 JAXBContext不能每次都new，存在Class泄露(注：以前在JDK1.7版本遇到过，不知1.8以后是否还存在)，它是线程安全的，只要new一次即可在不同的线程中使用。 可能存在XML的外部实体注入攻击，虽然配置文件不直接暴露给外部，从公司可信代码要求来看，存在风险。  再优化一下:
// JAXBContext jc = JAXBContext.newInstance(Constrains.class); 在初始化或静态区中确保jc只new一次 XMLInputFactory xif = XMLInputFactory.newFactory(); xif.setProperty(XMLInputFactory.IS_SUPPORTING_EXTERNAL_ENTITIES, false); // 关闭外部实体解释支持 xif.setProperty(XMLInputFactory.SUPPORT_DTD, false); // 注：视情况true/false，当存在DTD，可以由DTD检查XML合法性，请参考要相关文档 try (XMLStreamReader xsr = xif.createXMLStreamReader(new FilterInputStream(&amp;#34;constrains.xml&amp;#34;), &amp;#34;UTF-8&amp;#34;)) { Unmarshaller unmarshaller = jc.createUnmarshaller(); Constrains constrains = (Constrains)unmarshaller.unmarshal(xsr) } 背后的知识 读取配置文件是一个软件系统必不可少的一部分，现代编程语言通常内置不同格式的解释库。面向对象语言，也通常支持直接从配置内容映射到对象树，使用起来则非常的简洁方便。
配置文件不仅是给软件程序读取，也需要给维护者阅读修改，或自动化工具修改(如部署安装)，则可以从如下几个方面考虑：
 表达能力强，如支持典型的键值对，还支持数组，引用，层级关系等。 便于人书写，通常的文本编辑器能检查出一些语法问题，也方便自动化工具搜索修改。 便于人理解，不需要由专业人员也能一看就知道其含义。 机制上安全，不会存在设计上缺陷或过于灵活导致安全问题。 外部依赖少，最好是语言系统库中自带的能力，不需要依赖第三方库。  常用有如下几种配置格式：
 INI：表达能力弱，支持Section一个层级，键值对，对于数组与引用需要扩展。Python内置支持。 XML：表达能力较强，拥有层级结构，语法有些冗余，存在外部实体注入。Java，Go，Python内置支持。 JSON：表达能力较弱，最大的问题不支持注释，存在Type注入。它本为数据交换设计，做数据存储还行，适合于直接读取之后发给其它模块接口的场景。 YAML：表达能力强，支持层级与引用，不过缩进只能使用空格不能使用tab，空格需要对齐，其实不太好维护修改。  网上有人总结如下：
 适合人类编写：INI &amp;gt; YAML &amp;gt; JSON &amp;gt; XML 可以存储的数据复杂度：XML &amp;gt; YAML &amp;gt; JSON &amp;gt; INI  配置文件的选择还是需要考虑实际使用场景，个人没有倾向性。
配置数据分离 用户界面中对输入数据的约束可以粗略的分为两种:
 给出的约束是较为固定不变的，通常可以将约束“硬编码”到代码中。 给出的约束可能随着业务规则的变动而变动，当“硬编码”会导致系统的维护代价比较高。   在一个系统中，我们总是会遇到一些参数，它们和具体的程序逻辑无关，比如数据库的地址，启动时绑定的IP与端口。显然这些参数更不适合被“硬编码”在代码中。
通常需要把这类的数据抽出来放在配置文件，方便扩展与修改。广义上讲，配置文件也是属于代码一种承载形式。通过配置文件来存放数据，其实把纯数据从主体代码中移到配置文件中，本质是实现配置数据与逻辑代码的分离。
回到案例中的代码，显然也是对用户输入数据的约束规则，可能这种约束就是固定不变的，从是否可变的角色来看，把它“硬编码”到代码在代码似乎问题不大。
但当我们将这类配置数据从代码中分离出来，则可以：
 职责清晰： 配置与逻辑在代码结构上泾渭分明，他们的职责也是清晰的，方便我们修改和维护源码。 减少代码： 配置类代码通常是相似的，从代码中分离出来会减少重复代码量，相似重复的代码错一点很难肉眼发现。 降低出错： 通过代码读取配置数据，可以对数据本身做有效性检查（比如检查是否遗漏某一项），避免配置出错带来的问题。  结语 软件系统中必不可少地会出现配置类数据，数据是否“硬编码”到代码中，还是从代码中分离出来，分离时采用什么的配置格式，都要视场景来选择不同的策略。配置类数据代码通常也是重复相似代码问题的高发之地，拒绝写重复代码，让代码职责清晰，降低出错，把配置数据从代码中分离是不错的方向。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码5：消除重复，需要搞点设计模式</title>
        <url>http://lanlingzi.cn/post/technical/2020/0613_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一平台产品源码(Java语言)中：
public class RemoteExecuteHandler { public Future&amp;lt;RemoteExecuteResult&amp;gt; handleDownload() throws SspException { try { initSshClient(); Future&amp;lt;RemoteExecuteResult&amp;gt; feture = downloadPackage(); return feture; } catch (SspException e) { LOGGER.error(&amp;#34;CMC download package failed&amp;#34;, e); closeSshClient(); throw e; } } public Future&amp;lt;RemoteExecuteResult&amp;gt; handleLoad() throws SspException { try { initSshClient(); Future&amp;lt;RemoteExecuteResult&amp;gt; feture = loadPackage(); return feture; } catch (SspException e) { LOGGER.error(&amp;#34;Load site package failed&amp;#34;, e); closeSshClient(); throw e; } } // 下面还有几个类似的方法，不再一一列表 } 上面的代码较直观地出现重复（相似），除了执行具体的动作与日志不一样，都是样板代码。当然还存在其它问题:
 异常资源泄露：可能抛运行期异常，则存在未正常closeSshClient，close动作应该放在finally中，或采用try-with-resources语法，参见飞哥讲代码1：确保资源被释放。 方法有副作用：多个方法隐式操作了成员变量，initSshClient方法创建的SshClient对象赋值给成员变量，而应该是返回SshClient对象，作为参数传递给loadPackage与closeSshClient方法，这样多线程并发就没有问题。  我们再来看一下downloadPackage的实现：
private Future&amp;lt;RemoteExecuteResult&amp;gt; downloadPackage() throws SspException { String workspace = baseOption.getWorkspace(); String donwloadScript = LinuxFileSystemUtil.join(workspace, DOWNLOAD_SHEEL_SCRIPT); String resultFile = LinuxFileSystemUtil.join(workspace, DOWNLOAD_TASK_DIR, baseOption.getExecuteId(), DOWNLOAD_RESULT); String logFile = LinuxFileSystemUtil.join(workspace,DOWNLOAD_TASK_DIR, baseOption.getExecuteId(), DOWNLOAD_LOG); String configFile = makeExecuteConfigFile(); String cmdInstall = String.format(&amp;#34;chmod &#43;x %s &amp;amp;&amp;amp; %s %s %s &amp;gt; %s 2&amp;gt;&amp;amp;1 &amp;amp;&amp;#34;, donwloadScript, donwloadScript, configFile, resultFile, logFile); // 构建执行命令  SSHExistStatus result = null; try { result = sshClient.execute(cmdInstall); } catch (Exception e) { LOGGER.error(&amp;#34;Remote execute cmc download package failed: {}&amp;#34;, e); throw new SspException(&amp;#34;Remote execute cmc download package failed: &amp;#34; &#43; e.getMessage()); } if (result.getCode() != 0 ) { LOGGER.error(&amp;#34;Remote execute cmc download package failed: {}&amp;#34;, result); throw new SspException(&amp;#34;Remote execute cmc download package failed: &amp;#34; &#43; result.getError()); } return new RemoteExecuteResultFuture(this); } 上面的代码较同样出现重复（相似），每个动作的逻辑也是类似，开始是拼接命令行，再执行，检查结查，异常打印日志。另外代码还有其它的问题：
 命令注入：直接拼接命令会导致命令注入，如workspace是否可能会通过带 | &amp;amp; &amp;gt; 等危险字符拼了其它的危险命令。 命名风格不统一：SspException与SSHExistStatus，编程规范建议是Ssh，不要全大写。 类之间紧耦合：RemoteExecuteResultFuture(this)这一句可以看到RemoteExecuteHandler与RemoteExecuteResultFutere耦合了，把this传给RemoteExecuteResultFuture，说明Future依赖了Handler，则优化Future可以作为Handler的内部类？  想到样板代码，我们应该如何优化呢？把变化的隔离开，固化不变化的这是设计模式干的活。我们先不考虑采用什么模式，尝试优化一下：
第一步，抽象一个命令接口：
public interface Command { // 命令名称  String name(); // 构建命令参数  String buildCmdArgs(); } 第二步，固化不变化部分，那框架代码可以变成如下。先还是放在RemoteExecuteHandler中，包装SshClient实现AutoClosable接口：
public class RemoteExecuteHandler { public Future&amp;lt;RemoteExecuteResult&amp;gt; call(Command command) throws SspException { SSHExistStatus result = null; try (sshClient = createSslClient()) { result = sshClient.execute(command.buildCmdArgs()); } catch (Exception e) { LOGGER.error(&amp;#34;Remote execute {} failed: {}&amp;#34;, command.name(), e); throw new SspException(&amp;#34;Remote execute &amp;#34; &#43; command.name() &#43; &amp;#34; failed: &amp;#34; &#43; e.getMessage()); } if (result.getCode() != 0 ) { LOGGER.error(&amp;#34;Remote execute {} failed: {}&amp;#34;, command.name(), result); throw new SspException(&amp;#34;Remote execute &amp;#34; &#43; command.name() &#43; &amp;#34; failed: &amp;#34; &#43; result.getError()); } return new RemoteExecuteResultFuture(); } } 第三步，抽取变化的内容，扩展不同的Command接口实现，如下：
public class DownloadCommand implements Command { @Override public String name() { return &amp;#34;DownloadPackage&amp;#34;; } @Override public String buildCmdArgs() { // 构建命令需要执行的参数，本文不再例出了。  } } 经过这样一修改，代码消除了样板代码，也具有了扩展性。增加不同的命令，只要实现不同的Command子类即可。
但，等等&amp;hellip;&amp;hellip;这用了什么设计模式？没有使用任何模式，只是做了一层抽象，把Command的命令构建抽象了一个接口，而RemoteExecuteHandler执行时只依赖了接口，不关心具体的命令参数。那还有没有优化的空间？当然有。
背后的知识 重复的代码，本质其实都在表达（即依赖）同一项知识。如果它们表达（即依赖）的知识发生了变化，则需要多处修改。为了达成高内聚低耦合，大师们都会提到正交性设计，而正交性的第一点就是要消除重复。
正交性源自几何学，当两根直线互相垂直的时候，我们认为这两根直线是正交的，否则的话这两根直线就是不正交的。引入到软件设计中，引申意是说无重复，向不同的变化方向发展，正交性有四个策略（原则）：
 消除重复(最小化重复)：重复意味着耦合。正如上面的案例代码，Handler类需要耦合（理解）不同的命令行构建。 分离变化：识别变化方向，并对变化预留出扩展接口。案例优化代码，识别出了变化内容是不同的命令行，则抽象了Command接口。 缩小依赖范围：依赖接口，不要依赖实现，接口应尽可能地包含少的知识，案例优化代码，Handler不再耦合依赖具体的命令拼装逻辑，而是只看Command接口。 向稳定的方向依赖：定义的API应该关注What，而不是How。站在需求的角度，而不是实现方式的角度定义API，会让其更加稳定。需求的提出方，一定是客户端，而不是实现侧。案例优化代码，Handler是命令的客户端，则接口由它来定。  所有的设计原则与设计模式为了实现高内聚、低耦合。正交性设计的本质是关注背后的动力：变化。正交性的四个策略（原则）以变化驱动，让系统逐步向更好的正交性演进的策略。总结要点如下：
 一切围绕变化：由变化驱动，反过来让系统演进的更容易应对变化（扩展性）。 分离不同变化方向：把变化的部分从主系统中分离出来，让系统更加的局部化影响。  设计模式 设计模式是从许多优秀系统中总结出的成功，可复用的经验；提供了一套通用的设计词汇与形式来描述。设计模式不有同的层次，通常分层为：
 架构模式：描述软件系统的结构组成与纲要。如云服务抽象非常多的设计模式，比如Cache-Aside，Circuit Breaker，CQRS等等，可参见Cloud Design Patterns。 设计模式：描述软件程序设计反复出现的问题描述，如GoF总结的23个基本设计模式。 实现模式：描述具体语言实现的问题，如异常处理规则 ，函数命名规则等等。  本文所说的消除重复，需要搞点设计模式，它指的是第二层。
说真的，若去看设计模式的书籍，会陷入困惑：
 可能会觉得过于深奥，有些枯燥无味，根本学不下去； 有时也可能会走上拿着锤子满世界找钉子的过程。  笔者曾经喜欢上设计模式，总想把代码往设计模式上靠，不是导致过度设计就是画虎类猫了。现在我也不记得每种设计模式的类图结构，模式A与模式B之间到底他们之间的区别。“黑猫白猫，会捉老鼠就是好猫”。我们学习和使用设计模式时，也不应该把重点放在“是黄色的母马还是黑色的公马”上，而应该是这马适合长途负重、还是短距离冲刺。抓住本质（如正交性设计四原则），找准使用场景，方能应用设计模式。
我们还是来回顾一下23种经典的设计模式（来源于公司可信考试学习材料）：
 创建型：  Factory Method：隔离创建对象的细节，使得创建对象的行为可扩展。 Abstract Factory：创建一组相关的对象对接，其中每个方法即为Factory Method。 Builder：包含对象构建的若干过程，因些天然与Template结合。 Prototype：用于以某个对象为模子创建一个新的对象。 Singleton：确保对象实例唯一。   结构型：  Adapter Class/Object：处理遗留系统的不二法宝，也可以用空方法实现接口作为抽象父类 Bridge：使用关联代替继承，解决类多维的扩展导致的类爆炸的问题 Composite：将组件组装为整体使用 Decorator：用于各个Wrapper，在原函数执行前后做一些额外的工作 Facade：封装扇出，复用树状结构减少调用者的复杂度。 Flyweight：复用变化小的对象 Proxy：对原对象所有方法进行代理   行为型：  Interpreter：用于解释执行自定义的某种语法 Template Method：框架与钩子 Chain Of Responsibility：一组对象执照既定的顺序关联起来，依次处理请求 Command：将行为抽象与解耦 Iterator：封装数据的访问行为（顺序、可见性等） Mediator：用一个中介对象来封装一系列的交到；新增一个模块处理两个模块的交互 Memento：将当前对象的状态信息保存为中一个对象，可以基于状态镜像快速恢复原状态 Observer：订阅/发布模型，用于事件驱动的设计 State：封装有限状态机的状态与状态迁移 Strategy：使用接口即使用策略，用于隔离变化 Visitor：数据与行为分离方法    再次改进 前面提到优化还有空间，原因在于命令执行拿结果还需要看到RemoteExecuteResultFuture较底层的对象。理想的情况下，我发一个命令，执行，拿到最终结果。
过一遍设计模式，我们发现有一个命令（Command）模式。其实它非常适合于我们案例的场景。找到了使用场景，我们再来复习一下：
 命令模式：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。
  Command（抽象命令类）：抽象出命令对象，可以根据不同的命令类型，写出不同的实现类。 ConcreteCommand（具体命令类）：实现了抽象命令对象的具体实现。 Invoker（调用者/请求者）：请求的发送者，它通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令来之间存在关联。在程序运行时，将调用命令对象的execute() ，间接调用接收者的相关操作。 Receiver（接收者）：接收者执行与请求相关的操作，真正执行命令的对象。具体实现对请求的业务处理。未抽象前，实际执行操作内容的对象。 Client（客户端）：在客户类中需要创建调用者对象，具体命令类对象，在创建具体命令对象时指定对应的接收者。发送者和接收者之间没有之间关系。  再回到前面案例中
 具体的Command，如DownloadCommand，实现命令行的构建，以及响应结果的定义。 sshClient的包装类应该是Receiver，建议修改为RemoteExecuteReceiver。还是提供SSH远程命令执行，可以把代化之后RemoteExecuteHandler的call方法称到此类中（封装原生的SshClient的API调用，并在方法上动态创建sshClient对象与关闭）。 现有的RemoteExecuteHandler应该是Invoker类，提供callAndWaitResult方法，用于打印命令执行前后日志，调用receiver.action执行远程命令，等待RemoteExecuteResultFuture结果，把Future异步结果转换为各自命令对应的结果。  则客户端的代码简化为
RemoteExecuteReceiver receiver = new RemoteExecuteReceiver(); DownloadCommand downloadCmd = new DownloadCommand(receiver); RemoteExecuteInvoker invoker = new RemoteExecuteInvoker(downloadCmd); invoker.callAndWaitResult(); 结语 重复可能是软件中一切邪恶的根源，许多原则与实践规则都是为了控制与消除重复而创建。GoF总结的23种设计模式非常地经典，掌握它能解决我们绝大多数的问题。学习与应用设计模式有一个过程，就像案例优化的思路一样，我们先搞清那个是变化点，通过抽象隔离变化。再回过头来审视一下可参考的设计模式把它完善。当然最好像武林高手一样，忘记所有的设计模式招式，以正交性四原则为指导，以无招胜有招。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码4：消除重复，需要了解框架机制</title>
        <url>http://lanlingzi.cn/post/technical/2020/0605_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一平台产品源码(Java语言)中（代码一）：
public class ServiceFactory { private static ServiceFactory instance = new ServiceFactory(); public static ServiceFactory getInstance() { return instance; } @Getter @Setter @Autowired private AppTemplateDesignServie appTemplateDesignServie; @Getter @Setter @Autowired private AppTemplateExportServie appTemplateExportServie; // 下面还有十多个Service对象注入，提供Getter与Setter，不再一一列出 } 再来看另一平台服务的代码(Java语言)（代码二）：
public WebConfig implements WebMvcConfigurer { @Autowired private AucInterceptor aucInterceptor; @Autowired private AuthInterceptor authInterceptor; @override public void addInterceptor(InterceptorRegistry registry) { int order = 1; InterceptorRegistration metricInterceptorRegistration = registry.addInterceptor(new MetricInterceptor()); metricInterceptorRegistration.addPathPatterns(&amp;#34;/**&amp;#34;); metricInterceptorRegistration.order(order&#43;&#43;); InterceptorRegistration aucInterceptorRegistration = registry.addInterceptor(aucInterceptor); aucInterceptorRegistration.addPathPatterns(&amp;#34;/**&amp;#34;); aucInterceptorRegistration.order(order&#43;&#43;); InterceptorRegistration authInterceptorRegistration = registry.addInterceptor(authInterceptor); authInterceptorRegistration.addPathPatterns(&amp;#34;/**&amp;#34;); authInterceptorRegistration.order(order&#43;&#43;); } } 代码一的问题：
 ServiceFactory并不一个Factory，Factory的设计应该只生产对象，实际上它不产生对象，对象是注入的。 ServiceFactory也不是一个合格的单例，缺少private构造方法, instance未声明为final。 出现了十多个类似的对象注入代码，那后面我加一个XXXService，是不是要再修改代码，若有几十个Service要使用，是不是这个类就膨胀了。  写出ServiceFactory目的是想解决由于@Autowired只能用于Spring管理的Bean对象中，并不能用于其它对象中。当代码要在其它非Bean对象中随时调用XXXService时，ServiceFactory则提供了获取Spring管理的XXXService一种变通途径，只是这种途径没有使用到Spring提供的扩展机制。
代码二的问题：
 比较直观地发现，代码出现了重复（相似），但似乎也没有重复太多，一般人也能接受。 如果后面再增加一个Interceptor，那同样也要先采@Autowired注入，再在addInterceptor方法再增加三行相似代码。  上面两处代码都是基于Spring框架开发，不约而同的出现了重复（相似，冗余）。重复只是表象，背后则违背了开闭原则：
 没有做到：对扩展开放，对修改关闭。 扩展新的类似功能，需要修改此类的代码。  为什么上面集中且容易察觉到的重复（相似），我们不去消除它。因为写重复代码太容易了，传统消除重复的套路（提取函数）在上面的代码已不再能有效解决，更别说满足开闭原则。若消除这类重复，则需要我们对Spring的IoC运作机制较深入了解。
代码一的优化建议：
@Component public class SpringContextUtil implements ApplicationContextAware { private static ApplicationContext springContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { SpringContextUtil.springContext = applicationContext; } private static void checkContextNotNull() { // ...  } public static &amp;lt;T&amp;gt; T getBean(Class&amp;lt;T&amp;gt; interClazz) { checkContextNotNull(); return springContext.getBean(interClazz); } public static &amp;lt;T&amp;gt; T getBean(Class&amp;lt;T&amp;gt; clazz, String name) { checkContextNotNull(); return clazz.cast(springContext.getBean(name)); } } 拿到ApplicationContext之后，我们就可以获取任一Bean对象了，消除了相似代码，也解决了违背开闭原则的问题。
代码二的优化建议：
@Component public ServiceConfigurer implements WebMvcConfigurer { @Autowired(required=false) private List&amp;lt;Interceptor&amp;gt; interceptors; @override public void addInterceptor(InterceptorRegistry registry) { if (CollectionUtils.isEmpty(interceptors)){ return; } int order = 1; for(Interceptor interceptor: interceptors) { InterceptorRegistration registration = registry.addInterceptor(interceptor); registration.addPathPatterns(&amp;#34;/**&amp;#34;); registration.order(order&#43;&#43;); } } } 通过采用List注入方式解决了扩展性问题，那又怎么解决不同Interceptor注册先后问题？Spring还提供一个@Order注解，只需要在各个类声明时，给它排个序，那List中注入的对象就具有先后顺序：
@Order(1) @Component public class AucInterceptor .... 背后的知识 Spring提供的IoC容器负责管理Bean对象的生命周期，其底层核心对象：
 BeanDefinition：每个bean对应一个BeanDefinition实例。BeanDefinition负责保存bean对象的所有必要信息，包括bean对象的class类型、构造方法和参数、属性等等。 BeanDefinitionRegistry：抽象bean描述信息的注册逻辑。 BeanFactory：抽象出了bean的管理逻辑，各个BeanFactory的实现类就具体承担了bean的创建以及管理工作。  BeanFactory只是IoC容器的一种基础实现，它默认采用延迟初始化策略：只有当访问容器中的某个对象时，才对该对象进行初始化和依赖注入操作。而在实际场景下，我们更多的使用另外一种类型的容器（ApplicationContext），它构建在BeanFactory之上，除了具有BeanFactory的所有能力之外，还提供对事件监听机制以及国际化的支持等。它管理的bean，在容器启动时全部完成初始化和依赖注入操作。
在bean生命周期的不同阶段，Spring提供了不同的扩展点来观察与改变bean的命运。bean的整个生命周期简述如下：
在实例化和初始化Bean对象过程中，提供了一些生命周期回调方法：
 容器的启动阶段：提供BeanFactoryPostProcessor接口，允许我们在容器实例化相应Bean对象之前，对Bean进行预处理。比如我们经常使用到@Value(&amp;quot;${jdbc.url}&amp;quot;)来获取配置属性，则是PropertyPlaceholderConfigurer作为BeanFactoryPostProcessor来对属性占位替换。 对象实例化阶段：提供BeanPostProcessor接口，允许我们在Bean对象初始化之前/之后进行观察与处理。  除了这些，还有如下常用生命周期回调，本文就不再一一展开了，按他们的名称我们也就大概知道做什么（取好名字多么重要）：
 ApplicationContextAwareProcessor InitDestroyAnnotationBeanPostProcessor InstantiationAwareBeanPostProcessor CommonAnnotationBeanPostProcessor AutowiredAnnotationBeanPostProcessor RequiredAnnotationBeanPostProcessor BeanValidationPostProcessor  除了生命周期回调方法，还提供XXXAware系列接口，Aware字面义即可感知的，意味着实现了这个接口能够感知并获取到对应的对象组件。常见有：
 BeanFactoryAware ：感知BeanFactory ApplicationContextAware ： 感知ApplicationContext，再次感慨Spring的命名规范性 EnvironmentAware EmbeddedValueResolverAware ResourceLoaderAware ApplicationEventPublisherAware MessageSourceAware  Spring还提供Bean与Bean间的消息通信机制。当一个Bean处理完了一个任务以后，可以通知另一个Bean做出相应的处理，这是我们就需要让另一个Bean监听当前Bean所发送的事件。Spring加载过程中也大量采用此事件机制。事件处理核心概念主要涉及如下：
 定义事件：事件继承ApplicationEvent 发布事件：调用ApplicationContext.pushEvent方法发布事件 监控事件：实现ApplicationListener或采用@EventListener接收事件  @Order注解，底层对应提供了Ordered这个接口，是使用了策略模式，用来处理相同接口实现类的优先级问题。默认实现是在DefaultListableBeanFactory.resolveMultipleBeans 方法会对依赖注入的对象进行排序处理。
Spring的IoC知识内容非常多，不可能全都深入了解，但我们可以简单记注几个接口名称后辍：XXXRegistry，XXXFactory，XXXProcessor，XXXAware, XXXListener。不一定要记得细节，当你需要使用到某个能力时，就按后辍名去搜索找到我们需要的扩展机制。
DI与IoC 一提到Spring的Bean管理，我们也会提到两个词：DI与IoC。Spring是Bean的IoC容器，我们使用Bean时需要DI，初学者容易混淆他们。
 DI：依赖注入，将类的依赖通过外部注入进来。 IoC：控制反转，将类的对象创建交给框架来配置。 关系：不同角度描述，依赖注入则站在使用者角度，来说明被注入的对象依赖于IoC容器给配置依赖对象；控制反转是站在管理者角度，来说明你需要的依赖由我来配置。  IoC是一种设计思想，意味着将你设计好的对象交给框架容器控制，而不是传统的在你的对象内部直接控制。为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转。
IoC对编程带来的最大改变不是从代码上，而是从思想上，发生了“主从换位”的变化。 IoC很好的体现了面向对象设计法则之&amp;mdash;-好莱坞法则：“别找我们，我们找你”，即由IoC容器帮对象找相应的依赖对象并注入，而不是由对象主动去找。
IoC的意义是为了解除耦合，IoC创建对象的控制权进行转移，以前创建对象的主动权和创建时机是由自己把控的，而现在这种权力转移到IoC容器。你要什么对象，它就给你什么对象。有了IoC容器，依赖关系就变了，原先的依赖关系就没了，它们都依赖IoC容器了，通过IoC容器来建立它们之间的关系。
回到案例代码，消除重复需要理解Spring的运行机制，其进一步所思考的是如何学会IoC的本质。控制反转，让框架来帮我们完成依赖注入，而不是我们主动显示依赖其它对象，破坏代码的稳定性。
如何学习 本文提到的Spring IoC知识只是点到为止，市面上编程、框架介绍这类书籍都通常非常的厚，我们哪些时间去学习啊；甚至通篇大段的代码讲解，让我对学习失去了新鲜感。我们每个人都想掌握更多的知识，把代码写得更简练。面对编程中的各种体系，我们怎么去学习？学习有个金字塔理论：
 听讲：两周以后学习的内容只能留下5% 阅读：可以保留10% 声音、图片：可以记住20% 示范：可以记住30% 小组讨论：可以记住50% 做中学：可以记住75% 教别人：可以记住90%  后面几种效果高的学习方式，都是团队学习、主动学习与参与式学习。结合编程应用上述理论：
 我们应该积极参与代码Review，这不仅仅是Committer的工作。因为Review不仅可以学习其它同学是怎么写代码，当遇到不同或更好的写法，我们可以及时交流；还可以搜索相应的知识，举一反三地深入了解其背后的原理。 个人不建议平时花时间无目的地去看什么编程、框架之类的书籍，而是当工作中遇到问题，针对问题去主动寻求答案。正如案例代码一的写法，当你写一到三个对象注入时，可能不会想到优化。当写到七到八个时，那就应该想想有没有更好的办法。采取顺藤摸瓜式的思考，面向搜索学习：Spring怎么管理Bean的-&amp;gt;是否有Bean查询接口-&amp;gt;怎么拿到查询接口-&amp;gt;是否有扩展点&amp;hellip;&amp;hellip;刚开始可能完全没有背景知识毫无思路，但如果不走出第一步，也将永远停留在原地。 平时注意总结与分享，分享不一定要搞个正式会议，形式可以多样。当你去考虑如何教别人时，就会先去了解更多的相关知识，也会在总结中有更多的思考，在讲解的过程中有更深的体会。这样日积月累下来，将会有越来越多的收获。  在工作中 不断学习，将是程序员不断提升的不二法门。
结语 写出干净的代码，需要我们对所使用的框架机制有较深入的了解，一是可以避免出现框架已有机制没有使用出现重复与复杂的代码； 二是可以避免当出现问题时两手抓狂不知如何定位。在工作中带着问题，带着思考有目的地去学习。学习框架的运行机制，以及其应用的原理、设计原则，将会使自己从编码的纯体力劳动解放出来，发现更多有趣的新技术与技巧。把这些再应用到工作中，解决现实的问题，也将收获编程带来的满足感，快乐感。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码3：简洁高效的线程安全</title>
        <url>http://lanlingzi.cn/post/technical/2020/0531_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一中间件产品源码(Java语言)中（写法一）：
// ConcurrentMap&amp;lt;String, AtomicLong&amp;gt; rejectMessageCounts = new ConcurrentHashMap&amp;lt;&amp;gt;(); private AtomicLong getRejectMessageCount(String serviceName) { AtomicLong rejectMessageCount = rejectMessageCounts.get(serviceName); if (null == rejectMessageCount) { rejectMessageCount = new AtomicLong(); AtomicLong currentValue = rejectMessageCounts.putIfAbsent(serviceName, rejectMessageCount); if ( null != currentValue) { rejectMessageCount = currentValue; } } return rejectMessageCount; } 上面的代码是线程安全的，但不够简洁，Java 1.8的ConcurrentMap提供computeIfAbsent()方法，可以简化为（写法二）：
private AtomicLong getRejectMessageCount(String serviceName) { return rejectMessageCounts.computeIfAbsent(serviceName, (key)-&amp;gt; new AtomicLong()); } 回想起曾经走读代码见过如下的写法（写法三，还是以getRejectMessageCount实现为例）：
private AtomicLong getRejectMessageCount(String serviceName) { synchronized(rejectMessageCounts) { AtomicLong rejectMessageCount = rejectMessageCounts.get(serviceName); if (rejectMessageCount == null) { rejectMessageCount = new AtomicLong(); rejectMessageCounts.put(serviceName, rejectMessageCount); } return rejectMessageCount; } } 但上面的写法也没有线程安全问题，与写法一相比，由于存在synchronized同步锁，范围较大，性能并没有前者好。作者也知道get/put方法是只是原子操作，组合使用则需要synchronized来加锁确保线程安全。
上面案例代码看似简单，但涉及到了线程安全的多个知识点，促使了我写这一篇博文。本文虽是以Java语言呈现，但线程安全的原理是相通的。
背后的知识 ConcurrentMap是JDK1.5开始提供的新接口，用来解决Map操作线程不安全的问题。另一个代替是HashTable，通过synchronized来锁住整个table，无疑在多线程并发又是低效的。ConcurrentMap接口实现者ConcurrentHashMap有两个版本的实现逻辑（JDK1.8以前与1.8），简言之都是划整为零，避免大范围的锁。
1.8以前版本（为简化说明，后面统一以1.5版本代替）的ConcurrentHashMap采用Segment数组和多个HashEntry来存储数据结构，Segment数组将一个大的table分割成多个小的table来进行加锁。而每一个Segment元素存储的是HashEntry数组&#43;链表，这个和HashMap的数据存储结构一样。
1.8版本的实现已经摒弃了Segment的概念，而是直接用Node数组&#43;链表&#43;红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作。
以put操作实现为例，对当前的table进行无条件自循环直到put成功，使用了CAS&#43;Synchronized&#43;黑红树：
 如果没有初始化就先调用initTable方法来进行初始化过程 如果没有hash冲突就直接CAS插入 如果还在进行扩容操作就先进行扩容 如果存在hash冲突，就加锁（Synchronized）来保证线程安全 最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构  1.5与1.8版本的具体实现细节就不一一展开讲了，有兴趣的同学可以网上搜索相关源码分析。总结区别如下：
 1.5版本采用ReentrantLock&#43;Segment&#43;HashEntry；1.8版本中synchronized&#43;CAS&#43;HashEntry&#43;红黑树 1.8版本的实现降低锁的粒度，1.5版本锁的粒度是基于Segment的，包含多个HashEntry，1.8锁的粒度就是HashEntry（Hash值首节点） 1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为基于Hash计算冲突是否加锁，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了 1.8版本使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表 1.8版本使用内置锁synchronized来代替重入锁ReentrantLock，synchronized并不比ReentrantLock差，基于JVM的synchronized优化空间更大  回到案例的代码，再来对比说明一下
 写法三：采用synchronized锁get&#43;put，则锁的范围过大，完全把ConcurrentHashMap中分段/Hash冲突加锁给废了 写法一：putIfAbsent方法（底层是putValue）无论1.8版本或它之前的版本，相比synchronized锁get&#43;put进一步降低了锁的粒度 写法二：1.8版本针对不存在则put操作场景提供更为简单的API，涉及到线程安全的可见性  线程安全 JDK提供多种容器、原子对象与线程池，让多线程编程变得较为简单，简单后面往往也隐藏复杂性。若对他们不深入了解而使用不当，也会造成多线程安全问题。
多线程编程要确保并发程序正确地执行，必须满足下面三个特性，他们缺一不可：
 原子性：一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行 可见性：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值 顺序性：程序执行的顺序按照代码的先后顺序执行  再回到案例的代码：
 原子性：由于ConcurrentMap提供的get/put方法是原子操作，他们要么全部能执行，所以写法三需要加锁来确保 可见性：ConcurrentMap的putIfAbsent方法能立即返回其它线程已加入Map中的对象，即拿到最新的值，所以写法一是没有问题的 顺序性：涉及到Java中的指令重排序问题，案例代码不好直接说明此特征，简单说多个线程使用变量依赖是要有序的，不可被打断打乱，volatile变量则不可重排序  锁的优化 线程安全解决办法一般是采用加锁同步，但一旦使用到锁，就会导致多个线程竞争时阻塞。如何让锁的锁定障碍降到最低？
减少锁持有的时间
减少锁持有时间指让锁的的持有时间减少和锁的范围减少，锁的零界点就会降低，其他线程就会很快获取锁，尽可能减少了冲突时间。
减少锁粒度
减小锁粒度指将大对象拆成小对象，大大增加并行度，降低锁竞争。
前面提到的ConcurrentHashMap两种实现，都是为了减少锁粒度，在1.8以前的实现方案中，拆分成多个Segment，写操作时则先定位到某个Segment，只锁定一个Segment。而1.8的实现则更加优化，只有Hash冲突时才会有锁的竞争，Hash不冲突时则采有CAS插入。
锁分离
锁分离就是读写锁分离，JDK中ReadWriteLock维护了一对锁，读锁可允许多个读线程并发使用，写锁是独占的。
ConcurrentHashMap 1.8版本中的存储结构采用黑红树，它也采用锁分离的思路，针对读取的优化，来看一下它的数据结构：
static final class TreeBin&amp;lt;K,V&amp;gt; extends Node&amp;lt;K,V&amp;gt; { // 指向TreeNode列表和根节点 TreeNode&amp;lt;K,V&amp;gt; root; volatile TreeNode&amp;lt;K,V&amp;gt; first; volatile Thread waiter; volatile int lockState; // 读写锁状态 static final int WRITER = 1; // 获取写锁的状态 static final int WAITER = 2; // 等待写锁的状态 static final int READER = 4; // 增加数据时读锁的状态 .... 当数据操作互不影响，锁就可以分离，例如JDK中LinkedBlockingQueue，当队列中持有数据非一个时，头部和尾部之间的操作是不冲突的，也就可以读写分离，所以可以进行高并发操作。当只一个数据时，才会阻塞操作。
锁粗化
为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短。如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化。
锁粗化指可以把很多次请求的锁拿到一个锁里面。例如：
for(int i=0;i&amp;lt;MAX;i&#43;&#43;){ synchronized(lock){ // 处理逻辑  } } 则可以优化为：
synchronized(lock){ for(int i=0;i&amp;lt;MAX;i&#43;&#43;){ // 处理逻辑  } } 无锁编程
无锁编程指Lock-free，通常是Wait-free, 即确保线程永远不会阻塞。由于线程永远不会阻塞，所以当同步的细粒度是单一原子写或比较交换时。状态转变是原子性的，以至于在任何点失败都不会恶化数据结构。
无锁有很多种实现，最简单也最普遍的一个通用原语是CAS(Compare and Swap)。JDK提供的AtomicLong等对象，都是采用CAS机制。从命名我们也可以得知，他们的状态转变是原子性。但CAS也有其局限性，感兴趣的同学可以了解一下什么是ABA问题。
volatile变量具有锁的可见性，却不具备原子特性。volatile仅能使用在变量级别，volatile不会造成线程的阻塞。所以可以使用volatile变量来以比同步更低的成本存储共享数据，其使用场景是在多线程读而少线程写的情况。
结语 编写简洁又高效的线程安全代码还是有一定的难度的，我们需要在安全与性能之间平衡。无论Java还是其它语言，都提供了volatile，CAS的Atomic，Lock等不同程度的安全同步原语。JDK提供HashTable，不同版本的ConcurrentHashMap演进，内部的实现细节与其原理太值得我们去深入研究与学习。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码2：把大象装进冰箱要几步</title>
        <url>http://lanlingzi.cn/post/technical/2020/0523_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一老产品源码(C语言)中：
VOS_INT STARTER_Download(VOD_VOID) { VOS_UINT32 count, sleepTimeLen; VOS_CHAR ascExcuteFile[INSTALL_MAX_DIRNAME_LEN]={ 0 }; VOS_BOOL enIsHaveUpdateOk = VOS_FALSE; VOS_INT siRet; BOOTTRACE(TRACE_TIP, &amp;#34;Checking and updating files...&amp;#34;); if(LOAD_Init()==VOS_FALSE) { BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Init return error&amp;#34;); return VOS_ERR; } siRet=LOAD_Begin(LD_STAGE_INSCHK, &amp;amp;g_downloadFileCount, g_pstFileListInfo, LD_ONLINE_UPDATE); if(siRet != VOS_OK) { LOAD_End(); BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Begin return error&amp;#34;); return VOS_ERR; } while(VOS_TRUE) { for(count=0;count&amp;lt;g_downloadFileCount;count&#43;&#43;) { if (g_pstFileListInfo[count].enLoadCheckResult == LS_SUCESS_UPDATE ) { enIsHaveUpdateOk = VOS_TRUE; } } for(count=0;count&amp;lt;g_downloadFileCount;count&#43;&#43;) { if (g_pstFileListInfo[count].enLoadCheckResult != LS_SUCESS_UPDATE &amp;amp;&amp;amp; (g_pstFileListInfo[count].enLoadCheckResult != LS_NOT_NEED_UPDATE) &amp;amp;&amp;amp; (g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_NORESPONSE) &amp;amp;&amp;amp; (g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_REFUSE)) { BOOTTRACE(TRACE_ERR, &amp;#34;update file %s error and result=%d&amp;#34;, g_pstFileListInfo[count].acFileName, g_pstFileListInfo[count].enLoadCheckResult); break; } if ((g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_NORESPONSE) &amp;amp;&amp;amp; (enIsHaveUpdateOk == VOS_TRUE) ) { BOOTTRACE(TRACE_ERR, &amp;#34;Not all files are updated,download these file again&amp;#34;); break; } if ((g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_REFUSE) &amp;amp;&amp;amp; (enIsHaveUpdateOk == VOS_TRUE) ) { BOOTTRACE(TRACE_ERR, &amp;#34;Not all files version are consistent with inschk,download these file again&amp;#34;); break; } if ((g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_NORESPONSE) &amp;amp;&amp;amp; (g_pstFileListInfo[count].bLocalCheck = VOS_FALSE) ) { BOOTTRACE(TRACE_ERR, &amp;#34;Fail to connect witch OMU server and local file %s is uncertain, I will still download these files&amp;#34;, g_pstFileListInfo[count].acFileName); break; } if ((g_pstFileListInfo[count].enLoadCheckResult != LS_OMU_REFUSE) &amp;amp;&amp;amp; (g_pstFileListInfo[count].bLocalCheck = VOS_FALSE) ) { BOOTTRACE(TRACE_ERR, &amp;#34;OMU fesuse to update and %s local check result=%d or some file updated&amp;#34;, g_pstFileListInfo[count].acFileName, g_pstFileListInfo[count].bLocalCheck); break; } if (g_pstFileListInfo[count].ucFileType == PROG_FILE_TYPE ) { siRet = snprintf_s(ascExcuteFile, sizeof(ascExcuteFile), sizeof(ascExcuteFile)-1, &amp;#34;%s/%s&amp;#34;, g_pstFileListInfo[count].acFileExecuteDir, g_pstFileListInfo[count].acFileName); if (siRet &amp;lt;= 0 ) { BOOTTRACE(TRACE_ERR, &amp;#34;[%s:%d] snprintf_s failed,&amp;#34;, __FUNCTION__, __LINE__); break; } (void)chmod(ascExcuteFile, S_IRUSE | S_IXUSR); } } if (count == g_downloadFileCount) { BOOTTRACE(TRACE_TIP, &amp;#34;All %d files checked or updated OK.&amp;#34;, g_downloadFileCount); for(count=0;count&amp;lt;g_downloadFileCount;count&#43;&#43;) { BOOTTRACE(TRACE_LOD, &amp;#34;%d update result is %d and local check result is %d.&amp;#34;, g_pstFileListInfo[count].acFileName, g_pstFileListInfo[count].enLoadCheckResult, g_pstFileListInfo[count].bLocalCheck); } break; } else { if (g_pstFileListInfo[count].enLoadCheckResult == LS_DISK_FULL){ sleepTimeLen=INSTALL_DISK_FULL_AGAIN_TIMELEN; } else { sleepTimeLen=INSTALL_CONNECT_OMU_AGAIN_TIMELEN; } BOOTTRACE(TRACE_ERR, &amp;#34;Update file error so sleep for %d second and try again&amp;#34;, sleepTimeLen); SLEEP(sleepTimeLen); siRet=LOAD_Begin(LD_STAGE_INSCHK, &amp;amp;g_downloadFileCount, g_pstFileListInfo, LD_ONLINE_UPDATE); if(siRet != VOS_OK) { LOAD_End(); BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Begin return error&amp;#34;); return VOS_ERR; } } } BOOTTRACE(TRACE_DBG, &amp;#34;Exit STARTER_Download&amp;#34;); LOAD_End(); return VOS_OK; } 上面的代码我已是删除了每个条件判断的注释，但是代码看起还是有点长。如果不仔细读，还真不看出不函数完成的功能。再来看优化重构之后的代码：
VOS_BOOL CheckOneFileStatus(FileInfo&amp;amp; fileInfo, VOS_BOOL enIsHaveUpdateOk) { VOS_CHAR ascExcuteFile[INSTALL_MAX_DIRNAME_LEN]={ 0 }; if(fileInfo.enLoadCheckResult == LS_SUCESS_UPDATE) { return VOS_TRUE; } if (fileInfo.enLoadCheckResult != LS_SUCESS_UPDATE &amp;amp;&amp;amp; (fileInfo.enLoadCheckResult != LS_NOT_NEED_UPDATE) &amp;amp;&amp;amp; (fileInfo.enLoadCheckResult != LS_OMU_NORESPONSE) &amp;amp;&amp;amp; (fileInfo.enLoadCheckResult != LS_OMU_REFUSE)) { BOOTTRACE(TRACE_ERR, &amp;#34;update file %s error and result=%d&amp;#34;, fileInfo.acFileName, fileInfo.enLoadCheckResult); return VOS_FLASE; } ... // 为了说明本文所要表达解决思路，不再呈现其它的if判断代码  if (fileInfo.ucFileType == PROG_FILE_TYPE ) { siRet = snprintf_s(ascExcuteFile, sizeof(ascExcuteFile), sizeof(ascExcuteFile)-1, &amp;#34;%s/%s&amp;#34;, fileInfo.acFileExecuteDir, fileInfo.acFileName); if (siRet &amp;lt;= 0 ) { BOOTTRACE(TRACE_ERR, &amp;#34;[%s:%d] snprintf_s failed,&amp;#34;, __FUNCTION__, __LINE__); return VOS_FLASE; } (void)chmod(ascExcuteFile, S_IRUSE | S_IXUSR); } return VOS_TRUE; } VOS_VOID PrintAllFileStatus(VOS_VOID) { for(VOS_INT count=0;count&amp;lt;g_downloadFileCount;count&#43;&#43;) { BOOTTRACE(TRACE_LOD, &amp;#34;%d update result is %d and local check result is %d.&amp;#34;, g_pstFileListInfo[count].acFileName, g_pstFileListInfo[count].enLoadCheckResult, g_pstFileListInfo[count].bLocalCheck); } } VOS_INT SleepAndTryBeginAgain(FileInfo&amp;amp; fileInfo) { VOS_UINT32 sleepTimeLen; if (fileInfo.enLoadCheckResult == LS_DISK_FULL){ sleepTimeLen=INSTALL_DISK_FULL_AGAIN_TIMELEN; } else { sleepTimeLen=INSTALL_CONNECT_OMU_AGAIN_TIMELEN; } BOOTTRACE(TRACE_ERR, &amp;#34;Update file error so sleep for %d second and try again&amp;#34;, sleepTimeLen); SLEEP(sleepTimeLen); if(LOAD_Begin(LD_STAGE_INSCHK, &amp;amp;g_downloadFileCount, g_pstFileListInfo, LD_ONLINE_UPDATE) != VOS_OK) { BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Begin return error&amp;#34;); return VOS_ERR; } return VOS_OK; } // 注：此函数不应该操作g_pstFileListInfo，而是通过参数传入，本文仅仅想说明其中的一个问题，其它函数也是如此 VOS_INT LOAD_CheckeStatus() { VOS_BOOL enIsHaveUpdateOk = VOS_FALSE; VOS_INT count = 0; while(VOS_TRUE) { for(count=0;count&amp;lt;g_downloadFileCount;count&#43;&#43;) { if (CheckOneFileStatus(g_pstFileListInfo[count], enIsHaveUpdateOk) == VOS_FALSE) { break; } else { enIsHaveUpdateOk = VOS_TRUE; } } if (count == g_downloadFileCount) { break; } if (SleepAndTryBeginAgain(g_pstFileListInfo[count]) == VOS_ERR ) { return VOS_ERR; } } BOOTTRACE(TRACE_TIP, &amp;#34;All %d files checked or updated OK.&amp;#34;, g_downloadFileCount); PrintAllFileStatus(); return VOS_OK; } VOS_INT STARTER_Download(VOD_VOID) { VOS_INT siRet; BOOTTRACE(TRACE_TIP, &amp;#34;Checking and updating files...&amp;#34;); if(LOAD_Init()==VOS_FALSE) { BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Init return error&amp;#34;); return VOS_ERR; } siRet=LOAD_Begin(LD_STAGE_INSCHK, &amp;amp;g_downloadFileCount, g_pstFileListInfo, LD_ONLINE_UPDATE); if(siRet != VOS_OK) { LOAD_End(); BOOTTRACE(TRACE_ERR, &amp;#34;The LOAD Begin return error&amp;#34;); return VOS_ERR; } siRet=LOAD_CheckeStatus(); if(siRet != VOS_OK) { LOAD_End(); return VOS_ERR; } BOOTTRACE(TRACE_DBG, &amp;#34;Exit STARTER_Download&amp;#34;); LOAD_End(); return VOS_OK; } 上面把STARTER_Download一个方法由上百行拆成了五个不同层次的方法，STARTER_Download 则变得非常简洁，也就非常直白地说明它做了几件事：
 加载初始化：LOAD_Init 加载开始： LOAD_Begin 加载后的检查：LOAD_CheckStatus 加载结束：LOAD_End  而LOAD_CheckStatus我们再进一步展开:
 遍历检查所有文件状态  检查单个文件状态：CheckOneFileStatus 一旦存在有失败的状态，则暂停 X sec，重新加载一遍：SleepAndTryBeginAgain   直到所有状态是LS_SUCESS_UPDATE 打印所有文件状态: PrintAllFileStatus  背后的知识 那年春节，宋丹丹问赵本山：“把大象装冰箱，总共分几步?”，宋丹丹哈哈一笑说：
 第一步，把冰箱门打开 第二步，把大象塞进去 第三步，把冰箱门关上  小品中的智力问答虽是笑料，但说明解一个复杂问题也简单的哲学：把需要解决的问题拆分成不同层次的问题，逐一解决。而现实是我们很容易一下子就会陷入怎么把大象塞进去的众多细节步骤中。
正如写一篇作文，当思路凌乱不知从哪里下手，回想老师曾经的写作指导:
 第一步，先解题，拆分文章层次 第二步，列出提纲，理清思路 第三步，逐层递进地写，丰富内容  单一抽象层次 案例中的代码它是一个Long method（长方法），往往是存在着代码坏味道。编程界的大佬提出一个 SLAP（单一抽象层次原则），就可以明确无争议的避免上述长方法的产生。
SLAP 是 Single Level of Abstraction Principle 的缩写：指定代码块的代码应该在单一的抽象层次上。
什么是抽象层次，光看概念这个有点难以理解，换句话指一个函数或者方法中的所有操作处于相同层次：
 抽象是循序渐进的，分层的 上层抽象看不到下层的具体实现  回到前面的代码与宋丹丹问题，我们发现了原来STARTER_Download函数的问题所在：
 不同层次的抽象实现杂合在一个层次上，一下了暴露了太多的细节分不清主次 把所有的业务逻辑堆积写在一个方法中，让人一下了难以理解函数解路思路  解决办法:
 将违背SLAP原则的代码按功能层次提取为独立的方法 提取的方法，它更加具有原子性，职责更加单一  结语 抽象层次是软件开发中极其重要但又非常难以掌握的技巧。抽象层次越高，具体信息越少，概括能力越强；反之，具体细节越丰富，结果越确定，也需要更多表达。软件开发过程中，主体上应当采用自顶向下的方法，分层循序渐进地展开。通过抽取模块、类、函数，把类似的功能放在同一层级。这样，代码的整洁度会大大的提升，整个代码的逻辑也会更加清晰。
</content>
    </entry>
    
     <entry>
        <title>飞哥讲代码1：确保资源被释放</title>
        <url>http://lanlingzi.cn/post/technical/2020/0516_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 案例 下面的代码来自我们某一工具源码(Python语言)中：
file_gz = gzip.GzipFile(file_name) src_path, src_file = os.path.split(file_name) tmp_file_name = os.path.join(path_name, src_file).strip(&amp;#39;gz&amp;#39;).strip(&amp;#39;.&amp;#39;) tmp_file = open(tmp_file_name, &amp;#39;wb&amp;#39;) tmp_file.writeline(file_gz.realines()) file_gz.close() tmp_file.close() os.remove(file_name) 从代码健壮角度来看，存在如下两个问题：
 缺少捕获异常，在GzipFile打开文件，open打开文件之后的操作都可能抛出异常 当抛出异常时，file_gz与tmp_file就会出现未正常close，存在文件句柄的泄露问题  能正确释放资源的建议写法是:
src_path, src_file = os.path.split(file_name) dst_file_name = os.path.join(path_name, src_file).rstrip(&amp;#39;.gz&amp;#39;) with gzip.GzipFile(file_name) as src_gz_file, open(dst_file_name, &amp;#39;wb&amp;#39;) as out_file: out_file.writeline(src_gz_file.realines()) os.remove(file_name) 还有一种写法，采用try-except-finally，在finally中对打开的文件关闭，但这种写法的代码显得臃肿。所以Python又提供上述示例中with语句写法。
背后的知识 with语句启用了上下文管理器，标准库中contextlib模块包含用于处理上下文管理器一些工具。
上下文管理器涉及两个方法:
 当进入内部代码块时，执行 __enter__() 方法, 返回要在上下文中使用的对象 当离开 with 块时，执行 __exit__() 方法，清理正在使用的任何资源  对于任何一个对象能够使用 with 语句来清理资源，只要像下面来提供 __enter__() 方法与 __exit__() 方法：
class Context: def __enter__(self): print(&amp;#39;__enter__()&amp;#39;) return self def __exit__(self, exc_type, exc_val, exc_tb): print(&amp;#39;__exit__()&amp;#39;) with Context(): print(&amp;#39;do somethon in the context&amp;#39;) file 类内嵌支持上下文管理器API，但有些历史遗留下的其他对象并不支持，标准库文档中给出的 contextlib 示例是 urllib.urlopen() 返回的对象。还有其他遗留类使用 close() 方法，但不支持上下文管理器API。要确保资源已关闭，要使用 closing() 为其创建上下文管理器。
class Resource: def __init__(self): print(&amp;#39;__init__()&amp;#39;) self.status = &amp;#39;open&amp;#39; def close(self): print(&amp;#39;close()&amp;#39;) self.status = &amp;#39;closed&amp;#39; with contextlib.closing(Resource()) as r: print(&amp;#39;inside with statement: {}&amp;#39;.format(r.status)) 另外 contextlib 模块还提供了装饰器来简化上下文管理器相关场景的代码开发，这里不展开讲了，有兴趣的同学找资料研究吧。
其它语言玩法 对于资源的简洁释放是所有编程语言都要解决的问题，举一反三，我们再来看看其它语言的一些玩法。
Java 在Java1.7之前，是采用try-catch-finally的方式解决:
BufferedInputStream bin = null; BufferedOutputStream bout = null; try { bin = new BufferedInputStream(new FileInputStream(new File(&amp;#34;input.txt&amp;#34;))); bout = new BufferedOutputStream(new FileOutputStream(new File(&amp;#34;out.txt&amp;#34;))); int br = -1; while ((br = bin.read()) != -1) { bout.write(br); } } catch (IOException e) { log.error(&amp;#34;....&amp;#34;); } finally { if (bin != null) { try { bin.close(); } catch (IOException e) { log.error(&amp;#34;....&amp;#34;) } } if (bout != null) { try { bout.close(); } catch (IOException e) { log.error(&amp;#34;....&amp;#34;); } } } 上面的代码是不是不够简洁？关闭资源也要 try-catch ，否则会导致后续的close未被执行。Java 1.7中新增的try-with-resource语法糖，简化的代码就成了如下：
try (BufferedInputStream bin = new BufferedInputStream(new FileInputStream(new File(&amp;#34;input.txt&amp;#34;))); BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(new File(&amp;#34;out.txt&amp;#34;))) ) { int br = -1; while ((br = bin.read()) != -1) { bout.write(br); } } catch (IOException e) { log.error(&amp;#34;....&amp;#34;); } 与Python的with语句用法与效果真是异曲同工。为了能够配合try-with-resource，资源必须实现AutoClosable接口。
如果熟悉lombok库的同学，也会知道有个 @Cleanup 注解，它会帮助你安全的调用close方法来释放资源，相比Java内建的try-with-resource语法糖，它还可以调用非close方法。@Cleanup（“dispose”），通过指定方法名来调用相应的方法来清理资源。不过约束是被调用的方法要求是无参数方法。
无论是try-with-resource，还是lombok的@Cleanup注解，他们都是语法糖，通过编译帮你生成的字节码在finally中调用close方法来释放资源。
Go 作为后起之秀的Go，对于资源释放的解决方法，相比Python与Java来得更灵活些。它提供了defer关键字:
src, err := os.Open(srcFile) if err != nil { return } defer src.Close() defer的底层实现是：defer后面的表达式会被放入一个列表中，在当前方法返回的时候，列表中的表达式就会被执行。采用栈数据结构，一个方法中，当存在多个defer语句时，先加入列表则后执行。
当然，由于defer后面可以跟匿名函数块，如：
func test() int { i := 0 defer func () { i&#43;&#43; fmt.Println(&amp;#34;defer2:&amp;#34;, i) // 打印结果为 defer2: 2  }() defer func () { i&#43;&#43; fmt.Println(&amp;#34;defer1:&amp;#34;, i) // 打印结果为 defer1: 1  }() return i // 假如返回值是a，此时a=i，defer中修改i的值不会影响返回值a，defer也根本访问不到a } 若是像上面代码在defer的函数中有使用前面的变量并对它进行修改，则引入了复杂性。有兴趣的同学的不烦再对defer深挖一下。是不是像Java一样要求，不要在finally中修改基本类型或对象中的值的既视感？
再来一个例子，对命名返回值修改：
func test() (i int) { i = 1 defer func() { i&#43;&#43; fmt.Println(&amp;#34;defer2:&amp;#34;, i) // 打印结果为 defer2: 3  }() defer func() { i&#43;&#43; fmt.Println(&amp;#34;defer1:&amp;#34;, i) // 打印结果为 defer1: 2  }() return i // 返回的结果是几？ } 它的返回值又是什么，还有更多的defer坑等你去发现哦。
C&#43;&#43; C&#43;&#43;其实在资源管理上是最为成熟，RAII技术被认为是C&#43;&#43;中管理资源的最佳方法。 RAII是C&#43;&#43;的发明者Bjarne Stroustrup老爷子提出的概念，RAII全称是Resource Acquisition is Initialization，直译过来是资源获取即初始化，也就是说在构造函数中申请分配资源，在析构函数中释放资源。
智能指针（std::unique_ptr）即RAII最具代表的实现，使用智能指针，可以实现自动的内存管理，再也不需要担心忘记delete造成的内存泄漏。内存只是资源的一种，如对于文件的打开与关闭，也可以使用RAII来解决，不过有点麻烦，按照常规的RAII技术需要写一堆管理它们的类。
不过C&#43;&#43;11有lambda表达式，结合std::function，我们可以利用RAII机制完美地模拟Go的defer（效果与Go还是有些区别的，Go 是函数级，它是代码块级）：
#define SCOPEGUARD_LINENAME_CAT(name, line) name##line #define SCOPEGUARD_LINENAME(name, line) SCOPEGUARD_LINENAME_CAT(name, line) #define DEFER(callback) ScopeGuard SCOPEGUARD_LINENAME(EXIT, __LINE__)(callback)  class ScopeGuard { public: explicit ScopeGuard(std::function&amp;lt;void()&amp;gt; f) : handleExitScope(f){}; ~ScopeGuard() { handleExitScope(); } private: std::function&amp;lt;void()&amp;gt; handleExitScope; }; { std::ofstream file(&amp;#34;test.txt&amp;#34;); DEFER([&amp;amp;] { file.close(); }); } 上面的代码看起来是不是很Clean，妈妈再不用担心我的代码出现资源泄露了^_^。
结语 程序使用的资源，不仅仅是CPU与内存。在内存管理方面，有垃圾回归器的语言帮程序员省了很多事。但广义上资源还有文件、流、管道、连接与锁等等，这些都需要开发者手动关闭他们，否则随着程序的不断运行，资源泄露将会累积成重大的生产事故。我们也许会记得在正常流程中关闭这些资源，却可能经常忽视了异常分支场景，我们应该利用语言中最新的特性，既使代码Clean，能又能确保资源被正常释放。
</content>
    </entry>
    
     <entry>
        <title>阅读</title>
        <url>http://lanlingzi.cn/post/thoughts/2020/0329_read/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>写作</tag>
        </tags>
        <content type="html"> 生于80后，长相70后的我们，不知不觉已将跨入不惑不年。但还是为了房子、孩子、票子日复一日地忙碌工作，曾经年少的理想也慢慢被岁月磨平，也根本没有精力抽出一丁点的时间来读一本书，仰望一下星空。有人说：一日不读书，无人看得出；一周不读书，开始会爆粗；一月不读书，智商输给猪。当停下手中的工作工作，才发现自己知识结构那么地匮乏。
曾经梦想把阅读当成生活的重要组成部分，把阅读当作精神升华的方式。有自己一个独立的书房，书柜上摆上经典的、实用的、消遣的书籍，在空闲的时间里抱上一本细细咀嚼，娴静地阅读，享受书的世界，感受书的力量。
有些事，我们明知道是错的，也要去坚持，因为不甘心；有时候，我们明知道没有路了，却还在前行，因为习惯了。没有正确的方向，再多报努力也可能没有结果。阅读才能使自己的内心强大，也不会陷入死胡同，走正确的路，即时放弃错误的持着。
阅读是通向内心安宁的一条通道，它除了能解决人的生存之外，还能给心灵以慰藉，让人真正地拥有幸福。正是如此，做人要静得下心读书，读书了心不浮躁了，人心静了，就能坚守自己的初心，实现自己的人生梦想。
余秋雨先生说，阅读的最大理由是想摆脱平庸。谁都不想平庸，可总是有人在自己不查的情况下加入到庸庸之众的行列。因为什么呢？就是因为没有充实厚重的内心。只知盲目从众，昏昏度日，世俗的观点即是无误，人生最大目标不过是完成物质的丰厚。
阅读是一辈子的事情，一个养成了读书习惯的人，和一个不爱读书的人，他们其实生活在不同的世界里，看事物的观点也是大相径庭。现在我担心的，就是活在一个不爱读书的人的世界时，看见好的东西，除了一句WoCao，看不到事物背后的力量。
我是谁？想要什么样的生活？如何改变我自己？不只一次的问过自已。阅读想改变自己最基础的要求，通过阅读开阔自己的眼界，才能更容易看透彻一些事情，才能清楚地认识到真正需要什么。在人生的漫长旅途中，孤独是心灵的最大猎手，而书籍就像一位良友一直陪伴你左右。当经济下行，偶像坍塌，信仰失衡，才不至于自己完全处于一种茫然而无所适从的状态。
</content>
    </entry>
    
     <entry>
        <title>软件工程文化</title>
        <url>http://lanlingzi.cn/post/technical/2020/0322_engining/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 软件危机 软件工程师的困惑：软件具有太多的不确定性，软件工程师每天日复一日的工作，大多数面对的都是自己目前不知道答案的问题。我们依赖着过去的经验，朝着大致的方向，努力地解决一个又一个问题。但历史的经验并不解决未来的问题，反面太多成功的经验可能会让我们陷入经验主义。我们也会经常责怪前人犯下的错误，需要我们去应对。我们讨厌需求的变更，它让我们曾经的付出付诸东流。变更是软件开发中不可避免的，所以我们在任何的阶段都要去适应变。即使软件发布了，也不可能一劳永逸，它像一个生命体还得继续维护。
从软件项目管理角度的困惑，软件存在所谓的软件危机：软件的开发进度难以预测；软件的开发成本难以控制；软件的功能难以满足用户；软件的产品质量无法保证；软件产品难以维护&amp;hellip;..
正如《人月神话》中描述的一样：
 正像一只逃亡的野兽落到泥潭中做垂死的挣扎，越是挣扎，陷入越深，最后无法逃脱灭顶的灾难。
 软件工程学试图通过建立并使用良好的工程原则，以经济的成本方式，在目标的运行环境上，获得可靠并高效的运行软件。从早期的CMM，到传统的敏捷方法（Scrum/极限编程），到现在DevOps研发模式，以及各大厂产品线级工程实施。都在不同的阶段不同的场景一定程度地缓解了软件危机。
软件工程 软件工程学，就需要研究软件进行的一般规律，通过应用方式、方法，并持续进行改良研究。那又我们又如何理解软件工程？软件工程应该是也符合一般的工程性原则，包含规范化的过程，强调工具化和文档化。为了遵循实用性的原则，经常需要做多方面的权衡。
软件不像其它的项目工程，有些它自身独特的困难。软件是抽象的、不可见的、人思维逻辑的产物，容易变化也很容易变得很复杂。软件产品本身是去解决其它领域的问题，并可以应用于几乎所有领域，而领域差异性和多样性很强。
因此，不同的领域软件玩法可以差别极大，没有一套放之四海而皆准的打法。比如嵌入式系统与互联网的电商系统它们的技术体系与应用场景差异性很高。虽然软件工程的一般原则和思想像哲学一样可以高度概括都适用，但具体的实施方法和技术层面存在很大的差异。
工程文化 既然没有放之四海而皆准的打法，但还是有些实用的工程文化。
有效运转：让软件开发这事可以有效地运转起来。在适当的地方选择性的应用相关理论，方法和工具，即使没有可用的理论与方法，也会有试图发现问题的解决方案。在组织和经济约束如商用策略，成本，时间约束等条件下工作，并且必须考虑在这些约束之下寻求解决方案，没有约束是不可能也不现实的。
权衡决策：不要做一个完美的软件产品，追求实用而非完美，在进度与预算范围内追求品质，不同的方案中做权衡取舍决策，正如敏捷中所提倡的做刚刚好的系统。
精益敏捷：根据具体情况选择合适的方法，一般采用系统化、有组织的方法以实现高质量的软件开发。更加灵活、支持快速变化的开发方法在某些情况下是适用的，例如小规模的Web系统或移动应用。充分考虑软件的特点，就像需要市场经济与计划经济相结合，采用去中心的决策机制，分层授权，精益与敏捷相结合原则。
善于复用：利用已有的软件知识开发新的软件。通过复用封装专家知识，多次复用的软件经过检验，质量更可靠，复用软件成本可知，不确认性更低一些。复用能减少软件开发的和确认的时间，复用也使得实现更加的标准和统一。
加强协作：促进软件研发、运营与客户之间的沟通、协作，通过快速反馈提升软件的用户体验和研发效率。注重彼此之间的沟通，持续交付可靠且满足预期的软件产品与服务，降低不必要的返工和成本。
</content>
    </entry>
    
     <entry>
        <title>开源软件知识</title>
        <url>http://lanlingzi.cn/post/technical/2019/1013_opensource/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>OpenSource</tag>
        </tags>
        <content type="html"> 什么是开源软件 开放源代码促进会（OSI：Open Source Initiative），是一个致力于推动开源软件发展的非盈利组织。
开源软件（OSS：Open Source Softwar）即开放源代码软件，其定义首先起源于自由软件（FS：Free Software）。OSI将开放源码定义为：“开放源码，通过支持源代码的独立同行评议和快速发展演变，提高了软件的可靠性和质量。要通过 OSI 认证，软件必须在获得许可证的情况下发布，该许可证可保证免费读取、重新发布、修改和使用该软件的权利。
开源软件的特点：可自由使用、无任何担保、无许可费、可获得源代码、享有版本、有特定License
开源软件的三大组成要素；
 License：是游戏规则 ，有严密的组织监管 社区是组织方式：是其发展的核心学问所在，主要特征：无明确路标、子项目充分竞争、充分的对等评审、用户充分参与、源码发布、经常发布，Internet发布。 商业模式是本质：模式并不是其独有的，主要包括：捐赠、技术服务、广告、增值产品，双重授权、软硬件结合等。  自由软件VS开源软件VS免费软件
“自由软件运动”是一项倡导软件这种知识产品应该免费共享的社会运动，它主要是从社会伦理学，道德的高度，强调我们每个人都有自由使用软件的权利。自由软件反对软件私有，首先反对的就是软件的知识产权、版权，所以自由软件运动明确反对以申请专利的形式将软件产品据为私有。为了表达对Copyright（知识产权）的憎恶，Stallman甚至生造了一个单词Copyleft。
自由软件运动有点太极端、太理想化了，生活在这么一个商品化社会，要完全如此的反商业，还是很有难度。自由软件和商业软件之间的折中&amp;mdash;-开源软件就此诞生了，它既继承了自由软件所提倡的知识共享的理念，同时又允许人们以专利的形式从知识产品中谋取利益，从而保护了人们生产、创造知识产品的积极性。
免费软件就是免费提供给用户使用的软件，但是其免费的时候，通常都会有其他的限制，比如其源码不一定会公开，而且使用者也并没有使用、复制、研究、修改和再散布的权利。
开源License License是游戏规则，是开源软件许可证。在开源软件代码仓/包中，通常在NOTICE，COPYRIGHT，AUTHOR，README，COPYING，LICENSE说明其采用的开源许可证。
开源软件使用遵从义务：按照开源软件软件许可证规定开源软件使用者需要覆行的义务
 开源使用声明义务：在产品发布时，随产品附上一份文档Open Source Softwre Note，在该文档中写明产品所有使用的开源软件及其版权和许可证信息，并附上免责声明。 代码对外开源义务：按照开源许可证要求，将一定范围内的代码对外开源，开源范围视具体许可证的要求和使用方式而定。 修改声明义务：做出对修改的开源软件就修改时间，修改的代码以及修改过的文件做出具体的声明。  BSD类 BSD许可证原先是用在加州大学柏克利分校发表的各个BSD4.4/BSD4.4-Lite版本上面（BSD：Berkly Software Distribution）的，后来也就逐渐沿用下来。1979年加州大学伯克利分校发布了BSD Unix，被称为开放源代码的先驱，BSD许可证就是随着BSD Unix发展起来的。
BSD授权许可证没有实现&amp;quot;通透性&amp;quot;自由，也就是其不保证软件源代码开放的连续性。这样如果你希望采用别人开发的BSD软件，进行一些修改，然后作为产品卖，或者仅仅保密自己做的一些除了软件开发以外的工作，那么你就可以从中得利。
 Apache V2.0：如ACE，Tomcat BSD：Berkly Software Distribution，如FreeBSD MIT：Massachusetts Institute of Technology，X License，如X Windows，ASN.1  许可说明：
 允许各种链接，无开源义务 允许修改，无开源义务 软件所有人授予专利许可（Apache）、无专利规定（BSD、MIT）  推荐使用，商业友好许可证。
MPL类 MPL是The Mozilla Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对 源代码的需求和他们利用源代码获得的利益。
 CPL V1.0：Common Public License，如Junit EPL V1.0：Eclipse Public License，如Eclipse MPL V1.0：Mozilla Public License，如Firefox CDDL V1.0： Common Development and Distribution License，如OpenSolaris  许可说明：
 允许各种链接，无开源义务 允许修改，但修改部分需要开源 部分源码使用，或全部源使用与私有代码混合使用，会被视为对原有软件使用，则混用私有代码需要开源 软件所有人授予专利许可  可以使用，但关注修改后对应的开源义务。
GPL类 1980年美国人Richard Stallman因为无法容忍软件私有化，而建立了GPL许可证。他认为，软件的源代码是全人类的财富，应该允许程序员自由共享。
GPL许可证的核心含义是，允许任何人观看、修改，并散播程序软件里的原始程序码，条件是如果你要发布修改后的版本就要连源代码一起公布。
LGPL V2：
 许可说明  允许各种链接，动态链接无开源义务，静态链接需要开放与之链接私有软件的.o文件与makefile 允许修改再链接到私有软件，但是个性增加的功能实现不能依赖私有软件的数据功能 允许不受限制的使用头文件中数值参数，数据结构布局，存取，小宏，内联参数，十行以内的模板 仅原则性声明专利应免费许可，无详细规定   慎重使用，只允许动态链接方式使用  GPL V2：
 许可说明  允许各种链接，但被链接的整个产品需要开源 允许修改，但被修改的部分及整个产品均需要开源 通过pipes, sockets的命令行参数与GPL软件进行通讯，不会导致私有软件被传染 仅原则性声明专利应免费许可，无详细规定   慎重使用，由于可能导致产品整个负有开源义务，不建议使用  社区 社区是松散的组织方式，人人都可参与
 正式或非正式的网络支持 软件代码公开、共享 由志愿者运作管理 有多样性的可用资源 任何人可参与 非盈利组织  开源维权组织
 OSI（开源促进委员会）定义所有开源License FSF（自由软件基金会）是业界软件最大的开源软件维权组织 Software Freedom Law Center（软件自由律师联盟）  社区两种组织方式：
 会员制：如Liunx社区 集市：如Apache社区  区分社区可采用如下开放性原则：
 Open Code：只提供源码 Open Release：提供源码&#43;软件包 Open Dev：透明的开发过程 Community：透明的管理  Apache社区的组织架构：
 Contributor：任何人都可参是Contributor，但无代码库写权限，提交的内容需要Committer审核通过后才能合入代码库 Committer：相比Contributor增加代码库写权限 PMCer：社区项目有相关的决策权，能够影响项目的发展方向。有权提议将Contributor提升为Committer VP：项目的VP，领域专家 董事会：负责管理赞助，法务，品牌，公共事务，提议创建新项目，不参与具体项目管理  商业模式  捐赠模式：将项目捐赠给开源社区，达到打击竞争对手，或占领市场的目的 增值产品：在开源软件基础上开发增值产品 广告模式：在软件中植入广告，赚取广告投放费用 服务模式：提供开源相应的专业服务 双重授权：同时使用开源软件与商业授权模式 软硬件结合：通过对开源软件的支持，促进硬件的销售 社区模式：指那些并非为营利而存在的开源组织的运营模式，通过宣传，合作和开发、编写更好软件提供更好的技术支持，领导业界发展趋势。  使用开源 使用开源软件可能存在风险
 使用的开源软件可能没有维护 不可捉摸，未来没有固定的路标计划 发现Bug没有管，提交修改没有人理会 &amp;hellip;  用好开源软件基本要求
 来源可靠：来源正规社区官方网站，供应商或合作商提供，软件有明确的许可性或签订有相关使用协议 合法合规：按许可性要求使用，避免知识产权；履行开源义务；获取授权 网络安全：选型与评估，漏洞闭环管理，安全问题处理 可追溯：统一管理，先申请后使用，变更受控，修改记录可控 优选归一：建立优选库，给出优选版本与禁用版本等 生命周期管理：生命周期与产品版本配套  用好开源软件的秘决：
 生态选型：关键看是否可持续发展 架构解耦：架构上要适应开源软件频繁更迭 社区协同开发：影响力不是重点，关键是达成产品商用生态要求 同步社区特性及测试套：建立测试基线，构建验证的防护网 回馈社区：根据使用开源软件的重要程序，主导或参与社区实践，及明回馈社区。  开源软件声明的范围与内容
 范围：只需要声明开源软件，其它采购软件，免费软件，技术合作等非开源软件不在使用声明文档中声明 内容：使用声明文档、不担保声明，软件版本声明，软件许可证声明，书面邀约（GPL，LGPL需要开源义务的软件）  产品发布时，开源软件包的要求：
 完整性：开源范围满足License要求，如须包含所有GPL与LGPL代码，以及传染部分 可编译性：开源代码必须能够编译通过，提供详细的编译指导文档，不能含有.git等文件夹等冗余信息 一致性：开源代码包编译结果与产品发布中使用的开源部分一致；不得包含不涉及开源义务履行的二进制文件（若源始开源包含了，则要相应提供）  修改声明义务：
 修改时间 修改内容，简要说明修改内容 修改人及邮箱 若新增文件，则需要在文件头附上版本声明与免责声明 </content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-10：工具体系</title>
        <url>http://lanlingzi.cn/post/technical/2019/1006_java_base_10/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> JVMTI JVMTI（Java VM Tool Interface）就是JVM对外暴露的接口。
JVMTI 本质上是在JVM内部的许多事件进行了埋点。通过这些埋点可以给外部提供当前上下文的一些信息。甚至可以接受外部的命令来改变下一步的动作。外部程序一般利用C/C&#43;&#43;实现一个JVMTI Agent，在Agent里面注册一些JVM事件的回调。当事件发生时JVMTI调用这些回调方法。Agent可以在回调方法里面实现自己的逻辑。JVMTI Agent是以动态链接库的形式被虚拟机加载的。
JVMTI Agent启动方式： -agentlib:&amp;lt;agent-lib-name&amp;gt;=&amp;lt;options&amp;gt;
JVMTI Agent回调函数：
 OnLoad阶段： 调用动态库的Agent_OnLoad函数 Live阶段： 调用动态库的Agent_OnAttach函数 关闭阶段：调用动态库的Agent_OnUnload函数  JVMTI 并不一定在所有的 Java 虚拟机上都有实现，不同的虚拟机的实现也不尽相同。
JVMTI用途  对class文件加密：使用一些常规的手段（例如使用混淆器或者自定义类加载器）来对class文件进行加密很容易被反编译。使用JVMTI我们可以将解密的代码封装成.dll,或.so 文件。这些文件想要反编译就很麻烦了，另外还能加壳。解密代码不能被破解，从而也就保护了我们想要加密的class文件。 实现应用性能监控(APM)：基于JVMTI的APM能够解决分布式架构和微服务带来的监控和运维上的挑战。APM通过汇聚业务系统各处理环节的实时数据，分析业务系统各事务处理的交易路径和处理时间，实现对应用的全链路性能监测。开源的Pinpoint，ZipKin，Hawkular；商业的AppDynamics，OneAPM，Google Dapper等都是个中好手。 产品运行时错误监测及调试：基于JVMTI可以开发出一款工具来时事监控生产环境的异常。这方面有一款成熟的商业软件OverOps，其有三个主要的功能：1. 采集到所有的异常，包括try catch之后没有打印出来的异常；2. 可以采集到异常发生时上下文所有变量的值；3. 可以将异常发生的堆栈对应的源代码采集展示出来，从而在一个系统上就可以看代码定位问题，不需要打开ide调试源代码。 JAVA程序的调试(debug)：google甚至推出了云端调试工具cloud debugger。它时一个web应用，可以直接对生产环境进行远程调试，不需要重启或者中断服务。阿里也有类似的工具Zdebugger。 JAVA程序的诊断(profile)：当出现cpu使用率过高、线程死锁等问题时，需要使用一些JAVA性能剖析或者诊断工具来分析具体的原因。例如Alibaba开源的Java诊断工具Arthas，它可以查看或者动态修改某个变量的值、统计某个方法调用链上的耗时、拦截方法前后，打印参数值和返回值，以及异常信息等。 热加载：热加载指的是在不重启虚拟机的情况下重新加载一些class。热加载可以使本地调试代码非常节省时间，不用每次更新代码都重启一边程序。同时，在一线不方便重启的线上环境也能派上用场。这方面的代表产品有商业产品JRebel等。  Instrumention Java虽然提供了JVMTI，但是对应的Agent需要用C/C&#43;&#43;开发，对Java开发者而言并不是非常友好。因此在Java 5的新特性中加入了Instrumentation机制。有了 Instrumentation，开发者可以构建一个基于Java编写的Agent来监控或者操作JVM了，比如替换或者修改某些类的定义等。
使用参考：跟我一起复习Java-6
Attach 开发的Agent需要启动就必须在JVM启动时设置参数，但很多时候我们想要在程序运行时中途插入一个Agent运行。在Java 6的新特性中，就可以通过Attach的方式去加载一个Agent了。
Attach机制的实现涉及到了进程间的通信。主要涉及到两个JVM的线程：
 Attach Listener：用于JVM进程间的通信，但是它不一定会启动，启动它有两种方式。 Signal Dispatcher： 用于处理信号  启动Attach Listener方式
 命令行参数启动：java -XX:&#43;StartAttachListener 依靠Signal Dispatcher线程来启动  Attach Listener线程启动后，就会创建一个监听套接字，并创建了一个文件/tmp/.java_pid的IPC socketFile，之后客户端和目标JVM进程就通过这个socketFile进行通信。客户端可以通过这个socketFile发送相关命令。Attach Listener线程做的事情就是监听这个socketFile，发现有请求就解析，然后根据命令执行不同的方法，最后将结果返回。
JPDA JPDA（Java Platform Debugger Architecture）是Java提供的一套用于开发Java调试工具的规范，任何的JDK实现都需要实现这个规范。JPDA是一个Architecture，它包括了三个不同层次的规范。
/ |--------------| / | VM | debuggee - ( |--------------| &amp;lt;------- JVMTI - Java VM Tool Interface \ | back-end | \ |--------------| / | comm channel - ( | &amp;lt;--------------- JDWP - Java Debug Wire Protocol \ | / |--------------| / | front-end | debugger - ( |--------------| &amp;lt;------- JDI - Java Debug Interface \ | UI | \ |--------------| JDPA由3个模块组成：
 JVMTI，即底层的相关调试接口调用。Oracle公司提供了一个jdwp.dll( jdwp.so)动态链接库，就是我们前面说的Agent实现。 JDWP（Java Debug Wire Protocol）,定义了Agent和调试客户端之间的通讯交互协议。 JDI（Java Debug Interface），是由Java语言实现的。有了这套接口，我们就可以直接使用Java开发一套自己的调试工具。  下面启动Debug命令即采用Agent实现：
-agentlib:jdwp=transport=dt_socket,server=y,address=8787
Linux下会使用libjdwp.so这个动态链接库。JVM启动的时候会去调用Agent的Agent_OnLoad方法，这个方法中会去解析我们传进来的transport=dt_socket,server=y,address=8787。
参数说明 JDK1.5 之前
-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8888,onthrow=java.io.IOException,launch=/sbin/echo
JDK1.5 之后，老的还是可以使用
-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8888,onthrow=java.io.IOException,launch=/sbin/echo
参数说明
 -Xdebug：是通知JVM工作在DEBUG模式下 -Xrunjdwp：是通知JVM使用(java debug wire protocol)来运行调试环境 -agentlib:jdwp：通过JavaAgent加载jdwp动态库，见前面的介绍 transport：指定了调试数据的传送方式，dt_socket是指用SOCKET模式，另有dt_shmem指用共享内存方式，其中，dt_shmem只适用于Windows平台 server：参数是指是否支持在server模式的VM中 suspend：是否在调试客户端建立起来后，再执行JVM address：启动地址，与transport有关 onthrow：当产生该类型的Exception时，JVM就会中断下来，进行调式。该参数可选。 launch：当JVM被中断下来时，执行的可执行程序。该参数可选 onuncaught：值为y或n，出现uncaught exception 后，是否中断JVM的执行  样例：
 transport=dt_socket,server=y,address=8000  : 在8000端口监听Socket连接，挂起VM并且不加载运行主函数直到调试请求到达 transport=dt_shmem,server=y,suspend=n : 选择一个可用的共享内存（因为没有指address）并监听该内存连接，同时加载运行主函数 transport=dt_socket,address=myhost:8000  : 连接到myhost:8000提供的调试服务（server=n，以调试客户端存在），挂起VM并且不加载运行主函数 transport=dt_socket,server=y,address=8000, onthrow=java.io.IOException,launch=/usr/local/bin/debugstub  : 等待java.io.IOException被抛出，然后挂起VM并监听8000端口连接，在接到调试请求后以命令/usr/local/bin/debugstub dt_socket myhost:8000执行 transport=dt_shmem,server=y,onuncaught=y,launch=d:\bin\debugstub.exe : 等待一个RuntimeException被抛出，然后挂起VM并监听一个可用的共享内存，在接到调试请求后以命令d:\bin\debugstub.exe  官方参考：optionX
JDK工具 Oracle的JDK提供一些常用工具，用于定位Java问题。
jps 显示当前所有java进程pid的命令，我们可以通过这个命令来查看到底启动了几个java进程。
 jps -l : 输出应用程序main.class的完整package名或者应用程序jar文件完整路径名 jps -v : 输出传递给JVM的参数  jps的实现机制：
java程序启动后，会在目录/tmp/hsperfdata_{userName}/下生成几个文件，文件名就是java进程的pid，因此jps列出进程id就是把这个目录下的文件名列一下而已，至于系统参数，则是读取文件中的内容。
jstack 用于生成指定进程当前时刻的线程快照，线程快照是当前java虚拟机每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致长时间等待。
jmap 主要用于打印指定java进程的共享对象内存映射或堆内存细节。
 jmap pid： 输出的信息分别为：共享对象的起始地址、映射大小、共享对象路径的全程。 jmap -heap pid： 输出堆使用情况 jmap -histo pid：输出堆中对象数量和大小 jmap -dump:format=b,file=heapdump pid：将内存使用的详细情况输出到文件，然后使用jhat命令查看该文件：jhat -port 4000 文件名 ，在浏览器中访问http:localhost:4000/  jstat 主要是对java应用程序的资源和性能进行实时的命令行监控，包括了对heap size和垃圾回收状况的监控。
jstat -&amp;lt;option&amp;gt; [-t] [-h&amp;lt;lines&amp;gt;] &amp;lt;vmid&amp;gt; [&amp;lt;interval&amp;gt; [&amp;lt;count&amp;gt;]]
 option：我们经常使用的选项有gc、gcutil、class、compiler vmid：java进程id interval：间隔时间，单位为毫秒 count：打印次数  样例：
 jstat -gc PID 5000 20： 输出堆中各分代的使用容量与GC的次数与所用时间 jstat -gcutil PID 5000 20：输出堆中各分代的使用容量百分比  jinfo 用来查看正在运行的java运用程序的扩展参数，甚至支持在运行时动态地更改部分参数。
jinfo -&amp;lt;option&amp;gt; &amp;lt;pid&amp;gt;
 -flag &amp;lt;name&amp;gt;：打印指定java虚拟机的参数值 -flag [&#43;|-]&amp;lt;name&amp;gt;：设置或取消指定java虚拟机参数的布尔值 -flag &amp;lt;name&amp;gt;=&amp;lt;value&amp;gt;：设置指定java虚拟机的参数的值  jcmd JDK 1.7之后新增，用于向正在运行的JVM发送诊断信息请求。也可用来导出堆，查看java进程，导出线程信息，执行GC等。jcmd拥有jmap的大部分功能，Oracle官方建议使用jcmd代替jmap。
jstatd 是一个RMI服务器应用程序，用于监控JVM的创建与终止，并提供一个接口允许远程监控工具依附到在本地主机上运行的JVM。
jstatd服务器需要在本地主机上存在一个RMI注册表。jstatd服务器将尝试在默认端口或-p port选项指定的端口附加到该RMI注册表上。如果RMI注册表不存在，jstatd应用程序将会自动创建一个，并绑定到-p port选项指定的端口上，如果省略了-p port选项，则绑定到默认的RMI注册表端口。
 注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-9：JNI/JIT/SM</title>
        <url>http://lanlingzi.cn/post/technical/2019/1005_java_base_9/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> JNI JNI是Java Native Interface的缩写，通过使用 Java本地接口书写程序，可以确保代码在不同的平台上方便移植。JNI标准成为java平台的一部分，它允许Java代码和其他语言写的代码进行交互。JNI一开始是为了本地已编译语言，尤其是C和C&#43;&#43;而设计的，但是它并不妨碍你使用其他编程语言，只要调用约定受支持就可以了。
JNI开发流程主要分为以下6步：
 编写声明了native方法的Java类 将Java源代码编译成class字节码文件 用javah -jni命令生成.h头文件（javah是jdk自带的一个命令，-jni参数表示将class中用native声明的函数生成jni规则的函数） 用本地代码实现.h头文件中的函数 将本地代码编译成动态库（windows：*.dll，linux/unix：*.so，mac os x：*.jnilib） 拷贝动态库至 java.library.path 本地库搜索目录下，并运行Java程序  数据类型 其实不能互通的原因主要是数据类型的问题，JNI解决了这个问题，例如那个c文件中的jstring数据类型就是java传入的String对象，经过JNI函数的转化就能成为c的char*。
基本数据类型
   Java 类型 JNI本地类型 C/C&#43;&#43;数据类型 说明     boolean jboolean unsigned char 无符号，8 位   byte jbyte signed char 有符号，8 位   char jchar unsigned short 无符号，16 位   short jshort signed short 有符号，16 位   int jint signed int 有符号，32 位   long jlong signed long 有符号，64 位   float jfloat float 32 位   double jdouble double 64 位    引用数据类型
   Java数据类型 JNI的引用类型 类型描述     java.lang.Object jobject 可以表示任何Java的对象，或者没有。JNI对应类型的Java对象（实例方法的强制参数）   java.lang.String jstring Java的String字符串类型的对象   java.lang.Class jclass Java的Class类型对象（静态方法的强制参数）   Object[] jobjectArray Java任何对象的数组表示形式   boolean[] jbooleanArray Java基本类型boolean的数组表示形式   byte[] jbyteArray Java基本类型byte的数组表示形式   char[] jcharArray Java基本类型char的数组表示形式   short[] jshortArray Java基本类型short的数组表示形式   int[] jintArray Java基本类型int的数组表示形式   long[] jlongArray Java基本类型long的数组表示形式   float[] jfloatArray Java基本类型float的数组表示形式   double[] jdoubleArray Java基本类型double的数组表示形式   java.lang.Throwable jthrowable Java的Throwable类型，表示异常的所有类型和子类   void void N/A    双向访问 每个JNI固有方法都会接收一个特殊的自变量作为自己的第一个参数：JNIEnv自变量。利用JNIEnv自变量，程序员可访问一系列函数。
 传递或返回数据 操作实例变量或调用使用垃圾回收的堆中对象的方法 操作类变量或调用类方法 操作数组 对堆中对象加锁,以便被当前线程独占 创建对象 加载类 抛异常 捕获本地方法调用的Java方法抛出的异常 捕获虚拟机异常 告诉垃圾回收器某个对象不再需要  函数注册 JNI函数的注册：将Java层的native函数和JNI层对应的实现函数关联起来。
 静态注册：通过java对象中声明native方法 动态注册：通过JNINativeMethod结构用来记录Java的Native方法和JNI方法的关联关系  System.loadLibrary(&amp;ldquo;xxx&amp;rdquo;)用于加载动态库。
JIT JIT是Just In Time compiler的简称。，Java 程序最初是通过解释器（ Interpreter ）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁的时候，就会把这些代码认定为“热点代码”。为了提高热点代码的执行效率，在运行时，即时编译器（Just In Time Compiler ）会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化。
热点代码 在运行过程中会被即时编译的“热点代码”有两类，即：
 被多次调用的方法 被多次执行的循环体  判断一段代码是否是热点代码，探测算法有两种：
 基于采样的热点探测（Sample Based Hot Spot Detection）：虚拟机会周期的对各个线程栈顶进行检查，如果某些方法经常出现在栈顶，这个方法就是“热点方法”。好处是实现简单、高效，很容易获取方法调用关系。缺点是很难确认方法的reduce，容易受到线程阻塞或其他外因扰乱。 基于计数器的热点探测（Counter Based Hot Spot Detection）：为每个方法（甚至是代码块）建立计数器，执行次数超过阈值就认为是“热点方法”。优点是统计结果精确严谨。缺点是实现麻烦，不能直接获取方法的调用关系。  compile模式  client-compiler：是主要跑在客户端本地的。特点是使用资源少启动快速。 server-compiler：跑在服务器上，因为服务器上程序本身是长时间运行的，而且对启动时间没有严格的要求。那么就可以牺牲启动时间获得深度的优化。 tiered-compiler：是两者的结合体。在启动之初用client的方案，并且收集数据。随着时间的推移，使用服务器的解决方案并使用之前收集的数据。这样做可以充分利用二者各自的优势，实现最佳的优化结果。  一般而言，client-compiler会提升大概五到十倍的运行效率。server-compiler比client-compiler提升百分之五十左右，但是需要以更多的资源作为代价。
常见的优化 JIT的核心就是分析代码，优化运行效率。一方面是，代码可能写的不够最优，由JIT代替程序员做一些优化。另一方面是，程序代码本身没问题，但是cpu和内存的操作可以进一步优化，这些程序员并不知道，由JIT来帮程序员做了。
 未使用和去重：就是检查一下代码上下文，删一删。 loop：这个主要是优化方式是减少程序运行指针的jump操作。优化方案有把loop展开，这样不用跳转顺序执行即可；用if加do while代替while，感觉这样操作只解决了一个特殊情况，且增加了复杂度，并没什么必要。 inline：这个操作应该是JIT的核心之一。解决的问题还是指针跳转和机器码重用。具体操作就是把常用的代码段对应机器码直接插入到caller那里。  SecurityManager 应用都可以有自己的安全管理器，它是防范恶意攻击的主要安全卫士。安全管理器通过执行运行阶段检查和访问授权，以实施应用所需的安全策略，从而保护资源免受恶意操作的攻击。
基本概念  策略(Policy)：类装载器用Policy对象帮助它们决定，把一段代码导入虚拟机时应该给它们什么样的权限. 任何时候，每一个应用程序都只有一个Policy对象. 保护域(ProtectionDomain)：当类装载器将类型装入java虚拟机时，它们将为每一个类型指派一个保护域，保护域定义了授予一段特定的代码的所有权限.装载入java虚拟机的每一个类型都属于一个且仅属于一个保护域。  默认的安全管理器配置文件是 $JAVA_HOME/jre/lib/security/java.policy
使用方式 SecurityManager提供一系列的checkXXX方法，用于应用是否有权限操作。这些check方法，分别囊括了文件的读写删除和执行、网络的连接和监听、线程的访问、以及其他包括打印机剪贴板等系统功能。安全管理器可以自定义，作为核心API调用的部分，我们可以自己为自己的业务定制安全管理逻辑。
AccessController最重要的方法就是checkPermission()方法，作用是基于已经安装的Policy对象，能否得到某个权限。
AccessController的使用还是重度关联类加载器的。如果都是一个类加载器且都从一个保护域加载类，那么你构造的checkPermission的方法将正常返回。
AccessController另一个比较实用的功能是doPrivilege（授权）。假设一个保护域A有读文件的权限，另一个保护域B没有。那么通过AccessController.doPrivileged方法，可以将该权限临时授予B保护域的类。
启动方式  启动参数方式：-Djava.security.manager -Djava.security.policy=&amp;quot;java.policy&amp;quot; 编码方式启动：System.setSecurityManager(new SecurityManager());  配置文件 在启用安全管理器的时候，配置遵循以下基本原则：
 有配置的权限表示没有。 只能配置有什么权限，不能配置禁止做什么。 同一种权限可多次配置，取并集。 统一资源的多种权限可用逗号分割。  样例：
grant codeBase &amp;#34;file:${{java.ext.dirs}}/*&amp;#34; { permission java.security.AllPermission; }; grant { permission java.lang.RuntimePermission &amp;#34;stopThread&amp;#34;; …… } Java本身包括了一些 Permission类，如下:
 java.security.AllPermission：所有权限的集合 java.util.PropertyPermission：系统/环境属性权限 java.lang.RuntimePermission：运行时权限 java.net.SocketPermission：Socket权限 java.io.FilePermission：文件权限,包括读写,删除,执行 java.io.SerializablePermission：序列化权限 java.lang.reflect.ReflectPermission：反射权限 java.security.UnresolvedPermission：未解析的权限 java.net.NetPermission：网络权限 java.awt.AWTPermission：AWT权限 java.sql.SQLPermission：数据库sql权限 java.security.SecurityPermission：安全控制方面的权限 java.util.logging.LoggingPermission：日志控制权限 javax.net.ssl.SSLPermission：安全连接权限 javax.security.auth.AuthPermission：认证权限 javax.sound.sampled.AudioPermission：音频系统资源的访问权限   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-8：内存模型</title>
        <url>http://lanlingzi.cn/post/technical/2019/1004_java_base_8/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> 内存模型 堆 堆（Heap）是JVM所管理的内存中最大的一块内存区域，也是被各个线程共享的内存区域，该内存区域存放了对象实例及数组（但不是所有的对象实例都在堆中）。堆由垃圾收集器自动回收，是OOM故障最主要的发源地。
通过下两个参数来分配堆使用的内存大小：
 -Xms：最小堆容量，默认是物理内存的1/64。 -Xmx：最大堆容量，默认是物理内存的1/4。  上下界调节的方式：
 默认空余堆内存小于40%时，JVM 就会增大堆直到-Xmx 的最大限制，可以由 -XX:MinHeapFreeRatio 指定。 默认空余堆内存大于70%时，JVM 会减少堆直到-Xms的最小限制，可以由 -XX:MaxHeapFreeRatio 指定。  堆分成两大块：新生代和老年代。对象产生之初在新生代，步入暮年时进入老年代，但是老年代也接纳在新生代无法容纳的超大对象。
新生代：1个Eden区 &#43; 2个Survivor区。绝大部分对象在Eden区生成，当Eden区装填满的时候，会触发Young GC。垃圾回收的时候，在Eden区实现清除策略，没有被引用的对象则直接回收。依然存活的对象会被移送到Survivor区，这个区真是名副其实的存在。
方法区 方法区（Method Area）也称&amp;quot;永久代&amp;rdquo;，它用于存储虚拟机加载的类信息、常量、静态变量、是各个线程共享的内存区域。默认最小值为16MB，最大值为64MB。它是一片连续的堆空间，永久代的垃圾收集是和老年代(old generation)捆绑在一起的，因此无论谁满了，都会触发永久代和老年代的垃圾收集。
从JDK7开始移除永久代（但并没有移除，还是存在），贮存在永久代的一部分数据已经转移到了Java Heap或者是Native Heap：
 符号引用(Symbols)转移到了native heap 字面量(interned strings)转移到了java heap 类的静态变量(class statics)转移到了java heap  从JDK8开始使用元空间（Metaspace），元空间的大小受本地内存限制。通过下面的参数可以设置：
 -XX:MetaspaceSize：class metadata的初始空间配额，以bytes为单位，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当的降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize（如果设置了的话），适当的提高该值 -XX:MaxMetaspaceSize：可以为class metadata分配的最大空间。默认是没有限制的  上下界调节的方式：
 -XX:MinMetaspaceFreeRatio：在GC之后，最小的Metaspace剩余空间容量的百分比，减少为class metadata分配空间导致的垃圾收集 -XX:MaxMetaspaceFreeRatio：在GC之后，最大的Metaspace剩余空间容量的百分比，减少为class metadata释放空间导致的垃圾收集  由于类的元数据可以在本地内存(native memory)之外分配，所以其最大可利用空间是整个系统内存的可用空间。这样，你将不再会遇到OOM错误，溢出的内存会涌入到交换空间。最终用户可以为类元数据指定最大可利用的本地内存空间，JVM也可以增加本地内存空间来满足类元数据信息的存储。
JVM使用一个块分配器(chunking allocator)来管理Metaspace空间的内存分配。块的大小依赖于类加载器的类型。其中有一个全局的可使用的块列表（a global free list of chunks）。当类加载器需要一个块的时候，类加载器从全局块列表中取出一个块，添加到它自己维护的块列表中。当类加载器死亡，它的块将会被释放，归还给全局的块列表。块（chunk）会进一步被划分成blocks,每个block存储一个元数据单元(a unit of metadata)。Chunk中Blocks的分配线性的（pointer bump）。这些chunks被分配在内存映射空间(memory mapped(mmapped) spaces)之外。在一个全局的虚拟内存映射空间（global virtual mmapped spaces）的链表，当任何虚拟空间变为空时，就将该虚拟空间归还回操作系统。
程序计数寄存器 程序计数寄存器（Program Counter Register）是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。
它是线程私有。每条线程都有一个独立的程序计数器。生命周期随着线程的创建而创建，随着线程的结束而死亡。是唯一一个不会出现OOM的内存区域。
虚拟机栈 虚拟机栈(JVM Stack)是java方法执行的内存模型。每个方法被执行的时候都会创建一个&amp;quot;栈帧&amp;rdquo;，用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。
虚拟机栈通过压/出栈的方式，对每个方法对应的活动栈帧进行运算处理，方法正常执行结束，肯定会跳转到另一个栈帧上。在执行的过程中，如果出现异常，会进行异常回溯，返回地址通过异常处理表确定。
栈帧由下面几部分组成：
 局部变量表：存放方法参数和局部变量 操作数栈：是一个初始状态为空的桶式结构栈，在方法执行过程中，会有各种指令往栈中写入和提取信息 动态连接：每个栈帧中包含一个在常量池中对当前方法的引用，目的是支持方法调用过程的动态连接 方法返回地址：方法执行时有两种退出情况，正常退出（RETURN、IRETURN、ARETURN指令），异常退出  本地方法栈 本地方法栈(Native Stack)与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。(栈的空间大小远远小于堆)。
在JVM内存布局中，也是线程对象私有的，但是虚拟机栈“主内”，而本地方法栈“主外”。这个“内外”是针对JVM来说的，本地方法栈为Native方法服务。线程开始调用本地方法时，会进入一个不再受JVM约束的世界。本地方法可以通过JNI(Java Native Interface)来访问虚拟机运行时的数据区，甚至可以调用寄存器，具有和JVM相同的能力和权限。当大量本地方法出现时，势必会削弱JVM对系统的控制力，因为它的出错信息都比较黑盒。
直接内存 直接内存（也称堆外内存）并不是虚拟机内存的一部分，也不是Java虚拟机规范中定义的内存区域。jdk1.4中新加入的NIO，引入了通道与缓冲区的IO方式，它可以调用Native方法直接分配堆外内存，这个堆外内存就是本机内存，不会影响到堆内存的大小。
总结 JVM内存模型从线程维度归类分为：线程私有内存、线程共享内存、以及不在堆内的直接内存。如下图：
各空间的分配参数：
GC GC(Garbage Collection)：即垃圾回收器，诞生于1960年MIT的Lisp语言，主要是用来回收，释放垃圾占用的空间。java GC泛指java的垃圾回收机制。
Java堆是GC回收的“重点区域”。堆中基本存放着所有对象实例，gc进行回收前，第一件事就是确认哪些对象存活，哪些死去。
为了高效的回收，Jvm将堆分为三个区域：
 新生代（Young Generation）NewSize和MaxNewSize分别可以控制年轻代的初始大小和最大的大小 老年代（Old Generation） 永久代（Permanent Generation）（1.8以后采用元空间，就不在堆中了）  对象是否存活算法 引用计数算法
早期判断对象是否存活大多都是以这种算法，这种算法判断很简单，简单来说就是给对象添加一个引用计数器，每当对象被引用一次就加1，引用失效时就减1。当为0的时候就判断对象不会再被引用。
 优点：实现简单效率高，被广泛使用与如python何游戏脚本语言上。 缺点：难以解决循环引用的问题，就是假如两个对象互相引用已经不会再被其它其它引用，导致一直不会为0就无法进行回收。  可达性分析算法
目前主流的商用语言（如java、c#）采用的是可达性分析算法判断对象是否存活。这个算法有效解决了循环利用的弊端。它的基本思路是通过一个称为“GC Roots”的对象为起始点，搜索所经过的路径称为用链，当一个对象到GC Roots没有任何引用跟它连接则证明对象是不可用的。
可作为GC Roots的对象有四种：
 虚拟机栈(栈桢中的本地变量表)中的引用的对象，就是平时所指的java对象，存放在堆中。 方法区中的类静态属性引用的对象，一般指被static修饰引用的对象，加载类的时候就加载到内存中。 方法区中的常量引用的对象 本地方法栈中JNI（native方法)引用的对象  要真正宣告对象死亡需经过两个过程：
 可达性分析后没有发现引用链 查看对象是否有finalize方法，如果有重写且在方法内完成自救（比如再建立引用），还是可以抢救一下，注意这边一个类的finalize只执行一次，这就会出现一样的代码第一次自救成功第二次失败的情况。[如果类重写finalize且还没调用过，会将这个对象放到一个叫做F-Queue的序列里，这边finalize不承诺一定会执行，这么做是因为如果里面死循环的话可能会时F-Queue队列处于等待，严重会导致内存崩溃，这是我们不希望看到的。  垃圾收集算法 新生代采用复制算法
新生代中因为对象都是&amp;quot;朝生夕死的&amp;rdquo;，适用于复制算法。它优化了标记/清除算法的效率和内存碎片问题。由于存活率低，不需要复制保留那么大的区域造成空间上的浪费，因此不需要按1:1（原有区域:保留空间）划分内存区域，而是将内存分为一块Eden空间和From Survivor、To Survivor（保留空间），三者默认比例为8:1:1，优先使用Eden区，若Eden区满，则将对象复制到第二块内存区上。但是不能保证每次回收都只有不多于10%的对象存货，所以Survivor区不够的话，则会依赖老年代年存进行分配。
GC开始时，对象只会存于Eden和From Survivor区域，To Survivor（保留空间）为空。
GC进行时，Eden区所有存活的对象都被复制到To Survivor区，而From Survivor区中，仍存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阈值(默认15是因为对象头中年龄战4bit，新生代每熬过一次垃圾回收，年龄&#43;1)，则移到老年代，没有达到则复制到To Survivor。
老年代采用标记/清除算法或标记/整理算法
由于老年代存活率高，没有额外空间给他做担保，必须使用这两种算法。
标记/清除算法是几种GC算法中最基础的算法，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。
 标记阶段：标记的过程其实就是前面介绍的可达性分析算法的过程，遍历所有的GC Roots对象，对从GC Roots对象可达的对象都打上一个标识，一般是在对象的header中，将其记录为可达对象； 清除阶段：清除的过程是对堆内存进行遍历，如果发现某个对象没有被标记为可达对象（通过读取对象header信息），则将其回收。  标记/整理算法，与标记/清除算法一样，但后续步骤不是直接对可回收对象进行回收，而是让所有存活的对象都向一端移动，然后直接清理掉端边线以外的内存。
三种算法的对比
 效率：复制算法 &amp;gt; 标记/整理算法 &amp;gt; 标记/清除算法（标记/清除算法有内存碎片问题，给大对象分配内存时可能会触发新一轮垃圾回收） 内存整齐率：复制算法 = 标记/整理算法 &amp;gt; 标记/清除算法 内存利用率：标记/整理算法 = 标记/清除算法 &amp;gt; 复制算法  垃圾收集器 新生代收集器
 Serial：Serial是单线程收集器，Serial收集器只能使用一条线程进行收集工作，在收集的时候必须得停掉其它线程，等待收集工作完成其它线程才可以继续工作。对于Client模式下的jvm来说是个好的选择。 ParNew收集器：可以认为是Serial的升级版，因为它支持多线程GC。运行在Server模式下新生代首选的收集器。 Parallel Scavenge：采用复制算法的收集器，和ParNew一样支持多线程。该收集器重点关心的是吞吐量。也成为&amp;quot;吞吐量优先&amp;quot;收集器。  老年代收集器
 Serial Old：和新生代的Serial一样为单线程，Serial的老年代版本，不过它采用&amp;quot;标记-整理算法&amp;rdquo;，这个模式主要是给Client模式下的JVM使用。 Parallel Old：支持多线程，Parallel Scavenge的老年版本，jdk6开始出现， 采用&amp;quot;标记-整理算法&amp;rdquo;。Parallel Old的出现结合Parallel Scavenge，真正的形成“吞吐量优先”的收集器组合。 CMS：CMS收集器(Concurrent Mark Sweep)是以一种获取最短回收停顿时间为目标的收集器。重视响应，可以带来好的用户体验，被sun称为并发低停顿收集器 G1：G1(garbage first:尽可能多收垃圾，避免full gc)收集器是当前最为前沿的收集器之一(1.7以后才开始有)，同cms一样也是关注降低延迟，是用于替代cms功能更为强大的新型收集器，因为它解决了cms产生空间碎片等一系列缺陷。  GC分类  Minor GC：在年轻代Young space(包括Eden区和Survivor区)中的垃圾回收称之为 Minor GC,Minor GC只会清理年轻代。 Major GC：Major GC清理老年代(old GC)，但是通常也可以指和Full GC是等价，因为收集老年代的时候往往也会伴随着升级年轻代，收集整个Java堆。所以有人问的时候需问清楚它指的是full GC还是old GC。 Full GC：Full GC是对新生代、老年代、永久代（jdk1.8后没有这个概念了）统一的回收。 Mixed GC：只有G1有这个模式，收集整个young gen以及部分old gen的GC。  触发GC点 简单来说，触发的条件就是GC算法区域满了或将满了。
Minor GC:
 当年轻代中eden区分配满的时候触发。 值得一提的是因为Minor GC后部分存活的对象会已到老年代(比如对象熬过15轮)，所以过后old gen的占用量通常会变高。  Full GC:
 手动调用System.gc()方法 ，增加了full GC频率，不建议使用而是让jvm自己管理内存，可以设置-XX:&#43; DisableExplicitGC来禁止RMI调用System.gc 发现perm gen（如果存在永久代的话)需分配空间但已经没有足够空间 老年代空间不足，比如说新生代的大对象大数组晋升到老年代就可能导致老年代空间不足。 CMS GC时出现Promotion Faield 统计得到的Minor GC晋升到旧生代的平均大小大于老年代的剩余空间。这个比较难理解，这是HotSpot为了避免由于新生代晋升到老年代导致老年代空间不足而触发的FUll GC。比如程序第一次触发Minor GC后，有5m的对象晋升到老年代，姑且现在平均算5m，那么下次Minor GC发生时，先判断现在老年代剩余空间大小是否超过5m，如果小于5m，则HotSpot则会触发full GC  GC日志 JVM的GC日志的主要参数包括如下几个：
 -XX:&#43;PrintGC 输出GC日志 -XX:&#43;PrintGCDetails 输出GC的详细日志 -XX:&#43;PrintGCTimeStamps 输出GC的时间戳（以基准时间的形式） -XX:&#43;PrintGCDateStamps 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234&#43;0800） -XX:&#43;PrintHeapAtGC 在进行GC的前后打印出堆的信息 -XX:&#43;PrintGCApplicationStoppedTime // 输出GC造成应用暂停的时间 -Xloggc:logs/gc.log 日志文件的输出路径  GC日志样例：
0.070: [GC (Allocation Failure) [PSYoungGen: 7127K-&amp;gt;616K(9216K)] 11223K-&amp;gt;4720K(19456K), 0.0008663 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.072: [GC (Allocation Failure) --[PSYoungGen: 6923K-&amp;gt;6923K(9216K)] 11027K-&amp;gt;15123K(19456K), 0.0016749 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 0.073: [Full GC (Ergonomics) [PSYoungGen: 6923K-&amp;gt;0K(9216K)] [ParOldGen: 8200K-&amp;gt;6660K(10240K)] 15123K-&amp;gt;6660K(19456K), [Metaspace: 2559K-&amp;gt;2559K(1056768K)], 0.0044663 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap PSYoungGen total 9216K, used 4404K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000) eden space 8192K, 53% used [0x00000000ff600000,0x00000000ffa4d1a0,0x00000000ffe00000) from space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) to space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000) ParOldGen total 10240K, used 6660K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000) object space 10240K, 65% used [0x00000000fec00000,0x00000000ff281398,0x00000000ff600000) Metaspace used 2565K, capacity 4486K, committed 4864K, reserved 1056768K class space used 281K, capacity 386K, committed 512K, reserved 1048576K  最前面的数字 &amp;ldquo;0,070&amp;rdquo; 代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数 GC日志开头的“[GC 和 [Full GC” 说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是年老代GC的。 PSYoungGen, ParOldGen，PSPermGen表示GC发生的区域，这里显示的区域名称与使用的GC收集器密切相关，不同收集器对于不同区域所显示的名称可能不同。 后面方括号内部的 “ 7127K-&amp;gt;616K(9216K) ”含义是“GC前该内存区域已使用容量 -&amp;gt; GC后该内存区域已使用容量（该内存区域总容量）”。方括号之外的 11223K-&amp;gt;4720K(19456K) 表示GC前java堆已使用容量 -&amp;gt; GC后java堆已使用容量(Java堆总容量) 0.0008663 secs表示该内存区域GC所占用的时间，单位是秒。 [Times: user=0.00 sys=0.00, real=0.00 secs] 这里面的user、sys、和real与Linux的time命令所输出的时间含义一致。分别代表用户消耗的CPU时间，内存态消耗的CPU时间，和操作从开始到结束所经过的墙钟时间。   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-7：泛型</title>
        <url>http://lanlingzi.cn/post/technical/2019/1003_java_base_7/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> 泛型 泛型是Java 5的一项新特性，它的本质是参数化类型（Parameterized Type）的应用，也就是说所操作的数据类型被指定为一个参数，在用到的时候在指定具体的类型。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法。
泛型使类型（类和接口）在定义类、接口和方法时成为参数，好处在于：
 强化类型安全，由于泛型在编译期进行类型检查，从而保证类型安全，减少运行期的类型转换异常 提高代码复用，泛型能减少重复逻辑，编写更简洁的代码 类型依赖关系更加明确，接口定义更加优好，增强了代码和文档的易读性  实现 Java 5推出了泛型，也就是在原本的基础上加上了编译时类型检查的语法糖。泛型对于JVM来说是透明的，有泛型的和没有泛型的代码，通过编译器编译后所生成的二进制代码是完全相同的。这个语法糖的实现被称为擦除。Java中的泛型基本上都是在编译器这个层次来实现的。在生成的Java字节码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会在编译器在编译的时候去掉。这个过程就称为类型擦除。
无论何时定义一个泛型类型，都自动提供一个相应的原始类型(Raw Type，这里的原始类型并不是指int、boolean等基本数据类型)，原始类型的类名称就是带有泛型参数的类删去泛型参数后的类型名称，而原始类型会擦除(Erased)类型变量，并且把它们替换为限定类型(如果没有指定限定类型，则擦除为Object类型)。
泛型变量的类型的使用：
 在调用泛型方法的时候，可以指定泛型，也可以不指定泛型 在不指定泛型的情况下，泛型变量的类型为 该方法中的几种类型的同一个父类的最小级，直到Object 在指定泛型的时候，该方法中的几种类型必须是该泛型实例类型或者其子类  桥方法 什么是桥方法(Bridge Method)，从实际代码入手：
// 父类 public interface Supper&amp;lt;T&amp;gt; { void method(T t); } // 其中一个子类 public class Sub implements Supper&amp;lt;Integer&amp;gt; { @Override public void method(Integer value) { System.out.println(value); } } 父类Supper在泛型擦除后原始类型是：
public interface Supper{ void method(Object t); } 子类Sub虽然实现了父类Supper，但是它只实现了void method(Integer value)而没有实现父类中的void method(Object t)，这个时候，编译期编译器会为子类Sub创建此方法，也就是子类Sub会变成这样：
public class Sub implements Supper&amp;lt;Integer&amp;gt; { @Override public void method(Integer value) { System.out.println(value); } public void method(Object value) { this.method((Integer) value); } }  编译的时候Java的方法签名是方法名称加上方法参数类型列表，也就是方法名和参数类型列表确定一个方法的签名(这样就可以很好理解方法重载，还有Java中的参数都是形参，所以参数名称没有实质意义，只有参数类型才是有意义的)。 Java虚拟机定义一个方法的签名是由方法名称、方法返回值类型和方法参数类型列表组成，所以JVM认为返回值类型不同，而方法名称和参数类型列表一致的方法是不相同的方法。  约束  泛型类型变量不能是基本数据类型 运行时类型无法查询到，如a instanceof Pair&amp;lt;String&amp;gt;是错误的 方法重载问题：如void method(List&amp;lt;String&amp;gt; list)与void method(List&amp;lt;Integer&amp;gt; list)冲突 异常中使用泛型的问题：不能抛出也不能捕获泛型类的对象，不能再catch子句中使用泛型变量 不能声明参数化类型的数组：如Pair&amp;lt;String&amp;gt;[]是错误的 不能实例化泛型类型：如new T() 要支持擦除的转换，需要强行制一个类或者类型变量不能同时成为两个接口的子类，而这两个子类是同一接品的不同参数化 泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数  类型边界 泛型与向上转型的概念:
 协变：子类能向父类转换 逆变：父类能向子类转换 不变：两者均不能转变  无限定通配符使用&amp;lt;?&amp;gt;的格式，代表未知类型的泛型。 当可以使用Object类中提供的功能或当代码独立于类型参数来实现方法时，这样的参数可以使用任何对象。
限定通配符对类型进行了限制:
      PECS原则，Producer-Extend,Customer-Super，也就是泛型代码是生产者，使用Extend，泛型代码作为消费者Super
泛型反射 由于Java中的泛型，在编译后会被擦除类型参数。如果用instanceof来查询对象的类型，只能查到对应的原始类型(raw type)。虽然有类型擦除，但也不是所有的地方都会被擦除。
Java泛型有这么一种规律：
 位于声明一侧的，源码里写了什么到运行时就能看到什么； 位于使用一侧的，源码里写什么到运行时都没了。  import java.util.List; import java.util.Map; public class GenericClass&amp;lt;T&amp;gt; { // 1 private List&amp;lt;T&amp;gt; list; // 2 private Map&amp;lt;String, T&amp;gt; map; // 3 public &amp;lt;U&amp;gt; U genericMethod(Map&amp;lt;T, U&amp;gt; m) { // 4 return null; } } 上面的代码实际上：
 1的GenericClass，运行时通过Class.getTypeParameters()方法得到的数组可以获取那个“T”； 2的T、3的java.lang.String与T、4的T与U都可以获得。源码文本里写的是什么运行时就能得到什么； 像是T、U等在运行时的实际类型是获取不到的。  这是因为从Java 5开始class文件的格式有了调整，规定这些泛型信息要写到class文件中。在Java里面可以通过反射获取泛型信息的场景有：
 成员变量的泛型 方法参数的泛型 方法返回值的泛型  不能通过反射获取泛型类型信息的场景有：
 类或接口声明的泛型信息 局部变量的泛型信息  类型体系 Java 5在java.lang.reflect中新引入四种泛型类型：ParameterizedType、TypeVariable、WildcardType、GenericArrayType都是接口。
ParameterizedType 也就是参数化类型，注释里面说到ParameterizedType表示一个参数化类型，例如Collection&amp;lt;String&amp;gt;，实际上只要带有参数化(泛型)标签&amp;lt;ClassName&amp;gt;的参数或者属性，都属于ParameterizedType。
public interface ParameterizedType extends Type { Type[] getActualTypeArguments(); Type getRawType(); Type getOwnerType(); }  Type[] getActualTypeArguments()：返回这个ParameterizedType类型的参数的实际类型Type数组，Type数组里面的元素有可能是Class、ParameterizedType、TypeVariable、GenericArrayType或者WildcardType之一。值得注意的是，无论泛型符号&amp;lt;&amp;gt;中有几层&amp;lt;&amp;gt;嵌套，这个方法仅仅脱去最外层的&amp;lt;&amp;gt;，之后剩下的内容就作为这个方法的返回值。 Type getRawType()：返回的是当前这个ParameterizedType的原始类型，从ParameterizedTypeImpl的源码看来，原始类型rawType一定是一个Class实例，和List.class等价。 Type getOwnerType()：获取原始类型所属的类型，从ParameterizedTypeImpl的源码看来，就是调用了原始类型rawType的getDeclaringClass()方法，而像rawType为List、Map这些类型的getOwnerType()实际上就是调用List.class.getDeclaringClass()，Map.class.getDeclaringClass()，返回值都是null。  TypeVariable 也就是类型变量，它是各种类型变量的公共父接口，它主要用来表示带有上界的泛型参数的信息，它和ParameterizedType不同的地方是，ParameterizedType表示的参数的最外层一定是已知具体类型的(如List&amp;lt;String&amp;gt;)，而TypeVariable面向的是K、V、E等这些泛型参数字面量的表示。常见的TypeVariable的表示形式是&amp;lt;T extends KnownType-1 &amp;amp; KnownType-2&amp;gt;
public interface TypeVariable&amp;lt;D extends GenericDeclaration&amp;gt; extends Type { //获得泛型的上限，若未明确声明上边界则默认为Object Type[] getBounds(); //获取声明该类型变量实体(即获得类、方法或构造器名) D getGenericDeclaration(); //获得名称，即K、V、E之类名称 String getName(); //获得注解类型的上限，若未明确声明上边界则默认为长度为0的数组 AnnotatedType[] getAnnotatedBounds() }  Type[] getBounds()：获得该类型变量的上限(上边界)，若无显式定义(extends)，默认为Object，类型变量的上限可能不止一个，因为可以用&amp;amp;符号限定多个（这其中有且只能有一个为类或抽象类，且必须放在extends后的第一个，即若有多个上边界，则第一个&amp;amp;之后的必为接口）。 D getGenericDeclaration：获得声明(定义)这个类型变量的类型及名称，会使用泛型的参数字面量表示，如public void query(java.util.List&amp;lt;Person&amp;gt;) String getName()：获取泛型参数的字面量名称，即K、V、E之类名称。 AnnotatedType[] getAnnotatedBounds()：Jdk1.8新增的方法，用于获得注解类型的上限，若未明确声明上边界则默认为长度为0的数组。  WildcardType 用于表示通配符(?)类型的表达式的泛型参数，例如&amp;lt;? extends Number&amp;gt;等。根据WildcardType注释提示：现阶段通配符表达式仅仅接受一个上边界或者下边界，这个和定义类型变量时候可以指定多个上边界是不一样。但是为了保持扩展性，这里返回值类型写成了数组形式。实际上现在返回的数组的大小就是1。
public interface WildcardType extends Type { Type[] getUpperBounds(); Type[] getLowerBounds(); }  Type[] getUpperBounds()：获取泛型通配符的上限类型Type数组，实际上目前该数组只有一个元素，也就是说只能有一个上限类型。 Type[] getLowerBounds()：获取泛型通配符的下限类型Type数组，实际上目前该数组只有一个元素，也就是说只能有一个下限类型。  GenericArrayType 也就是泛型数组，也就是元素类型为泛型类型的数组实现了该接口。它要求元素的类型是ParameterizedType或TypeVariable(实际中发现元素是GenericArrayType也是允许的)。
public interface GenericArrayType extends Type { Type getGenericComponentType(); }  Type getGenericComponentType()：获取泛型数组中元素的类型。注意无论从左向右有几个[]并列，这个方法仅仅脱去最右边的[]之后剩下的内容就作为这个方法的返回值。  泛型API Class
 Type[] getGenericInterfaces()： 返回类实例的接口的泛型类型 Type getGenericSuperclass()：返回类实例的父类的泛型类型  Constructor：
 Type[] getGenericExceptionTypes()：返回构造器的异常的泛型类型 Type[] getGenericParameterTypes()：返回构造器的方法参数的泛型类型  Method：
 Type[] getGenericExceptionTypes()：返回方法的异常的泛型类型 Type[] getGenericParameterTypes()：返回方法参数的泛型类型 Type getGenericReturnType()：返回方法返回值的泛型类型  Field
 Type getGenericType()：返回属性的泛型类型   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-6：反射/动态代理</title>
        <url>http://lanlingzi.cn/post/technical/2019/0929_java_base_6/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> Java反射 Java的反射机制是在编译并不确定是哪个类被加载了，而是在程序运行的时候才加载、探知、自审，使用在编译期并不知道的类。这样的特点就是反射。
Java的反射就是利用加载到JVM中的.class文件来进行操作的。.class文件中包含Java类的所有信息，当你不知道某个类具体信息时，可以使用反射获取Class，然后进行各种操作。反射就是把Java类中的各种成分映射成一个个的Java对象，并且可以进行操作。
反射提供的主要功能：
 在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法 在运行时调用任意一个对象的方法  RTTI RTTI(RunTime Type Information)，所有的类型信息都必须在编译时已知。会在所有类第一次使用的时候，将class对象(保存在.class文件)动态加载到JVM。
RTTI与反射区别：
 编译器在编译时打开和检查.class文件 运行时打开和检查.class文件  Class对象 JVM至少四个对象：Class、Field、Method、Constructor用于存储反射所需要信息
 Class： 代表类的实体，在运行的Java应用程序中表示类和接口 Field： 代表类的成员变量（成员变量也称为类的属性） Method： 代表类的方法 Constructor： 代表类的构造方法  而Class对象是类信息的载体，使用反射的前提是要获得某个类型的Class对象，有三种方式获取：
 对象调用 getClass() 方法来获取: obj.getClass() 类名.class 的方式得到: Person.class 通过 Class 对象的 forName() 静态方法来获取: Class.forName(&amp;ldquo;reflex.Person&amp;rdquo;)  Class对象主要能获取如下信息，
 getName()：获得类的完整名字 getFields()：获得类的public类型的属性 getDeclaredFields()：获得类的所有属性，包括private 声明的和继承类 getMethods()：获得类的public类型的方法 getDeclaredMethods()：获得类的所有方法，包括private 声明的和继承类 getMethod(String name, Class[] parameterTypes)：获得类的特定方法，name参数指定方法的名字，parameterTypes 参数指定方法的参数类型。 getConstructors()：获得类的public类型的构造方法 getDeclaredConstructors(): 获得类构造方法，包括private 声明的和继承类 getConstructor(Class[] parameterTypes)：获得类的特定构造方法，parameterTypes 参数指定构造方法的参数类型  带有Declared修饰的方法可以反射到私有的方法或属性，没有Declared修饰的只能用来反射公有的方法或属性。
动态代理 动态代理是一种方便运行时候动态的处理代理方法的调用机制。通过代理可以让调用者和实现者之间解耦。
我们常见的动态代理有：
 JDK动态代理 Cglib(基于ASM) Aspectj(动态织入) Instrumentation(javaagent)  JDK动态代理 代理类在程序运行时创建的方式被成为动态代理。也就是说，代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的&amp;quot;指示&amp;quot;动态生成的。
JDK动态代理是基于Java的反射机制实现的，它主要提供java.lang.reflect包两个类与接口：
 Proxy：Java动态代理机制的主类，提供了一组静态方法来为一组接口动态地生成代理类及其实例。 InvocationHandler：调用处理器接口，它自定义了一个invoke方法，用于集中处理在动态代理对象上的方法调用，通常在该方法中实现对委托类的代理访问。每次生成动态代理对象时都需要指定一个实现了该接口的调用处理器对象。  JDK的反射是基于接口的，有一定的局限性。
Cglib代理 Cglib采用了底层的字节码技术，为代理类创建了一个子类来代理它。Cglib是针对类来实现代理的，他的原理是对代理的目标类生成一个子类，并覆盖其中方法实现增强，因为底层是基于创建被代理类的一个子类，所以它避免了JDK动态代理类的缺陷。
Cglib主要提供一个对象一个接口：
 Enhancer：加强器，用来创建动态代理类。需要指定需要代理的父类，以及方法拦截器，对于代理类上所有方法的调用。 MethodInterceptor：实现方法拦截器，  但因为采用的是继承，所以不能对final修饰的类进行代理。final修饰的类不可继承。
Aspectj Aspectj是面向切面编程（AOP）一种实现，也是基于字节码技术，与Cglib不同，它是修改目标类的字节，织入代理的字节，在程序编译的时候 插入动态代理的字节码，不会生成全新的Class。
面向切面的概念：
 aspect（切面）：实现了cross-cutting功能，是针对切面的模块 jointpoint（连接点）：连接点是切面插入应用程序的地方，该点能被方法调用，而且也会被抛出意外。连接点是应用程序提供给切面插入的地方，可以添加新的方法。 advice（处理逻辑）：advice是我们切面功能的实现，它通知程序新的行为。 pointcut（切入点）：pointcut可以控制你把哪些advice应用于jointpoint上去，通常你使用pointcuts通过正则表达式来把明显的名字和模式进行匹配应用。决定了那个jointpoint会获得通知。 introduction：允许添加新的方法和属性到类中。 target（目标类）：是指那些将使用advice的类，一般是指独立的那些商务模型。 proxy（代理类）：使用了proxy的模式。是指应用了advice的对象，看起来和target对象很相似。 weaving(插入）：是指应用aspects到一个target对象创建proxy对象的过程：complie time，classload time，runtime。把切面连接到其它应用程序类型或者对象上，并创建一个被通知的对象，在运行时完成织入。  Instrumentation Instrumentation是可以独立于应用程序之外的代理程序，可以用来监控和扩展JVM上运行的应用程序，相当于是JVM层面的AOP。Instrumentation需要借助JVM的JavaAgent机制。
JavaAgent 相当于一个插件，在JVM启动的时候可以添加 JavaAgent 配置指定启动之前需要启动的agent jar包。这个Agent包中需要有MANIFEST.MF文件必须指定Premain-Class配置，且Premain-Class配置指定的Class必须实现premain()方法。
premain方法有两种：
 static void premain(String agentArgs, Instrumentation inst) static void premain(String agentArgs)  premain方法中有一个参数，Instrumentation，这个是才是agent实现更强大的功能都核心所在。Instrumentation主要功能：监控和扩展JVM上的运行程序，替换和修改java类定义，提供一套代理机制，支持独立于JVM应用程序之外的程序以代理的方式连接和访问JVM
Instrumentation是的个接口定义，主要提供如下方法：
 addTransformer：添加ClassFileTransformer removeTransformer： 移除ClassFileTransformer redefineClasses： 重新定义Class文件  ClassFileTransformer这个接口的作用是改变Class文件的字节码，返回新的字节码数组。
 注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-5：字节码/类加载器</title>
        <url>http://lanlingzi.cn/post/technical/2019/0928_java_base_5/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> Java字节码 Java源文件编译之后生成的class文件，它是供JVM解释执行的二进制字节码文件。
其结构如下：
   类型 名称 说明 长度     u4 magic 魔数，识别Class文件格式，0XCAFEBABE 4个字节   u2 minor_version 副版本号，如0x0000 2个字节   u2 major_version 主版本号，如0x0034 2个字节   u2 constant_pool_count 常量池计数 2个字节   cp_info constant_pool 常量池 n个字节   u2 access_flags 访问标志 2个字节   u2 this_class 类索引 2个字节   u2 super_class 父类索引 2个字节   u2 interfaces_count 接口计数 2个字节   u2 interfaces 接口索引集合 2个字节   u2 fields_count 字段个数 2个字节   field_info fields 字段集合 n个字节   u2 methods_count 方法计数器 2个字节   method_info methods 方法集合 n个字节   u2 attributes_count 附加属性计数 2个字节   attribute_info attributes 附加属性集合 n个字节    class文件只有两种数据类型：无符号数和表。
   数据类型 定义 说明     无符号数 无符号数可以用来描述数字、索引引用、数量值或按照utf-8编码构成的字符串值 其中无符号数属于基本的数据类型。以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节   表 表是由多个无符号数或其他表构成的复合数据结构 所有的表都以“_info”结尾。由于表没有固定长度，所以通常会在其前面加上个数说明    常量池 常量池主要存放两大类常量：
 字面量：文本字符串，声明为final的常量值 符号引用：类和接口的全限定名，字段的名称和描述符，方法的名称和描述符  描述符 描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。
 B：基本数据类型byte C：基本数据类型char D：基本数据类型double F：基本数据类型float I：基本数据类型int J：基本数据类型long S：基本数据类型short Z：基本数据类型boolean V：基本数据类型void L：对象类型,如Ljava/lang/Object  javap javap是JDK自带的反解析工具。它的作用就是根据class字节码文件，反解析出当前类对应的code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等等信息。
-help --help -? 输出此用法消息 -version 版本信息，其实是当前javap所在jdk的版本信息，不是class在哪个jdk下生成的。 -v -verbose 输出附加信息（包括行号、本地变量表，反汇编等详细信息） -l 输出行号和本地变量表 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -package 显示程序包/受保护的/公共类 和成员 (默认) -p -private 显示所有类和成员 -c 对代码进行反汇编 -s 输出内部类型签名 -sysinfo 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列) -constants 显示静态最终常量 -classpath &amp;lt;path&amp;gt; 指定查找用户类文件的位置 -bootclasspath &amp;lt;path&amp;gt; 覆盖引导类文件的位置 类加载器 类加载器（ClassLoader）是用来加载Class的。它负责将Class的字节码形式转换成内存形式的Class对象。主要作用：
 负责将 Class 加载到 JVM 中 审查每个类由谁加载（父优先的等级加载机制） 将 Class 字节码重新解析成 JVM 统一要求的对象格式  Java语言系统自带有三个类加载器:
 Bootstrap ClassLoader：最顶层的加载类，主要加载核心类库，%JRE_HOME%\lib下的rt.jar、resources.jar、charsets.jar和class等。另外需要注意的是可以通过启动JVM时指定-Xbootclasspath和路径来改变Bootstrap ClassLoader的加载目录。 Extention ClassLoader：扩展的类加载器，加载目录%JRE_HOME%\lib\ext目录下的jar包和class文件。还可以加载-Djava.ext.dirs选项指定的目录。 Application ClassLoader：也称为System ClassLoader 加载当前应用的classpath的所有类  加载器特点 传递性 JVM的策略是使用调用者 Class 对象的 ClassLoader 来加载当前未知的类。所有延迟加载的类都会由初始调用 main 方法的这个 ClassLoader 全全负责，它就是 App ClassLoader。
双亲委派 每个 ClassLoader 实例都有一个父类加载器的引用（不是继承的关系，是一个组合的关系），每个 ClassLoader 都很懒，尽量把工作交给父亲做，父亲干不了了自己才会干。每个 ClassLoader 对象内部都会有一个 parent 属性指向它的父加载器。
动态性 程序启动时，并不是一次把所有的类全部加载后再运行，它总是先把保证程序运行的基础类一次性加载到JVM中，其它类等到JVM用到的时候再加载。而用到时再加载这也是java动态性的一种体现。
类与加载器 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。比较两个类是否”相等”，只有再这两个类是有同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。
自定义加载器 Java中提供的默认ClassLoader，只加载指定目录下的jar和class，如果我们想加载其它位置的类或jar时，需要自定义加载器。
ClassLoader 里面有三个重要的方法，调用顺序为：loadClass -&amp;gt; findClass -&amp;gt; defineClass
 loadClass()：是加载目标类的入口，它首先会查找当前 ClassLoader 以及它的双亲里面是否已经加载了目标类，如果没有找到就会让双亲尝试加载 findClass()：如果双亲都加载不了，就会调用 findClass() 让自定义加载器自己来加载目标类。ClassLoader 的 findClass() 方法是需要子类来覆盖的，不同的加载器将使用不同的逻辑来获取目标类的字节码。 defineClass()：拿到这个字节码之后再调用 defineClass() 方法将字节码转换成 Class 对象。  定义自已的类加载器分为两步：
 继承java.lang.ClassLoader 重写父类的findClass方法  Class加载过程 类从被加载到虚拟机内存中开始，直到卸载出内存为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）。
 顺序确定的：加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的 顺序不确认的：解析阶段在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定。  类的实例化与类的初始化是两个完全不同的概念：
 类的实例化是指创建一个类的实例(对象)的过程 类的初始化是指为类中各个类成员(被static修饰的成员变量)赋初始值的过程，是类生命周期中的一个阶段。  加载方式 JVM加载class文件的两种方法：
 隐式加载：程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到JVM中 显式加载：通过Class.forname()、ClassLoader().loadClass()等方法显式加载需要的类，或者我们自己实现的 ClassLoader 的 findlass() 方法。  Class.forName vs ClassLoader.loadClass
这两个方法都可以用来加载目标类，它们之间有一个小小的区别，那就是 Class.forName() 方法可以获取原生类型的 Class，而 ClassLoader.loadClass() 则会报错。
如 Class&amp;lt;?&amp;gt; x = Class.forName(&amp;quot;[I&amp;quot;);
Thread.contextClassLoader
contextClassLoader是线程上下文类加载器，是从父线程那里继承过来的，用途如下：
 它可以做到跨线程共享类，只要它们共享同一个 contextClassLoader。父子线程之间会自动传递 contextClassLoader，所以共享起来将是自动化的。 如果不同的线程使用不同的 contextClassLoader，那么不同的线程使用的类就可以隔离开来。  加载异常 在类加载过程与初始化过程中，会出现如下异常：
 ClassNotFoundExecption：当 JVM 要加载指定文件的字节码到内存时，并没有找到这个文件对应的字节码，也就是这个文件并不存在。解决方法就是检查在当前的 classpath 目录下有没有指定的文件。 NoClassDefFoundError：可能的情况就是使用new关键字、属性引用某个类、继承了某个接口或者类，以及方法的某个参数中引用了某个类，这时就会触发JVM或者类加载器实例尝试加载类型的定义，但是该定义却没有找到，影响了执行路径。换句话说，在编译时这个类是能够被找到的，但是在执行时却没有找到。解决这个错误的方法就是确保每个类引用的类都在当前的classpath下面。 UnsatisfiedLinkError：通常是在 JVM 启动的时候，如果 JVM 中的某个 lib 删除了，就有可能报这个错误。 ExceptionInInitializerError：在初始化时出异常，如给静态成员赋值出错。 NoSuchMethodError：NoSuchMethodError代表这个类型确实存在，但是一个不正确的版本被加载了，出现使用的方法不存在。  Java9变化 Java9模块化之后，对ClassLoader有所改造，对应的ClassLoader加载各自对应的模块：
 Bootstrap ClassLoader：加载lib/modules下基本的modules，如java.base ，jdk.net等20个modules Extention ClassLoader：更名为Platform Classloader，加载lib/modules下其它的30个modules Application classloader加载-cp，-mp指定的类，也会加载lib/modules下25个moduels   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-4：IO体系</title>
        <url>http://lanlingzi.cn/post/technical/2019/0924_java_base_4/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> IO体系 普通IO 整个Java.io包主要分为两大部分
 文件特征对象 文件内容操作对象  文件对象 在类Unix系统中，一切对象皆文件，文件是最为基本的对象。Java API提供了最为基本的文件对象。
文件特征对象主要有如下：
 文件（File）：用于文件或者目录的描述信息，例如生成新目录，修改文件名，删除文件，判断文件所在路径等 文件描述符（FileDescriptor）： 主要映射到OS层的文件句柄对象 文件系统（FileSystem）：子类有UnixFileSystem，WinNTFileSystem等，用于适配不同的文件系统，仅内部使用，用户层不可调用。通过DefaultFileSystem.getFileSystem获取对应平台文件系统 文件特征，包括Closeable，Flushable，FileFilter，Serializable  文件内容操作对象主要有两大类：流式操作与数据转换。
IO操作 流式操作组件 流式操作又分类(byte)字节流，与字符(char)流
   分类 字节输入流 字节输出流 字符输入流 字符输出流     接口 InputStream OutputStream Reader Writer   Filter FilterInputStream FilterOutputStream FilterReader FilterWriter   访问文件 FileInputStream FileOutputStream FileReader FileWriter   访问数组 ByteArrayInputStream ByteArrayOutputStream CharArrayReader CharArrayWriter   访问管道 PipedInputStream PipedOutputStream PipedReader PipedWriter   访问字符串   StringReader StringWriter   缓冲流 BufferedInputStream BufferedOutputStream BufferedReader BufferedWriter   转换流   InputStreamReader OutputStreamWriter   打印流  PrintStream  PrintWriter   推回输入流 PushbackInputStream  PushbackReader    数据流 DataInputStream DataOutputStream     对象流 ObjectInputStream ObjectOutputStream      数据转换组件 数据转换，支持把字节流与Java基本数据类型间相互转换
   分类 数据输入 数据输出     抽象基类 DataInput DataOut   数据操作 DataInputStream DataOutputStream   对象操作 ObjectInput ObjectOut   对象操作 ObjectInputStream ObjectOutputStream   文件操作 RandomAccessFile RandomAccessFile    NIO NIO是Java 1.4推出，提供一种更主高效的IO操作API，可以代替部分普通IO操作API。
区别 NIO和普通IO（后简称IO）之间第一个最大的区别是：
 IO是面向流的。面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 NIO是面向缓冲区的。NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。  另一个区别是是否阻塞：
 IO是阻塞的。意味着当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了 NIO可以是非阻塞的。 NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变得可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。  特性 基于通道（Channel）与缓冲区（Buffer）操作：
 Channel：为所有IO提供Input/Output抽象,就像普通IO中的Stream一样原始IO操作 Buffer：为所有基础类型提供缓冲操作 操作：数据从Channel读到Buffer，从Buffer写入到Channel  基于非阻塞（Non-Blocking）:
 提供 多路 非阻塞的I/O 抽象  IO选择器（Selector）:
 用于监控多个Channel的事件，如连接打开，数据到达 单个线程可以监控多个数据通道  其它：
 提供字符编码/解码方案，java.nio.charset 支持内存映射文件，锁文件的访问接口  核心组件    核心组件 定义 作用 特点 使用     通道Channel 是数据的源头与目的地 给Buffer提供数据，从Buffer读取数据 双向读取异步读写 按数据来源划分:FileChannle: 从文件读写数据DatagramChannel: 从UDP连接读写数据SocketChannel：从TCP连接读写数据ServerSocketChannel：TCP服务侧的连接读写数据   缓存区Buffer 缓存数据 适用于所有基础数据类型（除了boolean） 按类型类型划分：ByteBufferShortBuffer&amp;hellip;不同的类型的Buffer可以相互换：提供asXxxBuffer()    选择器Selector 异步IO的核心对象 实现异步、非阻塞操作 允许一个Selector线程管理与操作多个Channel事件驱动：监控多个Channel的事件，并对事件分发 向Selector注册Channel调用Selector的select方法监控    Buffer Buffer顾名思义：缓冲区，实际上是一个容器，一个连续数组。Channel提供从文件、网络读取数据的渠道，但是读写的数据都必须经过Buffer。
向Buffer中写数据：
 从Channel写到Buffer (fileChannel.read(buf)) 通过Buffer的put()方法 （buf.put(…)）  从Buffer中读取数据：
 从Buffer读取到Channel (channel.write(buf)) 使用get()方法从Buffer中读取数据 （buf.get()）  可以把Buffer简单地理解为一组基本数据类型的元素列表，它通过几个变量来保存这个数据的当前位置状态：capacity, position, limit, mark：
   索引 说明     capacity 缓冲区数组的总长度   position 下一个要操作的数据元素的位置   limit 缓冲区数组中不可操作的下一个元素的位置：limit&amp;lt;=capacity   mark 用于记录当前position的前一个位置或者默认是-1    几个重要标识操作方法：clear，compact，mark，mark|
   方法 说明     clear() position将被设回0，limit设置成capacity，换句话说，Buffer被“清空”了，其实Buffer中的数据并未被清除，只是这些标记告诉我们可以从哪里开始往Buffer里读写数据   compact() 将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面，limit设置成capacity，Buffer准备好写数据但不会覆盖未读的数据   mark() 可以标记Buffer中的一个特定的position，之后可以通过调用reset()方法恢复到这个position   rewind() 将position设回0，可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素    Selector Selector可以监控的四种不同类型的事件：
 Connect：某个channel成功连接到另一个服务器称为“连接就绪” Accept：一个server socket channel准备好接收新进入的连接称为“接收就绪” Read：一个有数据可读的通道可以说是“读就绪” Write：等待写数据的通道可以说是“写就绪”  通过Selector选择通道，有几种方法
 int select()：阻塞到至少有一个通道在你注册的事件上就绪了 int select(long timeout)：和select()一样，除了最长会阻塞timeout毫秒(参数) int selectNow()：不会阻塞，不管什么通道就绪都立刻返回  select()方法返回的int值表示有多少通道已经就绪。然后可以通过调用selector的selectedKeys()方法，访问“ 已选择键集（selected key set）”中的就绪通道。
其它 内存映射文件 处理大文件，一般用BufferedReader,BufferedInputStream这类带缓冲的IO类，不过如果文件超大的话，更快的方式是采用MappedByteBuffer。
ByteBuffer有两种模式:直接/间接。间接模式最典型(也只有这么一种)的就是HeapByteBuffer,即操作堆内存 (byte[])。
ByteBuffer.MappedByteBuffer 只是一种特殊的ByteBuffer MappedByteBuffer 将文件直接映射到内存（这里的内存指的是虚拟内存，并不是物理内存）。通常，可以映射整个文件，如果文件比较大的话可以分段进行映射，只要指定文件的那个部分就可以。
FileChannel提供了map方法（MappedByteBuffer map(int mode,long position,long size)）来把文件影射为内存映像文件。 可以把文件的从position开始的size大小的区域映射为内存映像文件，mode指出了 可访问该内存映像文件的方式：
 READ_ONLY,（只读）： 试图修改得到的缓冲区将导致抛出 ReadOnlyBufferException READ_WRITE（读/写）： 对得到的缓冲区的更改最终将传播到文件；该更改对映射到同一文件的其他程序不一定是可见的 PRIVATE（专用）： 对得到的缓冲区的更改不会传播到文件，并且该更改对映射到同一文件的其他程序也不是可见的；相反，会创建缓冲区已修改部分的专用副本  工具 Scatter/Gatter
 分散（scatter）从Channel中读取是指在读操作时将读取的数据写入多个buffer中 聚集（gather）写入Channel是指在写操作时将多个buffer的数据写入同一个Channel  Pipe是两个线程之间的单向数据连接
 Pipe有一个source通道和一个sink通道 数据会被写到sink通道，从source通道读取  Path表示文件系统中的路径
 一个路径可以指向一个文件或一个目录。路径可以是绝对路径，也可以是相对路径 绝对路径包含从文件系统的根目录到它指向的文件或目录的完整路径 相对路径包含相对于其他路径的文件或目录的路径  Files提供一些工具，它依赖于Path
 Files.exists() Files.createDirectory() Files.copy() Files.move() Files.delete() Files.walkFileTree()   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-3：并发体系</title>
        <url>http://lanlingzi.cn/post/technical/2019/0923_java_base_3/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> 并发体系 线程 线程安全 线程安全性：当多个对象访问同一个对象时，如果不考虑这些线程运行环境的调度与交替执行，也不需要额外的同步，或者进行调用方任何其它协调操作。调用这个对象都可以获得正确的结果，那这个对象就是线程安全的。
 原子性 可见性 顺序的  线程实现：
 Runnable：函数没有返回值 Callable：函数有返回值 Future：对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果、设置结果操作。 FutureTask：是Future也是Runnable，又是包装了的Callable Thread：代表JVM一个线程  线程状态  NEW：至今尚未启动的线程处于该状态，通俗来讲，该状态是线程实例化后还从未执行start()方法的状态； RUNNABLE：正在java虚拟机中执行的线程处于这种状态； BLOCKED：受阻塞并等待某个监视器锁的线程处于这种状态； WAITING：无限期地等待另一个线程来执行某一特定操作的线程处于这种状态； TIMED_WAITING：等待另一个线程来执行取决于指定等待时间的操作的线程处于这种状态； TERMINATED：已退出的线程处于这种状态，线程被销毁。  方法：
 sleep： 暂停阻塞等待一段时间，时间过了就继续。注意这个是不释放“锁”的 wait： 也是阻塞和等待，但是需要notify来唤醒。wait是需要释放“锁”的 join： 在一个线程中调用other.join(),将等待other执行完后才继续本线程 notify/notifyAll: 唤醒线程 yield: 当前线程可转让cpu控制权，让别的就绪状态线程运行（切换），也会等待阻塞一段时间，但是时间不是由客户控制了 interrupte: 打断线程，可代替过时方法stop setPriority： MIN_PRIORITY 最小优先级=1 ， NORM_PRIORITY 默认优先级=5 ，MAX_PRIORITY 最大优先级=10  线程安全实现方法 互斥同步：
 synchronized关键字， Java 5 以前使用，独占锁是一种悲观锁，synchronized就是一种独占锁 锁：重量型，消耗内存较多，原子性，可见的，顺序：公平锁 、非顺序：非公平锁  非阻塞同步：
 volatile 变量：轻量级的线程同步，不会引起线程调度，提供可见性，但是不提供原子性 CAS 原子指令：轻量级线程同步，不会引起线程调度，提供可见性和原子性  无锁方案：
 不共享对象 线程本地变量 不可变对象  synchronized与volatile：
 volatile是线程安全的轻量级实现，volatile性能比synchronized好，且volatile只能修饰于变量，synchronized可以修饰方法，以及代码块 多线程访问volatile不会发生阻塞，而synchronized会发生阻塞 volatile能保证数据可见性，但不能保证原子性；而synchronized可以保证原子性，也可以间接保证可见性，因为它会将私有内存和公有内存中的数据做同步。  ##3 线程池
线程池的两个主要作用：
 控制线程数量，避免因为创建大量的线程导致的系统崩溃 重用线程，避免频繁地创建销毁线程  Java 1.5引入Executor与ExecutorService：
 Executor： 提交普通的可执行任务 ExecutorService： 在Executor的基础上增强了对任务的控制，同时包括对自身生命周期的管理 ScheduledExecutorService： 在ExecutorService基础上，提供对任务的周期性执行支持  Executors，是生产Executor的工厂：
 固定线程数的线程池：newFixedThreadPool 单个线程的线程池：newSingleThreadExecutor 可缓存的线程池：newCachedThreadPool 可延时/周期调度的线程池：newScheduledThreadPool Fork/Join线程池：newWorkStealingPool，在Java 1.7时才引入，其核心实现就是ForkJoinPool类  工作窃取算法 由于线程处理不同任务的速度不同，这样就可能存在某个线程先执行完了自己队列中的任务的情况，这时为了提升效率，我们可以让该线程去“窃取”其它任务队列中的任务，这就是所谓的工作窃取算法。ForkJoinPool是一种实现了工作窃取算法的线程池。
与OS线程关系 Java线程在JDK1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，而在JDK1.2中，线程模型替换为基于操作系统原生线程模型来实现。也就是说，现在的Java中线程的本质，其实就是操作系统中的线程，Linux下是基于pthread库实现的NPTL，Windows下是原生的系统Win32 API提供系统调用从而实现多线程。
轻量级进程（LWP）与内核线程之间1:1的关系称为一对一的线程模型。NPTL（ Native POSIX Thread Library），内核2.6开始有了新的线程实现方式NPTL。NPTL同样使用的是1:1模型，但此时对应内核的管理结构不再是LWP了：
 LWP： 调度实体都是进程，内核并没有真正支持线程。它是能过一个系统调用clone()来实现的，这个调用创建了一份调用进程的拷贝，跟fork()不同的是,这份进程拷贝完全共享了调用进程的地址空间。 NPTL：在内核里面线程仍然被当作是一个进程，并且仍然使用了clone()系统调用(在NPTL库里调用)。但是，NPTL需要内核级的特殊支持来实现，比如需要挂起然后再唤醒线程的线程同步原语futex。  简言之，他们之间的关系：java线程（N）&amp;lt;-&amp;gt; 用户线程/C线程（N）&amp;lt;-&amp;gt; 内核线程/OS线程（N）&amp;lt;-&amp;gt; CPU核（1）
状态关系 从实际意义上来讲，操作系统中的线程除去new和terminated状态，一个线程真实存在的状态，只有：
 ready：表示线程已经被创建，正在等待系统调度分配CPU使用权。 running：表示线程获得了CPU使用权，正在进行运算 waiting：表示线程等待（或者说挂起），让出CPU资源给其他线程使用  对于Java中的线程状态：无论是Timed Waiting ，Waiting还是Blocked，对应的都是操作系统线程的**waiting（等待）**状态。而Runnable状态，则对应了操作系统中的ready和running状态。
而对不同的操作系统，由于本身设计思路不一样，对于线程的设计也存在种种差异，所以JVM在设计上，就已经声明：虚拟机中的线程状态，不反应任何操作系统线程状态。只是作为理解模型，Java线程和操作系统线程，实际上同根同源，但又相差甚远。
锁 乐观锁/悲观锁 乐观锁与悲观锁概念：
 悲观锁：认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。 乐观锁：认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。一般会使用“数据版本机制”或“CAS操作”来实现。  乐观锁与悲观锁使用场景：
 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升  数据版本机制 实现数据版本一般有两种，第一种是使用版本号，第二种是使用时间戳。
版本号方式：一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
CAS CAS全称Compare And Swap（比较与交换），在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。
CAS算法涉及到三个操作数：
 需要读写的内存值 V 进行比较的值 A 要写入的新值 B  问题：
 ABA问题： CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。Java 1.5的实现是compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大： CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作： 对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。  Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。
独享锁/共享锁  独享锁：指该锁一次只能被一个线程所持有。ReentrantLock是独享锁，Synchronized是独享锁。 共享锁：指该锁可被多个线程所持有。ReadWriteLock其读锁是共享锁，其写锁是独享锁。  AQS 独享锁与共享锁也是通过AQS（AbstractQueuedSynchronized）来实现的，通过实现不同的方法，来实现独享或者共享。
AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch。AQS维护了一个volatile int state(代表共享资源)和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。
AQS定义两种资源共享方式：
 Exclusive：独占，只有一个线程能执行，如ReentrantLock Share：共享，多个线程可同时执行，如Semaphore/CountDownLatch  AQS支持中断、超时：
 阻塞和非阻塞（例如tryLock）同步 可选的超时设置，让调用者可以放弃等待 可中断的阻塞操作  自旋锁/适应性自旋锁  自旋锁：指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。  自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。   适应性自旋锁：自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。  在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock。    公平锁/非公平锁  公平锁：指多个线程按照申请锁的顺序来获取锁。ReetrantLock通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 非公平锁：指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。Synchronized是非公平锁。  无锁/偏向锁/轻量级锁/重量级锁 后三种锁是指锁的状态，并且是针对Synchronized。
 无锁：没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 偏向锁：指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。 轻量级锁：是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 重量级锁：是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让他申请的线程进入阻塞，性能降低。     锁状态 存储内容 标识位     无锁 对象的hashcode、对象分代年龄、是否是偏向锁（0） 01   偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01   轻量级锁 指向栈中锁记录的指针 00   重量级锁 指向互斥量的指针 10    偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。
整体的锁状态升级流程如下：
无锁 &amp;mdash;&amp;gt; 偏向锁 &amp;mdash;&amp;gt; 轻量级锁 &amp;mdash;&amp;gt; 重量级锁
可重入锁/非可重入锁  可重入锁：又名递归锁，表示该锁能够支持 一个线程对资源的重复加锁，不会因为之前已经获取过还没释放而阻塞。ReentrantLock和synchronized都是重入锁。可重入锁的一个优点是可一定程度避免死锁。 非可重入锁：表示该锁不支持 一个线程 对资源的重复加锁，同一线程重入会导致死锁。   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-2：集合/Stream</title>
        <url>http://lanlingzi.cn/post/technical/2019/0922_java_base_2/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> 集合体系 集合是存储多个元素的容器，数组长度固定，不能满足长度变化的需求。其特点：
 长度可变 存储元素可以是引用类型 可以存储多种类型的对象  Iterator Iterator接口：
 对 Collection 进行迭代的迭代器，即对所有的Collection容器进行元素取出的公共接口。 提供boolean hasNext()和E next()两个方法  ListIterator：
 只能用于List的迭代器。 在使用迭代器迭代的过程中需要使用集合中的方法操作元素，出现ConcurrentModificationException异常时，可以使用ListIterator避免  Collection Collection接口：
 List接口：有序(存入和取出的顺序一致),元素都有索引(下标)，元素可以重复。  Vector：内部是 数组 数据结构，是同步的。增删，查询都很慢！100%延长（几乎不用了） ArrayList：内部是 数组 数据结构，是不同步的。替代了Vector，查询的速度快，增删速度慢。50%延长。查询时是从容器的第一个元素往后找，由于数组的内存空间是连续的，所以查询快；增删的话所有元素内存地址都要改变，所以增删慢。 LinkedList：内部是 链表 数据结构，是不同步的。增删元素的速度很快。同理，链表的内存空间是不连续的，所以查询慢；增删时只需改变单个指针的指向，所以快。   Set接口：无序，元素不能重复。Set接口中的方法和Collection一致。  HashSet：内部数据结构是哈希表 ，是不同步的。 LinkedHashSet：内部数据结构是哈希表和链表，是有顺序的HashSet。 TreeSet：内部数据结构是有序的二叉树，它的作用是提供有序的Set集合，是不同步的。    List接口：
 有一个最大的共性特点就是都可以操作角标，所以LinkedList也是有索引的。list集合可以完成对元素的增删改查。  Set和List的区别：
 Set 接口实例存储的是无序的，不重复的数据。List 接口实例存储的是有序的，可以重复的元素。 Set检索效率低下，删除和插入效率高，插入和删除不会引起元素位置改变 。 List和数组类似，可以动态增长，根据实际存储的数据的长度自动增长List的长度。查找元素效率高，插入删除效率低，因为会引起其他元素位置改变。  Map Map接口：
 一次添加一对元素，Collection 一次添加一个元素。 Map也称为双列集合，Collection集合也称为单列集合。 map集合中存储的就是键值对，map集合中必须保证键的唯一性  Map常用的子类：
 Hashtable :内部结构是哈希表，是同步的。不允许null作为键，null作为值。  Properties：用来存储键值对型的配置文件的信息，可以和IO技术相结合。   HashMap : 内部结构是哈希表，不是同步的。允许null作为键，null作为值。 TreeMap : 内部结构是二叉树，不是同步的。可以对Map集合中的键进行排序。  Map的迭代方法（Map本身没有迭代器）：
 利用Map接口的values()方法,返回此映射中包含的值的 Collection（值不唯一），然后通过Collecion的迭代器进行迭代。（只需要Value，不需要Key的时候） 通过keySet方法获取map中所有的键所在的Set集合（Key和Set的都具有唯一性），再通过Set的迭代器获取到每一个键，再对每一个键通过Map集合的get方法获取其对应的值即可。 利用Map的内部接口Map.Entry&amp;lt;K,V&amp;gt;使用iterator。  Queue Queue接口:
 继承Collection boolean add(E e)，队列满，抛IllegalStateException / boolean offer(E e)，当容量限制时，与add相同抛IllegalStateException E remove()，抛NoSuchElementException / E poll()，不抛，返回null E element()，抛NoSuchElementException / E peek()，不抛，返回null  Deque接口，是一个实现了双端队列数据结构的队列，即在头尾都可进行删除和新增操作；
 继承Queue 依旧保持着“先进先出”的本质 增加 xxxFirst与xxxLast方法 可以被当做“栈”来使用，即“后进先出”，添加元素、删除元素都在队头进行通过push/pop两个方法来实现 主要两个实现LinkedList与ArrayDeque  PriorityQueue:
 不同于先进先出，它可以通过比较器控制元素的输出顺序（优先级） 本质上就是一个最小堆存储结构数组了 通过“极大优先级堆”实现的，即堆顶元素是优先级最大的元素。算是集成了大根堆和小根堆的功能。 堆的操作，主要就是两个：siftUp和siftDown，一个是向上调整堆，一个是向下调整堆。  工具类Collections 根据字符串长度的正序和倒序排序：
 Collections.reverse(List&amp;lt;?&amp;gt; list)  反转指定列表中元素的顺序。 &amp;lt;T&amp;gt; Comparator&amp;lt;T&amp;gt; Collections.reverseOrder() 返回一个比较器，它强行逆转实现了 Comparable 接口的对象 collection 的自然顺序。 &amp;lt;T&amp;gt; Comparator&amp;lt;T&amp;gt; reverseOrder(Comparator&amp;lt;T&amp;gt; cmp)  返回一个比较器，它强行逆转指定比较器的顺序。  排序
 Collections.sort(List&amp;lt;?&amp;gt; list) Collections.sort(List&amp;lt;?&amp;gt; list, Collections.reverseOrder())  同步视图
 &amp;lt;T&amp;gt; Collection&amp;lt;T&amp;gt; synchronizedCollection(Collection&amp;lt;T&amp;gt; c) &amp;lt;T&amp;gt; Collection&amp;lt;T&amp;gt; synchronizedCollection(Collection&amp;lt;T&amp;gt; c, Object mutex)  只读视图
 &amp;lt;T&amp;gt; Collection&amp;lt;T&amp;gt; unmodifiableCollection(Collection&amp;lt;? extends T&amp;gt; c)  其它工具
 &amp;lt;T&amp;gt; int binarySearch(List&amp;lt;? extends Comparable&amp;lt;? super T&amp;gt;&amp;gt; list, T key) &amp;lt;T&amp;gt; int indexedBinarySearch(List&amp;lt;? extends Comparable&amp;lt;? super T&amp;gt;&amp;gt; list, T key) &amp;lt;T&amp;gt; T max(Collection&amp;lt;? extends T&amp;gt; coll, Comparator&amp;lt;? super T&amp;gt; comp) &amp;lt;T&amp;gt; T min(Collection&amp;lt;? extends T&amp;gt; coll, Comparator&amp;lt;? super T&amp;gt; comp) &amp;lt;T&amp;gt; void fill(List&amp;lt;? super T&amp;gt; list, T obj) &amp;lt;T&amp;gt; List&amp;lt;T&amp;gt; nCopies(int n, T o)  并发集合 List接口:
 CopyOnWriteArrayList,线程安全的ArrayList  适用于读操作远远多于写操作，并且数据量较小的情况 修改容器的代价是昂贵的，因此建议批量增加addAll、批量删除removeAll CopyOnWrite机制  使用volatile修饰数组引用：确保数组引用的内存可见性 对容器修改操作进行同步：从而确保同一时刻只能有一条线程修改容器（因为修改容器都会产生一个新的容器，增加同步可避免同一时刻复制生成多个容器，从而无法保证数组数据的一致性） 修改时复制容器：确保所有修改操作都作用在新数组上，原本的数组在创建过后就用不变化，从而其他线程可以放心地读。      Set接口:
 CopyOnWriteArraySet是线程安全的Set，它内部包含了一个CopyOnWriteArrayList，因此本质上是由CopyOnWriteArrayList实现的。 ConcurrentSkipListSet相当于线程安全的TreeSet。它是有序的Set。它由ConcurrentSkipListMap实现。  它是一个有序的、线程安全的Set，相当于线程安全的TreeSet。     Map接口：
 ConcurrentHashMap线程安全的HashMap。采用分段锁实现高效并发。  ConcurrentHashMap由多个Segment构成，每个Segment都包含一张哈希表。每次操作只将操作数据所属的Segment锁起来，从而避免将整个锁住。   ConcurrentSkipListMap线程安全的有序Map。使用跳表实现高效并发。  它是一个有序的Map，相当于TreeMap。TreeMap采用红黑树实现排序，而ConcurrentHashMap采用跳表实现有序。 跳表是条有序的单链表，它的每个节点都有多个指向后继节点的引用。    Queue：
 ConcurrentLinkedQueue线程安全的无界队列。底层采用单链表。支持FIFO。  head、tail、next、item均使用volatile修饰，保证其内存可见性，并未使用锁，从而提高并发效率。   ConcurrentLinkedDeque线程安全的无界双端队列。底层采用双向链表。支持FIFO和FILO。 ArrayBlockingQueue数组实现的阻塞队列。  内部由Object数组存储元素，构造时必须要指定队列容量。 由ReentrantLock实现队列的互斥访问，并由notEmpty、notFull这两个Condition分别实现队空、队满的阻塞。 ReentrantLock分为公平锁和非公平锁，可以在构造ArrayBlockingQueue时指定。默认为非公平锁。 队满阻塞：当添加元素时，若队满，则调用notFull.await()阻塞当前线程；当移除一个元素时调用notFull.signal()唤醒在notFull上等待的线程。 队空阻塞：当删除元素时，若队为空，则调用notEmpty.await()阻塞当前线程；当队首添加元素时，调用notEmpty.signal()唤醒在notEmpty上等待的线程。   LinkedBlockingQueue链表实现的阻塞队列。  由单链表实现，因此是个无限队列。但为了方式无限膨胀，构造时可以加上容量加以限制。 分别采用读取锁和插入锁控制读取/删除 和 插入过程的并发访问，并采用notEmpty和notFull两个Condition实现队满队空的阻塞与唤醒。 队满阻塞：若要插入元素，首先需要获取putLock；在此基础上，若此时队满，则调用notFull.await()，阻塞当前线程；当移除一个元素后调用notFull.signal()唤醒在notFull上等待的线程；最后，当插入操作完成后释放putLock。 若要删除/获取元素，首先要获取takeLock；在此基础上，若队为空，则调用notEmpty.await()，阻塞当前线程；当插入一个元素后调用notEmpty.signal()唤醒在notEmpty上等待的线程；最后，当删除操作完成后释放takeLock。   LinkedBlockingDeque双向链表实现的双端阻塞队列。  Stream Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。
对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。
操作类型  Intermediate（中间操作）: 可以后面跟随零个或多个 intermediate 操作。这类操作都是惰性化的（lazy）。map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered等 Terminal（终止操作）: 只能有一个 terminal 操作, Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果。forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator等  还有一种操作被称为 short-circuiting（短路操作）：
 对于一个 intermediate 操作，如果它接受的是一个无限流，它可以返回一个有限的新 Stream。 对于一个 terminal 操作，如果它接受的是一个无限流，但能在有限的时间计算出结果。anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit  构造  Stream.of(T… values)：需要注意的是，不能全是null Stream.empty()：构造一个空流 Stream.iterate(BigInteger.ONE, n-&amp;gt;n.add(BigInteger.ONE)) Stream.generate(new Random()::nextInt) Stream.concat(list1.stream(),list2.stream()) IntStream.range(1, 3) IntStream.rangeClosed(1, 3)  reduce reduce的作用是把stream中的元素给组合起来。至于怎么组合起来：它需要我们首先提供一个起始种子，然后依照某种运算规则使其与stream的第一个元素发生关系产生一个新的种子，这个新的种子再紧接着与stream的第二个元素发生关系产生又一个新的种子，就这样依次递归执行，最后产生的结果就是reduce的最终产出。
运用reduce我们可以做sum,min,max,average，这些常用的reduce，stream api已经为我们封装了对应的方法。
 reduce(T iden, BinaryOperator b)： 可以将流中元素反复结合起来，得到一个值，返回 T reduce(BinaryOperator b)： 可以将流中元素反复结合起来，得到一个值，返回 Optional reduce(U identity, BiFunction a, BinaryOperator combiner)： 可以将流中元素反复结合起来，得到一个值，返回 Optional  三个参数时是最难以理解的。 分析下它的三个参数：
 identity: 一个初始化的值；这个初始化的值其类型是泛型U，与Reduce方法返回的类型一致；注意此时Stream中元素的类型是T，与U可以不一样也可以一样，这样的话操作空间就大了；不管Stream中存储的元素是什么类型，U都可以是任何类型，如U可以是一些基本数据类型的包装类型Integer、Long等；或者是String，又或者是一些集合类型ArrayList等 accumulator: 其类型是BiFunction，输入是U与T两个类型的数据，而返回的是U类型；也就是说返回的类型与输入的第一个参数类型是一样的，而输入的第二个参数类型与Stream中元素类型是一样的 combiner: 其类型是BinaryOperator，支持的是对U类型的对象进行操作  collect Collectors里常用搜集器
 toList：list.stream().collect(Collectors.toList()) toSet：list.stream().collect(Collectors.toSet()) toCollection：list.stream().collect(Collectors.toCollection()) counting：计算流中元素的个数， list.stream().collect(Collectors.counting()) summingInt：对流中的元素的整数求和, list.stream().collect(Collectors.summingInt(Employee::getSalary)) averagingInt：对流中的元素的整数求平均值，list.stream().collect(Collectors.averagingInt(Employee::getSalary)) summarizingInt：对流中的元素的整数求统计值，list.stream().collect(Collectors.summarizingInt(Employee::getSalary)).getAverage() joining：连接每个字符串，list.stream().map(Employee::getName).collect(Collectors.joining(&amp;rdquo;,&amp;quot;)) maxBy：根据比较器选择最大值，list.stream().collect(Collectors.maxBy(comparingInt(Employee::getSalary))) minBy：根据比较器选择最小值，list.stream().collect(Collectors.minBy(comparingInt(Employee::getSalary))) reduce：list.stream().collect(Collectors.reduc(0, Employee::getSalary, Integer::sum)) collectingAndThen：list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List::size)) groupBy：根据属性对流分组，返回Map，属性为K，list.stream().collect(Collectors.groupBy(Employee::status)) partitiongBy：根据true/fase对流分组，返回Map, toMap：toMap最少应接受两个参数，一个用来生成key，另外一个用来生成value。当key重复时，会抛出异常;当value为null时，会抛出异常，list.stream() .collect(toMap(t -&amp;gt; t.getId(), Function.identity(), (k1, k2) -&amp;gt; k1, LinkedHashMap::new)) toConcurrentMap: 线程安全的Map   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>跟我一起复习Java-1：基础/正则</title>
        <url>http://lanlingzi.cn/post/technical/2019/0921_java_base_1/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> 基本数据类型    数据类型 大小 范围 默认值     byte(字节) 8 -128 - 127 0   shot(短整型) 16 -2^15 - 2^15-1 0   int(整型) 32 -2^31 - 2^31-1 0   long(长整型) 64 -2^63 - 2^63-1 0   float(浮点型) 32 1.4013E-45 - 3.4028E&#43;38 0.0f   double(双精度) 64 -1.7976E&#43;308 - 1.79769E&#43;308 0.0d   char(字符型) 16 \u0000 - u\ffff \u0000   boolean(布尔型) 1 true/false false    控制语句 主要例举一些需要注意的点
swith switch(A)括号中A的取值类型如下：
 byte short int char 枚举 String(Java 7)  注意不能是long
case B:C
 case是常量表达式， case后的语句可以不用大括号，也就是说C不需要使用大括号； default没有符合的case就执行它，default并不是必须的。  for  无限循环： for（；；） index for: for(int i = 0; i &amp;lt; MAX; i&#43;&#43;) for each: for（a : iterator） Java 5  labeled loop 对循环打标签，用于控制语句跳到不同层次的循环。
vectorLoop: for( int idx = 0; idx &amp;lt; vectorLength; idx&#43;&#43;) { if( conditionAtVectorPosition( v, idx ) ) continue vectorLoop; matrixLoop: for( rowIdx = 0; rowIdx &amp;lt; n; rowIdx&#43;&#43; ) { if( anotherConditionAtVector( v, rowIdx ) ) continue matrixLoop; if( conditionAtMatrixRowCol( m, rowIdx, idx ) ) continue vectorLoop; } setValueInVector( v, idx ); } 异常体系  Throwable作为所有异常的超类 Error（错误）：是程序中无法处理的错误，表示运行应用程序中出现了严重的错误。此类错误一般表示代码运行时JVM出现问题。通常有Virtual MachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如说当jvm耗完可用内存时，将出现OutOfMemoryError。此类错误发生时，JVM将终止线程。这些错误是不可查的，非代码性错误。因此，当此类错误发生时，应用不应该去处理此类错误。 Exception（异常）：程序本身可以捕获并且可以处理的异常。  运行时异常(不受检异常)：RuntimeException类极其子类表示JVM在运行期间可能出现的错误。比如说试图使用空值对象的引用（NullPointerException）、数组下标越界（ArrayIndexOutBoundException）。此类异常属于不可查异常，一般是由程序逻辑错误引起的，在程序中可以选择捕获处理，也可以不处理。 编译异常(受检异常)：Exception中除RuntimeException极其子类之外的异常。如果程序中出现此类异常，比如说IOException，必须对该异常进行处理，否则编译不通过。在程序中，通常不会自定义该类异常，而是直接使用系统提供的异常类。    正则表达式 正则表达式定义了字符串的模式，可以用来搜索、编辑或处理文本。并不仅限于某一种语言，但是在每种语言中有细微的差别。
Java 正则表达式和 Perl 的是最为相似的。
 Pattern 类：是一个正则表达式的编译表示。Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。该方法接受一个正则表达式作为它的第一个参数。 Matcher 类： Matcher 对象是对输入字符串进行解释和匹配操作的引擎。与Pattern 类一样，Matcher 也没有公共构造方法。你需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。  捕获组 捕获组是把多个字符当一个单独单元进行处理的方法，它通过对括号内的字符分组来创建。
捕获组是通过从左至右计算其开括号来编号。例如，在表达式（（A）（B（C））），有四个这样的组：
 ((A)(B(C))) (A) (B(C)) (C)  可以通过调用 matcher 对象的 groupCount 方法来查看表达式有多少个分组。groupCount 方法返回一个 int 值，表示matcher对象当前有多个捕获组。 还有一个特殊的组（group(0)），它总是代表整个表达式。该组不包括在 groupCount 的返回值中。
语法 元字符
 . : 匹配除换行符以外的任意字符 \w: 匹配字母或数字或下划线或汉字 \s: 匹配任意的空白符 \d: 匹配数字 ^: 匹配字符串的开始 $: 匹配字符串的结束 \b: 匹配单词的边界  重复
 * : 重复零次或更多次 &#43; : 重复一次或更多次 ? : 重复零次或一次 {n} : 重复n次 {n,} : 重复n次或更多次 {n,m} : 重复n到m次  反义
 [^x] : 匹配除了x以外的任意字符 [^aeiou] : 匹配除了aeiou这几个字母以外的任意字符 \W : 匹配任意不是字母，数字，下划线，汉字的字符 \S : 匹配任意不是空白符的字符 \D : 匹配任意非数字的字符 \B : 匹配不是单词开头或结束的位置  零宽断言
 (?=exp) : 匹配exp前面的位置 (?&amp;lt;=exp) : 匹配exp后面的位置 (?!exp) : 匹配后面跟的不是exp的位置 (?&amp;lt;!exp) : 匹配前面不是exp的位置  注释
 (?#comment) : 注释  贪婪与懒惰
 *? : 重复任意次，但尽可能少重复 &#43;? : 重复1次或更多次，但尽可能少重复 ?? : 重复0次或1次，但尽可能少重复 {n,m}? : 重复n到m次，但尽可能少重复 {n,}? : 重复n次以上，但尽可能少重复  其他
 POSIX 字符类: 如\p{Lower}表示小写字母字符：[a-z] 引用： \, \Q, \E   注：以上内容收集于互联网多篇文章，在此感谢原作者们。
</content>
    </entry>
    
     <entry>
        <title>正确地打印日志</title>
        <url>http://lanlingzi.cn/post/technical/2019/0706_logging/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 日志种类 软件记录日志非常重要，公司已积累了非常多的日志输出经验，也制定了不少的规范。通常会把业务软件系统的日志分为如下几种：
用于软件问题定界定位的日志：
 调试日志：其目的是为了快速定位问题的根源，主要记录程序的执行轨迹，充当软件的调试器。 运行日志：其目的是为了跟踪程序的指标变化，主要记录程序各种关键指标数据统计，运行环境数据。 接口日志：其目的是为了快速对问题边界排查，主要记录接口的输入信息，以及处理结果。  用于用户行为安全审计的日志：
 操作日志：其目的是为了跟踪用户操作安全审计，主要记录用户操作行为轨迹，操作什么资源内容，其结果是什么。 安全日志：其目的是为了跟踪用户安全变更审计，主要记录用户的登录录出事件，权限修改等安全事件或行为。  日志问题 对于安全审计日志，使用者主要是审计人员，所以一般都会经常严格的设计，采用结构化的信息，日志的有效性不会差到哪里去。
现在大都采用微服务开发框架，框架会对内嵌支持接口日志，输出用作服务间接口消息跟踪。但用于定位的调试日志与运行日志却是经常是被遗忘的角落，几乎完全依赖开发人员的经验与能力，很少有设计，日志风格与内容也是千差万别。
我们经常发现代码中充斥着大量日志打印代码，也经常出现日志泛滥与风暴，出现问题时却发现他们并没有给我们带来期望的价值。代码中打印日志是非常讲究技巧，如何正确地打印日志，提升软件的可维护性？
级别问题 日志通常有会使用四种级别，从高到低分别是：ERROR、WARN、INFO、DEBUG。
问题一：INFO与DEBUG如何区分？大概有90%的程序员都不太注意日志的级别，都是用一个级别来记录日志，通常不是INFO就是DEBUG。
  DEBUG：主要是记录程序的执行过程，一般会记录各层次的对象中的操作名称，操作的参数，执行的分支等，什么原因导致错误的发现。在不重现错误的情况下，可以通过DEBUG级别的日志记录对问题进行诊断。由于DEBUG级别的日志记录过细，这种级别的日志很容易出现日志泛滥，在生产环境中一般不会开启。所以个人觉得，对于业务系统中DEBUG级别的日志记录意义不是太大。而是对业务系统中接口处理定义明确的错误码，通过接口日志中记录的错误码来对问题进行诊断。在记录DEBUG日志时要先想想它是否能帮我带来收益，并不是记录越细越好。大量地输出无效日志，不利于系统性能提升，也不利于快速定位错误点，最后也不会有人去看它。
  INFO：主要是记录系统中系统操作行为、关键资源的变化等，并且这种操作通常不是非常频繁的，它常用于反馈系统当前状态给最终用户。由于INFO通常会在生产环境中开启，在记录INFO日志时，一定要想想它是否影响性能，是否能快速找到它。
 系统操作行为：如开启/销毁线程，打开/关闭连接，定时任务触发等 资源或状态变化：系统初始化成功，关键资源的统计信息 非预期执行：为程序在“有可能”执行到的地方打印日志，如switch case语句块中的default 耗时的业务处理：如批处理，IO操作。输出他们运行耗时，大数据量的执行进度等    问题二：ERROR与WARN如何区分？
  WARN：出现WARN日志的地方，可能不会影响程序继续执行后续的逻辑，更多是一种重要提示需要引起重视。程序可以容忍这些信息，不过它们应该被及时地检查及修复。打印WARN日志典型有如下场景：
 潜在的问题和建议：如用户密码不足够安全，存在潜在的风险；系统参数未正确指定，采用系统默认值；系统性能处理导致服务降级等等 存在明显问题但未影响系统：如当前数据不可用使用缓存数据；删除临时文件失败后面统一清理；调用服务接口失败正在重试等等 存在危险的操作：如错误的密码登录；出现未允许的操作；正在删除重要的资源。    ERROR：主要是记录发生了严重的错误，这种错误会导致检验用户体验，导致关键路径不能继续执行，甚至导致系统完全不可用：
 系统启动失败 关键资源加载失败 数据库连接失败 关键资源清理失败 业务处理逻辑错误 调用外部系统接口返回失败    ERROR与WARN处理经验：
 ERROR：并不是所有出现异常的地方都要打ERROR，如果你觉得某个地方出问题时需要解决，就打ERROR，如果不需要解决就不要打ERROR。ERROR是相对程序正确运行来说的，如果出现了ERROR那就代表出问题了，开发人员必须要查一下原因，或许是程序问题，或许是环境问题，或许是理论上不该出错的地方出错了。  举例：如果有一个接口。调用者传过来的参数不在你的接受范围内，在这种情况下你不能打ERROR，因为传什么值是用户决定的，并不影响程序正确运行。   WARN：出现了不影响程序正确运行的问题，WARN也是问题但不影响程序正常运行，如果WARN出现的过于频繁或次数太多，那就说明你要检查一下程序或环境或依赖程序是否真的出问题了。  举例：服务接口调用超时打印WARN，如果此类WARN出现极其频繁，那可能对端服务可能直接出问题了。    有些日志规范还定义了FATAL与EMERGENCY级别，他们都比ERROR严重，严重级别是EMERGENCY小于FALAL。
 EMERGENCY：问题是突发并紧急的，如系统达到最大负载。 FATAL：问题是致命的，如数据库连接失败导致系统完全不可用。  出现FATAL与EMERGENCY应该是向告警系统发现告警，通知管理员及时处理。
内容问题 日志需要打印什么内容，日志应该是结构化的。日志框架已解决了时间、进程ID、线程ID、级别、模块等通用信息，但日志内容却没有严格限制。日志内容应该考虑是可读性与可分析性，符合人的理解。
 日志格式：采用 主语&#43;谓语&#43;宾语&#43;状语 的格式，日志打印应该遵从人类的自然语言: 主语：会话的发起者 谓语：将要具体进行什么样的操作 宾语：行为对象 状语：行为产生的结果 分析性：各个字段可以加入分隔符，使用分隔符使每个字段都能够清晰识别 可读性：使用[]进行参数变量隔离，这样的格式写法，对于排查问题更有帮助（如是否存在空白字符） 可读性：尽可能不要只打印标识，而是也要打印相应的名称、描述等。如不应该只打印错误码标识，而是要打印错误码对应的错误名称与描述，一个错误码标识只是一个数字，不查手册根本不知代表什么 可读性：不打无用的、无意义、不完全的日志，例如不是打印 &amp;ldquo;Unknown message type&amp;rdquo;，而是打印 &amp;ldquo;Unknown message type，type=, supported types=[A,B,C]&amp;rdquo; 安全性：避免在日志中输出一些敏感信息，例如密码与Key等；同时对于用户输入的内容打印到日志中要考虑日志注入风险  性能问题 日志写到文件还是数据库，都需要消耗IO资源。适当的控制日志的输出也有利于提高程序的性能。
 禁止字符串拼接：使用字符串拼接的方式打印日志，可读性、可维护性都比较差 必要的级别判断：INFO与DEBUG级别的日志输出，必须使用条件输出形式或者使用占位符的方式 禁止循环打印：大循环中逐行打印影响性能，而是考虑循环外汇总打印 适当地打印堆栈：预期会被正常处理的异常，仅需要打印基本信息留作记录，不需要去打印异常堆栈信息，使用堆栈的跟踪是一个巨大的开销，要谨慎使用 避免一条日志过大：当处理列表、数组类数据时，避免输出所有内容，而是打印处理的条数或者关键信息（如对象标识列表） 日志本地不落盘：一般日志是输出到文件，会产生IO操作，而文件IO通常阻塞，适当考虑日志本地不落盘，直接通过网络IO输出到日志系统 日志异步输出：对于非常频繁的日志，可以考虑采用进程内队列或进程内队列异步输出到日志系统  重复问题 像我司规范了文章开头说的多种日志类型，实际上见过代码中大量在一处打印不同的日志问题。日志非常重要，但我们还是有一些技术手段来避免重复打印日志的代码，日志的重复出现的问题。
 重复输出到不同文件：一条日志重复输出到不同的文件中，如像Java中log4j配置文件中，可以设置additivity=false 重复输出到不同类型：能在接口日志中打印的就不要在调试日志中打印，日志关联借助外部日志分析工具，而不是在代码中打印两次 不层次重复打印日志：比如下层catch异常时打印日志，异常继续往上抛，在上层catch又打印日志。对于异常处理建议是统一拦截打印日志 重复的日志打印代码：比如接口入口与出口打印日志，以及各处catch异常打印日志，不是要每处代码点打印而是可以借助AOP、拦截器等机制统一处理  在java体系的语言中，解决代码重复的主要技术有：
 AOP：定义切入点，在方法执行之前与之后打印日志 Filter：实现一个Filter类，在Filter的doFilter方法中执行前后的日志打印 Interceptor：自定义注解，实现HandlerInterceptor，在preHandle与postHandle根据注解输出日志  日志工具 工欲善其事，必先利其器。在java体系中，slf4j是最好的日志API:
 slf4j提供 {} 占位符，不仅提升日志代码的可读性，而且减少字符串拼接 slf4j是门面模式，统一API，后端可以对接多种日志输出框架，如log4j2，logback  日志框架应该可以扩展与过滤：
 对敏感信息进行过滤，如密码，卡号等 防止日志注入，对日志内容过滤与检查 支持对接不同的日志系统，日志不落盘  结语 日志写好其实不难，只要我们站在日志使用者角度多思考。日志也应该像代码一样易于阅读和理解，正确的日志级别让日志更容易使用。在日志输出技巧上可以使用AOP/Filter/Interceptor等机制集中统一输出，减少相似日志代码。
</content>
    </entry>
    
     <entry>
        <title>优雅地使用异常</title>
        <url>http://lanlingzi.cn/post/technical/2019/0615_execption/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 异常与错误码 在开发业务系统代码，我们会经常与异常与错误码打交道，但有时傻傻地分不清楚。编写代码时，到底是使用异常还是返回错误码，一直以来都被程序员们广泛争论。
我们先来看看他们的区别，在编程语言上区别：
 异常：与面向对象编程结合紧密，它是一个类型系统，表示程序运行时发生错误的信号，一种识别及响应错误情况的一致性机制。 错误码：与面向过程编程结合紧密，它通常是一串数字，表示处理函数返回业务流程错误的结果，错误码很容易被忽略且经常被忽略。  在接口定义上区别：
 异常： 面向代码开发者，通常用于在代码实现层，尤其是在面对象语言中，接口定义异常需要方法签名，以强制要求接口使用都处理异常。 错误码：面向客户界面，通常用于对外接口响应非正常结果定义，自定义错误码以增加接口的交互体验与问题定位。  从语言设计工程化来说，异常优于错误码，它有如下优点：
 正常控制流会被立即中止，无效值或状态不会在系统中继续传播 提供了异常堆栈，便于开发者定位异常发生的位置。 提供了统一的处理错误的方法，有非常强的合约。  因此很多的书籍建议：用抛出异常代替返回错误代码，但实际运用中，异常和继承一样，经常被滥用的东西，适得其反。
受检异常 以Java为例，异常系统又分为两种：
 受检异常（checked exception）：继承自java.lang.Exception的异常，这种异常需要显式的try/catch或throw出来。引起该异常的原因多种多样，比如说文件不存在、或者是连接错误等等。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。 非检查异常（unchecked exception）：继承自java.lang.RunTimeException的异常，这种异常不需要显式的try/catch或throw。与受检异常不同，它则是代码Bug导致的异常，如空指针异常，下标越界异常等。非检查异常我们应该是通过完善代码来避免它的出现。  受检异常也是我们常纠结说的：是使用异常还是返回错误码 中的异常，它实际上是业务层需要处理的错误，在开发时可以确定。受检异常设计的出发点很好，严谨的处理这些异常会很好地提高软件的健壮性。因为受检异常它强调：一个方法指定自己一定会抛什么异常，调用者必须一定要处理，或者明确声明继续向上抛。那么整个程序对异常的处理是明确而清晰的。
现实问题 从实际经验来看，受检异常运用在较底层的SDK上，会使SDK与其使用者之间形成一种契约。但我们开发的大多是业务系统，如果强行套用受检异常真是吃力却不讨人喜欢。我曾接手一个业务系统的代码，看到满眼的异常处理与异常转换，增加了很多其实是对业务逻辑无意义的代码，代码显得非常臃肿而不是那么的Clean。原因是在业务系统中，一个典型的业务接口，一个正常结果，却可能有上十个不正常的错误结果返回，如果每种都定义一个异常，则受检异常要求必要一个个声明，一个个处理。
是人大多都有惰性，一个个处理显然是不现实的，常用的手段就是catch根Exception，吃掉所有异常就无法区分不同的错误结果；要么是直接都往上抛，一般来说，业务系统通常会在最上层有一个收底的异常处理。不同层次的代码对异常的理解不一样，到了最上层收底，它只能是像catch根Exception，对外显示系统错误这类非常笼统的东西，让人非常地迷惑。
业内观点 有非常多的学者都在讨论受检异常应该去掉，理由大概是：
受检异常要求客户端程序员必要处理异常，但是程序员未必能知道如何处理，而从异常中恢复其实挺困难的，强迫程序员去处理的话是不现实的。常变成了编写什么不做的代码来“处理”它，导致“吞食则有害”的问题。吞掉能通过编译，但也隐藏了问题。
所以即使在JVM系统的Scala与Kotlin，他们在设计上没有继承了Java的受检异常机制，方法上异常的签名变成了可选。在Java系统中，也有像apache commons工具类ExceptionUtils.rethrow把受检异常转成运行异常，也有Lombok的@SneakyThrows注解来自动生成转换代码。这也侧面说明受检异常不受欢迎大有它的市场。
再来看看函数式编程中，对于错误处理通用是Result类型，Rust语言吸纳它。而Go语言则更为简化，直接把错误码作为一种返回类型，异常则是panic。从他们设计上可以看出，把逻辑上的Bug（Java中的RunTimeException）与业务可恢复错误机制（Java中的Exception）区分了，而不是像Java那样统一采用异常机制：
 逻辑Bug：提供是一种快速失败Fail-Fast机制，如Go中的panic，以及Rust中异常，他们会导致程序运行崩溃，崩溃时可以打印堆栈用于定位问题。 业务错误：提供是一种错误模型，如Go中的error接口，以及Rust中的Result类型，他们是一种编程契约，要求其使用处理可恢复。  业务错误码 回到开头的问题，对于Java程序，我们可以基于异常机制来传递错误码。基于这种开发方式可以避免大量的重复的try/catch（受检异常检查）或者if/else（错误码的判断）语句，让我们的代码更加简洁。
基于个人的经验建议实施如下：
 基于Exception或RunTimeException定义一个业务异常基类，如BizException BizException类包含httpStatusCode（对应Http的状态码）, errorCode（业务错误码）, description（错误码描述）, params（参数列表，可用于上层基于错误码做国际化字段替换） 基于场景细分几大类子异常，如非法参数异常，未认证异常，无权限异常等 方法对异常签名可以统一为BizException基类 业务处理异常分支时，直接构造BizException或其子类，填充errorCode，description，params参数抛出 一般没有必要catch BizException，而是直接继续向上抛 最后一个收底的ExceptionHandler，把BizException中的字段转换为http状态码，以及Json Body（含errorCode，description，params等）  带来收益：
 代码干净清爽，不存在无意义的异常转换 格式统一，机制统一 接口错误码与实现保持一致  需要注意是，需要区分接口错误码与内部异常。有哪些需要内部消化的异常，不能直接透传给接口响应，如数据库异常，调用其它服务口超时异常
结语 受检异常在新的语言纷纷抛弃，编译上语法约定并不能根本上解决业务场景上错误处理的健壮性（吞食问题）。业务系统主要还是要设计出合理的错误码，异常可以作为传递错误码的载体。切不可采用复杂的受检异常类型体系来映射到每个业务错误码，这只会让代码过于臃肿。
</content>
    </entry>
    
     <entry>
        <title>合理有效的注释</title>
        <url>http://lanlingzi.cn/post/technical/2019/0609_comment/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 注释是什么 注释是否有用一直以来都被程序员们广泛争论。也有人说，良好的编程习惯从写注释开始；有的人说，注释是恶魔，它将我们的代码变得很难理解。那什么才是注释？
 注释就是对代码的解释和说明，其目的是让人们能够更加轻松地了解代码。注释是编写程序时，写程序的人给一个语句、程序段、函数等的解释或提示，能提高程序代码的可读性。 &amp;ndash; 百度百科
 注释主要是给人看的，其目的是增加代码的可读性。不同的公司、项目，对代码注释要求不同，他们被写入到编程规范中。而大多的规范中对注释关注的是格式，却难以说明如何正确地写注释，什么样的注释不应该写，什么地方需要写注释。
注释必要性 写注释与维护注释需要花费大量的时间，甚至比写代码与维护代码更花时间，大多的程序员都不喜欢写注释。即使在编程规范要求下，为了注释而注释，这种不情愿的做法导致形成了某种主义：注释是恶魔，认为代码注释实际上是有害的。大家都想逃避注释时，大多会举起这种主义大旗来反对。虽然代码注释有时候确实会适得其反，但真正有害的是我们对它的看法。
确实在一段晦涩难懂的代码中有一段合理有效的注释，会比仅仅有代码好很多。也有人要说，我们应该去重构晦涩难懂的代码，直到让代码能够自解释，让人非常容易理解，也就不需要注释了。我们通过有意义的变量名，自解释的方法、类名称，清晰的代码结构，能大大提升代码可读性。清晰的实现让我们产生一种错觉，认为不需要再写注释了。
的确好的代码能正确地反映代码正在做什么，但它却无法说明为什么这样做的背景、原因等。理想很丰满，现实却很骨感，完全自解释的代码是不存在的。过了几个月之后，当我们自己回头再看我们写的代码，有时候却难以理解为什么要这么实现。不要过于相信自己的理解力，因为当你写代码时，可能是思路清晰的；当你阅读代码，可能没有了当时的思路。
任何一个稍大点的软件系统，需要多人协作一起完成。一个人写的代码，需要被整个团队的其他人所理解。合理的注释会增强团队之间的沟通，尤其是对于接口类代码，是非常有必要通过注释来明确接口的行为，接口的用法。注释不是为了要指出代码中存在的缺陷，而是为了避免可能由于不恰当的使用导致的缺陷。
注释与文档 有一种观点，代码即文档。我们不能望文生义，注释提升了代码的可读性，但它并不能代替全部的文档。每一种编程语言，都有自己的注释格式规范，基于特定的标签，通过工具能自动生成格式化的文档。
对外提供的API，通过注释文档化是非常有必要的，我们把这类叫API文档。这类注释文档好处是，开发代码的同时开发文档，保持一致性。
生成的文档能清晰地说明每个类、方法的作用与用法。但他们通常是片段式，缺少整体连贯性。虽不说注释能代替架构设计类文档，即使使用指导或开发指导都无法代替。
怎么写注释 现在，我们不难发现：注释是必要的，只是注释不应该记录代码在做什么，而是记录为什么要这么做以及怎样做。
大部分代码不是SDK之类的代码，而是业务逻辑代码。大部分情况下不需要、也不应该注释。尤其是业务类的代码，当需求改变了，代码也随之跟着变化。如果我们写注释，这就意味着必须去维护注释。如果注释没有跟随代码的变化而变化，那终将是无用的注释。所以：
 不必要对每行代码都写注释 不必要对每个函数都写注释 不要写直接代码翻译的注释 不要写没有额外含义的注释 不要写代码是谁写的，SCM有提交记录  有必要的注释是：
  描述解决的问题
注释将代码做的事情用语言再描述一遍，其实是画蛇添足。后续维护者或者代码阅读者，最想知道的是为什么这么做，是为了解决什么特殊问题吗？有没有什么复杂的业务背景。
  描述场景的约束
任何一段代码，有它的输入输出。不同的前置条件，会有不同的结果。在什么场景下使用，使用后会产生什么样的后果。当代码本身无法表达它的约束时，需要通过注释额外地说明使用场景，系统约束。
  描述关键算法实现
当代码涉及到算法实现时，由于可能会使用到数学公式，公式到代码的实现通常是比较以及理解的。这类的代码我们应该描述使用了什么算法，算法实现可参考的论文地址等。
  描述代码实现思路
有时我们写代码会考虑比较深远，但现有代码并不会完全实现将来可能发生的情况。针对他们可能已有明确的实现思路，为了代码的连续性，我们有必要说明后续可能的变化，在现有代码如何地修改，从而避免后续维护者破坏性的修改。
  结语 代码自解释不代表不用写注释，也不存在能完全自斛释的代码。没有人喜欢糟糕的注释，也不应由于注释会过时成为偷懒的借口。排斥注释并不能解决注释本身质量的问题。合理有效的注释是代码一部分，站在维护者角色来思考如何写好必要的注释，将会有不少的收益。
</content>
    </entry>
    
     <entry>
        <title>不可变减少副作用</title>
        <url>http://lanlingzi.cn/post/technical/2019/0608_inmutable/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 可变与不可变 在JVM系统语言如Scala与Kotlin中有两个关键字定义变量
 var是一个可变变量，可以通过重新分配来更改为另一个值的变量 val是一个只读变量，创建的时候必须初始化，以后不能再被改变  为什么新的语言需要强调变量不可改变？ 我再来看一下Rust语言中的变量不可改变。
 let，采用此关键字来绑定变量，变量默认不可变 let mut，采用此关键字来绑定可以变更的变量  Rust在mutable（可变）与immutable（不可变）上相比Scala上更进了一步：
 Scala的val只能约束了同一个变量名不可再重新赋值，变量绑定的对象是可以改变的（如val的list对象，可以调用它的append方法修改对象内容） Rust通过借用（borrow）语义与mut关键字，约束了只有声明为 mut 的变量，才能对绑定的对象是进变更（如只有是mut的vec对象，才能调用它的push方法修改其内容）  小结一下，关于var、val与mutable、immutable的区别：
 变量不可变性：val和var只是表明定义的变量是否能被修改而指向其他内容，即变量是否能重新 绑定 新的内容 内容不可变性：mutable和immutable表明定义的内容能否被修改，即变量所指向内容是否可以被重新修改  可变的问题 对于变量声明，var相比val有如下问题：
 分支遗漏：var变量多个地方重用，可能存在某个分支遗漏修改，导致代码逻辑错误 未初始使用：变量可能会在使用前没有初始化的代码，会导致空指针异常 可读性变差：阅读代码时，确定变量的值是比较困难，因为存在不同的地方对它可能的修改  在编程中我们更希望是对象是immutable（不可变）的，简言之：
 mutable：对象的内部数据可变，变化就会引入风险 immutable：对象的内部数据的不可变导致其更加安全，可以用作多线程的共享对象而不必考虑同步问题  不可变其实是函数式编程相关的重要概念，函数式编程中认为可变性是万恶之源，因为可变性的对象会给程序带来“副作用”；函数式编程也认为: 只有纯的没有副作用的函数，才是合格的函数。
什么是“副作用”：
 在计算机科学中，函数副作用指当调用函数时，除了返回函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量）或修改参数。－－维基百科
 函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并降低程序的可读性。严格的函数式语言要求函数必须无副作用。
而面向对象语言中虽强调对象的封装性，但没有在语义上强制约束对象的不可变性。面向对象的编程通过封装可变的部分来构造能够让人读懂的代码，函数式编程则是通过最大程度地减少可变的部分来构造出可让人读懂的代码。
函数式风格 Scala与Kotlin鼓励使用val，变量只是只读，使代码像函数式风格。我们来一个简单的Scala例子：
def printArgs(args: Array[String]): Unit = { var i = 0 while (i &amp;lt; args.length) { println(args(i)) i &#43;= 1 } } 可以通过去掉var的办法把这个代码变得偏函数式风格:
def printArgs(args: Array[String]): Unit = { args.foreach(println) } 很显然，重构后的代码比原来的代码更简洁明了，也更少机会犯错。因为它消除了var变量，也消除了var变量上述可能导致的问题。
当然它并不是纯函数式的，因为它有副作用，其副作用是打印到标准输出流。如果某个函数不返回任何值，就是说其结果类型为Unit，那么这个函数唯一能让其有点儿变化的办法就是通过某种副作用。而函数式的方式应该是定义对需打印的arg进行格式化的方法，但是仅返回格式化之后的字串。
def formatArgs(args: Array[String]) = args.mkString(&amp;#34;\n&amp;#34;) val res = formatArgs(Array(&amp;#34;zero&amp;#34;, &amp;#34;one&amp;#34;, &amp;#34;two&amp;#34;)) println(res) 回到Java Java中的String类的对象都是典型的immutable数据类型，一个String对象一旦被new出来，其代表的数据便不可被重新修改。
对于变量是否可以重新赋值，Java采用final关键字，同时被final修饰的方法不能被重写，他们也都强制变量或方法不可变性。Java还有一种用法，匿名内部类用的变量必须final，为用什么要有这种约束？
是为了保护数据安全和代码稳定，Java通过类的封装规范了类与类之间的访问权限，而内部类却打破了这种规范。它可以直接访问自身所在的外部类里私有成员，而且自身还可以创建相同的成员（另一个有意思的问题，变量遮蔽Shadow）。从作用域角度看，内部类的新成员修改了什么值，外部方法也是不知道，因为程序的运行由外而内的，所以外部根本无法确定内部这时到底有没有这个东西。综上所述，选择final来修饰外部方法的成员，让其引用地址保持不变、值也不能被改变保证了外部类的稳定性。
多使用final 除了匿名内部类用的变量必须final有这种约束，Java没有其它的语法上强约束不变性。我们还是可以善用不可变性的特点，来减少由可变带来的风险，提升代码的安全性与健壮性。
建议多使用final让对象不可变、让变量不可变：
 类的域值不可变：尽可能把成员变量声明成final，对于构造方法传入外部参数，若此参数是直接赋值给成员变量，那把此声明final；在构造方法中能通过计算初始化的成员变量，那把此声明final。 类与方法不可变：将类或方法声明为final，这样就不会重写它，不允许将类子类化，也不会存在子类来修改父类的成员变量与方法。Kotlin直接在语言上就遵循了这一条最佳实践，Kotlin中的类默认是final的，若想能子类化，则必须声明为open。 返回值不可变：对于成员变量的getter方法，其返回值尽可能是新对象，防止外部直接修改内部数据。如返回list类型的成员变量，不是直接返回其引用，而是直接再new一个list对象，拷贝成员变量的值，因为外部直接引用的修改，内部不感知 参数变量不可变：对于方法的输入参数，我们尽可能地通过final修饰，避免在方法内对入参重新赋值操作。 局部变量不可变：对于局部变量，尽可能地通过final修饰，避免不同的分支对变量多次赋值操作。  函数式编程 函数式编程是java8的一大特色，说到函数式编程，就不得不提及流Stream。
Stream其中有一个特点：它不会改变原集合，它是一堆元素顺序或者并行执行我们串起来的函数，函数并不会对集合中的元素造成影响。对Stream的使用就是实现一个filter-map-reduce过程，这个过程我也叫做聚合操作，产生一个最终结果。
final List&amp;lt;Integer&amp;gt; nums = Arrays.asList(1, 2, 3, 4); final Integer sum = nums.stream() .filter(n -&amp;gt; n % 2 == 0) .map(n -&amp;gt; n * n) .reduce(0, Integer::sum); 正如上面的代码，我们对nums重新聚合，新的结果sum并没有对原有nums产生副作用。同时我们都可以把两个变量都声明为final，不需要对变量进行改变。
结语 不可变可以摈弃Java中许多一些典型烦心的缺陷。因为改变越多，就需要越多的测试来确保导致变化的做法是正确的。通过严格限制改变来隔离变化的发生，那么错误的发生在更小的空间，需要测试的地方也就更少。
而函数式认为可变是万恶之源，不可变的好处是使得开发更加简单，测试友好，减少了任何可能的副作用。做一名传统的面向对象语言的开发人员，我们更要吸纳函数式语言的特点，在代码尽可能让变量不可变，对象不可变，来提升我们代码中的可读性与安全性。
</content>
    </entry>
    
     <entry>
        <title>拒绝重复代码</title>
        <url>http://lanlingzi.cn/post/technical/2019/0602_dry/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 拒绝重复 软件是让机器有了指令能执行一系列的动作，可将重复的机械劳动自动化。软件工程师们大多数会对重复都深恶痛疾，一旦发现有重复的迹象，就会想尽办法用技术手段去解决它。重复代码也意味着重复劳动，每次变更都必须要同时修改好几个地方，很容易遗漏而出镨，因而我们相信没有人喜欢重复的代码。
但是，实际项目中的业务逻辑总是错综复杂，有很多看似重复的场景，却又不完全一样。虽然我们不喜欢重复，实际上受限项目时间与经验技能，又不知不觉地在制造重复。人大多都有惰性，编写代码也是从模仿开发，都会经过拷贝与粘贴的阶段，当完成了软件开发任务，再也没有回过来再看看我们写的代码。久而久之，软件中充斥着大量的重复、相似的代码。他们的持续存在造成了代码可维护性差，代码质量下降。
Robert C.Martin在他的代码整洁之道一书中写道:
 重复可能是软件中一切邪恶的根源，许多原则与实践规则都是为了控制与消除重复而创建。…… 软件开发领域的所有创新都是不断在尝试从源代码中消除重复。
 重复类型 何谓重复代码，简言之，就是指重复或近似的代码。
重复代码都有哪些类型？最为简单明了的是完全一样的代码片段，其它的有如下，可让我们更好识别重复:
 类型Ⅰ，代码片段中除了空格、注释以及换行以外的内容__完全一致__ 类型Ⅱ，代码片段中除了空格、注释、换行以及__变量名以外__的内容完全一致 类型Ⅲ，代码片段中除了空格、注释、换行以及变量名以外的语句可能有__增删改，功能不变__ 类型Ⅳ，两个或更多个代码段执行__相同的运算__，但通过__不同的语法和变量__来实现。  重复原因 消除复杂代码除了需要技巧之外，个人觉得存在重复代码主观上更多是一种工作态度的反映，需要我们有责任心，兴趣与热情。
 懒惰，能够容忍不好的代码  打一份工的心态，做完这份就去做其它的，哪管生死 进度很紧，以完成任务为优先，后续没有再进行优化   技能不足，出现不必要的重复代码  老人留下的祖传代码，又缺少文档说明与测试用例，根本不敢随便动 新人进来，一是对整体代码不熟悉，二是从模仿开发，Ctrl&#43;C/Ctrl&#43;V   缺乏沟通，团队之间协作不够  没有 code review 机制，缺少代码持续看护 团队成员间缺少交流，每个人自扫门前雪    除主观原因之外，在软件架构与设计上不恰当，也会导致重复代码（更多情况是相似代码）：
 模块的职责分离不清晰：职责的分配不准确，就可能导致代码结构不清晰，也就可能导致代码的重复。比如说，每个模块都需要访问数据库，都会涉及到数据库的映射，事务管理等，如果能把数据访问层分离出单独一层，就可能避免数据操作的重复代码。也就是我们需要在设计上就抽取公共的模块。 模块内抽象的粒度过大：重用的关键是保持合适的粒度，以及对关系的解耦。粒度表现类一级，缺少可复用的辅助类或模板类，可以通过寻找共性，以泛化的方式提取共性特征。粒度表现在方法级，需要编写许多小的方法，找到类中可以重复调用的职责，抽取为单独的方法。  重复层次 像Java/C/C&#43;&#43;语言，我们一般采用工具 Simian 或 PMD 集成到CI来自动检查代码重复率。根据重复所在范围，我们通常可以分为如下几种：
在同一个类中重复
在同一个类中存在重复代码，通过走读代码就可以识别出来，也最容易解决。解决办法也相当简单，通常是采用 提取方法 来消除。
在同一个类树下重复
在同一个类树下的不同子类中重复，也比较能容易识别出来。可以通过 上移方法 和 模板方法 将公共部分上移到共同的父类。如果方法中没有操作成员变量，可以提到辅助类。
在不相干的类中重复
在两个完全不相干的类中，如果不是专门地寻找很难发现，借助工具一般能扫描出来。 可以先 提取方法 ，然后 移动方法 到新建的类，来消除重复。
在不同的模块中重复
在不同的模块中存在重复代码，一般考虑提供公共的模块。提取公共模块可以消除重复，但也带来了依赖，提到公共横块中的代码应该是稳定的。公共模块通常需要从整个软件设计来思考，合理的模块划分能有效地消除大量的重复。
大量大段重复代码
如果出现大量大段重复的代码，如相似的配置项解释代码，当超过几百行时，我们可以考虑采用代码自动生成，虽没有消除重复代码，但消除重复劳动。有些语言提供代码宏机制，合理的使用宏也可以消除大段重复代码。
重复轮子 还有一种重复，是工具扫描不出来的，就是与其它项目的重复。在开源的世界里，提供了非常多并且成熟的轮子。有人说，软件工程师写多少代码不重要，重要的是解决问题的效率，而提升效率之一就是懂得使用已有的轮子。好的软件工程师，要善用前人打下的基础，站在成功的肩膀上。
最大的问题是我们不知有轮子存在，那我们怎么解决呢？开源社区总是存在非常多有热心的人，他们整理各个 awesome 项目，首先是要善用搜索与社区：
 Java: https://github.com/akullpp/awesome-java Java: https://github.com/jobbole/awesome-java-cn Go: https://github.com/avelino/awesome-go  上面只是简单列出有哪些项目，还需要我们进一步的选型分析。对于Java软件工程师来说，已有足够多的工具库，常用他们也可以大量降低我们代码量：
 Apache Commons： 最为常用的是Lang，Collections，IO，Math库 Guava： Guava教程  结语 消除重复代码的技能，没有什么特别的复杂的东西，无非就是提取函数，提取类，提取公共模块、复用现有的轮子。
消除重复代码，其实就是解放软件工程师自己的时间，只有正确的心态去面对，自己才会有更大的收获，而不是在无意义地重复地劳动。
解决重复并不困难，困难的是发现重复。发现重复并不困难，困难是培养发现重复的习惯。当我们开始习惯性地向内看看同组的代码，向看外看看开源代码，只有看得多才能有更开阔的眼界，消除重复就是轻而易举。
</content>
    </entry>
    
     <entry>
        <title>逐层递进地编写代码</title>
        <url>http://lanlingzi.cn/post/technical/2019/0531_layer/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 书的目录 现在的软件类的书籍是越来越厚，尤其是语言类书籍很多通篇都是代码，需要花费很长的时间去阅读，久而之对厚厚的书就有一种莫名的恐惧感。个人看书喜欢先看一本书的目录，快速了解整本书的内容，挑选自己最感兴趣的章节直接开始阅读。
目录是什么？一本书的大纲，它的精炼所在，好的目录如点睛之笔，将书中内容尽是涵盖：
 让人清楚地知道书所讲的框架内容，一目了然 让人知道章节之间的逻辑关系，主次之分 让人了解体察作者写作该书的思想和行文脉络  画出整体框架 大约在2007年，有幸接触过部门请的雅各布森咨询公司的顾问，他们给我们培训如何使用 Use Case Driven 方法论来做设计。当时感觉顾问没有说出的心里话是：在座的都是垃圾，连个UML时序图都不会画。对我映像最深是，他们竟然直接按时序图的流程映射到代码实现层。
后来我就有一种习惯，当写代码时，喜欢先去编写整体的框架，先定义出有哪些类、方法，像UML的时序图一样把整个业务流程串起来。而这些类与方法先是空实现，就形成了基础骨架。初始的骨架能够避免陷入实现的细节而不能自拔，就像书籍的目录一样，清楚地呈现了流程的几个阶段或步骤。
这个基础骨架的形成，与个人的思维习惯和对业务场景深入了解有一定的关系。当开始编写代码时，可能层次不够清晰；不过随着我们不断地深入写代码可以不断地去调整层次，最终代码也可能达到较理想的状态。
搭建代码骨架就类似于编写一本书的目录，先有目录，再按目录的章节逐层展开，编写代码亦是如此。
单一抽象层次 单一抽象层次（ Single Level of Abstraction Principle，简称SLAP），指让一个方法中所有的操作处于相同的抽象层。从代码阅读与理解来看，不同的抽象层次跳跃的代码，就会破坏了代码的流畅性。
什么是抽象层次，它需要与业务域结合一起来看：
 对一个问题进行一个粒度的划分 代码对解决问题的一种抽象实现 抽象层次是循序渐进，逐步分层  例如，对某一个数据集进行分析，第一层抽象：
func AnalysisData() { // 1. 读取数据 loadDataset() // 2. 处理数据 processDataset() // 3. 输出结果 outputResult() } 对处理数据进行第二层抽象：
func processDataset() { // 2.1 转换数据 transformData() // 2.2 选择算法，建立模型 buildModel() // 2.3 评估模型 evaluateModel() } 如果在 AnalysisData 函数中 loadDataset 与 processDataset 间插入一行代码，或直接把 processDataset 所有实现都展示在此函数中，则这种实现破环了抽象层次。
在抽象层次中存在一种规则：自顶向下。按业务的处理逻辑进行了一定粒度的拆分，把软件变成一个个不同层次的功能点。像UML时序图一样，我们按照先后顺序，从上往下一层层的组装。单一抽象层次原则使代码块在单一的抽象层，每个代码块也是就是函数的目录或章节，当我们去读这种代码时，就像阅读书本一样，层次清晰。
再说函数 在上一篇 编写短小的函数/方法 中，提到小函数的优点，以及通过度量指标来思考把函数如何变 ”小“。结合 单一职责原则（SRP） 与 单一抽象层次原则（SLAP），发现他们在编写函数时是相辅相成的。
 SRP，说函数只应该做一件事，那此函数应该不能再拆分出不在此函数层次上的新函数 SLAP，说函数中的语句应该是一个抽象层上的步骤组合，也就是只做了一件事  另外我们在写函数代码时，通常会通过空行或注释分割逻辑片段，就像文章的段落：
//注释1 代码片段1 //注释2 代码片段2 //注释3 代码片段3 如果所有片段都是在同一个抽象层次上，只要方法不是过长（如有效性不超过25行），并不需要把每个片段抽取为函数。个人觉得这种做法不算违背SLAP，尽信书不如无书，我们需要有思考与权衡。当然若是一部分提取而一部分不提取那肯是不对的。
平铺的片段往往随着时间的推移，一是可能当增加需求会导致方法膨胀；二是新增的代码可能不在一个抽象层次上。个人建议对于新增小段代码时，优先考虑它是否可以独立为一个函数，而只在原有的代码地方去调用新增的函数。当新的内容打破了代码层次平衡，则需要及时地重构，原来的代码该提取函数就提取。
常见思路 为达成SLAP，函数重构主要有两种方法：
 提取函数(Extract Method) 分解函数(Compose Method)  Extract Method 来自 [重构&amp;ndash;改善既有代码的设计] 一书，就是把在原来函数的内部的一些语句抽离出来，放到一个独立的目标小函数中，再在原来函数中的地方修改成对目标函数的调用。它解决函数过长的问题，只把大的拆成小的，似乎并不有考虑抽象层次。
Compose Method 来自 Industrial Logic 的重构模式，说的是 Transform the logic into a small number of intention-revealing steps at the same level of detail。目的就是朝着单一抽象层次来组装函数。
有哪些常见的场景，我们需要提取函数：
 函数名称上存在And或Or的语义，函数代码也不是几个函数的And与Or组装，而是大段代码 For/While循环中存在较长的代码逻辑，循环体可以考虑抽取函数 Switch/Case分支存在较长的代码逻辑，则Case块可以考虑抽取函数 Try的代码块过多，或者Catch较多的异常，异常多说明分支多，则Try块可以考虑抽取函数 函数中存在相似代码，如对Rest请求体的每个参数校验，则校验可抽取函数集中处理 两个数据结构体间采用多个Setter与Geter语句来拷贝数据，则实现拷贝的代码可以提取到工具类或其中一个类上的一个函数  结语 编写代码可以像编写一本书一样，先列出目录编出骨干代码，从抽象到具体，逐层分解细化；在函数实现上遵循单一抽象层次原则，在适当的抽象层次上做合适的事，代码就会显得层次分明，也就更好地理解与维护。
</content>
    </entry>
    
     <entry>
        <title>编写短小的函数/方法</title>
        <url>http://lanlingzi.cn/post/technical/2019/0529_function/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 函数与方法 我们经常会遇到两个词，函数（Function）与方法（Method），简言之：
 函数不属于任何对象 方法是关联到对象内的函数  他们的区别：
 函数是面向过程编程中，为解决问题划分每个步骤的体现 方法是面向对象编程中，对象能提供的能力或行为的体现  方法底层实现本质还是函数，只是隐式传递了对象引用或指针，方法最终通过转化为函数的形式进行调用。为了简化后面的叙述，方法与函数统一称函数，不再区分。
他们的必要性：
 让代码可以重复使用，他们是”积木“ 函数黑盒特性，有效封装，隐藏细节  短小的好处 Kent Beck 在 Smalltalk Best Practice Patterns 中定义的 Composed Method 模式。指出函数应该只能做一个层次上的抽象。函数应该是短小的，对于Smalltalk函数大小应该在一至六行。
如果是现代语言像Java/Go/Scala/Kotlin等，每个函数应该是控制有效行数在 20到25 行 。短小的函数会带来如下好处：
 维护成本：越长的函数越要花费更大的成本去了解它要做什么，以及在什么地方作修改。而对于小函数，你可以快速的查明应该在何处作修改（尤其是在应用测试驱动开发的时候） 代码可读性：在初始的学习曲线之后，小函数使得你更容易理解一个类要做什么。而且你不必滑动窗口就可以理解代码 拥有重用潜力：把函数分解成一些小的模块，你可以识别出代码中通用的抽象，通过使用这些通用的抽象使你的代码总量急剧下降 拥有子类化潜力：函数越长，你就越难以创建一个子类使用这个函数 命名：小的函数命名起来要容易一些，因为它做的事情少 性能属性：遇到了性能问题，一个使用composed method的系统更容易定位性能瓶颈 灵活性：小函数使得重构更加容易，并且容易找到设计缺陷，比如feature envy 代码质量：把大函数分解成小函数，定位隐晦的错误更加容易 最小化注释：虽然注释是很有价值的东西，大多数注释可以通过谨慎的命名和调整结构消除。代码已经能说清楚，则注释是没有必要的。  注：来自Small Methods: Nine Benefits of Making Your Methods Shorter
影响因素 为了达成短小的函数，业界已有非常多的度量指标，指导我们写出可读性很好的函数。当然我们不能只是奔着降低指标而去，指标只是手段，不是目标。
圈复杂度 圈复杂度是一种衡量代码复杂程度的标准，由Thomas J. McCabe, Sr.提出。它用来衡量一个模块判定结构的复杂程度，数量上表现为独立的行路径条数。
圈复杂度高带来的害处有（建议平均值控制在15以内）：
 过高说明逻辑复杂不容易理解 逻辑复杂可能导致质量低下 路径过多难以测试覆盖  圈复杂度高主要表现：
 分支语句多：if/else, switch/case, for, while 表达式复杂：条件表达式复杂，3个及以上逻辑运算符  降低圈复杂度方法：
 抽取函数：独立业务代码封装为函数，通过函数名诠释代码作用，做到见名知意 合并重复：不同条件的分支，有相似的处理，可以提炼出分支以外，或者封装为函数 分解条件式：复杂的条件表达式，使用函数进行封装 移除控制标记：有控制标签作为条件的，使用break/return取代 设计模式：对于同一层的if/else, switch/case分支过多，可考虑采用状态机或策略模式、表驱动法（Map查找） 单一职责：一个函数应该只实现一个功能点  嵌套层次 不恰当的if/else与try/catch语句，是最为常见的嵌套层次过深代码；对于异步api，像nodejs还没有promise与async/await语言特性时，也会导致callback嵌套层次过深。
嵌套层次过深带来害处显而易见（建议层次不要超过4层）：
 圈复杂度变高，难以理解与测试 有时像”横放着的金字塔“，代码太长，不方法阅读  降低if/else嵌套层次方法：
 少使用else：使用if &#43; return，代码反向判断，避免进入 else 分支，提前 return 减少非空判断：如Java8引用Optional的orElse或orElseGet方法 合并if条件判断：使用条件与（&amp;amp;&amp;amp;），利用条件短路的特性 三元表达式：如Java中的  e = (a==b) ? c : d ，c与d可以是函数调用  try/catch可以再嵌套try/catch，但也是最容易出逻辑问题的地方，降低try/catch嵌套层次方法：
 抽取函数：try与catch的中各代码块超过10行以上，建议是分别抽取函数，try/catch块内只有函数调用 合并try/catch：分析是否可以合并try/catch到同一层次 折分try/catch：让try的范围更小，尽早catch，避免大try中不必要的嵌套  我们会经常对数据进行操作，Java8引入Stream对象。若能合理使用它，也可以减少迭代（for语句&amp;ndash;&amp;gt; map方法调用）、条件判断（if/else语句 &amp;ndash;&amp;gt; filter方法调用）组合带来的嵌套。面向过程变成面向函数式编程，也会让你的代码更为的清爽。
参数个数 函数的输入参数过多，会使函数易于受外部的变化影响，从而导致函数变得不稳定，代码维护困难。过多的控制标记参数也会导致参数的使用组合变多，代码的分支路径变多，也就增加了测试的工作量。
参数个数多少个才算多？建议是不超过5个。
是否要将参数封装成对象，不能只看参数的数量，还要看它的业务意义，有时封装成对象反倒增加了阅读成本。参数过多说明它依赖过多，我们需要考虑是否需要对函数进一步拆分。
对于构造方法参数过多，我们可以采用 链式调用 ，它是一种Builder模式，比一堆的参数列表调用更有意义，也不容易出现赋值顺序出错而导致问题。
变量个数 函数局部变量个数多，是函数的逻辑实现需要依赖较多的外数或内部数据，依赖多则会导致复杂度增加。
局部变量个数多少个才算多？建议是不超过5个。
解决局部变量变多的另一种思路是 Replace Method with Method Object (来自重构一书)，以函数对象取代函数，做法是将函数放进一个单独的对象当中，使用这个单独对象的值域（filed）来替代原函数中的局部变量。若这个单独的对象使用的范围非常小，我们通过把它声明为内部静态类。
结语 千里之堤溃于蚁泬，短小精悍的函数，是构建健壮的软件基石。千里之行始于足下，从编写短小精悍的函数开始。
</content>
    </entry>
    
     <entry>
        <title>类的职责单一</title>
        <url>http://lanlingzi.cn/post/technical/2019/0526_class/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 理解类 类（实例化产生对象）是面向对象编程中最基本的组成单元，将逻辑和数据封装其中，以提高软件的重用性、灵活性和扩展性等。它相比人类社会组成，系统/子系统、组件/（微）服务、模块/包这些相当于社会中不同层次的实体或虚拟的组织机构；而类则相当于一类自然人，一个对象相当一个自然人。一个类在系统中承担着一种的 ”角色“ ，从事一种职业。
单一职责 大多数人只从事一种职业，也就是单一职责原则。若一个类只关注的就是自身职责的完成，也就是单一职责原则。
面向对象设计的五个基本原则（SOLID），排在第一就是单一职责原则（SRP：Single responsibility principle）。SRP的原话解释是：There should never be more than one reason for a class to change。应该有且仅有一个原因引起类的变更。
单一职责原则是指导”高内聚，低耦合“的基本原则，但也是最难实施的原则。
类的构成 类是什么，两个角度来看：
 组成派：是对一类事物的抽象，由成员属性和成员方法组成的数据结构，强调封装 职责派：是为达成一种目标一组能力的集合，承担它所代表的抽象的职责，强调行为  上述两个角度，可能是导致两种不同的类代码结构排版的原因？
 先属性再是方法，莫非是组成派，首先考虑是类是由哪些元素（属性）组成，再是具备哪些行为操作（方法） 先方法再是属性，莫非是职责派，首先考虑是类需要承担什么职责（方法），再是完成这些方法的功能需要哪些资源（属性）  当然也可能是我的无稽之谈，由于个人主要使用Java系语言，建议类按如下顺序组成，这只是一种编码风格：
 类的静态常量 类的静态变量 类的成员变量 类的构建方法 类的成员方法（public-&amp;gt;protect-&amp;gt;private）  类的模型 Martin Fowler写过一篇文章叫”贫血模型”，批判贫血领域模型不够优雅、不够面向对象，提倡使用充血领域模型。若此观点应用在普通的类设计上非常有争议，至少在面向对象的语言体系中，这两种模型都存在，适用不同的场景。
贫血模型 贫血模型是指对象只有属性（getter/setter），或者包含少量的CRUD方法，而业务逻辑都不包含在其中，而是放在单独的业务处理逻辑层。JavaBean就是最为典型的代表，像Scala，Kotin在语言层次都存在数据类的概念，用于只描述数据的构成。
该模型的确是不够面向对象，对象只是作为保存状态（如数据层的表映射）或者传递状态（如方法中的出入参数）使用，所以就说只有数据没有行为的对象不是真正的对象。
在Java体系中，非常流程的就是这种设计，接口门面层（Controller）-&amp;gt; 业务逻辑处理层（Service）-&amp;gt; 数据访问层（ORM）。
充血模型 充血模型是指对象里即有数据和状态，也有行为，行为负责维持本身的数据和状态，具有内聚性，最符合面向对象的设计，满足单一职责原则。这也是我们最为常见的对象设计方式。
Martin Fowler主张这种模型，他是从领域驱动开发（DDD）中领域模型对象来分析的，领域模型（Domain Model）是一个商业建模范畴。从一个模型的封装性来说，即有状态又有行为是合理的，但领域模型并非直接映射为单一类对象，它要比类的模型大很多，可能是由一组类聚合而成。
遵循充血模型的规范，出发点非常好，但对开发人员要求非高，随着变化与演进，最后可能一个类充满了乱七八糟的内容，反而忘记初心，违背单一原则。
类的坏味道 inFusion是一款非常不错的软件设计度量工具，它能帮助我们发现代码上坏味道。借助它分析，也讲讲inFusion中提到了哪些类的坏味道，他们违反了单一原则。
God Class 上帝类通常为过多地操作其它类的数据，从而破坏了类的封装类，上帝类从其它类中获得功能，却增加了自身的耦合性，通常会导致自己体积过大和较大的复杂度。
导致出现上帝类一般是出现在业务逻辑层，没有对逻辑层合理的分层。此类有点像八爪鱼，手上攥了东西太多，聚合太多其它对象在一个对象中直接组合所有逻辑；另一个原因是被引用的对象的封装性不好，不够内聚，暴露太多数据需要其它类来完成它自身的职责。
Blob Class 复杂类，它具有体积大（通常超过千行），高度复杂的特征。
导致出现复杂类，除了类中的方法存在行数过大的原因之外。另一个原因是一个类最早只有简单的CRUD方法，每个方法复杂度不高。后面随着需求的增加，一种场景是方法实现的场景分支越来越多，导致方法复杂度变高；另一个场景是方法个数增加太多，如Query方法，一开始只有Query1，后面不断增加Query2，Query3&amp;hellip;以满足不同的查询条件以及响应内容等等。
Schizophrenic Class 紊乱类，一个类本应该一种抽象，完成一类责任。而该类确完成完成两种或以上的抽象，会影响类的理解和修改。特点是定义大量的接口方法，以及被不同的Client使用。
导致出现复杂类，一般出现在门面类（如Controller）、工具类（Util）中，即提供太多公共方法，又同时处理相应的业务逻辑。
怎么做 再回到单一职责，结合上面怎么进一步理解它，关键是职责的划分，但也是难点。
职责的划分有一定的范围与层次，比如关注的是华为手机和其它东西的区别，那华为手机就是一个整体，就是用来实现手机的功能，不是用来切水果的，所以切水果的方法，不应该实现在华为手机中。当要关注华为手机的内部结构时，那它的模块肯定是隔离的，显示屏只关注显示，通信模块只关注通信，其实每个模块都是单一职责，最终聚合在一起，就是一个手机。
在实际操作中非常难，正如上面”职责“是一个相对的概念，没有一个明确的划分原则，什么才是单一的。我们可以尝试按下面去思考一个类的设计，从多个角度来考虑，如类的构成，类的规模：
 类自己的数据与状态的变化尽可能地能控制在类内部 变化的来源只有一类原因，原因导致变化也是围绕完成同一层次的一件事 类的每个方法逻辑处理足够简单，整个类的逻辑才会简单 类的方法数量不宜过多，个人觉得是少于15个，整个类的代码行数少于1000行左右  遵循单一职责有不少的好处：
 可以降低类的复杂度：一个类只负责一项职责，其逻辑肯定要比负责多项职责简单。 提高代码的可读性：类内中复杂度降低了，容易理解，也提升了整个系统的可维护性。 降低变更产生的风险：变更是必然，单一职责遵守好，修改一个功能时，可以对其它功能无影响。  结语 由于职责划分无量化的标准，在实际中我们尽量根据项目需求的不同角度去划分职责。像充血模型一样，生搬硬套单一职责原则会引起类的体积膨胀。过细的职责划分，也导致类的数量膨胀，造成整个系统的复杂。单一职责关键是要看职责的范围与层次，在一定范围内的类足够封装性，引起它的变化只有一类原因。
</content>
    </entry>
    
     <entry>
        <title>降低模块间耦合</title>
        <url>http://lanlingzi.cn/post/technical/2019/0523_dep_couple/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 提到耦合，必须先提依赖。依赖不可避免，而是尽可能地降低耦合。
依赖 模块依赖指模块之间发生了关系，如模块A调用了模块B的接口，则模块A依赖了模块B。依赖的英语是Dependency。
模块依赖是系统内不可避免的，复杂的系统都是分而治之，软件架构活动中最重要的事就是如何正确把系统分解，并定义他们之间关系。存在关系就会存在依赖，依赖是系统分解的必然产物。如果一个系统内的模块间不存在任何的关联，那他们应该划分为不同的系统；一个模块没有与其它的模块发生关联，那这个模块就应该不存在这个系统中。
模块的依赖关系，按生命周期阶段可分为：
 开发态依赖：如开发模块A时，需要依赖其它模块提供的接口，数据结构等文件依赖；还有一种如测试依赖，仅仅发生在开发阶段，在测试时，需要依赖测试数据，测试框架等，测试完成就不需要了。 运行态依赖：在系统运行时，模块A必须依赖其它模块提供能力才能完成某种完整的功能或服务，依赖的形态可能是本地或远程接口，集中配置数据，模型数据信息等。  开发态依赖可能引发运行态依赖，但运行态依赖不一定需要在开发态就依赖。我们经常关注的是运行态依赖导致的问题，目前的微服务架构设计，减少了开发态的依赖，把依赖导致的问题后移到运行态。
模块之间最好还是单向的依赖，如果出现A依赖B，B也依赖A，那么要么是A、B应该属于一个模块，要么就是系统整体拆分有问题。一个完整的软件系统的模块依赖应该是一张有向无环图。
耦合 模块耦合是指去修改一个模块A，需要同时要求依赖它的模块也跟着修改，则他们发生耦合。耦合相比依赖强调的是变化及影响，耦合的英语是Coupling。
由于依赖关系必然存在，变化也不可能避免，当变化发生在某个模块时，影响可能会波开到其它模块，这是依赖带的危害：
 过多依赖：如一个模块的变化，导致其它多个模块需要跟着发生变化，这是一种强耦合，也势必对系统带来非常多的修改，造成系统的不稳定。 依赖传递：如一个模块的变化，导致其多层的下游依赖需要跟着都发生变化，这也是一种耦合，带的的影响往往对系统难评估、不可控。  提到耦合，不得不提一下正交性。正交性是从几何学中借鉴过来的，从软件开发的角度来看，就是一个方法，类，模块的改动不对另一个方法，类，模块造成影响，那么它们就是正交的。正交性设计是有助于简化复杂度，因为任何操作均无副作用，也就能降低模块间的耦合。常说“高内聚，低耦合”，我理解的低耦合，其实是降低变化所带来的影响程度，尽可能地较小影响，甚至不感知变化而无影响。那依赖关系中，被依赖的模块需要设计为；
 稳定：模块的功能，接口，模型尽可能是不经常变化的。 抽象：模块进行了抽象，屏蔽了实现具体细节，依赖看不到变化。  另外一种思路则是想办法控制和消除不必要的耦合，首先是减少不必要的依赖：
 内聚：控制好模块划分粒度，一个模块跟另一个模块没有功能重叠，一个模型只做好份内事。 紧凑：模块暴露的接口，数据越少越好，他们之间越正交，一个模块的变动对另一个模块的影响就最少。  方法 降低耦合是软件界经常谈论的话题，软件大师们已给我们总结一些原则、方法论，下面是我的一些收集与整理。
依赖倒置&amp;ndash;面向接口 依赖倒置原则是 Robert Martin 大师在 《Reduce Coupling》书中提出，一句总结就是将依赖关系倒置为依赖抽象，而抽象是往往建立在接口之上。
使用Java的同学，感受最深的是就是interface，在JDK代码中存在大量的设计是基于接口抽象，比如IO操作就抽象出InputStream与OutpuStream接口，定义了统一的Read与Write行为。而实现这些接口可能是本地文件，也可能是网络连接。又如JDBC抽象出核心的Connection与Statement，定义了统一的连接与SQL语句操作方法，可以达到不同的实现对接不同的数据库系统的目的。
抽象带来好处就是，以不变应万变，它隐藏了实现的细节，有效地隔离了变化，从而很大程度地避免了因变化带来更大的波及范围，因为抽象与具体相互完全分离。
同样，降低模块之间的耦合，首先是要面向接口来设计模块。领域驱动设计（DDD）告诉我们的怎么去定义模块的接口：
 领域就是问题域，有边界，一个模块至少是在领域内，解决其问题 建立领域模型来解决领域中的核心问题 领域模型是抽象了领域内的核心概念，解决其核心问题 核心概念无关技术实现细节，基于接口定义概念 梳理领域内的核心概念之间的关系，形成接口的依赖关系  不同的层面的模块，接口形态也有多种，小到语言级的Interface/trait，大到与语言实现无关的RESTful与gPRC接口，他们本质还是DDD中所说的领域通用语言一种描述呈现。
控制反转&amp;ndash;关注点分离 控制反转（IoC）是Spring发家秘籍，作为一个框架（Beans管理容器），它成功有效地消除了应用中不同类之间的显示依赖关系。一句总结就是不要让你来调用我，我来主动调用你。
我们的代码实现，大都是组装一个个对象，对象A调用对象B，一直调用下去来完成某种功能，这也是常见的面向过程编程，顺序地组装各类过程。对象A需要主动地创建与管理对象B的生命周期，这是一种正向控制。而反向控制则是由框架来帮忙创建及注入依赖对象，对象只是被动的接受依赖对象，依赖对象的获取被反转了。
反转给我带来启示是，主从地位的变化，把创建和查找依赖对象的控制权交给了框架，由框架进行注入组合对象，带来的好处就对象与对象之间是松散耦合，一是方便测试，二是利于功能复用，使得程序的整个体系结构变得非常灵活。
同样，降低模块之间的耦合，使用控制反转思想，把调用者与被调用者分开。调用者不关心谁是被调用者，只要知道存在一个具有某种特定接口，达到关注点分离：
 一个关注点就是一个特定的目标或概念，一个模块只有一个关注点，聚集才能高内聚 分离的目的是保证模块之间没有功能上的重复，形成正交性 被分离的功能通过依赖注入完成逻辑组装  当然，控制反转的前提还是依赖倒置，依赖的对象变成是一个抽象（接口），并不关心接口的实现者是谁。
事件驱动&amp;ndash;观察与订阅 经常会碰到这种困境: 模块之间常有一对多的依赖关系，当被依赖模块的状态变化时，其他所有依赖模块都要发生改变。需要维护这种具有依赖关系的对象之间的一致性，又不希望为了维护这种一致性导致模块之间紧密耦合。
撇清关系是降低彼此耦合最为直接手段，以事件的弱引用去解决模块边界的耦合。当模块A需要执行模块B中的业务逻辑，相比于直接调用，我们可以发送一个事件出来。模块B通过一种机制能够接收到这个事件，当这类事件被触发时再去执行它的逻辑。
事件也是的一种抽象，独立于这两个模块之外，这样使得模块之间相互独立，事件在模块之间也实现共享。事件驱动可能存在一个共享内核（事件分发器，事件总线），模块只依赖于这个共享内核，而无需知道彼此的存在，也就实现了解耦合。
事件驱动还有另外一个好处，可能降低模块间的时序耦合：
 有些业务处理需要耗费相当长的执行时间，不想看到用户耗费时间去等待这些逻辑处理完成，则可以作为异步任务来执行。所要做的是触发一个事件，让Worker来调度执行。 有些业务逻辑不需要关注是否在同一个上下文环境中。例如在CQRS框架，命令与查询分离，面向查询优化，查询数据来源是事件的接收与记录。  对于事件的处理，通常有两种方式，他们的区别如下：
 观察者模式：采用监听器（Listener），通过监听器来监听事件的发生，依据事件做出相应的处理，每个监听器一般小巧，专注于响应特定事件的单个职能。观察者模式常常用于对象或模块之间的一对多依赖，通过事件通知方式来达到解耦合的目的。 发布订阅模式：采用订阅者（Subscriber），发布订阅模式需要存一个共享内核，订阅者向这个内核订阅不同的主题（Topic），事件可能被这个内核过滤、缓存，甚至修改了。它更适当异步处理，发布订阅模式是观察者模式一种跨模块（不同的进程）间通讯的延伸。  像Vert.X框架是目前比较受欢迎的基于事件驱动的异步微服务框架，它最主要是把HTTP处理变成事件驱动，核心还是来源于Netty，搞Java的同学不妨多看看Netty源码。
结语 依赖不可避免，但可以降低耦合。降低耦合首先尽可能地是单向依赖；被依赖的模块是稳定的，面向抽象（接口）编程；模块接口操作尽可能无副作用，满足正交性；模块实现上关注点分离，聚集才能高内聚；事件的弱引用一定程度能解决边界与时序耦合。
最重要一点，随着需求的增加变化，依赖与耦合并不是一成不变的，需要不断地去重构才能达到某种平衡，没有绝对松耦合，只是在特定场景下一定程度的松耦合。松耦合目的是降低变化给系统带的危害，切莫本末倒置。
</content>
    </entry>
    
     <entry>
        <title>清晰的代码结构</title>
        <url>http://lanlingzi.cn/post/technical/2019/0519_structure/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 问题 架构设计中常常关注几个视图，如功能视图、逻辑视图、运行视图与部署视图。但架构师们由于层次较高，长期缺少代码编写能力，往往就直接忽视了开发视图。开发视图主要描述软件的开发工程结构、代码规范，以及构建技术等。代码结构和构建关系到项目的可持续维护以及维护的周期，非常重要。但实现开发活动，架构到开发中间层的GAP，真正重视并落地的很少很少。
清淅明确的代码结构，是软件项目成功的重要开始。
代码结构不应该仅仅归纳为 “代码编码风格” 一类，它是架构在代码层次的真实反应，架构是否能落地，代码结构的良好设计起着至关重要的作用。软件是有生命力的，需要考虑其可持续性发展。一个结构层次非常不好软件，它的逻辑可能并不一定复杂，但随着时间的推移，需要花费非常长的时间去理解它表达的的意思。同样不好的代码结构，让构建变得困难或效率低下，进一步降低了它的生命力。
目的 当然，代码层次结构在软件质量属性方面，还是归于开发态的 “可读性和可维护性” 的范畴，我们设计一个层次清晰的代码结构，就是为了达到以下几点目的：
 代码即架构：同样也是架构即代码，源码就可以解析软件架构，软件的组成，软件系统之间的依赖关系。也正如12因子中提到的CodeBase，一份代码能构建出不同的形态的软件，部署在不同的环境。背后的根因是代码能真实地反映出软件的运行与部署架构，构建都能通过代码来跟踪，由良好的代码结构来承载软件的不同形态的运行组成。 可读性：代码不仅仅是编译给机器来读，更重要是软件人员参与其中，代码让人读懂，它才能更好的生命力。接手这个软件代码的人，一眼就能看懂目录结构，知道软件由什么功能组成，他们的依赖关系是什么；软件启动入口在哪里，测试目录在哪儿，配置文件在哪儿等等，从而非常快速的了解这个项目。 可维护性：清晰明确的代码结构划分，也是软件各功能模块的边界划分，一旦定义好组织规则后，维护者就能很明确地知道，新的功能能增加在哪里，新增的文件能放在什么目录下，好处是随着时间的推移，代码与配置的规模增加，代码结构不会那么快的腐烂，变更导致乱麻一团。  代码层次结构大到子系统、服务（组件）的划分，中到模块工程目录的划分，小到工程内的各个package（Java/Go）目录的划分。无论何种层次，重要还是保持一个层次清晰的目录结构。组织一个良好的目录结构也是设计思想直接体现，其实也并不是那么的简单能设计出来，实际需要根据软件的功能划分不断地调整。
模块结构 系统结构的划分是对系统逐步分解的一个过程。设计软件结构的具体任务是将一个复杂系统按功能进行模块划分、建立模块的层次结构及调用关系、确定模块间的接口和人机界面等。模块的划发也是第一层项目工程目录结构划分，只要是模块划分是清晰的，还是较容易映射到代码工程结构。
模块的划分方法论很多，模块往往是将由一个或多个功能(或目标)密切相关或相似的应用程序所组成的程序集合抽象出来组成在一起。这本质是对业务需求深入了解之后的功能与数据层面的分解。之前的SOA，以及现在微服务都是一种软件架构工程上的优秀实践，但它不能给出业务系统中是按什么维度来划分多少个服务或微服务的答案。
大的道理与原则还是有一些：
 拆分：任何组织结构都是这样，软件架构的核心就是拆分再组成。拆分涉及到一个粒度的问题，非常考验设计者的水平和经验。 分层：任一细分小的组织结构也会存在分层，在软件中最为经典的还是MVC，它不仅仅是用于Web开发，而是数据、逻辑和表示的分离思想。 隔离：明确责任才能更好地工作，软件亦是如些，划清界限，不要过多假设，不要拖泥带水，任何模块只做它该做的事情就对了。  包结构 模块在架构设计大都能较清晰明确，但模块内的包结构是常见混乱的地方。在Java体系中，Maven作为优秀的工程实践，它约定了源码、测试与资源三种顶层目录，我们还需要进一步在模块内如何划分包（package）结构。
同样需要有一种按功能划分Package的意识：
 功能子模块，尽量做到高内聚，低耦合，子模块的依赖是单向的 功能与分层划分相结合，如一个功能内，可能涉及到逻辑，数据，接口，这些在以功能名为package下进一步划分子pakcage 全局用到的变量，常量，应该放到一个地方去维护，全局变量尽量不要跨子模块，定义也是放在子模块的package内 用到的各种工具类，放在一个package下统一管理，若工具类多了，要考虑按功能进一步划分 对需要使用的数据结构，应分类存放，而不是混沌的一锅粥  优秀的包结构划分有着非常多的参考，例如JDK的源码，Spring boot的源码。
命名 对模块，包package，类，方法的命名对于提升代码结构清晰度也非常的重要，好的命名让代码自解释，使用与维护时都能快速知道它所要表达的涵意。
 多看开源代码，积累好的用词，多采用业界惯用词 模块，能代表它提供功能特点，常用的gateway，worker，schudler，service, web，agent等后辍。 包，一是代表它提供的功能，还有些子模块的分层，如mapper/dao, service, controller, api, util, config等作为子package名称 类，常用的Factory，Builder，Command，Proxy，Adapter，Osberver，Compsite，Service，Controller，Request/Response等作为后辍 方法：采用动宾组词，常用的add/remove，lock/unlock，open/close，send/receive，show/hide，begin/end等作为前辍  结语 最近一直在和团队成员写代码，深感软件代码结构的重要性。若代码架构不清晰，是前人挖坑后人掉坑里难以出来。若有代码架构清晰，（微）服务、模块内可能有一两骨干再加一些新手就完全可以搞定。这样带来显著的效果是，既可以节省人力成本，也可以快速培养新人。
</content>
    </entry>
    
     <entry>
        <title>不断学习</title>
        <url>http://lanlingzi.cn/post/thoughts/2019/0511_study/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 忽视的差距 公司推崇工程师文化，提拔一些软件工程师作为标杆没有任何问题。事实上发现很难去标签化软件编码高手的特征。资深软件工程师和新手似乎看起来没啥区别，区别他们是异常困难，尤其这个群体中很多的人不愿意展现自己，他们可能藏在一个领域默默奉献着，不显山不露水。
软件开发中很多例行却看是平淡的活动，大家都能做到。以产品交付为中心的文化里，人人都是螺丝钉，往往忽然一个人的价值点，很少有人能愿意去了解甚至去分析新手与高手之间的差距。软件开发中专业性总容易被主管们忽视，也因此严重影响了软件工程师追求卓越的过程。曾经发生过可怕的高层观点：精英做架构，资深做设计，随便招个高中生编码就行了。试图把软件产品开发也做成像其它物理产品一样的流水线，这多么年来证明是错误的。
软件工程师中的高手，往往是“上善若水，水善利万物而不争”。他们的专业性看似冰山一角，藏锋敛锐，却在关键时，才会发现他绵绵不绝的力量。这种力量源自他们不断学习的程度，这也是区分高手与普通一种非显性的重要特征。他们大多是持续保持着谦虚，刻苦的学习新知识与技能，向更专业的方向不断地努力。
软件行业是一个知识更新非常快的行业，而软件高手又常常被现实工作中忽略。大多数人觉得看不到付出得到回报的希望，而是寻找30或35之后其它的出路。逃离似乎成了中国很多程序员的政治正确选择，因而国内少有出现软件界大神级的人物。运动员必须经常锻炼，来保持竞技状态；同样，资深的软件工程师也需要花费更多的时间来维持水平。逆水行舟，不进则退。很多工程师疲于996的工作方式，没有精力与动力去付出更多的时间去学习。
学习的能力 要想成为高手，就从学习开始。学习能使人进步，则更专业的学习就能使人更快速的成长。学习本身，当然也有高下之别。
带着思考学习 努力非常重要，正确地努力才能离高手更进一步。
对于擅于学习的人来说，书本本身所描述的知识并不重要。这些知识就在那里，每个人都能看到，但并不是每个人都有相同的收获。学习更多是一个思考的过程，面对知识是否有所启发。
软件方面的学习，不是因你看了多少本编程、工程、设计等方面的书籍；而是当你看到这些知识时，能否发现工作中的问题，思考如何利用他们来改进提升你解决实际问题的能力。学习过程是努力从中挖掘对自己有用的东西，并掌握它。而不是看到别人学习了我也要去学习，没有目的的学习也是走马观花，片叶不粘身。
沿着方向积累 不积跬步无以至千里，不积小流无以成江海。
知识是一个不断积累的过程，但无方向的积累，会杂草丛生。尤其是在百花齐放的软件界，眼花缭乱的语言、技术、框架等更会让人迷失了方向。沿着一个方向积累，是你成功高手必经之路。只有在某方面积累达到一定程度了，才更容易扩展到其它的方向。
选择一个方向可能不一定由你自主的选择，人就像软件一样有特定的工作场景与约束，没有万精油的软件，也没有什么都懂的工程师。不管是什么原因，一旦进入某一方向，就坚定选择的方向。放弃往往比坚持容易，高手一个更重要的特征就是坚持，尤其是百尺竿头更进一步，是十分困难，越到一个领域的顶尖，需要更多的付出。
</content>
    </entry>
    
     <entry>
        <title>支持LateX</title>
        <url>http://lanlingzi.cn/post/notes/2019/0504_latex/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>theme</tag>
        </tags>
        <content type="html"> 五一放假正好有点时间，于是计划完成这个 Issue: Is it possible to add latex support&amp;hellip;，要解决支持LateX，只需要集成MathJax。
如何集成 在主题文件layouts/partials/script.html中增加如下，先采用了cloudflare的CDN，暂没有打包到主题目录中，国内可能稍慢些。
&amp;lt;script type=&amp;#34;text/x-mathjax-config&amp;#34;&amp;gt; MathJax.Hub.Config({ extensions: [&amp;#34;tex2jax.js&amp;#34;], jax: [&amp;#34;input/TeX&amp;#34;, &amp;#34;output/HTML-CSS&amp;#34;], tex2jax: { inlineMath: [ [&amp;#39;$&amp;#39;,&amp;#39;$&amp;#39;] ], displayMath: [ [&amp;#39;$$&amp;#39;,&amp;#39;$$&amp;#39;] ], processEscapes: true }, &amp;#34;HTML-CSS&amp;#34;: { fonts: [&amp;#34;TeX&amp;#34;] } }); &amp;lt;/script&amp;gt; &amp;lt;script src=&amp;#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML&amp;#39; async&amp;gt;&amp;lt;/script&amp;gt; 加上 TeX-AMS-MML_HTMLorMML 使得我们可以支持Tex和MathML公式，表示如果浏览器支持MathML解析，那么就使用它，否则会使用HTML-with-CSS来显示数学公式。
如何使用 LaTeX 格式的公式使用主要有两种形式：
 包含在段落之中，见上面的inlineMath配置，采用以 $...$ 引用 独立于其他文字，见上面的displayMath配置，采用以 $$...$$ 引用  更多的使用请参考： http://docs.mathjax.org/en/latest/tex.html
样例 段落行内显示 When $ a \ne 0 $, there are two solutions to $ax^2 &#43; bx &#43; c = 0$ and they are 将会生成
When $ a \ne 0 $, there are two solutions to $ax^2 &#43; bx &#43; c = 0$ and they are
独立段落显示 $$ x = {-b \pm \sqrt{b^2-4ac} \over 2a}. $$ $$ |AB| = \sqrt{(x_1-x_2)^2 &#43; (y_1-y_2)^2} $$ 将会生成
$$ x = {-b \pm \sqrt{b^2-4ac} \over 2a}. $$
$$ |AB| = \sqrt{(x_1-x_2)^2 &#43; (y_1-y_2)^2} $$
</content>
    </entry>
    
     <entry>
        <title>代码整洁与洁癖</title>
        <url>http://lanlingzi.cn/post/technical/2019/0501_clean_code/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 背景 我司强执行力，很容易把事情做得极致，但有时过于极致反而带来不好的意外结果。我参与了公司C/Java等编程规范的评审，但让我受不了的是编程规范中条款事无巨细。连运算符或关键字之间几个空格都要写入规范，太多关于格式、命名等条款。这种在代码格式上的洁癖，可能是见仁见智。但我司的特点是一旦形成规范，就会强行执行，先是考试，再是落入到项目中，像有几个空格这种拿来考试不是折磨人吗，能使用工具解决的为什么不去开发一个工具来提升效率，而不是死记硬背的规范。
整洁代码 Robert C. Martin的《Clean Code》书是本非常接地气的多年开发经验总结，他告诉我们什么是好的代码，怎么去消除代码中“坏的味道”。如何才能写出整洁代码呢？总的原则无非是KISS（Keep It Simple Stupid）：让代码简单直接，让阅读者可以很容易地看出设计者的意图。本书谈到了大量的小技巧和规则，遵循这些规则可以帮你写出更加的整洁代码。整洁代码力求集中，每个函数、每个类和每个模块都全神贯注于一件事。整洁代码简单直接，从不隐藏设计者的意图。
代码洁癖 写出整洁代码并不是一定像处女座一样强迫，陷入代码洁癖症。代码洁癖与整洁相比，他们最终的目的可能不同，代码洁癖者往往多有强迫症，自我欣赏，它关注是代码的格式上的清洁，追求代码视觉上的感受，而不是追求代码逻辑上、可读性与可维护性上整洁。什么是洁癖症表现：
 多余的空格、空行，见一个删一个 什么情况下应该留空格、空行，就会去增加 凡是没有注释，非得加上一个注释，连增删改查不例外，不管有没有意义 纠结字符串统一采用单引号或双引号 连常用无歧义的0或1数字等也得定义一个常量 局部变量命名也非常长，看起来非常明确的样子 &amp;hellip;&amp;hellip;  结语 整洁代码是为了代码更好的阅读与维护，做到代码表义上精确无二义性，逻辑上简洁高效；但切不要陷入一些可以通过工具自动化的感观上干净，以及一些无意义的风格上统一。
</content>
    </entry>
    
     <entry>
        <title>成就感</title>
        <url>http://lanlingzi.cn/post/thoughts/2019/0427_fulfillment/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 前天公司HR找我聊天，聊到问我的成就感是什么。我想表达的观点是成就感是内心一直能处于心态平和，心里踏实，不为事情所扰。尤其是作为一名技术人员，当前的工作是希望是不被打扰，不要去呈现价值，不要去讲故事而去获取更多的资源；而是把自己手上的工作尽自己最大可能努力去做好，自己问心无愧，自己也收获成长。
这似乎有点高大上，不食人间烟火；或者是一种上升到生活哲学的感悟。现实生活中，我们到处都有着功利心，成就感就是对功利的满足。人们更乐于朝着自己收益最大的方向努力，而不是原地享受安逸。个人很难超脱学古人淡泊名利，即使在相对单纯的技术体系，你也会发现人没有功利心的确是一种不容易的事情。
我们在做事情时，往往会被别人莫名地关心与指导。有时这种关心真的是对你有帮助，有时可能却是站在他的立场下，却忽略了被关心人的感受，也可能并非关心你做的事件是否真的的有什么用，而是能给他带来什么。
回到开头，要想自己处于心态平和，其实是非常地难，也是我一直想追求的终极目标。摒弃功利心，不是说要消极处世，一切看淡。而是不要去关注你目前不应该关注的东西，依然保持对做事的专注，或许也是一种积极的处世态度。我可以并不关心工作所服务的产品它最终产生的价值有多大，因为这种价值还不是你能左右。我要做的可能更多地是关注我如何地解一个个自己面临的实际问题，内心才充分踏实感。成就感是一步一步小小的满足，而不是像一次忽中大奖的感觉。
当今浮躁的社会，太缺乏怡然自得的做事方式了，人人都很急，急着产出更大的价值。但大多人却是平凡的，能清楚地认识到自已的不足与做合适地事其实非常地难。对技术无比痴迷精益求精的勤恳程序员们，往往出身平凡。而有着极强目标性的人，通过不断的挑战自我，也早已走向了心中更高的境界。
我们很容易看到山顶的风景，却难以看到山中也存在独特的秀丽。曾经年少时，我也急于求成地做一些事，现在回想起来，我还能坚持做着么？即使现在坚持达成，我还能获得成就感吗？我想若是心身疲惫地达成，获取也是片刻的快乐，过程中的快乐或者才是最好的快乐。
</content>
    </entry>
    
     <entry>
        <title>一指流沙，程序年华</title>
        <url>http://lanlingzi.cn/post/thoughts/2018/1226_hw_soft_king/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 时间就像指间握不住的流沙，静静从身边溜走。
这些年来，我所从事的工作领域在变化，所使用的技术在变化，经历过一线比拼的激情，持续熬夜的艰辛，产品上线的喜悦，一直在公司从事基层研发工作。人生就像自己编写的程序，在程序化地运行着，但能在最好的年华，做自己最热爱的事，于我是一种幸福。
有了电脑后的“放飞” 上世纪90年代，爸爸单位用电脑记账，我觉得很是神奇，买不起电脑就买了个学习机，按照说明书，用GBASIC语言输出满屏各种形状的图形，心中被巨大的喜悦填满，开始了编程的启蒙。高考那年，又被《第一次亲密接触》中互联网的桥段吸引，毫不犹豫报了计算机专业，但遗憾被调剂到信息管理专业，这两个专业之间关系不大，我与编程失之交臂了。
大一下学期买了电脑后，我开始“放飞”自己，各种操作系统只要出新的版本，我就会重装体验，此外就是打游戏，或者“泡”论坛，渐渐发现编程的乐趣，之后就在编码的路上停不下来了。参加过学校计算机编程比赛获三等奖，和室友一起搭建系里的网站，大学毕业去了一家互联网公司做程序员，直到2005年，我有幸加入华为，一晃已经十三年了。
因挑战才能快速成长 来到华为之后，我才发现编程之外有一个更大的世界——一套业务与体系化的技术。外部形势与内部因素持续都在变化，对业务与技能的要求变化太快，我几乎时时刻刻都面临着挑战。
2008年，我们启动了下一代智能网平台的开发，当时智能网产品刚进入欧洲市场。版本刚开发不久，质量不稳定，经常出现宕机。在项目紧急关头，开发代表找到我，让原本做消息平台的我转做话音平台。一开始我是想拒绝的，话音的信令协议我从来没接触过，而且我对产品的代码一无所知，更遑论解决问题。
抱着先做做看的想法还是同意了，不熟悉信令协议，我就把协议规范打印出来当成案头书来读，和业务的兄弟一起开发业务，定位解决问题，让我渐渐熟悉信令协议；面对宕机的问题，尤其遇到地址空间完全破坏的情况，“疯狂”学习汇编指令来提升定位问题的能力。记得当时与一位同事同住坂田市场附近，每天下班回家的路上，我们都会一起讨论今天遇到什么问题，要怎么解决，要是找到解决的办法，有时甚至兴奋得睡不着。
从宕机的泥潭中走出来后，又遇产品在欧洲比拼测试，客户明确提出了稳定性与性能测试的诉求，领导再次安排我负责性能提升的攻关。我非常担心搞不定，一是时间很紧，离客户验收只有两个多月，二是我还没有非常熟悉整个系统的代码。性能提升不仅涉及到编码细节的优化，还要梳理业务流程与模块边界问题，好在领导给了我“一双翅膀”，我带着一名测试与一名开发兄弟，开始沟通与制定测试和优化计划。在计划上，白天我们全心投入分析前一晚的测试数据与优化代码，晚上用机器持续测试稳定性；在优化实施上，采用2/8原则，先解决优先级在前20%的问题，20%的问题大都能提升80%的性能。经过一多月的努力，产品的72小时稳定性呼叫各指标表现平稳，基准流程CAPS（每秒试呼次数）从原来每块单板100&#43;提升到1300。
做完优化之后，我立即出差欧洲参与验证。一开始我没有经验，草率地拿出自研的测试工具给了我们的测试数据，但友商的系统CAPS刚破百，客户自己的测试工具最高也只能到200多，严谨的客户怀疑数据的真实性。我对我们的数据很有信心，于是尝试和客户沟通，对接实验室核心网设备，客户的测试工具以及我们的自研测试工具，一起呼叫测试。在长时间的稳定性测试过程中，即使增加到130%呼叫量的压力测试，我们的产品表现一直稳定如初。我还记得，验证完成的那个下午，客户当场对我们竖起了大拇指。在团队共同的努力下，华为最终拿下TLF三国子网的合同，这也是我们软件业务第一次交付欧洲客户。
努力与付出赢得了信任，让我有更多的机会去接触新的挑战，有了更多的成长机会。后来产品在欧洲大T不断地比拼测试和交付，都有我的参与。在VDF，与友商的核心网对接，发现我们系统的SIP协议连接转换功能缺失，一周内我疯狂写代码，成功对接上并调通业务流程。在DT，在一个月时间内独自完成了版本从Linux到PC的版本轻量化移植，解决客户在PC上一站式业务开发与调测诉求，获得客户认可……
越努力，越从容 2011年我们启动了新的虚拟化、云化支撑平台项目，曾经一起共事的领导点名让我参加新项目。改变对我来说，从来都不是事儿，这一次我还是选择了继续挑战自己。但转变也带给了我可能无法胜任工作的危机感，这让我从来不敢放松自己，而唯一能缓解危机感的方法就是增强应对实际困难的知识与技能。
从无到有构建项目中多个模块，开发基础框架来考虑提升团队开发效率，帮助大家解决很多技术问题，慢慢地团队内有人开始称我为“大侠”。但在我看来，做一个“大侠”，不仅仅是大家认为的“能力强，效率高”，那充其量只是个人贡献，更重要的是能带动团队成员一起成长。无论身处什么岗位，我都会在团队内积极总结和分享。迄今为止，我在Hi3MS上分享了180多篇技术博文，整理过三十页编码最佳实践来指导团队开发。这一过程可以督促我不断完善想法，加深认识，而且也可以传承知识，这可能远甚于写代码本身。
除了自我学习总结，面对层出不穷的知识，做技术的人更不可闭门造车，盲目自信，而是要多从业界“喝咖啡”吸收宇宙能量。2012年，我们基于开源CMDB（配置管理数据库）构建了网络拓扑服务，能端到端开通业务虚拟机组网下的网络配置，成功应用在某局点；2013年，我们研究TOSCA (云应用拓扑编排）规范，把它引入标准化图形化拓扑编排，简化了编排模型……
成功不是未来前进的可靠向导，对软件来说亦然，曾经优秀的技术也可能成为架构演进的绊脚石。2014年以前，我们的开发框架是OSGi，它的模块化，面向接口编程模式曾为我们带来开发便利。我一度很喜爱，但是由于它生态式微，越来越多的第三方组件不再支持，我们使用成本越来越高，反倒成了历史技术债务，团队内也因此多次争论它的去留。2015年初我作为负责人，带队渐进式地引入微服务框架替换了OSGi，提升了团队并行开发效率。
软件设计是一个不断打磨不断完善的过程，技术的提升更多需要亲身的实践。我做方案设计时，都会参与框架与核心代码的编写，也只有深入其中，才会知道其中的关键点，才能更好地解决问题。从2014年开始，我设计并编写了项目中调度控制部件的任务编排框架的代码，从支撑某局点业务的一百多虚拟机节点并发，优化到上千虚拟机节点并发……
多一份努力，就多一分收获。就这样在点点滴滴实战中，一路坚持下来，像玩游戏打怪升级技术点一样，我积累了非常多的技术经验，不管是面对技术方案还是技术实现，都多了一些从容。
诚于己，心得其宜 除了日常工作，我算得上是一个编程语言控了。写过种菜游戏的自动偷菜外挂，刷过手机多个版本，帮老婆微商写过小微记账App，可同时支持安卓与iOS……即使现在，每种语言流行时，我下班回到家只要有时间都会“练手”，关注其生态框架，还涉猎过Typescript、Go、 Rust、Scala，虽谈不上样样精通，但每每有新项目涉及到新语言与框架的应用，对我来说都不是一件太难的事。
我们就像一粒粒种子，因为有着对外面世界的好奇，才能从土壤中探出头来，亲眼见证这个美好的世界。这也是我坚持走技术路线的内在驱动力，是我在成长中能不断适应变化的关键所在。
如今我大学毕业十多年了，以前同学聚会被问得最多的问题是“你还在华为啊？”“还在写代码啊？”，现在大家已经不问了，因为他们知道我足够热爱，不会轻易放弃。
从2016年到2018年初，软件组织结构经历了多次调整。看着身边的同事，曾经带过的徒弟奔赴到新岗位，说实话，内心彷徨过。自己的转身在哪里？自己的追求是什么？要不要去新的领域开始新的挑战？我和很多留在软件的兄弟聊天，我们一致认为，软件一直存在新技术新业务的土壤，也曾是创新的推手。对于喜欢钻研技术的我们而言，组织的调整对我们影响不大，经过这次的变革，大家更加务实，我们有更多的时间来编写热爱的代码。能在一个环境中安心做自己喜欢的事，诚于己，心得其宜，这就是我的情怀。
软件需要传承，也需要积累。今天万物互联与人工智能已至，软件新的机会窗口已打开。去年末，我有幸和同事按需构建部分公共服务能力，开始支撑业务SaaS化探索。现在我又有幸开始参与构建一些智能运营数据分析的技术储备。在产业互联网这一条新的赛道上，虽然我们是后来的学习者，但我们为客户解决业务问题的能力从来不缺。能力源于专业的技术积累，核心竞争力源于关键技术突破，新的赛道上也就不缺技术人员的用武之地。
不记得自己何时把“一指流沙，程序年华”作为eSpace签名，当写下这句话时，我清楚地知道，我将会在技术这条路上坚定而持续地走下去。感谢公司为我提供了广阔的平台，但我还远远不够优秀，需要不断学习与提升。软件开发从来没有标准可以遵循，过程与结果充满不确定性，现在的产品也没有引领世界，我们还须继续努力。始于初心，保持好奇心，坚定恒心，我相信方向已越来越清晰，在前进的道路上，摆正自己的心态，我将继续为软件业务贡献微薄之力。
</content>
    </entry>
    
     <entry>
        <title>Scala中的符号</title>
        <url>http://lanlingzi.cn/post/notes/2018/0721_scala_symbol/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Scala</tag>
        </tags>
        <content type="html"> Scala被有人戏称是 “太阳系最难的语言” ，那我们来看看他那些各种奇怪的符号使用吧，语言充满语法糖，真让人甜得受不了。一旦这些符号组合起来使用，那只能用 “惊为天书” 来形容啊。
(map1 /: map2 ) { case (map, (k,v)) =&amp;gt; map &#43; ( k -&amp;gt; (v &#43; map.getOrElse(k, 0)) ) } 上面的看得懂吗，其实要实现的就是：合并两个Map集合对象（将两个对应KEY的值累加）。
说明：本文为学习笔记，下面内容多数来源于网上多篇文档的收集与汇总，在此感谢原作者们。
泛型 : scala中泛型使用[]指定泛型的类型参数，上下文界定是隐式参数的语法糖
 : 表示上下文界定，如A：B 表示 B 可以进行隐式转化的A类型  示例：
 T:A:B 表示即同时满足AT这种隐式值和BT这种隐式值  &amp;lt;: 与 :&amp;gt;  &amp;lt;: 表示只限定子类，如 T &amp;lt;: A 表示T必须为A的子类 &amp;gt;: 表示只限定子类，如 T &amp;gt;: A 表示T必须为A的父类  &amp;lt;: 与 :&amp;gt; 相当于java范型编程中的extends，super对泛型变量的限定。
示例：
 T &amp;lt;: A with B 表示A和B为T上界 T &amp;gt;: A with B 表示A和B为T下界 T &amp;gt;: A &amp;lt;: B 表示同时拥有上界和下界，并且A为下界，B为上界，A为B的子类，顺序不能颠倒。  &amp;lt;% &amp;lt;% 表示“view bounds”(视界)，比 &amp;lt;: 适用的范围更广，除了所有的子类型，还允许隐式转换过去的类型。
示例：
 T &amp;lt;% A &amp;lt;% B  表示：同时能够满足隐式转换的A和隐式转换的B  =：= , &amp;lt;:&amp;lt; 与 &amp;lt;%&amp;lt; 这些被称为广义的类型约束。他们允许你从一个类型参数化的class或trait，进一步约束其类型参数之一。
 =：= 表示必须是这种类型，如 A =:= B 表示 A 必须是 B 类型 &amp;lt;:&amp;lt; 表示必须是子类型，如 A &amp;lt;:&amp;lt; B 表示 A 必须是B的子类型 (类似于简单类型约束 &amp;lt;: ) &amp;lt;%&amp;lt; 表示必须是可视化类型，A &amp;lt;%&amp;lt; B 表示 A 必须是可视化为 B类型, 可能通过隐式转换 (类似与简单类型约束 &amp;lt;% )  [&#43;T] 与 [-T] 在泛型中，需要描述泛型的类型之间继承关系可以转化的关系。
 [&#43;T] 表示“协变“，是指能够使用与原始指定的派生类型相比，派生程度更大的类型。如：String =&amp;gt; AnyRef [-T] 表示“逆变”，是指能够使用派生程度更小的类型。如： AnyRef =&amp;gt; String  [&#43;T] A是B的子类，如果想让Container[A]是Container[B]的子类，那么只需在定义Container的时候加上“[&#43;T]”就好了；但是注意，如果只加了“[&#43;T]”，只可以实例化从父类到子类的引用。
假定，Bird extends Animal extends Earth
当有Space[&#43;T]定义时，
var a = new Space[Animal] a = new Space[Bird] 但不能是
var a = new Space[Animal] a = new Space[Earth] [-T] 面向对象编程中，子类也可以指向父类的引用，在正常情况下，通过强制类型转换，是可以实现。但是在有集合类的情况下如何实现呢？这就是“协变”[-T]了，只需在定义集合类的时候在集合类上加上“[-T]”即可。
假定，Bird extends Animal extends Earth
当有Space[-T]类定义时，
则如下是OK的：
var a = new Space[Animal] a = new Space[Earth] 列表操作符 :: 与 &#43;&#43; :: 表示普通元素与List的连接操作，示例：
val a = 1 val b = List(3, 4) val c = 1 :: b 则c的结果是List(1,3,4)，需要注意的是，1 :: b 操作，:: 是右侧对象的方法，即它是b对象的方法，而::左侧的运算数是 :: 方法的参数，所以 1::b 的含义是 b.::(1)
&#43;&#43; 表示用于连接两个集合， 示例
val a = List(1, 2) val b = List(3, 4) val c = a &#43;&#43; b 其中a,b保持不变，a和b连接产生一个新表List(1,2,3,4)，而不是在a上面做add操作。
&#43;&#43;= 表示连接两个集合，并赋值，示例
var a = List(1, 2) a &#43;&#43;= List(3, 4) ::: ::: 表示只能List的连接操作，示例：
val a = List(1, 2) val b = List(3, 4) val c = a ::: b 其中a,b保持不变，a和b连接产生一个新表List(1,2,3,4)，而不是在a上面做add操作。
:&#43; 与 &#43;:  :&#43; 用于List在尾部追加元素 &#43;: 用于List在头部追加元素  示例：
 &amp;quot;A&amp;quot;&#43;:&amp;quot;B&amp;quot;&#43;:Nil 结果为 List(A, B) Nil:&#43;&amp;quot;A&amp;quot;:&#43;&amp;quot;B&amp;quot; 结果为 List(A, B)  成对的符号 -&amp;gt; 与 &amp;lt;-  -&amp;gt; 是所有Scala对象都有的方法，生成元组，如 A-&amp;gt;B 结果是返回一个二元的元组(A,B) -&amp;gt; 用于map构建，表示Key -&amp;gt; Value， 如 Map(1 -&amp;gt; &amp;quot;one&amp;quot;, 2 -&amp;gt; &amp;quot;two&amp;quot;) &amp;lt;- 用于for循环中，&amp;lt;- 在Scala中称为generator，在每次遍历的过程中，生成一个新的对象A，这个A是val，而不是var  &amp;lt;= 与 =&amp;gt;  &amp;lt;= 只表示 小于等于号 =&amp;gt; 使用场景相当地多  =&amp;gt;用法 Call by name 传名调用(Call by name)，在 传名调用 求值中，根本就不求值给函数的实际参数，而是使用避免捕获代换把函数的实际参数直接代换入函数体内。如果实际参数在函数的求值中未被用到，则它永不被求值；如果这个实际参数使用多次，则它每次都被重新求值。
传名调用求值超过传值调用求值的优点是传名调用求值在一个值存在的时候总是生成这个值，而传名调用可能不终止如果这个函数的实际参数是求值这个函数所不需要的不终止计算。反过来说，在函数的实际参数会用到的时候传名调用就非常慢了，这是因为实践中几乎总是要使用如 thunk 这样的机制。
传需求调用(Call by need)，传需求调用 是 传名调用 的记忆化版本，如果 “函数的实际参数被求值了”，这个值被存储起来已备后续使用。在“纯”(无副作用)设置下，这产生同传名调用一样的结果；当函数实际参数被使用两次或更多次的时候，传需求调用总是更快。
object Add { def addByName(a: Int, b: =&amp;gt; Int) = a &#43; b def addByValue(a: Int, b: Int) = a &#43; b } addByName是传名调用，addByValue是传值调用。语法上可以看出，使用传名调用时，在参数名称和参数类型中间有一个 =&amp;gt; 符号。
addByName(2, 2 &#43; 2) -&amp;gt;2 &#43; (2 &#43; 2) -&amp;gt;2 &#43; 4 -&amp;gt;6 addByValue(2, 2 &#43; 2) -&amp;gt;addByValue(2, 4) -&amp;gt;2 &#43; 4 -&amp;gt;6 可以看出，在进入函数内部前，传值调用方式就已经将参数表达式的值计算完毕，而传名调用是在函数内部进行参数表达式的值计算的。这就造成了一种现象，每次使用传名调用时，解释器都会计算一次表达式的值。对于有副作用(side-effect)的参数来说，这无疑造成了两种调用方式结果的不同。
复杂示例：
object TargetTest extends App { def loop(body: =&amp;gt; Unit): LoopUnlessCond = new LoopUnlessCond(body) protected class LoopUnlessCond(body: =&amp;gt; Unit) { def unless(cond: =&amp;gt; Boolean) { body if (!cond) unless(cond) } } var i = 10 loop { println(&amp;#34;i = &amp;#34; &#43; i) i -= 1 } unless (i == 0) } 函数定义 使用方式一：In a value：it introduces a function literal（通译为匿名函数，有时候也叫函数显式声明，函数字面量）, or lambda（参考lambda表达式的文章，其实也是匿名函数），示例：
List(1,2,3).map { (x: Int) =&amp;gt; x * 2 } 使用方式二：in a type, with symbols on both sides of the arrow (e.g. A =&amp;gt; T, (A,B) =&amp;gt; T, (A,B,C) =&amp;gt; T, etc.) it&amp;rsquo;s sugar（syntactic sugar语法糖） for Function[A[,B,&amp;hellip;],T], that is, a function that takes parameters of type A[,B&amp;hellip;], and returns a value of type T.（语法糖通过更简洁的语法达到目的，直接把所需要的参数、类型、函数最简化，然后把解析的工作交给编译器来完成，这步称为去糖化。例如，(A,B)=&amp;gt;T，包含了函数，参数以及类型，实际上是一个匿名函数，func(A,B,T)或者func(A T,B T)）。
示例：
scala&amp;gt; val f: Function1[Int,String] = myInt =&amp;gt; &amp;#34;my int: &amp;#34;&#43;myInt.toString f: (Int) =&amp;gt; String = &amp;lt;function1&amp;gt; scala&amp;gt; f(0) res0: String = my int: 0 scala&amp;gt; val f2: Int =&amp;gt; String = myInt =&amp;gt; &amp;#34;my int v2: &amp;#34;&#43;myInt.toString f2: (Int) =&amp;gt; String = &amp;lt;function1&amp;gt; scala&amp;gt; f2(1) res1: String = my int v2: 1 scala&amp;gt; val f2: Function2[Int,Int,String] = (myInt1,myInt2) =&amp;gt; &amp;#34;This is my function to transfer &amp;#34; &#43; myInt1 &#43; &amp;#34; and &amp;#34; &#43; myInt2 &#43; &amp;#34; as a string component.&amp;#34; f2: (Int, Int) =&amp;gt; String = &amp;lt;function2&amp;gt; scala&amp;gt; f2(1,2) res6: String = This is my function to transfer 1 and 2 as a string component. scala&amp;gt; val f22:(Int,Int)=&amp;gt;String = (myInt1,myInt2) =&amp;gt; &amp;#34;This is my function to transfer &amp;#34; &#43; myInt1 &#43; &amp;#34; and &amp;#34; &#43; myInt2 &#43; &amp;#34; as a string component.&amp;#34; f22: (Int, Int) =&amp;gt; String = &amp;lt;function2&amp;gt; scala&amp;gt; f22(2,4) res7: String = This is my function to transfer 2 and 4 as a string component. Here myInt is binded to the argument value passed to f and f2. () =&amp;gt; T is the type of a function that takes no arguments and returns a T. It is equivalent to Function0[T]. () is called a zero parameter list I believe. scala&amp;gt; val f: () =&amp;gt; Unit = () =&amp;gt; { println(&amp;#34;x&amp;#34;)} f: () =&amp;gt; Unit = &amp;lt;function0&amp;gt; scala&amp;gt; f() x 使用方式三：Empty parens on the left hand side (e.g. () =&amp;gt; T) indicate that the function takes no parameters (also sometimes called a &amp;ldquo;thunk&amp;rdquo;);
示例：
object TimerAnonymous { def oncePerSecond(callback: () =&amp;gt; Unit) { while (true) { callback(); Thread sleep 1000 } } def main(args: Array[String]) { oncePerSecond(() =&amp;gt; println(&amp;#34;time flies like an arrow...&amp;#34;)) } } 模式匹配 这个比较容易理解，示例：
object MatchTest extends App { def matchTest(x: Int): String = x match { case 1 =&amp;gt; &amp;#34;one&amp;#34; case 2 =&amp;gt; &amp;#34;two&amp;#34; case _ =&amp;gt; &amp;#34;many&amp;#34; } println(matchTest(3)) } 自身类型（self type） When a trait extends a class, there is a guarantee that the superclass is present in any class mixing in the trait. Scala has analternate mechanism for guaranteeing this: self types. When a trait starts out with
this: Type =&amp;gt;
then it can only be mixed into a subclass of the given type.
示例
scala&amp;gt; trait LoggedException { | this: Exception =&amp;gt; | def log(): Unit = { | println(&amp;#34;Please check errors.&amp;#34;) | } | } defined trait LoggedException scala&amp;gt; import java.io.File import java.io.File scala&amp;gt; val file = new File(&amp;#34;/user&amp;#34;) with LoggedException &amp;lt;console&amp;gt;:13: error: illegal inheritance; self-type java.io.File with LoggedException does not conform to LoggedException&amp;#39;s selftype LoggedException with Exception val file = new File(&amp;#34;/user&amp;#34;) with LoggedException 在定义LoggedException使用了this: Exception =&amp;gt;那么意味着LoggedException只能被“混入”Exception的子类中，因为File不是Exception的子类，所以报错。
下划线 _ _ 在Scala上通常代表是通配符，占位符。
作为标识符 例如定义一个变量 val _num = 123
作为通配符 import语句 例如 import scala.math._
case语句 object MatchTest extends App { def matchTest(x: Int): String = x match { case 1 =&amp;gt; &amp;#34;one&amp;#34; case 2 =&amp;gt; &amp;#34;two&amp;#34; case _ =&amp;gt; &amp;#34;many&amp;#34; } println(matchTest(3)) } 元组（tuple）访问 scala&amp;gt; val t = (1, 3.14, &amp;#34;Fred&amp;#34;) t: (Int, Double, String) = (1,3.14,Fred) //可以用_1，_2，_3访问这个元组 scala&amp;gt; t._1 res3: Int = 1 scala&amp;gt; t._2 res4: Double = 3.14 scala&amp;gt; t._3 res5: String = Fred 可以通过模式匹配获取元组的元素，当不需要某个值的时候可以使用_替代，例如：
scala&amp;gt; val t = (1, 3.14, &amp;#34;Fred&amp;#34;) t: (Int, Double, String) = (1,3.14,Fred) scala&amp;gt; val (first, second, _) = t first: Int = 1 second: Double = 3.14 scala&amp;gt; val (first, _, _) = t first: Int = 1 将方法转换为函数 请参见 Scala中Method方法和Function函数的区别
作为函数的参数 一个匿名的函数传递给一个方法或者函数的时候，scala会尽量推断出参数类型。例如一个完整的匿名函数作为参数可以写为：
scala&amp;gt; def compute(f: (Double)=&amp;gt;Double) = f(3) compute: (f: Double =&amp;gt; Double)Double //传递一个匿名函数作为compute的参数 scala&amp;gt; compute((x: Double) =&amp;gt; 2 * x) res1: Double = 6.0 如果参数x在=&amp;gt;右侧只出现一次，可以用_替代这个参数，简写为：
scala&amp;gt; compute(2 * _) res2: Double = 6.0 更常见的使用方式为：
scala&amp;gt; (1 to 9).filter(_ % 2 == 0) res0: scala.collection.immutable.IndexedSeq[Int] = Vector(2, 4, 6, 8) scala&amp;gt; (1 to 3).map(_ * 3) res1: scala.collection.immutable.IndexedSeq[Int] = Vector(3, 6, 9) 以上所说的为一元函数，那么对于二元函数，即有两个参数x和y的函数，是如何使用 _ 的？下面方法需要的参数是一个二元函数，而且函数参数的类型为T，可以用 _ 分别表示二元函数中的参数 x 和 y 。例如：
scala&amp;gt; List(10, 5, 8, 1, 7).sortWith(_ &amp;lt; _) res0: List[Int] = List(1, 5, 7, 8, 10) 函数组合的参数
scala&amp;gt; def f(s: String) = &amp;#34;f(&amp;#34; &#43; s &#43; &amp;#34;)&amp;#34; f: (String)java.lang.String scala&amp;gt; def g(s: String) = &amp;#34;g(&amp;#34; &#43; s &#43; &amp;#34;)&amp;#34; g: (String)java.lang.String compose 组合其他函数形成一个新的函数 f(g(x))
scala&amp;gt; val fComposeG = f _ compose g _ fComposeG: (String) =&amp;gt; java.lang.String = &amp;lt;function&amp;gt; scala&amp;gt; fComposeG(&amp;#34;yay&amp;#34;) res0: java.lang.String = f(g(yay)) 有时候，你并不关心是否能够命名一个类型变量，例如：
scala&amp;gt; def count[A](l: List[A]) = l.size count: [A](List[A])Int 这时你可以使用“通配符”取而代之：
scala&amp;gt; def count(l: List[_]) = l.size count: (List[_])Int 这相当于是下面代码的简写：
scala&amp;gt; def count(l: List[T forSome { type T }]) = l.size count: (List[T forSome { type T }])Int 你也可以为通配符类型变量应用边界：
scala&amp;gt; def hashcodes(l: Seq[_ &amp;lt;: AnyRef]) = l map (_.hashCode) hashcodes: (Seq[_ &amp;lt;: AnyRef])Seq[Int] scala&amp;gt; hashcodes(Seq(1,2,3)) &amp;lt;console&amp;gt;:7: error: type mismatch; found : Int(1) required: AnyRef Note: primitive types are not implicitly converted to AnyRef. You can safely force boxing by casting x.asInstanceOf[AnyRef]. hashcodes(Seq(1,2,3)) ^ scala&amp;gt; hashcodes(Seq(&amp;#34;one&amp;#34;, &amp;#34;two&amp;#34;, &amp;#34;three&amp;#34;)) res1: Seq[Int] = List(110182, 115276, 110339486) 下划线和其他符号组合的使用方式 下划线与等号 _= 自定义setter方法，请参见 Overriding def with var in Scala
下划线与星号 _* 变长参数 例如定义一个变长参数的方法sum，然后计算 1-5 的和，可以写为：
scala&amp;gt; def sum(args: Int*) = { | var result = 0 | for (arg &amp;lt;- args) result &#43;= arg | result | } sum: (args: Int*)Int scala&amp;gt; val s = sum(1,2,3,4,5) s: Int = 15 但是如果使用这种方式就会报错
scala&amp;gt; val s = sum(1 to 5) &amp;lt;console&amp;gt;:12: error: type mismatch; found : scala.collection.immutable.Range.Inclusive required: Int val s = sum(1 to 5) ^ 这种情况必须在后面写上: _* 将 1 to 5 转化为参数序列
scala&amp;gt; val s = sum(1 to 5: _*) s: Int = 15 变量声明中的模式 例如，下面代码分别将arr中的第一个和第二个值赋给first和second
scala&amp;gt; val arr = Array(1, 2, 3, 4, 5) arr: Array[Int] = Array(1, 2, 3, 4, 5) scala&amp;gt; val Array(1, 2, _*) = arr scala&amp;gt; val Array(first, second, _*) = arr first: Int = 1 second: Int = 2 At符 @ 标识注解 在方法，类，属性上标识一个注解， 如:
@deprecated(&amp;#34;the delayedInit mechanism will disappear&amp;#34;, &amp;#34;2.11.0&amp;#34;) override def delayedInit(body: =&amp;gt; Unit) { initCode &#43;= (() =&amp;gt; body) } 赋值检测 object test { def main(args: Array[String]) { val b=Some(2) val a@Some(1) = Some(1) println(b) println(a) val bb= 2 val aa@&amp;#34;IMF&amp;#34; = &amp;#34;IMF&amp;#34; println(bb) println(aa) } } 输出结果如下，@ 符号在scala编译中做了一个模式配置的工作。将字符串做了比对，如果值相等，将这个值取到赋值给变量；如果值不相等，匹配不上，就报一个异常
Some(2) Some(1) 2 IMF 值匹配重命名 使用在match case场景，可以将匹配的值重新命名，示例：
def calcType(calc: Calculator) = calc match { case Calculator(&amp;#34;HP&amp;#34;, &amp;#34;20B&amp;#34;) =&amp;gt; &amp;#34;financial&amp;#34; case Calculator(&amp;#34;HP&amp;#34;, &amp;#34;48G&amp;#34;) =&amp;gt; &amp;#34;scientific&amp;#34; case Calculator(&amp;#34;HP&amp;#34;, &amp;#34;30B&amp;#34;) =&amp;gt; &amp;#34;business&amp;#34; case c@Calculator(_, _) =&amp;gt; &amp;#34;Calculator: %s of unknown type&amp;#34;.format(c) } /: 与 :\ 了解这两个符号，先要知道fold, foldLeft与foldRight，表示操作遍历问题集合的顺序：
 fold：遍历的顺序没有特殊的次序 foldLeft：是从左开始计算，然后往右遍历 foldRight：是从右开始算，然后往左遍历  他们定义如下：
def fold[A1 &amp;gt;: A](z: A1)(op: (A1, A1) =&amp;gt; A1): A1 = foldLeft(z)(op) def foldLeft[B](z: B)(op: (B, A) =&amp;gt; B): B = { var result = z this.seq foreach (x =&amp;gt; result = op(result, x)) result } def foldRight[B](z: B)(op: (A, B) =&amp;gt; B): B = reversed.foldLeft(z)((x, y) =&amp;gt; op(y, x)) foldLeft和foldRight函数还有两个缩写的函数：
def /:[B](z: B)(op: (B, A) =&amp;gt; B): B = foldLeft(z)(op) def :\[B](z: B)(op: (A, B) =&amp;gt; B): B = foldRight(z)(op) /: 是foldLeft的简写， 示例：
scala&amp;gt; (0/:(1 to 100))(_&#43;_) res32: Int = 5050 等价于
scala&amp;gt; (1 to 100).foldLeft(0)(_&#43;_) res33: Int = 5050 :\ 是foldRight的简写， 示例：
scala&amp;gt; ((1 to 5):\100)((i,sum)=&amp;gt; sum-i) res51: Int = 85 % 与 %% 使用SBT时，在build.st文件中，通常会看到
&amp;#34;org.hibernate&amp;#34; % &amp;#34;hibernate-entitymanager&amp;#34; % &amp;#34;4.1.0.Final&amp;#34;, &amp;#34;com.typesafe&amp;#34; %% &amp;#34;play-plugins-mailer&amp;#34; % &amp;#34;2.1&amp;#34; groupID %% artifactID % revision 来代替 groupID % artifactID % revision
%% 表示SBT会增加工程的Scala版本到 artifact name 结尾，示例：
org.scala-tools&amp;#34; % &amp;#34;scala-stm_2.9.1&amp;#34; % &amp;#34;0.3&amp;#34; 假定工程的Scala版本为2.9.1，则上面可以简写为
org.scala-tools&amp;#34; %% &amp;#34;scala-stm&amp;#34; % &amp;#34;0.3&amp;#34;  参考：
 FAQ HOW DO I FIND WHAT SOME SYMBOL MEANS OR DOES? scala =&amp;gt;符号含义总结 Scala中_(下划线)的常见用法 Scala中那些令人头痛的符号 Scala的foldLeft和foldRight scala - 从合并两个Map说开去 - foldLeft 和 foldRight 还有模式匹配 </content>
    </entry>
    
     <entry>
        <title>Cache设计</title>
        <url>http://lanlingzi.cn/post/technical/2018/0624_cache_design/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件设计</tag>
        </tags>
        <content type="html"> 一提到Cache，就想到08年我为公司写的消息缓存系统的惨痛教训。当时Redis与Memcached远还没有流行，公司对使用开源项目也是慎重，于是我和另一个同事自己撸了一个系统，但做着做着就变成一个带有强业务逻辑的Cache了。后面又扩大他的使用场景，也导致了一些问题。这个系统的要满足如下场景：
 针对消息对象缓存，每个消息都非常小，要高效地使用内存 存在定时消息，当定时到了，需要回到业务系统中去调度 消息有优先级与时序性，要支持按不同的属性来索引（消息ID，发送人，收件人等） 消息量非常大，缓存需要有淘汰机制，支持淘汰的消息本地文件存储（相当于多级缓存，本地文件存储要求高效索引）  从上面的场景来，它比纯Key/Value的缓存复杂，即要高效使用内存，同一个Value缓存，存在多个Key映射，而Value只能缓存一份，Value有优先级与时序性，索引时需排序处理，又有点消息队列的诉求。
今天，我们大量在使用Redis来做缓存，Redis只作为Key/Value存储，上层复杂的缓存相关业务逻辑是在其外来叠加实现。但由于对于业务系统来说，永远都是具体情况具体分析，没有最好，只有最合适，所以也不得不要考虑通用问题：缓存穿透、缓存雪崩，缓存击穿。
缓存穿透 缓存系统一般都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统（如DB）查找。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。
解决办法：
 对空结果缓存，缓存时间设置较短，当该key对应的数据有抛入时更新 对Key进行过滤，设计Key有一定的规范，当Key满足规范时才去后端查找。 布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉  缓存雪崩 当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统带来很大压力。
解决办法：
 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期（此点为补充）  缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，导致大并发的请求可能会瞬间把后端DB压垮。这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。
解决办法：
 使用互斥锁(mutex key)：如使用Redis的SETNX（SET if Not eXists，只有不存在的时候才设置，可以利用它来实现锁的效果） &amp;ldquo;提前&amp;quot;使用互斥锁(mutex key)：在value内部设置1个超时值(timeout1), timeout1比实际的cache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。 &amp;ldquo;永远不过期&amp;rdquo;：对于热点数据的Key，快过期时预先加载，难点在于热点数据如何统计。 过载保护：应用层的过载保护，比如API调用降级，避免对后端系统高并发访问。  参考：
 基于Redis的布隆过滤器的实现 如何应对缓存穿透 缓存使用与设计系列文章&amp;ndash;目录 </content>
    </entry>
    
     <entry>
        <title>自定义扩展Spring Cache注解</title>
        <url>http://lanlingzi.cn/post/technical/2018/0623_customize_spring_cache/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> 昨天在公司发现采用@Aspect定义一个切面，对MyBatis的Mapper接口方法上标注自定义的注解，无法切入拦截。
背景 Spring Cache提供了声明式的@Cacheable等注解，很方便地对Mapper接口方法来实现缓存。他们好用但简单，缓存的Key大多选择主键。但实际项目上有不少关系对象表（如下面的代码所示）；不能采用主键作为Key，因为大多数的查询场景是根据其关联的另一个字段查询。若以此字段作为Key，当存在批量插入，更新或删除时，都会影响缓存的数据。而Spring Cache的注解无法对参数为数组或List的生成Key。
于是想到自定义Cache注解来解决批量插入，更新或删除来刷新相应的缓存。对注解的拦截@Aspect声明的切面是最为简单的方式。核心实现代码如下：
@Data public class RoleAuthPO { String relId; // primary key String roleId; // cache key String authId; // roleId&amp;lt;-&amp;gt;authId: n&amp;lt;-&amp;gt;m } @Mapper @CacheConfig(cacheNames = &amp;#34;role-auth) public interface RoleAuthMapper { @UpdateProvider(type=RoleAuthSQLProvider.class, method=&amp;#34;batchUpdate&amp;#34;) @BatchCache(keyPrefix=&amp;#34;role-auth:role-id:&amp;#34;, keyFiled=&amp;#34;roleId&amp;#34;) void batchUpdate(List&amp;lt;RoleAuthPO&amp;gt; pos); @Select(&amp;#34;SELECT * FROM T_ROLE_AUTH WHERE ROLE_ID=#{roleId}&amp;#34;) @Cacheable(key=&amp;#34;`role-auth:role-id:`&#43;p0&amp;#34;) List&amp;lt;RoleAuthPO&amp;gt; queryByRoleId(@Param(&amp;#34;roleId&amp;#34;) String roleId); } @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface BatchCache { String keyPrefix() default &amp;#34;&amp;#34;; String keyFiled() default &amp;#34;&amp;#34;; } @Aspect @Component public class BatchCacheAspect { @AfterReturing(&amp;#34;@annotation(BatchCache)&amp;#34;) public void doBatchCache(JoinPoint point) { System.out.println(&amp;#34;before batchCache&amp;#34;); } } 笔者的项目是使用Spring Boot 1.5.12，Debug跟踪都无法进入doBatchCache方法。而项目也有采用@Aspect来实现其它的注解，这些注解能正常切入，他们的区别是这些注解是标注在具体类的方法上，而不是接口方法。
问题浮现 那为什么Spring Cache的注解可以切入？通过查看Cache的注解实现，它并没有采用@Aspect声明的切面，而是采用CacheOperationSourcePointcut。
后又做了一个验证，把Spring Boot切换到2.X，奇迹发生了，居然是可以切入。那有一种可能就是这个问题就出在Spring Boot 1.5.X的@Aspect不支持对标识在接口方法的拦截。
网上已有牛人对这个问题做了深入的分析，参见 接口方法上的注解无法被 @Aspect 声明的切面拦截的原因分析 ，从他的分析来看，Mybatis的Mapper接口是通过JDK动态代理生成的逻辑，此问题在Spring Boot 1.5.X下是无解的，@Aspect不支持切入不受Spring Bean管理的对象。而我的项目中存在大量的Mapper，也不可能给每个Mapper定义一个FactoryBean来达到让Spring来管理。
另一解决思路 既然Spring Cache的注解在接口方法上有效，那我们再来看看它的机制。当我们在Configuration类打上@EnableCaching注释时，除了启动Spring AOP机制,引入的另一个类ProxyCachingConfiguration就是SpringCache具体实现相关bean的配置类：
@Configuration public class ProxyCachingConfiguration extends AbstractCachingConfiguration { @Bean(name = CacheManagementConfigUtils.CACHE_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryCacheOperationSourceAdvisor cacheAdvisor() { BeanFactoryCacheOperationSourceAdvisor advisor = new BeanFactoryCacheOperationSourceAdvisor(); advisor.setCacheOperationSource(cacheOperationSource()); advisor.setAdvice(cacheInterceptor()); advisor.setOrder(this.enableCaching.&amp;lt;Integer&amp;gt;getNumber(&amp;#34;order&amp;#34;)); return advisor; } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public CacheOperationSource cacheOperationSource() { return new AnnotationCacheOperationSource(); } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public CacheInterceptor cacheInterceptor() { CacheInterceptor interceptor = new CacheInterceptor(); interceptor.setCacheOperationSources(cacheOperationSource()); ..... return interceptor; } }  AnnotationCacheOperationSource的主要作用是获取定义在类和方法上的SpringCache相关的标注并将其转换为对应的CacheOperation属性。 BeanFactoryCacheOperationSourceAdvisor是一个PointcutAdvisor，是SpringCache使用Spring AOP机制的关键所在，该advisor会织入到需要执行缓存操作的bean的增强代理中形成一个切面。并在方法调用时在该切面上执行拦截器CacheInterceptor的业务逻辑。 CacheInterceptor是一个拦截器，当方法调用时碰到了BeanFactoryCacheOperationSourceAdvisor定义的切面，就会执行CacheInterceptor的业务逻辑，该业务逻辑就是缓存的核心业务逻辑。  从Spring的AOP机制已知，要对一个方法或类切入需要实现如下：
 一个Advisor，它可以扩展Spring中AbstractBeanFactoryPointcutAdvisor 一个Pointcut，它可以扩展Spring中StaticMethodMatcherPointcut 一个MethodInterceptor，在此接口中实现拦截逻辑  参考Spring Cache的ProxyCachingConfiguration，实现对@BatchCache拦截核心实现如下：
@Configuration public class ProxyBatchCacheConfiguration { @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BatchCacheBeanFactorySourceAdvisor batchCacheAdvisor(@Autowired CacheManager cacheManager) { BatchCacheBeanFactorySourceAdvisor advisor = new BatchCacheBeanFactorySourceAdvisor(); advisor.setAdvice(new BatchCacheInterceptor(cacheManager)); return advisor; } } // 对存在标识有@BatchCache方法进行切入 public class BatchCacheSourcePointcut extends StaticMethodMatcherPointcut implements Serializable { @Override public boolean matches(Method method, Class&amp;lt;?&amp;gt; aClass) { BatchCache batchCache = method.getAnnotation(BatchCache.class); return batchCache != null; } } // 定义一个Advisor，指定Pointcut public class BatchCacheBeanFactorySourceAdvisor extends AbstractBeanFactoryPointcutAdvisor { @Override public Pointcut getPointcut() { return new BatchCacheSourcePointcut(); } } // 当Pointcut.matches时，Spring框架会调用invoke，即可实现BatchCache所要逻辑了 public class BatchCacheInterceptor implements MethodInterceptor, Serializable { // 注入CacheManager，可以根据cacheNames来操作Cache final CacheManager cacheManager; public BatchCacheInterceptor(CacheManager cacheManager) { this.cacheManager = cacheManager; } @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable { Method method = methodInvocation.getMethod(); BatchCache batchCache = method.getAnnotation(BatchCache.class); // .... 省略BatchCache的逻辑 return methodInvocation.proceed(); } } 从Debug调用栈来看，在Spring框架中，当调用是接口动态代理对象方法时，会生成JdkDynamicAopProxy，此对象会设置所有advisors。只要我们写的advisor以Bean方式注入到Spring框架，它会就生效，流程总结如下：
声明advisor-&amp;gt;Pointcut.matches-&amp;gt;MethodInterceptor.invoke
</content>
    </entry>
    
     <entry>
        <title>Rust支持既存类型的理解</title>
        <url>http://lanlingzi.cn/post/technical/2018/0602_existential_types/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Rust</tag>
        </tags>
        <content type="html"> 最近利用周末时间来学习Rust编程，发现新发布的1.26版本，带来了impl Trait，一时对它的写法难以理解，今天又找点资料再温习一下。
 impl Trait is now stable allowing you to have abstract types in returns or in function parameters. e.g. fn foo() -&amp;gt; impl Iterator&amp;lt;Item=u8&amp;gt; or fn open(path: impl AsRef).
 既存类型 impl Trait是对既存类型(Existential types)的支持，那什么是既存类型?
 Existential types are frequently used in connection with record types to represent modules and abstract data types, due to their ability to separate implementation from interface. For example, the type &amp;ldquo;T = ∃X { a: X; f: (X → int); }&amp;rdquo; describes a module interface that has a data member named a of type X and a function named f that takes a parameter of the same type X and returns an integer. This could be implemented in different ways; for example:
intT = { a: int; f: (int → int); }
floatT = { a: float; f: (float → int); }
These types are both subtypes of the more general existential type T and correspond to concrete implementation types, so any value of one of these types is a value of type T. Given a value &amp;ldquo;t&amp;rdquo; of type &amp;ldquo;T&amp;rdquo;, we know that &amp;ldquo;t.f(t.a)&amp;rdquo; is well-typed, regardless of what the abstract type X is. This gives flexibility for choosing types suited to a particular implementation while clients that use only values of the interface type—the existential type—are isolated from these choices.
In general it&amp;rsquo;s impossible for the typechecker to infer which existential type a given module belongs to. In the above example intT { a: int; f: (int → int); } could also have the type ∃X { a: X; f: (int → int); }. The simplest solution is to annotate every module with its intended type, e.g.:
intT = { a: int; f: (int → int); } as ∃X { a: X; f: (X → int); }
 从上面wiki的介绍，既存类型相对还是比较容易理解，既存类型早已发明，有着距今约30年的历史。既存类型是用来表达一种抽象类型，它连接record types（如rust中的struct），其实现与接口分离。说白一点，有点像Java中interface或GO的Interface。
在Rust中，我们可以采用impl Trait指定函数的返回类型，而不必指出具体是哪一种类型。例如：
fn foo() -&amp;gt; impl Trait { // ... } 如果是这样，为什么Rust不直接设计为如下，Trait像Java8中interface或GO的Interface，函数返回interface：
fn foo() -&amp;gt; Trait { // ... } 遗憾地是，上面的写法在Rust都不可能编译通过，因为在Rust变量lifetime之说，返回值的lifetime不能悬空，那只能变成这种写法
fn foo3() -&amp;gt; Box&amp;lt;Trait&amp;gt; { Box::new(5) as Box&amp;lt;Trait&amp;gt; } 这样写是不是很繁琐，不过，使用Box意味着动态分配，我们并非总是希望或需要这样，而impl Trait确保了静态分配。这种方法使foo仅能返回同样的类型。
trait Trait { fn method(&amp;amp;self); } // 表示类型T实现了Trait impl&amp;lt;T: Sized&amp;gt; Trait for T { fn method(&amp;amp;self) { } } fn new_foo1() -&amp;gt; impl Trait { 5 // 返回一个i32类型的值 } fn new_foo2() -&amp;gt; impl Trait { 5.0f32 // 返回一个f32类型的值 } 在定义返回闭包的函数时，新的impl Trait语法也可以如下使用，闭包函数实现了特性Fn：
fn foo() -&amp;gt; impl Fn(i32) -&amp;gt; i32 { |x| x &#43; 1 } 另外，impl Trait语法还可以用于替代泛型类型的声明，如下例所示，虽然在这种情况下，它定义了一个通用类型，而不是存在类型：
// 之前 fn foo&amp;lt;T: Trait&amp;gt;(x: T) { // 之后 fn foo(x: impl Trait) { 从上面来看，impl Trait其实就是一种语法糖而已，在其中语言中司空见惯的用法，由于在Rust的lifetime管理，函数不支持返回抽象类型，简单问题复杂化了。
具体应用 actix是rust实现的一个web框架，它很快就使用到impl Trait，如下所示：
[derive(Serialize)] struct Measurement { temperature: f32, } fn hello_world() -&amp;gt; impl Responder { &amp;#34;Hello World!&amp;#34; } fn greet(req: HttpRequest) -&amp;gt; impl Responder { let to = req.match_info().get(&amp;#34;name&amp;#34;).unwrap_or(&amp;#34;World&amp;#34;); format!(&amp;#34;Hello {}!&amp;#34;, to) } fn current_temperature(_req: HttpRequest) -&amp;gt; impl Responder { Json(Measurement { temperature: 42.3 }) } 其中Responder是一个Trait，它定义如下：
// https://github.com/actix/actix-web/blob/master/src/handler.rs#L24 pub trait Responder { /// The associated item which can be returned. type Item: Into&amp;lt;AsyncResult&amp;lt;HttpResponse&amp;gt;&amp;gt;; /// The associated error which can be returned. type Error: Into&amp;lt;Error&amp;gt;; /// Convert itself to `AsyncResult` or `Error`. fn respond_to&amp;lt;S: &amp;#39;static&amp;gt;( self, req: &amp;amp;HttpRequest&amp;lt;S&amp;gt;, ) -&amp;gt; Result&amp;lt;Self::Item, Self::Error&amp;gt;; Json是一个struct，它的实现在json.rs文件，也是实现了Responder Trait，在respond_to方法中对T进行了序列化，并生成Result对象
// https://github.com/actix/actix-web/blob/master/src/json.rs#L119 impl&amp;lt;T: Serialize&amp;gt; Responder for Json&amp;lt;T&amp;gt; { type Item = HttpResponse; type Error = Error; fn respond_to&amp;lt;S&amp;gt;(self, req: &amp;amp;HttpRequest&amp;lt;S&amp;gt;) -&amp;gt; Result&amp;lt;HttpResponse, Error&amp;gt; { let body = serde_json::to_string(&amp;amp;self.0)?; Ok(req .build_response(StatusCode::OK) .content_type(&amp;#34;application/json&amp;#34;) .body(body)) } } 为什么直接返回&amp;quot;Hello World!&amp;ldquo;与format!(&amp;ldquo;Hello {}!&amp;rdquo;, to)也行，它是怎么做到，原因在于在handler.rs中AsyncResult实现From Trait，支持把任一类型转成AsyncResult。
https://github.com/actix/actix-web/blob/master/src/handler.rs#L292 impl&amp;lt;T&amp;gt; From&amp;lt;T&amp;gt; for AsyncResult&amp;lt;T&amp;gt; { #[inline] fn from(resp: T) -&amp;gt; AsyncResult&amp;lt;T&amp;gt; { AsyncResult(Some(AsyncResultItem::Ok(resp))) } } 参考： [1] https://www.infoq.com/news/2018/05/rust-1.26-existential-types
</content>
    </entry>
    
     <entry>
        <title>从Archlinux到Manjaro&#43;i3 WM</title>
        <url>http://lanlingzi.cn/post/notes/2018/0415_manjaro_i3/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>Manjaro</tag>
        </tags>
        <content type="html"> 这个周未又在家折腾我的Archlinux，把Archlinux换成了Manjaro，窗口管理采用i3-wm，先上图：
本文是折腾之后的记录备份，也适合于目前是Archlinux，想把系统转成Manjaro的同学们参考。
Manjaro安装软件列表与配置已归档到GitHub: xtfly/mydots 。
安装Manjaro 修改/etc/pacman.d/mirrorlist
Server = https://mirrors.tuna.tsinghua.edu.cn/manjaro/stable/$repo/$arch 修改/etc/pacman.conf，由于在Archlinux上安装Manjaro，签名key变化，先配置为对安装包不做签名检查，SigLevel配置为Optional TrustAll，等所有软件安装完成之后再恢复 。
并配置archlinuxcn，用于下载一些国人已打包的软件，如yaourt, vscode等。
SigLevel = Optional TrustAll #Required DatabaseOptional LocalFileSigLevel = Optional TrustAll #Optional ...... [archlinuxcn] SigLevel = Optional TrustAll Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch 个人目前系统的安装包列表： mydots/files/manjaro_i3_packages.txt。
根据安装包列来安装所有包，大约有1000个包共1G的下载量，请耐心等待。
pacman -Syu pacman -S `cat manjaro_i3_packages.txt` 主要使用软件 下面这些软件已包含在manjaro_i3_packages.txt，部分介绍：
 桌面窗口管理：i3-wm，一种平铺风格的窗口管理，简单高效，适合于键盘党 状态栏：i3pystatus，结合i3 bar使用，各种插件 桌面菜单：dmenu与maro_menu 终端模拟器：urxvt 终端下的菜单：bmenu 中文输入：fcitx 浏览器：google-chrome-stable 编辑器：visual-studio-code与VIM 文件管理：PcManFM 视频：VLC 视频：PulseAudio与pavucontrol（配置界面） 蓝牙：blueman 多显示器: xrandr与arandr（配置界面） &amp;hellip;&amp;hellip;  i3pystatus i3pystatus是采用python写的i3stauts，它比原生的i3stauts有更多的插件，配置也更丰富
配置python pip，在root目录下，打开.pip/pip.conf，修改为国内源
[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple/ 执行安装，i3pystatus若显示网卡流量，需要安装netifaces等
sudo pip install git&#43;https://github.com/enkore/i3pystatus.git sudo pip install netifaces colour pypi 配置 本人参考了网上多个配置，形成自己的配置，已经上传到个人GitHub: xtfly/mydots ，供大家参考：
下载之后，在某个用户下，直接执行install.sh可快速安装配置文件，则此用户即采用i3来做窗口管理，主要配置文件
 i3配置，快捷键参考: mydots/files/.i3 i3pystatus配置: files/.config/i3pystatus .Xresources配置：files/.Xresources </content>
    </entry>
    
     <entry>
        <title>响应式编程</title>
        <url>http://lanlingzi.cn/post/technical/2017/1001_reactive_programming/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>Java</tag>
        </tags>
        <content type="html"> RxJava 最早接触响应式编程，是分析Netflix的架构时，发现Netflix系统中大量使用了RxJava(Reactive Extension for Java)。由于Netflix中服务的高并发请求，需要一个高效的异步编程框架，于是他们参考了微软的Rx.Net的实现原理，在JVM上实现了响应式编程(Reactive Programming)的一种方式。同类的库还有Project Reactor, Akka和Agera等等。
传统编程模式下，我们通常是同步实现。同步是最能简单理解的，调用一个函数或方法，等待响应返回。但对于要求高并发的服务端的软件开发，同步实现带来的开销也是巨大的。像Java中，并没有语言层面实现异步，如果没有借助一些框架，1K的并发请求，可能使用1K的线程来处理；如果采用一些异步框架来实现异步，就会像早期的JavaScript，通常是CallBack，Future模式，代码逻辑变得离散而复杂，造成所谓的Callback Hell。JavaScript在ES6引入Promise机制，在ES7引入async关键字，就是想语言原生层面来解决Callback Hell。而Go语言则更进一步，在内置Runtime中，通过Goroutine调度实现IO调用等异步机制，让上层使用感不到异步调用的存在。
再拿RxJava来说，其最基础的原理是引入了Observable概念，一种观察者模式与Reactor模式的增强，但又与传统的观察者模式又不完全相同。传统的观察者模式只涉及到两个对象：观察者（Observer）和被观察者（Observable）。观察者通过将被观察的对象加到自己的观察队列中，当被观察者发生改变时，就会通知观察者东西已经改变。而RxJava中涉及到4个概念：
 Observable：可观察者，即被观察者 Observer：观察者 Subscribe：订阅 Event：事件  Observable和Observer通过subscribe()方法实现订阅关系，从而Observable可以在需要的时候发出事件来通知 Observer数据刷新。而上游只管同过Observable发送数据，或是异步或是同步。下游只管处理，也无须关心上游数据到底怎么生成。
如果这样的话，其实和CallBack也差不多啊。但Observable通过Observable Contract，使得所有CallBack都可以走上同一个管道。这就引出Stream的概念，也是Java 8中最主要的特性。Stream是Java弥补函数式编程的缺陷，解决集合类型函数式与链式操作，它看起来像一个管道的不断地Iterable流。回到RxJava，它使得CallBack都到一个Stream管道流了，而可以与Java 8的函数式编程完美结合，从而避免了Callback Hell。
响应式编程 回到正题，什么是响应式编程，如下是来自Reactive programming - Wikipedia的定义：
 In computing, reactive programming is an asynchronous programming paradigm concerned with data streams and the propagation of change.
 响应式编程(简称RP)是一种异步编程范式，包含两个重要的关键词：
  Data streams: 即数据流，分为静态数据流（比如数组，文件）和动态数据流（比如事件流，日志流）两种。基于数据流模型，RP得以提供一套统一的Stream风格的数据处理接口。和Java 8中的Stream API相比，RP API除了支持静态数据流，还支持动态数据流，并且允许复用和同时接入多个订阅者。
  The propagation of change: 变化传播，简单来说就是以一个数据流为输入，经过一连串操作转化为另一个数据流，然后分发给各个订阅者的过程。这就有点像函数式编程中的组合函数，将多个函数串联起来，把一组输入数据转化为格式迥异的输出数据。
  在JVM上，由于Java语言层面不支持原生异步，RxJava与Rector等都是一种异步编程框架，他们涵盖以下三个特性：
  描述而非执行：在你最终调用subscribe()方法之前，从发布端到订阅端，没有任何事会发生。就好比无论多长的水管，只要水龙头不打开，水管里的水就不会流动。为了提高描述能力，RP提供了比Stream丰富的多的多的API，比如buffer(), merge(), onErrorMap()等。
  提高吞吐量：RP通过线程复用来提高吞吐量，它有点像异步IO的多路复用机制，通过线程复用来处理数据流。
  背压（Backpressure）机制：背压就是一种流控机制。就是消费者需要多少，生产者就生产多少。这有点类似于TCP里的流量控制，接收方根据自己的接收窗口的情况来控制接收速率，并通过反向的ACK包来控制发送方的发送速率。
  当然，与任何框架一样，有优势必然就有劣势：
 优势： 适用于高并发、带延迟操作 劣势： 线程无法细粒度隔离：由于是线程复用，若线程存在卡死，可能导致整个应用被拖垮而不可用。 调试定位因难：采用Stream的链式表达式，一旦出错，你将很难定位到具体是哪个环节出了问题。  响应式宣言 和敏捷宣言一样，响应式编程也有响应式宣言:
 We want systems that are Responsive, Resilient, Elastic and Message Driven. We call these Reactive Systems.
 宣言中也包含了4组关键词:
 Responsive: 可响应的。要求系统尽可能做到在任何时候都能及时响应。 Resilient: 可恢复的。要求系统即使出错了，也能保持可响应性。 Elastic: 可伸缩的。要求系统在各种负载下都能保持可响应性。 Message Driven: 消息驱动的。要求系统通过异步消息连接各个组件。  从上面可以看，响应式宣言，主要目的是解决系统的可用性，用用性首先要保证就是可响应性。
Spring 5 WebFlux 让我还在留在Java开发，还是因为Spring社区。Spring一直是Java编程领域的急先峰，如最早的IOC，后面AOP，当前微服务框架SpringCloud， SprintBoot，以及刚发布的Spring 5中最主要的WebFlux。它积极吸引业界优秀的实践，带入Java世界，给暮色沉沉的Java带来一些新意。
Spring 5最大的亮点是提供了提供了完整的端到端响应式编程的支持，也是Java世界首个响应式Web框架。
左侧是传统的基于Servlet的Spring Web MVC框架，右侧是5.0版本新引入的基于Reactive Streams的Spring WebFlux框架，从上到下依次是Router Functions，WebFlux，Reactive Streams三个新组件。
 Router Functions: 对标@Controller，@RequestMapping等标准的Spring MVC注解，提供一套函数式风格的API，用于创建Router，Handler和Filter。 WebFlux: 核心组件，协调上下游各个组件提供响应式编程支持。 Reactive Streams: 一种支持背压（Backpressure）的异步数据流处理标准，主流实现有RxJava和Reactor，Spring WebFlux默认集成的是Reactor。  除了新的Router Functions接口，Spring WebFlux同时支持使用老的Spring MVC注解声明Reactive Controller。在Web容器的选择上，Spring WebFlux既支持像Tomcat，Jetty这样的的传统容器（前提是支持Servlet 3.1 Non-Blocking IO API），又支持像Netty，Undertow那样的异步容器。
参考：
 Understanding Reactive types [Designing, Implementing, and Using Reactive APIs](Designing, Implementing, and Using Reactive APIs) Spring Framework 5: History and Reactive features 响应式编程总览 </content>
    </entry>
    
     <entry>
        <title>软件的困境</title>
        <url>http://lanlingzi.cn/post/thoughts/2017/0925_soft_dilemma/</url>
        <categories>
          <category>感想</category><category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag>
        </tags>
        <content type="html"> 最近我司的软件产品线面临其史上最大的因境，今天晚上坐班车时，与一位曾经共过事的同事，聊起现在的软件，感慨颇多。大家都认为我们镨过太多的机会点，现在面对互联网软件的直面冲击，以及运营商本身经营上的乏力，运营商这个领域的软件已经无力回天了。另外之前与其它的同事也聊过，我司本质是一家硬件公司，没有做软件的基因。凭着做硬件的套路，做了这么多年的软件产品，也实属于不容易了。做软件产品与做软件服务是完全不同的套路，软件产品是需要卖给不同的客户，交付形态存在多样化，定制不可避免。而卖服务给不同的客户，客户关注是的服务体验，并不太关心软件的本身，只要软件能搞定客户的问题就行，就不会像卖产品那样面临不同的交付形态问题。而目前我们最大的因境就是软件产品不具有可复制性，不能像硬件那样形成规模效应。
今天我们再来只谈谈做软件的不容易。基于传统的软件技术，传统的软件思维，做软件产品，我们会遇到如下三个矛盾，是非常难以有所突破的。
反复重建，架构无法持续演进 我们很容易想到我们国家的城市建设，是一个不断反复重建的过程，建筑的生命力非常的短暂。一个城市的规划师很重要，但再强大的规划师也是难以预见一个城市的发展未来，尤其是一个快速上升，充满经济活力的城市。
同样，面对软件的架构，上世纪60年代就有人提出“软件没有银弹”，再牛逼的架构师，设计出来软件产品，5到10年也必然面临着被推倒重来。原因很简单，软件是为业务服务的，业务在不同的时期，对软件的诉求也是完全不同的。业务的初期，大家对问题的本质往往看不清楚，考虑不全面，而此时很难做出具有非常前瞻性的软件架构，能够持续地与业务发展而演进。
软件技术可以借鉴，但软件本质是具有业务属性，一个软件产品不可能脱离了业务场景而纯技术的存在。就像建房子，中国建造方式与中东可能就不一样，因为他们面临的环境不同，使用人群的文化不同。纯技术的照搬，可能并不能解决实际的痛点，可能造就的是一个被人吐槽的烂软件。
同样，再拿房子做比较，房子一旦主体结构建成，接来来几年，想再来做水平或垂直扩展，很难实现，为了支持更广的使用场景，可能10到15年之后，又被彻底推倒重来。软件产品也是如些，看似年年卖的是房子，之前的老房子再怎么装修也难以拿出手来卖了。
金无足赤，功能无法完美支撑业务 业务本质是什么，不同的业务专家有不同的见解，我们往往被业务的表面特征所迷惑，这也导致我们的难以对业务进行抽象建模分析。虽然业界在一方面有一些方法论的探索，像领域驱动设计。但业务人员与软件开发技术人员之间往往存在鸿沟，他们之间的通用语言是什么，大家是否理解一致。双方参与的深度，也决定了软件产品的可用性。而做软件产品，恰恰最懂业务的却离软件开发很远。精通业务的人，不懂软件开发；而精通软件开发的，却不懂业务，隔行如隔山。
所以，软件产品通常功能大致满足客户诉求，但似乎又差了一点点，并不是客户心中其实期望的。软件即使三头六臂，也无法完美支撑业务。而一方面，软件不好用，是由于存在”数据孤岛“问题，为了不至于把软件做得庞大无比，必然会对软件进行边界的划分。一旦完成了边界设定，也是形成了一个”数据孤岛“。各个系统（数据孤岛）之间对接集成，都是非常复杂而棘手的问题。需要对接的系统越多，其复杂度是指数级的增长。
资源有限，软件无法满足需求无限 业务的需求是多样化的，并且是随时间变化的，这是需求的无限性，但软件要解决的问题总是有限的。同时，面对不同的客户群，众口难调，业务客户对软件的差异化是客观存在的，期望用一套标准，一套软件产品来解决所有问题，永远是一个美好的梦想。在这种情况下，要么无法满足大量的个性化的需求；要么成本巨大，导致软件产品无法承受。
而在传统的软件开发模式下，软件开发周期长，我们通常的做法，是收集所有的需求合并整理，形成一个功能繁多的超级大版本，看似你需要的功能都有。但对于某些个体使用者来说，众多的功能导致易用性下降，复杂度上升；而需要使用到的功能，却没有做到极致。
通常一个功能众多的软件，对物理资源的诉求也是巨大的，为了能按特性交付给不同的客户，我们又不得不对软件在架构层面进行划分。不管是纵向的切分而是模向的切分，都会导致软件的内部的复杂度，而因为切割带来的的复杂度是业务使用者不愿意看到的。
</content>
    </entry>
    
     <entry>
        <title>开源DNS Server</title>
        <url>http://lanlingzi.cn/post/technical/2017/0910_dns_opensource/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>DNS</tag>
        </tags>
        <content type="html"> DNS是互联网的基础设施，开源的DNS也有不少，下面列出主要的几种供参考：
Bind9 ISC（Internet System Consortium）的Bind一直以来基本上都是DNS的工业标准，Bind应该是目前世界上使用最为广泛的DNS服务器了。Bind起源于1980年的Berkeley大学，比起我的年龄还大，Bind的名称也是源自Berkeley Internet Name Domain。不过Bind也是一直漏洞不断，Bind9是ISC开发人员对Bind重写，目前常见的Linux发行版本中，会自带Bind9的安装包。
Bind9可以作为权威与递归DNS。主要特性如下：
作为权威DNS时：
 Response Rate Limiting (RRL)：对DNS增强，以减少放大攻击 Dynamically-Loadable Zones (DLZ)：支持从外部数据库获取Zone数据，但不建议使用在高性的权威DNS。 Minimum Re-load Time：支持配置文件动态加载。 HSM Support：支持通过原生的 PKCS#11接口或OpenSSL PKCS#11的接口的HSM（ Hardware Security Modules）。 DNSSEC with In-line Signing：支持NSEC与NSEC3的安全协议的签名。 Catalog Zones：支持多Zone的目录管理。 Scalable Master/Slave Hierarchy：支持Master&#43;多Slave组网，Slave从Master同步Zone配置。  作为递归DNS时：
 NXDOMAIN Redirect：当查询一个不存在域名时，转向一个Web页面，它依赖于DLZ特征。 Flexible Cache Controls：对于不正确或过期的域名记录，灵活的缓存控制。 Split DNS：通过配置不同的View，来保护部分私有信息。 Optimum Cache Hit Rate：通过 DNS pre-fetch 技术来优化缓存命中率。 Resolver rate-limiting：在受攻击下，对权威DNS查询限速，减轻对路径解析器的DDoS攻击影响。 DNSSEC Validation：支持对DNSSEC的检验。 GeoIP：支持基于来源不同的递归DNS的请求给出不同的响应。 Response Policy Zone（RPZ）：通过响应策略的Zone来减少对被认为是滥用或非法目的Zone的访问。  双License：ISC 与Mozilla Public 2.0。
开发语言：C。
官方网站：https://www.isc.org/
PowerDNS PownerDNS发起于1999年，也是一个老牌的开源DNS了。它可以作为权威（最新版本3.4.11）与递归DNS（最新版本3.7.4）。2011年07月23日，PowerDNS 3.0 正式版发布，主要特性如下：
 完全支持 DNSSEC ，包括自动签名、rollovers 和密钥维护 TSIG，兼容 MyDNS 的后端 基于 IPv6 的主从结构，并行从节点引擎，MongoDB 支持和 Lua 的区域编辑  欧洲30%&#43;的域名采用PownerDNS，以及全世界75%&#43;的DNSSEC应用。
作为权威DNS时：
 Standards compliant serving of DNS information from all relevant databases Text files, dynamic scripts in various languages Native support for legacy BIND zonefiles Leading DNSSEC implementation worldwide, hosting &amp;gt;75% of all DNSSEC domains Powerful dynamic abilities Geographical load balancing Content redirection, &amp;lsquo;best answer&amp;rsquo; generation Supported on generic hardware running generic operating systems  作为递归DNS时：
 Standards compliant resolution of domain names Strive for maximum resolution percentage or conversely, least customer complaints Powerful dynamic abilities Content redirection &amp;lsquo;best answer&amp;rsquo; generation query &amp;amp; answer modification Filtering Supported on generic hardware running generic operating systems  提供相关的工具：
 dnsscope: query/answer latency time statistics dnsreplay: replay existing traffic against reference nameservers dnsgram: per-time period sampling of traffic to determine overloads dnswash: anonimize PCAP traces, hiding IP addresses, for third party analysis  支持API，承载在（Local socket，&amp;ldquo;raw&amp;rdquo; TCP/IP，RESTful API direct，）
 Statistics Provisioning Zone editing Master/slave operations Log-file investigations Configuration (updates) Stop/Start/Upgrade/Restart  License：GPL 2.0。
开发语言：C&#43;&#43;，扩展：Lua。
官方网站：https://www.powerdns.com/
CoreDNS CoreDNS去年8月份发起新的开源项目，目前已纳入开源基金会CNCF（Cloud Native Computing Foundation，云端原生计算基金会），它归属于Linux基金会。
CoreDNS的前身是SkyDNS，它的主要目的是构建一个快速灵活的DNS服务器，让用户可以通过不同方式访问和使用DNS内的数据。它被设计为Caddy网络服务的一个服务器插件。CoreDNS的每个特性都可以被实现为可插拔的中间件，如，日志、基于文件的DNS以及多种后端技术，进而可以拼接多个插件来创建定制化的管道。CoreDNS已经得到扩展，可以直接被Kubernetes访问服务数据，并以KubeDNS的形式提供给用户使用。
CoreDNS同样可以权威与递归DNS，目前官方的中间件已有31个：
 bind: Serve zone data from a file; both DNSSEC (NSEC only) and DNS are supported (file). dnssec: Sign zone data on-the-fly cache: Caching etcd: Use etcd as a backend, i.e., a 101.5% replacement for SkyDNS kubernetes: Use k8s (kubernetes) as a backend proxy: Serve as a proxy to forward queries to some other (recursive) nameserver loadbalance:Load balancing of responses rewrite: Rewrite queries (qtype, qclass and qname) &amp;hellip;  License： Apache-2.0。
开发语言：GO。
官方网站：https://coredns.io/
其它 DNSPod-SR dnspod-sr是中国最大域名解析服务商DNSPod官方于2012年6月1日开源的一款递归DNS服务器软件。
主要特性：
 CNAME解析加速 A记录组包缓存 请求转发功能 缓存刷新功能 HASH表缓存  License：BSD。
开发语言：C。
官方网站：https://github.com/DNSPod/dnspod-sr
Dnsmasq DNSmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。
作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。
License： GPL-2.0。
开发语言：C。
官方网站：http://www.thekelleys.org.uk/dnsmasq/
Atomia DNS Atomia DNS是一个多租户DNS管理系统，通过编程接口处理大量的DNS数据。Atomia DNS支持对PowerDNS和BIND-DLZ DNS服务器的代理，PowerDNS是默认代理选项。
主要特性：
 支持DNSSEC 完整，易于使用的API  Atomia DNS License：ISC。
开发语言：PHP。
官方网站：http://atomiadns.com/
SmartDNS smartdns是python语言编写，基于twisted框架实现的dns server，能够支持针对不同的dns请求根据配置返回不同的解析结果。smartdns获取dns请求的源IP或者客户端IP（支持edns协议的请求可以获取客户端IP），根据本地的静态IP库获取请求IP的特性，包括所在的国家、省份、城市、ISP等，然后根据我们的调度配置返回解析结果。
smartdns的使用场景：
 服务的多机房流量调度，比如电信流量调度到电信机房、联通流量调度到联通机房； 用户访问控制，将用户调度到离用户最近或者链路质量最好的节点上。  主要特性：
 支持A、SOA、NS记录的查询 支持DNS forward功能  License：未注名
开发语言：Python。
官方网站：https://github.com/xiaomi-sa/smartdns
总结 Bind9是最为成熟的DNS Server，代表了DNS的标准，它特性丰富，License友好，使用者众多，是作为权威与递归DNS的首先，缺点是扩展性一般（相对于CoreDNS），安全漏洞相对比较多（也说明使用者多，被研究与攻击多）。
CoreDNS是开源DNS Server的新星，它的架构优秀，扩展性非常好，是非常有前途的DNS；又在Linux基金会下，有Google带头大哥，主创人员为安全公司Infoblox，所谓是背影深厚。但由于项目时间太短，使用未经大规模考验，待它成熟之后，不排除它可能代替Bind9，成为互联网的基础设施。
PowerDNS它有成熟的管理控制系统，相比于Bind9，它提供基于REST API以及基于Lua脚本的扩展能力。但它的License商用不友好。在商用产品中集成或使用它要注意边界，避免使整个产品开源。
</content>
    </entry>
    
     <entry>
        <title>[转]DNS扫盲系列</title>
        <url>http://lanlingzi.cn/post/technical/2017/0903_dns/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>DNS</tag>
        </tags>
        <content type="html"> 致谢：转自 http://bbs.chinaunix.net/thread-1573358-1-1.html ，由 llzqq 发表。
有关公网DNS 公网DNS服务器是直接服务于广大上网用户的，负责域名（域名记录）到IP地址之间的翻译工作。公网DNS通常是各个网络运营商按照自己的网络分布规划DNS的分布，一般做法是按行政区域放置，如按省份放置。每个省份内也有细分在各地区放置的情况。
近几年来细心的网友会发现上网时如果打错了URL地址（或干脆莫名其妙）会访问到114网站或百度等网站。今天我画了一个简单的图表简要说明一下原因。
如图所示，大方形框内为公网DNS网络基本构架，负责接收用户解析请求的是前端硬件设备如大家常常提到的F5（硬件设备功能单一，负载能力巨大，故把它做为前端设备很合适，图中用A表示）。前端设备后面与递归服务器群连接（一般是LAN连接，也有WAN连接的）。当用户请求域名解析时前端设备会把请求传递到其后的递归DNS处理，最后把结果告知用户。同时前端设备还有负载均衡，链路状态检查等功能。
近年来各个网络运营商如网通，电信等在利益驱使下推出了利用DNS技术实现的网络推广业务。原理很简单，就是当用户不小心打错URL地址或者由于某种原因（如域名欠费）访问的域名不能解析时，公网DNS的前端设备会自动为用户解析到一个被推广的网站上，以此来获得网络推广收入（真是无耻啊，根本不考虑用户感受）。
如果是这样的话，我们为什么不绕过前端设备直接向递归服务器群请求域名解析呢？恩，想法是好的，但这里有两个困难：
 那些递归DNS的IP地址没有公布，大家不知道，没法用啊。 运营商限制了向递归服务器请求的IP地址，也没法用！！  权益之计：
 使用国外的DNS。 自己架设递归DNS。  域名解析及DNS功能分类 按功能（角色）的分类   权威DNS
权威DNS是经过上一级授权对域名进行解析的服务器，同时它可以把解析授权转授给其他人，如COM顶级服务器可以授权ABC.COM的权威服务器为NS.ABC.COM，同时NS.ABC.COM还可以把授权转授给NS.DDD.COM，这样NS.DDD.COM就成了ABC.COM实际上的权威服务器了。平时我们解析域名的结果都源自权威DNS。
  递归DNS
负责接受用户对任意域名查询，并返回结果给用户。递归DNS的工作过程参见本文第二节。递归DNS可以缓存结果以避免重复向上查询。我们平时使用最多的就是这类DNS，他对公众开放服务，一般由网络运营商提供，大家都自己可以架递归DNS提供服务。递归DNS一定要有可靠的互联网连接方可使用。
  转发DNS:
负责接受用户查询，并返回结果给用户。但这个结果不是按标准的域名解析过程得到的，而是直接把递归DNS的结果转发给用户。它也具备缓存功能。他主要使用在没有直接的互联网连接，但可以连接到一个递归DNS那里，这时使用转发DNS就比较合适。其缺陷是：直接受递归DNS的影响，服务品质较差。
  域名解析过程 用户&amp;mdash;&amp;gt;本地递归服务器&amp;mdash;&amp;gt;根权威服务器&amp;mdash;&amp;gt;COM权威服务器&amp;mdash;&amp;gt;ABC.COM权威服务器&amp;mdash;&amp;gt;用户
如图所示，用户A解析域名的过程就是上面的过程。用户B是先经过转发服务器，由转发服务器再向递归服务器请求的。
FAQ：
  递归服务器怎么知道根权威服务器的地址？
很简单，在递归服务器上都保存有一份根服务器的地址列表。最新的根服务器地址列表在这里可以得到：ftp://ftp.internic.net/domain/named.root
  递归服务器每次查询域名都要向根那里找权威服务器吗？
不是的，一旦成功一次，递归服务器就会把权威服务器列表缓存下来（如COM顶级服务器列表可以缓存48小时）。
  这些DNS都是什么人在管理？
本地递归服务器一般由电信运营商架设，服务于自己的用户，并有其管理，自然人也架设。根服务器与顶级域服务器由国际组织统一部署管理（实际控制器在美国政府）。对顶级域服务器来说销售商有可控的写入权。对于像图中所示的NS.ABC.COM的权威服务器就没有门槛了，谁都可以架设。
  智能DNS 前言 智能DNS即为BIND&#43;VIEW的功能实现。在国内，最早把智能DNS投向市场的是偶（怎么给人不谦虚的感觉呢）。我想BIND9.X引入VIEW（视图）功能并不是针对中国的，但是这个功能正好能解决我国网络运营商之间的互联互通问题，可谓天上的馅饼。本文结合自己这几年来架设维护智能DNS的经验体会随便写些东西，希望对大家有所帮助。时间仓促加之知识有限，难免错误之处，大家一块讨论吧。
前提 使用智能DNS有个前提假设，就是各个网络运营商都有自用的公网DNS为自己的用户提供域名解析服务。如果不是这样的，那智能DNS就没有存在的必要了（原因将在下面讨论）。所幸的是目前情况基本满足这个条件，网通，电信，教育网等都自成体系。
功能 智能DNS最基本的功能是可以智能的判断访问您网站的用户，然后根据不同的访问者把您的域名（域名记录）分别解析成不同的地址。如访问者是网通用户，智能DNS服务器会把你域名对应的网通IP地址解析给这个访问者。如果用户是电信用户，智能DNS服务器会把您域名对应的电信IP地址解析给这个访问者。由此我们可以让网通、电信、教育网、移动、国外用户智能的选择访问你的服务器。
原理 以ABC.COM域名为例。用户访问WWW.ABC.COM时的工作过程如图所示。这里省略了与本文讨论无关的细节，目的是化繁为简。
 网通用户向本地DNS请求解析WWW.ABC.COM。 本地DNS向ABC.COM的权威DNS（这里的权威DNS一定是智能DNS）。 智能DNS根据请求者（这里是本地DNS）的IP地址在自己的ACL里面进行匹配，然后把匹配的结果返回给本地DNS。 本地DNS把结果告诉用户，并把结果缓存起来。 用户访问网通线路上的网站服务器。  特别关注 这里有几点重要问题，值得单独列出，不然在使用智能DNS的过程中碰到就诧异了。
 智能DNS判断用户来源的依据是“本地DNS”而非是用户自身的IP地址。 由上延伸，如果电信用户使用了网通DNS，通过智能DNS将会匹配到网通的解析结果。 本地DNS一般情况下不会亲自向智能DNS请求解析，这是由本地DNS的网络拓扑决定的，详情见另一篇帖子《扫盲系列之：有关公网DNS》  面临的问题  各网络运营商的IP地址收集困难，有其是象“长城宽带”、“广电网”等这样的小运营商他们的用户使用的DNS五花八门，根本不适于使用智能 DNS。所以说智能DNS并不是把运营商划分的越细越好。总之结合自己的能力就好。 各大网络运营商相互渗透的情况（幸好是个别现象，但要引起重视），比如广东电信的公网DNS的后台有数目不详的服务器架设到网通的线路上 了。这样造成的后果就是明明使用的是电信DNS，但有时候解析到网通的结果。 众所周知的网络攻击事件越来越多的落到了DNS上面，这个事情很无奈。 最后，关于架设智能DNS技术细节这里就不讨论了，相信很容易就能在网上找到。  域名迁移 说的更通俗一点，域名迁移就是修改域名的权威DNS，即将域名ABC.COM的原权威DNS由A迁移到B。实际工作中最常见的形式是将域名转到另一家DNS服务商来解析。本文就域名迁移过程中几个值得关注的问题讨论一下。
为什么要域名迁移? 通常情况下，我们从那里购买的域名就由那家的DNS作为该域名的权威DNS负责解析该域名。如你不满意他们的服务质量，或他们无法提供你需要的服务内容，这时就需要把域名迁移到你认为更好的DNS上。
域名迁移正确流程   首先到B把你的域名添加上去，包括SOA、NS、A、CNAME、MX记录等。然后用dig/nslookup等工具验证一下是否刚才添加的记录是否生效，如验证A记录WWW.ABC.COM：dig @B WWW.ABC.COM A
  到原域名注册商处修改域名权威DNS为B，即修改域名的NS记录为B。注意，位于域名原权威DNS上的其他各种记录要保留一段时间不要马上删除。然后在该域名的顶级域DNS上验证一下刚才的修改是否生效。如验证ABC.COM现在的权威DNS：dig @a.gtld-servers.net ABC.COM NS
  域名迁移的过渡期 域名权威DNS由A转移到B的过程中域名解析权发生变化，世界各地的递归DNS要知道这个变化需要一段时间，因为各地DNS都缓存了该域名以前的状态，更新到最新的状态需要时间。
过渡期时长的确定 我们对域名进行trace查询以便了解该域名NS记录的TTL值。如查询CN类域名。
# dig xxx.cn ns &#43;trace xxx.cn. 21600 IN NS ns.xxx.cn. xxx.cn. 21600 IN NS ns.xxx.com. ;; Received 83 bytes from 203.119.25.1#53(A.DNS.cn) in 46 ms xxx.cn. 21600 IN NS ns.xxx.cn. xxx.cn. 21600 IN NS ns.xxx.com. ;; Received 83 bytes from 129.44.79.4#53(ns.xxx.cn) in 78 ms 上面权威DNS与顶级域DNS上NS记录的TTL值相同，则过渡期为21600秒。特殊情况，如果该域名的原权威DNS上定义的该域名NS记录的TTL值与顶级域DNS上定义的值不同。则这个时候原权威DNS上的TTL为有效值。如163.cn:
# dig 163.cn ns &#43;trace 163.cn. 21600 IN NS ns1.newfavor.net. 163.cn. 21600 IN NS ns2.newfavor.net. ;; Received 72 bytes from 203.119.28.1#53(D.DNS.cn) in 62 ms 163.cn. 10800 IN NS dns1.amway.com. 163.cn. 10800 IN NS ns2.newfavor.net. 163.cn. 10800 IN NS ns1.newfavor.net. ;; Received 174 bytes from 61.145.126.88#53(ns1.newfavor.net) in 93 ms 可以看到该域名在顶级域上NS记录的TTL为21600，而在权威DNS上有重新定义为10800，则这个时候原权威DNS上的TTL为有效值。 在实际工作中稳妥起见我们取两者中较大的为最后的参考值。下面列出几种域名NS记录的TTL值：
COM. TTL = 172800 (48小时) NET. TTL = 172800 (48小时) ORG. TTL = 86400 (24小时) CN. TTL = 21600 (6小时) 域名配置ZONE文件 这次把ZONE文件拿出来简单说明一下。ZONE文件是DNS上保存域名配置的文件，对BIND来说一个域名对应一个ZONE文件，现以abc.com的ZONE文件为例展开。罗嗦一句，该ZONE存在于权威DNS上。
$TTL 6h //第1行 $ORIGIN abc.com. //第2行 @ 3600 IN SOA ns1.ddd.com. root.ddd.com.( //第3行 929142851 ; Serial //第4行 1800 ; Refresh //第5行 600 ; Retry //第6行 2w ; Expire /第7行 300 ; Minimum //第8行 ) @ 2d IN NS ns1.ddd.com. //第9行 @ 2d IN NS ns2.ddd.com. //第10行 @ 2d IN NS ns3.ddd.com. //第11行 @ 3600 IN A 120.172.234.27 //第12行 a 3600 IN A 120.172.234.27 //第13行 b 3600 IN CNAME a.abc.com. //第14行 @ 3600 IN MX a.abc.com. //第15行 @ 3600 IN TXT &amp;#34;TXT&amp;#34; //第15行 第1行，这行内容给出了该域名(abc.com)各种记录的默认TTL值，这里为6小时。即如果该域名的记录没有特别定义TTL，则默认TTL为有效值。
第2行，这行内容标识出该ZONE文件是隶属那个域名的，这里为abc.com。
第3行，从这行开始到第8行为该域名的SOA记录部分，这里的@代表域名本身。ns1.ddd.com表示该域名的主权威DNS。root.ddd.com表示该主权威DNS管理员邮箱，等价于root@ddd.com。
第4行，Serial部分，这部分用来标记ZONE文件更新，如果发生更新则Serial要单增，否则MASTER不会通知SLAVE进行更新。
第5行，Refresh部分，这个标记SLAVE服务器多长时间主动(忽略MASTER的更新通知)向MASTER复核Serial是否有变，如有变则更新之。
第6行，Retry部分，如Refresh过程不能完成，重试的时间间隔。
第7行，Expire部分，如SLAVE无法与MASTER取得联系，SLAVE继续提供DNS服务的时间，这里为2W(两周时间)。Expire时间到期后SLAVE仍然无法联系MASTER则停止工作，拒绝继续提供服务。Expire的实际意义在于它决定了MASTER服务器的最长下线时间(如MASTER迁移，DOWN机等)。
第8行，Minimum部分，这个部分定义了DNS对否定回答(NXDOMAIN即访问的记录在权威DNS上不存在)的缓存时间。
第9-11行，定义了该域名的3个权威DNS服务器。通常NS记录的TTL大些为宜，这里为2天。设置过小只会增加服务器无谓的负担，同时解析稳定性会受影响。
第12-15行，比较简单，是两个A,CNAME,MX记录，不再讨论了。
名词解释：
 SOA记录：权威记录从这里开始，它定义了3-8行这些重要的参数。 A记录：记录域名到IP之间的关联。 CAME记录：让张三住到李四家里，这时张三李四是同一个地址。 MX记录：定义了发往XXX@ABC.COM邮箱的邮件服务器地址。 TXT记录：这个记录的内容是文本格式如126.COM的TXT为&amp;quot;v=spf1 include:spf.163.com -all&amp;rdquo;,TXT通常用于邮件服务器来标识自己的身份避免被认为是垃圾邮件服务器。这里不再深入讨论。 其他不常用记录类型没有列出！  域名安全 网络安全不应该只停留在口头上，事实证明网络安全隐患遍布互联网。近期Twitter与Baidu出现的问题如出一辙。以下多出自本人见解未必全面，仅供探讨。
网络安全层面   互联网线路的安全隐患，如数据包中途探嗅与篡改、骨干路由器被入侵等，这个层面是网络运营商的问题，我们作为互联网用户是无力涉及的。
  服务器安全隐患，包括操作系统、运行的软件及服务器自身的物理安全问题等。提升服务器安全总的原则是“一多一少”，一多是做个勤快的管理员，多多关注软件的BUG公布并及时升级软件。一少是尽量少的运行非必要的程序，尽量少的向互联网开放网络端口。举个简单的例子，互联网上很大部分的服务器都向外开放SQL数据库的监听端口，真不知道管理员是怎么想的。
  一度被人遗忘的角落就是域名的安全，究其原因主要是很少人真正认识域名与DNS体系，缺乏相关的技术支持。
  本文将就上面提到的“3”即域名安全问题展开。首先了解一下域名体系现存的安全隐患。主要有如下3个方面：
  域名管理平台的安全问题，有能力出售域名的商家多如牛毛，但有能力管理好域名的就很少。我们知道通常情况下域名提供商对其出售的域名提供权威DNS来解析域名，并且提供域名管理平台（WEB管理平台）。域名管理平台主要功能首先是登录验证并添加/修改域名的NS、A、CNAME、MX、TXT等记录。一旦这个域名管理平台发生问题，后果不言而喻。Twitter与Baidu出现的问题就是通过域名管理平台篡改了域名的NS记录导致的。现实中域名所有者安全意识淡薄往往设置非常简单的登录管理密码，或表现为从来不更新密码，这都是危险的信号。
  网络运营商的恶意拦截域名解析，这个现象多出现在国内。具体表现为地方性域名解析异常。其做法一般是运营商在所属的公用DNS上硬性绑定域名解析到特定IP地址上。深层次原因无非是利益驱动。
  病毒、木马等滋事捣乱，这个只发生在受侵害的计算机上，具体表现为本机DNS地址被篡改为一个恶意DNS上，导致解析异常。
  解决之道   针对域名管理平台的安全问题，普通大众（穷人）由于受各种条件限制能做的不多：首先选择比较好的域名提供商并树立起域名安全意识。对大型网站能做的就比较多（主要是有钱啊，如google、baidu等）：首先是直接向域名机构购买域名（跳过域名提供商），用自己的域名管理平台管理域名（当然这个后台是不对外的，用的时候开机，平时在保险柜），这就从根本上遏制了“黑客”的滋扰。
  对于网络运营商的恶意拦截域名解析，受害者通常是无权无钱的。能做的只能是向其上级部门申诉，祈祷上帝帮忙了。
  针对病毒、木马等滋事捣乱，涉及面比较小，没啥可说的，杀之而后快。
  域名解析的授权 首先是两个相关的概念：
 域名授权： 指定谁是该域名的权威DNS，即由谁负责解析该域名（由NS记录操作完成）。 权威DNS: 特指对特定域名具有权威发布能力的DNS；互联网上域名（域名记录）解析果的原出处。  目前域名解析授权状况 目前在互联网上域名解析授权大体上是谁出售域名就把域名的权威DNS授权给谁并由其提供域名的权威DNS来完成域名解析工作，如购买了新网域名。默认就是由新网的权威DNS（nsx.xinnetdns.com、nsx.xinnet.cn）负责所售域名解析:
[root@test root]#dig @a.gtld-servers.net xinnet.com ns ;; ANSWER SECTION: xinnet.com. 172800 IN NS ns.xinnet.cn. xinnet.com. 172800 IN NS ns.xinnetdns.com. xinnet.com. 172800 IN NS ns2.xinnet.cn. xinnet.com. 172800 IN NS ns2.xinnetdns.com. 域名解析授权是怎么实现的 域名解析授权是个树状的，从上而下的分层体系，简图如下：
首先“.”DNS把COM/NET/CN/ORG/TV等等域名按后缀的不同分别授权给不同的DNS，以利于分别管理。如COM/NET域名被授权给了如下几个权威DNS。这里不难想像要修改COM/NET的授权DNS要到“.”DNS上去操作才能完成。
[root@test root]#dig com. ns ;; ANSWER SECTION: com. 96045 IN NS d.gtld-servers.net. com. 96045 IN NS g.gtld-servers.net. com. 96045 IN NS b.gtld-servers.net. com. 96045 IN NS k.gtld-servers.net. com. 96045 IN NS f.gtld-servers.net. com. 96045 IN NS l.gtld-servers.net. com. 96045 IN NS j.gtld-servers.net. com. 96045 IN NS a.gtld-servers.net. com. 96045 IN NS i.gtld-servers.net. com. 96045 IN NS m.gtld-servers.net. com. 96045 IN NS e.gtld-servers.net. com. 96045 IN NS h.gtld-servers.net. com. 96045 IN NS c.gtld-servers.net. 同理可知，要指定或修改ABC.COM的权威DNS要去顶级DNS上操作。通常来说一般的域名所有者是无权登录顶级DNS进行操作的。只能通过域名提供商（如新网，万网等）的专用接口（位于域名商的域名管理平台上）来间接操作顶级DNS上的记录。
以ABC.COM为例简要说明怎么指定自己的权威DNS，假设ABC.COM是在新网购买，那么默认该域名的权威DNS就是nsx.xinnetdns.com、nsx.xinnet.cn。这时候要修改默认权威DNS。首先登录新网的域名管理后台，找到修改域名DNS页面即可完成操作（详细过程这里有：http://docs.aidns.cn/help02.htm）。操作完成后要验证一下是否修改成功：
[root@test root]#dig @a.gtld-servers.net abc.com ns ;; ANSWER SECTION: abc.com. 172800 IN NS ns1.ai-dns.com. abc.com. 172800 IN NS ns2.ai-dns.com. abc.com. 172800 IN NS ns3.ai-dns.com. 这里我们把ABC.COM授权给了nsx.ai-dns.com了。
域名权威DNS的再授权 以ABC.COM为例，再授权是指在nsx.ai-dns.com上面再次指定该域名的权威DNS，再授权的意义有这么几个：
  扩展现有的权威DNS数量，如现有ns1,ns2,ns3.ai-dns.com共三台DNS，现在要增加到4台，则可以在原3台DNS上abc.com的ZONE文件内增加ns4这个NS记录。原来的ZONE内容：
$TTL 2d $ORIGIN abc.com. @ 3600 IN SOA ns1.ai-dns.com. root.ai-dns.com.( 2288091841 1h 600 1w 900 ) @ 2d IN NS ns1.ai-dns.com. @ 2d IN NS ns2.ai-dns.com. @ 2d IN NS ns3.ai-dns.com. 增加ns4这个NS记录后为：
  $TTL 2d $ORIGIN abc.com. @ 3600 IN SOA ns1.ai-dns.com. root.ai-dns.com.( 2288091841 1h 600 1w 900 ) @ 2d IN NS ns1.ai-dns.com. @ 2d IN NS ns2.ai-dns.com. @ 2d IN NS ns3.ai-dns.com. @ 2d IN NS ns4.ai-dns.com.
当然增加NS4的操作也可以在顶级DNS上完成，不再赘述。 2. 把权威DNS重新授权给其他DNS，如把原来的权威DNS（nsx.ai-dns.com）重新授权给别人（nsx.ddd.com）。操作过程同上，不再赘述。 ### 再授权可能存在的潜在问题 再授权无疑使得域名解析授权变得更灵活，但是存在以下潜在的隐患。当原授权的权威DNS（即在顶级DNS定义的权威DNS）故障时，这时再授权的DNS将无法工作，导致域名无法解析（这是由域名解析过程是自上而下的这个特性决定的）。同时也增加了安全隐患。 附加部分1：慎用WHOIS来查看域名权威DNS。 对于域名的Whois数据库是由域名销售商控制的，即每个域名销售商都有自己的WHOIS服务器，这些服务器用来存储自身出售的域名信息，如域名所有人，联系方法，到期时间等内容。WHOIS信息中显示的域名当前权威DNS信息很可能没有及时与域名实际的权威DNS信息同步而导致错误的判断。 附加部分2：“.”根DNS是怎么被授权的？ 由于“.”根DNS所处域名解析体系的顶端，无法按照常规方法对其授权。到目前为止其授权方法是把所有“.”DNS列表存放在一个文本文件内（自己授权给自己），名字通常为root.hint内容如下（部分节选）： . 3600000 IN NS A.ROOT-SERVERS.NET. A.ROOT-SERVERS.NET. 3600000 A 198.41.0.4 . 3600000 NS B.ROOT-SERVERS.NET. B.ROOT-SERVERS.NET. 3600000 A 192.228.79.201
## 擅用日志排除BIND故障 这么多年来耳闻目染，发现网友提出的几乎99%的问题本来是不需要求助就能解决的，追其根源是不擅于（或不知道）使用软件本身提供的运行日志来解决问题。本文就BIND服务器日志简要说明。这里假设一网友反映“启动named进程后配置的域名解析服务不工作”这一简单问题说明怎么使用named的日志来解决。 首先了解一个named启动参数:“-g”，这个参数可以使named启动过程的细节展现在面前，自然的哪里的问题就一目了然了。 [root@test ~]#named -gc /var/named/etc/named.conf 02-Jan-2010 11:05:54.687 starting BIND 9.5.1-P3 -gc /var/named/etc/named.conf 02-Jan-2010 11:05:54.687 found 1 CPU, using 1 worker thread 02-Jan-2010 11:05:54.688 using up to 4096 sockets 02-Jan-2010 11:05:54.697 loading configuration from &amp;lsquo;/var/named/etc/named.conf&amp;rsquo; 02-Jan-2010 11:05:54.698 /var/named/etc/named.conf:45: missing &amp;lsquo;;&amp;rsquo; before &amp;lsquo;key&amp;rsquo; 02-Jan-2010 11:05:54.698 loading configuration: failure 02-Jan-2010 11:05:54.698 exiting (due to fatal error)
我们看到日志提示在named.conf文件的第45行少写了“；”，好，问题找到了排除问题就简单了。打开named.conf把那个“；”补上。 [root@test ~]##named -gc /var/named/etc/named.conf 02-Jan-2010 11:06:33.807 starting BIND 9.5.1-P3 -gc /var/named/etc/named.conf 02-Jan-2010 11:06:33.807 found 1 CPU, using 1 worker thread 02-Jan-2010 11:06:33.808 using up to 4096 sockets 02-Jan-2010 11:06:33.817 loading configuration from &amp;lsquo;/var/named/etc/named.conf&amp;rsquo; 02-Jan-2010 11:06:33.819 using default UDP/IPv4 port range: [49152, 65535] 02-Jan-2010 11:06:33.819 using default UDP/IPv6 port range: [49152, 65535] 02-Jan-2010 11:06:33.821 no IPv6 interfaces found 02-Jan-2010 11:06:33.821 listening on IPv4 interface re0, 192.168.0.20#53 02-Jan-2010 11:06:33.822 listening on IPv4 interface re0, 192.168.0.10#53 02-Jan-2010 11:06:33.823 listening on IPv4 interface lo0, 127.0.0.1#53 02-Jan-2010 11:06:33.832 command channel listening on 127.0.0.1#953 02-Jan-2010 11:06:33.833 ignoring config file logging statement due to -g option 02-Jan-2010 11:06:33.840 zone 127.IN-ADDR.ARPA/IN: loaded serial 1 02-Jan-2010 11:06:33.840 zone test.com/IN: loaded serial 912200620 02-Jan-2010 11:06:33.841 running 02-Jan-2010 11:06:33.841 zone test.com/IN: sending notifies (serial 912200620)
问题排除。上面方法适用于下列情形： 1. 安装BIND后调试named,看看有没有问题。 2. 出现致命错误named中断运行了。 3. 非重要DNS服务器，可以停机检查的。 对于正在运行的DNS服务器，不想让其停止运行，这时候要发现潜在问题再使用上述方法就不太适宜了。这就要求我们可以让named把日志记录到专门的文件内，供我们随时查询。具体操作是在named.conf配置log: logging { channel warning { file &amp;ldquo;log/named.log&amp;rdquo; versions 3 size 2048k; severity warning; print-category yes; print-severity yes; print-time yes; }; channel query { file &amp;ldquo;log/query.log&amp;rdquo; versions 3 size 2048k; severity info; print-category yes; print-severity yes; print-time yes; }; category default { warning; }; category queries { query; }; };
这里我们让named把named运行日志和日常查询日志分别记录到named.log和query.log文件内。最后测试一下解析是否正常了： [root@test ~]#dig @localhost www.test.com ; &amp;laquo;&amp;raquo; DiG 9.5.1-P3 &amp;laquo;&amp;raquo; @localhost www.test.com ; (1 server found) ;; global options: printcmd ;; Got answer: ;; -&amp;raquo;HEADER&amp;laquo;- opcode: QUERY, status: NOERROR, id: 45637 ;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 3, ADDITIONAL: 3 ;; WARNING: recursion requested but not available ;; QUESTION SECTION: ;www.test.com. IN A ;; ANSWER SECTION: www.test.com. 3600 IN A 12.1.1.1 ;; AUTHORITY SECTION: test.com. 172800 IN NS ns2.test.com. test.com. 172800 IN NS ns1.test.com. test.com. 172800 IN NS ns3.test.com. ;; ADDITIONAL SECTION: ns1.test.com. 3600 IN A 12.2.2.2 ns2.test.com. 3600 IN A 12.3.3.3 ns3.test.com. 3600 IN A 12.4.4.4 ;; Query time: 29 msec ;; SERVER: 127.0.0.1#53(127.0.0.1) ;; WHEN: Sat Jan 2 11:48:03 2010 ;; MSG SIZE rcvd: 148
由于是针对初级用户，更深相关细节不再赘述。 </content>
    </entry>
    
     <entry>
        <title>4A技术概览</title>
        <url>http://lanlingzi.cn/post/technical/2017/0730_4a/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>安全</tag>
        </tags>
        <content type="html"> 什么是4A 4A是指：账号Account、认证Authentication、授权Authorization、审计Audit，中文名称为统一安全管理平台解决方案。即将身份认证、授权、审计和账号(即不可否认性及数据完整性)定义为网络安全的四大组成部分，从而确立了身份认证在整个网络安全系统中的地位与作用。(来源百度百科)
账号Account 为用户提供统一集中的帐号管理，包括：用户身份信息的集中存储与统一管理。参考AWS等系统，涉及到概念包括：
 主账号：一般指管理资源的唯一身份标识，他为资源付费。也是自然人在4A中的唯一身份标识，一个用户只会有一个主账号，唯一标识了他的身份。 从账号：一般指资源访问的账号，如虚拟机的访问用户，数据库的访问用户等。 用户：实现操作资源的人员，对应物理存在的人，它由账号分配。 群组：一般对应企业的组织，把用户归属到一个群组里，用户可以自动获得这个群组所具有的权限。对于大型的企业，组织可能分为人员组织与业务组织。对于用户来说，群组也是为提供分级管理能力。  用户身份信息，主要包括名称与密码。对于不同的系统，其它信息各不相同，比如互联网中用户信息，一般包括昵称，邮箱，电话，爱好等信息。从账号身份信息，主要包括名称与密码。不同的资源形态身份也不相同，像AWS中，API访问还有AK/SK，虚拟机访问还有SSH证书。
账号与用户的信息身份都是敏感信息，需要完整的安全控制。密码类一般采用密码策略管理，如密码长度，字符限定，过期时间等，密码存储一般采用不可逆加密保存。
目前安全的不可逆加密算法有：PBKDF2，bcrypt。但在一些场景下，由于政策或法规原因，要求可以掌握用户密码，存储也需要加密，但它是可逆的。一般采用非对称加密，采用私钥/公钥对，公钥用于加密密码存储，私钥用于解密，私钥的存储在物理上与系统隔离，以防私钥泄漏。
认证Authentication 根据用户应用的实际需要，为用户提供不同强度的认证方式。认证的方式一般有以下几种：
 静态口令：如基于用户与密码； 动态口令令牌：如手机验证码； 数字证书：如早期的银行USB盾，其实USB中存储即发放给用户的PKI（Public Key Infrastructure）证书； USB令牌：如工商银行的USB盾，USB动态生成令牌。  这些认证是可以组合使用的，其中重要说明的PKI，一个有效的PKI系统必须是安全的和透明的，用户在获得加密和数字签名服务时，不需要详细地了解PKI的内部运作机制。
PKI发展的一个重要方面就是标准化问题，它也是建立互操作性的基础。目前，PKI标准化主要有两个方面：一是RSA公司的公钥加密标准PKCS（Public Key Cryptography Standards）,它定义了许多基本PKI部件，包括数字签名和证书请求格式等；二是由Internet工程任务组IETF（Internet Engineering Task Force）和PKI工作组PKIX（Public Key Infrastructure Working Group）所定义的一组具有互操作性的公钥基础设施协议。PKI产品的生产厂家很多，比较有代表性的主要有VeriSign和Entrust。
对于一个复杂的系统、大型网站，他们内部会划分多个子系统。则用户认证需要统一管理，为用户提供统一的认证门户，实现单点登录（Single Sign On，简称SSO）。单点登录与认证服务常见的标准有：
 CAS：Central Authentication Service，由Yale 大学发起的一个开源项目，是目前最为常见，简单实效的SSO实现。 OpenID：用户在多个网站注册，需要注册并记住多个用户名密码，OpenID希望帮用户提供一个身份ID，可以在多个网站用来登录。登录网站时，用户选择用其身份ID登录，跳转到身份ID颁发的网站输入用户名、密码进行身份认证，然后跳转会网站实现登录。 OAuth：比如用户通过第三方照片打印应用打印在某个网站存储的照片，而不希望泄露照片网站的用户名、密码等信息给第三方的照片打印应用。使用OAuth来授权给第三方应用访问照片资源，也会跳转到照片资源所在网站，要求输入用户名、密码进行身份认证并授权，然后跳转会打印应用网络。注意：OAuth1有安全漏洞，现在都是使用OAuth2协议。 SAML：Security Assertion Markup Language，是一个基于XML的标准，用于在不同的安全域(security domain)之间交换认证和授权数据。  后二种也包含授权能力定义，授权先要认证。单系统身份认证，根据使用场景和技术特点，选择OpenID、OAuth、或者SAML。如果不是单系统，不仅涉及身份认证，而是涉及众多系统需要单点登录，则需要选择CAS&#43;认证方案(OpenID/OAuth/SAML)来实现的。其中OAuth2也涵盖了CAS的功能，也可以单点登录(如采用密码模式/客户端模式)。
在非WEB领域，不得不提一下的是GSSAPI（Generic Security Services Application Program Interface），它是提供了程序能够访问安全服务的一个应用程序接口，可用于完成认证。它是一个框架，不负责具体的安全机制。
授权Authorization 对用户的资源访问权限进行集中控制。授权/鉴权系统中涉及到概念主要有：
 权限：对资源功能、数据进行访问的范围或程度； 角色：资源中若干访问权限的集合； 角色组：角色构成的集合。  授权关系应包括三个元素，授权主体、授权客体、授权关系：
 授权主体：主帐号、用户，用户群组； 授权客体：角色、角色组、权限以及三者的组合； 授权关系：应任意主体对客体的授权。  授权方式常见包括如下：
 UBAC：Userbased Access Control，基于用户的授权，也有称IBAC，I:identity； RBAC：Role-based Access Control，基于用户角色的授权； ABAC：Attribute-based Access Control，基于资源的授权ABAC。  前面提到的SAML，其采用访问者、被请求资源、被请求行为和环境属性来描述策略，是一个典型的在ABAC环境下的策略描述语言。如AWS的IAM的策略（Policy）描述，它更加的灵活，可以涵盖UBAC，RBAC与ABAC的功能。策略是用JSON来描述的，主要包含Statement，也就是这个policy拥有的权限的陈述，一言以蔽之，即：谁在什么条件下能对哪些资源的哪些操作进行处理。也就是所谓的撰写Policy的PARCE原则：
 Principal：谁； Action：哪些操作； Resource：哪些资源； Condition：什么条件； Effect：怎么处理（Allow/Deny）。  在操作系统，设备系统，数据系统中，权限控制还提供简单的访问控制列表ACL(Access Control List)。ACL的认证鉴权主要分为：
 登陆认证鉴权：在用户登陆的时候，进行信息认证。根据用户标识，加载上来该用户所拥有的权限模块； 即时认证鉴权：是用户对某一模块或记录是否有增删改查的权限。  审计Audit 为了能做到有效的监督，监督各类管理员的日常的管理行为。系统将对管理员的每个操作做出日志记录，并且分类进行整理。提供相关的报表和查询功能。以方便对管理员工作的审计。
审计功能主要实现安全审计功能，包括：
 用户帐号合法性; 访问行为审计和合规审计。   参考：
[1] 统一安全管理平台解决方案 [2] PKI系统深入介绍 [3] 基于SAML的单点登录介绍 [4] cas sso oauth openid saml的联系与区别 [5] GSS-API 介绍
[6] 理解OAuth 2.0
[7] 深入了解IAM和访问控制
</content>
    </entry>
    
     <entry>
        <title>云设计模式</title>
        <url>http://lanlingzi.cn/post/technical/2017/0715_cloud_design_pattern/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>cloud</tag><tag>软件架构</tag>
        </tags>
        <content type="html"> 在云环境下，如何构建出可靠，弹性，安全的应用？有哪些挑战？面对这些挑战如何解决，微软Azure总结一系列的设计模式。本文是翻译Azure架构中心在线资料中的云设计模式，仅个人的笔记，借翻译学习一下，英文好的可以直接阅读原文。
挑战 可用性 可用性是指系统功能可用的时间占整体的比例，通常以正常运行时间比来衡量，它会受到系统错误、基础设施问题、恶意攻击和系统负载的影响。云应用典型为用户提供提供服务级协议（SLA），因此必须设计应用以最大限度地可用性。
数据管理 数据管理是云应用的关键要素，影响着大多数质量属性。由于性能、可伸缩性或可用性等原因，数据通常被存放在不同的位置和跨多个服务器上，这可能会带来一系列的挑战。例如，必须保持数据一致性，并且数据通常需要跨不同的位置同步。
设计与实施 好的设计包括组件设计和部署的一致性和关联性、可简化管理和开发的可维护性，以及允许组件和子系统在其他应用和其他场景中的可重用性等因素。在设计和实施阶段作出的决定，对云托管应用和服务的质量和总成本产生巨大影响。
消息 云应用的分布式属性需要一个消息交互基础设施，它将组件和服务连接起来，最好是以松耦合的方式，以最大限度地提高可伸缩性。异步消息的广泛使用，并提供了许多好处，但也带来了挑战，如消息的时序，消息的回环、幂等性等
管理与监控 云应用运行在远程数据中心中，在那里你不能完全控制基础设施，有时也无法控制操作系统。这会使管理和监控比私有部署环境下更加困难。应用必须暴露出管理员和运维员可以使用管理和监控系统运行信息，以及支持在不断变化的业务需求和定制下，而不需要停止或重新部署应用。
性能与扩展性 性能是指一个系统在给定的时间间隔内执行任何操作的响应指标，而可伸缩性是系统处理负载增加而不影响性能或所用资源容易地增加的能力。云应用通常会遇到不同的工作负载和活动高峰。预测这些，尤其是在多租户场景中，几乎是不可能的。相反，应用应该能够在限定范围内扩展，以满足需求高峰，并在需求减少时规模扩大。可伸缩性不仅涉及计算实例，还涉及其他元素，如数据存储、消息传递基础设施等等。
可靠性 可靠性是一个系统优雅地处理和从失败中恢复的能力。云托管的本质是，应用通常是多租户，使用共享平台服务，争夺资源和带宽，通过互联网进行通信，并在通用硬件上运行，这意味着出现瞬态故障和永久故障的可能性增加。检测故障并快速有效地恢复是保持可靠性的必要条件。
安全 安全性是系统在设计使用之外防止恶意或意外行为的能力，以及防止信息泄露或丢失的能力。云应用在互联网上暴露在可信的私有区域之外，通常向公众开放，并且可能服务于不可信的用户。应用必须设计和部署，以保护它们免受恶意攻击，限制对只有已允许的用户访问，并保护敏感数据。
设计模式    模式 摘要     Ambassador 创建帮助服务，代表消费者服务或应用发送网络请求。   Anti-Corruption Layer 在现代应用和遗留系统之间实现个门面或适配层。   Backends for Frontends 创建隔离的后端服务，提供接口给特定的前端应用使用。   Bulkhead 将应用的元素隔离到池中，以便当一个失败时，其他元素将继续发挥作用。   Cache-Aside 将数据数从据存储中按需加载到缓存中。   Circuit Breaker 当是连接远程服务或资源时，修复错误可能需要花费可变的时间。（注：直译不好理解，指发生错误时像电源断路器一样断开访问远程服务或资源）   CQRS 更新数据的操作与读取数据的操作的接口隔离。   Compensating Transaction 撤消由一系列步骤执行，这些步骤一起达到一个最终一致的操作结果。   Competing Consumers 允许多个并发消费者在同一通道上接收处理消息。   Compute Resource Consolidation 将多个任务或操作合并到单个计算单元中。   Event Sourcing 使用额外的只可追加的存储来记录域中数据所有的操作事件。   External Configuration Store 将配置信息从应用部署包中移到一个集中位置。   Federated Identity 将身份验证委托给外部身份提供者。   Gatekeeper 在客户端与应用或服务之间，采用专用的主机实例作为代理，以保护应用或服务，代理在他们之间验证和审查请求，并传递请求和数据。   Gateway Aggregation 使用网关把多个独立请求合并一个请求。   Gateway Offloading 分担共享与特定服务到网关代理。   Gateway Routing 使用同一端点路由请求到多个服务实例。   Health Endpoint Monitoring 在外部工具可以定期通过暴露的端点检查应用中实现功能是否健康。   Index Table 给频繁查询的数据字段创建索引。   Leader Election 在分布式应用中，一组协作的任务实例执行时，由Leader协同执行。Leader是通过选举一个实例来负责管理其它的实例。   Materialized View 在一个或多个数据存储，当数据不理想数据格式查询时，生成预先设置好视图。   Pipes and Filters 将执行复杂处理的任务分解成一系列可重用的独立元素。   Priority Queue 优先级高的请求发送给服务，较高优先级的请求比那些优先级较低的请求更快地接收和处理。   Queue-Based Load Leveling 使用一个队列作为一个任务和它调用的服务之间的缓冲区，以平滑间歇性的重载.   Retry 当它试图连接到一个服务或网络资源时，使应用能够处理预期的，暂时的失败，并透明地重试。   Scheduler Agent Supervisor 协调跨分布式服务集和其他远程资源的一组操作。   Sharding 将数据存储水平分区或分片。   Sidecar 将应用的组件部署到一个单独的进程或容器中，以提供隔离和封装.   Static Content Hosting 将静态内容部署到基于云的存储服务，该服务可以直接将它们提供给客户端。   Strangler 通过新的应用和服务逐步替换特定的功能块，来逐步迁移遗留系统。   Throttling 控制应用实例、单个租户或整个服务所使用的资源的消耗。   Valet Key 使用令牌或密钥，为客户提供对特定资源或服务的受限直接访问。   </content>
    </entry>
    
     <entry>
        <title>运维模式</title>
        <url>http://lanlingzi.cn/post/technical/2017/0708_ops_pattern/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>运维</tag>
        </tags>
        <content type="html"> 背景 最近一段时间由于工作内容重心变化，从PaaS系统的设计到运维系统的设计。运维系统的设计对我来说，还是一项全新的领域，需要学习的理念与技术很多。全司虽有大量的产品涉及到软件系统，但本质还是一个硬件盒子，运维的对象还是偏硬件。
熟悉电信IT系统的人或许听说过：OSS(Operation Support System)，运营支撑系统，它是运营商IT系统中三大支柱系统之一。其它两大系统是：BSS(Bussiness Support System), MSS(Management Support System)。
OSS是面向资源的后台支撑系统。资源主要包括网络，电信设备，计算系统等。系统的主要功能是包括专业网络管理，综合网络管理，资源管理，业务开通，服务保障等。但公司的产品线众多，产品形态也是千差万别，公司的OSS产品也一直在探索与发展。产品开发部门也是分分合合，一直是想打造一套统一的运营支撑平台。
我们所说的OSS，其实与互联网的业务运维系统主要功能也是相同的：
 对网络，设备，计算系统，业务系统的监控，维护 对监控数据的智能分析，结果用于支持业务运营决策  而我现在工作的范畴也是面向软件业务的运维系统构建，与一些业界（互联网公司）的同行交流，发现运维理念是在面向的业务特征与场景上有着显著的差异。总结起来是业务产品形态决定运维系统的模式, 大概分为两种运维模式：
标准化运维 标准化运维是基于标准化的体系建设，对业务环境、配置、操作、流程等通过制定、发布和实施标准达到统一，以获得最佳秩序和效益。标准化的优势是显而易见的，标准是实现运维自动化地基础，是提高团队效率的重要方式，是梳理运维杂乱问题的重要依据。
标准化运维模式是非常适合于自研业务的运维。自研的业务在行政政策下，标准规范可以统一规划，推广普及。所有的业务在服务器、操作系统、中间件，语言框架统一选型；制定统一的业务开发规范，如安装目录，配置标准，日志标准，发布包标准，CI/CD流程标准等。标准化制定由统一的委员会制定，委员会由各领域的专家组成，规范基于业界或自身一些最佳实践整理。
标准化的另一个目的是可以简化运维平台的建设，让人和系统更有效率地做事。尤其是在一个大型企业，若先不做规范，就做运维系统的建设，到最后极可能会失控，运维系统变得自已不可维护，整体成本倍增。符合标准规范的业务，可以快速接入到运维系统，操作流程化，自动化，从而提升运维效率，减少维护成本的支出。
标准化不只是针对有问题的地方，就去设定规范和标准化，输出相应的规范文档。而是把规范工具化，规范必须沉淀到平台，才能真正做到方便运维，体现规范的价值。
我司在标准化做得非常的好，设计了一个专门的行管组织，制定了相当多的标准规范。但随着时间的推移、人员的更替、业务的发展与技术的换代，标准化也可能变成了教条。标准规范只在一定时间，一定范围内才能最大效益化。另外一个需要注意的问题是，若行管组织只负责规范制定，不对具体的业务运维负责，也会导致规范会越来越脱离实际。
SaaS运维 另一种运维模式是运维能力平台化，把运维能力通过API的方式开放出来。不同的业务运维基于API开发、模板定制、能力编排来开发与定制SaaS运维应用。SaaS运维的基础是运维系统的能力成熟度与开放度。
SaaS运维模式非常适合于异构环境下的业务运维。尤其是业务系统非公司自研，购买于不同的厂商。这是因为他们的资源诉求不同，架构不同，运行形态不同，操作流程不同。在这种场景下，标准化运维很难执行落地，业务购买时已成型，不可能再修改；采购时也不太可能要求供应商遵循你私有的标准。
随着云计算的发展，现在越来越多的传统APM（Application Performance Management）或其它运维产品的公司推出他们的运维SaaS在线云服务，业务系统可以接入到运维系统或使用其提供运维云服务，来完成业务的运维，从来减少运维的基础设施投资。
SaaS运维是一种新的模型，也是后续运维系统的主要发展模式，SaaS将是未来主战场。但SaaS运维系统构建的困难相对于标准化在于：
 无侵入的运维接入 集成与被集成能力 简易定制开发能力 运维数据的安全性 运维生态系统构建  小结 标准化运维与SaaS运维有着不同的适应场景，但他们并不完全冲突，在SaaS运维系统中，也可以引入一些标准规范。目前一些开源社区或基金组织在推动一些项目，如OpenTracing，Prometheus Exporter等，这可能会形成事实标准。在云时代，SaaS云运维刚刚起步，也将是群雄逐鹿，有着不少的机会。
</content>
    </entry>
    
     <entry>
        <title>为什么我写不下去</title>
        <url>http://lanlingzi.cn/post/thoughts/2017/0626_how_to_write/</url>
        <categories>
          <category>感想</category><category>杂记</category>
        </categories>
        <tags>
          <tag>写作</tag>
        </tags>
        <content type="html"> 近一年来，写博客很少。总结起来有如下三点：
 没有时间 没有素材 没有心情  我很佩服那种每天都能写上千字博文或公众号的人，因为坚持写作需要很强的毅力。我没有能够坚持下来，其实最重要还是没有心情，动力不足。那作为一位内心深处又想写点东西的人，如何破？
没有时间 没有时间，是我们最常用的借口。但有一句名言：
 时间就如海绵里的水，去挤总是有的
 换作搞IT的术语来说，我们工作中的空闲时间就像内存使用产生的碎片。碎片化的时间我们用来做什么呢，刷刷朋友圈，看看新闻。如果没有一套行之有效的碎片整理机制，系统的性能就会越来越下降，工作效率也是如此，还谈何写作。有时我也想像Windows一样有个磁盘碎片整理工具。但这些都是事后整理，最有效地还是如何事先减少碎片的产生。
减少碎片工作重要的做好等级划分，杂事集中在某一时间段处理。其实，重要的工作没有想像的那么多，紧急事情也不会像担心的地么紧急。不要搬石头砸自己的脚，否则格外的痛，而且没有地方埋怨。
工作分解如果不能将碎片化整理成一个更大的块，那么就把工作分成碎片放进去。这样慢是慢了些，但总比浪费的好。写作尤其适合这样的原则，不要强迫自己一次性从第一个字敲到最后一个字，那我们发现，时间过去了，我们没有写下几个字。
写作的碎片分解还是非常简单的可参考：金字塔原理，先设计好文档结构，再完成具体地写作；即先设计好蓝图，再去搭建。这与软件开发中面向对象设计有异曲同工之处。先设计好软件框架，类及关系，对象运行机制等；再去一一实现。先自上而下，大道至简，很多东西是相通，可以相互借鉴。
没有素材 写东西，尤其是写工作相关的总结性文档，不需要有惊天地、泣鬼神的才华。简单明了，直抒胸意即可，但要杜绝啰嗦，逻辑混乱。
有时候，发现写作是素材极缺，不知如何的展开。其实我们将现有的资料完善，系统化，并能够使自己头脑中零散的知识更加有效地使用。把这些写出来，可以理解更加的深刻，系统地把握其中的要素。
每个人或多或少会对自己所工作范围有些小的“创新”，如果能够及时地文档化，系统化地整理，并通过某种方式分享出来。这不仅会增强自己的知名度，也共享给其他人一个不一样的思想，不何尝不是一种双赢的事情。
当然写作也非常讲究技巧，尤其是文章的排版技巧。俗话说，”三分靠长相，七分靠衣着“。文章的版面工作，虽决定不了文档的内涵丰富，但它却有那七分的影响。试想若排版乱七八糟，会影响看文章人的心情，内容再好，可能由看不下去而错过。文章的版面不只是它需要漂亮的图片，格式来装饰。而是至少达到它的结构层清楚，逻辑清晰。更一步来说，若能图表化让表达更为直观明了，一图胜过千言万语。当感觉使用文字描述很麻烦时，不妨考虑使用图表来简化了。
好的文章一定也是艺术化，人的审美观是有一个交集的。越是同一个文化背景下的人们，交集越大。所以如果能将自己个性审美融入到写作中，并体现出来。作品往往就会产生一定的艺术气质，也会让人产生共鸣。所以我们写作时也可以尝试融入自己的喜怒哀乐。
没有心情 没有心情写作，其实很多时间是我们无法静心下来。
我们有时太过于注重在说，而忘记写了。说与写是相互影响的。说，具有及时，直接，感染的优点。但它却稍纵即逝，局部，浅显的缺点；写，就是为了弥补说的缺点而生。写能够让我们完整，系统，深刻，持久地，感情十分丰富地去阐述自己的观点；写能够真正长久地传播经验，知识。
一般来说，我们都会说会写，只是没有掌握方法，也没有去有意识地加强。有些人强于说弱于写，有些人反之，强弱差距间，这就需要我们在平时工作学习中弥补。行动从来都是非常重要的，说与写好比鸟的一对翅膀，只有两者都平衡了，才能更好地飞起来。
写作时需要放下心来，这没有什么好说的。静心你才能专注，专注才能从容。若是烦躁不安，怎么能写出东西来呢。静心需要合适的时间点，合适的外部环境。写作之前，不防先听一首好歌，喝一怀好茶。有时我们为写点东西，拖拖拉拉，硬着头皮，还不如痛痛快快，高高兴兴地完成。
人是需要成就感来填充时间的。这样人才能觉得清力充沛，状态良好。有很多的方式去获取成就感，最容易一种可能是如下方法：保持每天要抽出一点时间做自己最感兴趣的事，让自己每天进点一点点；每一阶段定一个小目标，达成学会庆祝自己。成就感也源自对自己的自信与满足。比如每周完成一篇博文，也是不错的，自我感觉良好。
 说了这么多，也是对我为什么写不去一种救赎思考：没有时间，好就计划好时间；没有素材，从工作生活中寻找；没有心情，那就静下心来。
</content>
    </entry>
    
     <entry>
        <title>Install MySQL on MacOS</title>
        <url>http://lanlingzi.cn/post/notes/2017/0603_mac_mysql/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>MySQL</tag><tag>MacOS</tag>
        </tags>
        <content type="html"> 最近在家想写的东西，在MacOS上需要使用到MySQL。在MacOS下，使用brew来安装软件是最便捷。关于brew是什么，可在brew官网查看：brew官网
安装：
➜ ~ brew info mysql mysql: stable 5.7.18 (bottled) Open source relational database management system ...... ➜ ~ brew install mysql  mysql的安装过程会显示，注，我安装的5.7.18，目录为/usr/local/Cellar/mysql/5.7.18_1：
==&amp;gt; /usr/local/Cellar/mysql/5.7.18_1/bin/mysqld –initialize-insecure –user=xiao –basedir=/usr/local/Cellar/mysql/5.7.18_1 –datadir=/usr/local/var/mysql –t ..... We’ve installed your MySQL database without a root password. To secure it run: mysql_secure_installation  这说明MySQL已安装成功，必需要使用mysql_secure_installation来初始化用户密码：
➜ ~ mysql.server start Starting MySQL SUCCESS! ➜ ~ mysql_secure_installation Securing the MySQL server deployment. Connecting to MySQL using a blank password. ......  按英文提示一步步设置password validation policy与password等。
测试，输入mysql_secure_installation设置过程的密码：
➜ ~ mysql -u root –p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 6 Server version: 5.7.18 Homebrew ......  新增用户xiao，密码为123456，并赋所有权限给他：
mysql&amp;gt;use mysql; mysql&amp;gt;GRANT ALL PRIVILEGES ON *.* TO &#39;xiao&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION; mysql&amp;gt;flush privileges;  如果想设置开机启动MySQL，执行如下命令：
➜ ~ mkdir -p ~/Library/LaunchAgents ➜ ~ cp /usr/local/Cellar/mysql/5.7.18_1/homebrew.mxcl.mysql.plist ~/Library/LaunchAgents/ ➜ ~ launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist  使用命令行来操作MySQL不方便，推荐使用Navicat MySQL/Preminum软件。软件安装包在网上搜索吧。
参考：
[1] https://dev.mysql.com/doc/refman/5.7/en/mysql-secure-installation.html
</content>
    </entry>
    
     <entry>
        <title>PaaS的发展</title>
        <url>http://lanlingzi.cn/post/technical/2017/0304_paas/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>PaaS</tag>
        </tags>
        <content type="html"> 云计算按提供服务层次，通常划分为三层：
 IaaS ：基础构架即服务。这一层主要是对基础设施进行管理以给用户提供资源使用，如提供计算服务、安全备份、负载管理等。 PaaS ：平台即服务。这一层主要是基于IaaS之上，简化应用的部署、维护等，提供一些通用平台软件能力，如数据挖掘、系统管理、编程模型等。 SaaS ：软件即服务。这一层主要是面向终端客户，提供一站式的解决方案。如提供CRM、HRM、SCM等，是可以直接使用其服务。  个人一直从事PaaS的研发，而我们做的又是面向电信领域的PaaS。与外面的朋又交流发现，大家对PaaS的理解是不一样的，主要还是由于PaaS的本质是要解决的问题是：
 简化开发，打通DevOps，实现业务应用的敏捷与弹性。
 不同的业务领域，要面对是不同的传统应用架构如何通过PaaS平台迁移到云上，这就会导致各自对PaaS的需求或多或少有着不同的差异，理解不一样也是正常的。
PaaS定义 NIST（National Institute Of Standards and Technoloy）曾对PaaS有过经典的定义：
 面向应用的核心平台，封装应用分布式复杂性，实现应用层自动化、高可用。
 从功能定义来看，主要包含三个方面：
 应用托管：可将开发者创建或拥有的应用部署到云基础设施上。其价值是应用对基础设施资源的获取自动化。 应用开发：开发者使用供应商提供的运行环境，编程语言框架，服务以及工具等来构建应用。其价值是应用对中间件服务的获取自动化，软件开发自动化。 应用运维：应用的运维无需管理或控制底下的基础设施（计算、网络、存储、OS等），可以控制已部署的应用，并有可能对应用托管的环境、其配置进行控制。其价值是应用的运维管理（伸缩，配置，升级等）自动化。  所以PaaS是以应用开发为中心，解决如下三个问题：
 应用全生命周期管理：从应用的开发、部署，到运维的全流程生命周期管理。开发者可使用供应商提供的运行环境，编程语言框架，服务与工具等快速构建应用；通过平台将应用部署到云基础设施上，并对应用进行自动伸缩，弹性扩展，灰度发布等；对上线的应用可以实现监控管理，故障分析，自动迁移，自动恢复，为应用提供高用性，高可扩展性。 中间件云服务：提供丰富的预集成服务，如分布式数据库服务，分布式消息队列服务，分布式缓存服务等。把通用的软件能力服务化，使得应用能快速拥有分布式的高用性，高可扩展性。同时中间件服务让多租能力变得可行，在中间件云服务层，不同的租户可参共享或隔离不同的服务资源。 基础资源的高效利用：对底层资源的抽象，可以按用户要求分配的相应用资源部署实例。大规模的应用部署在云基础设施上，PaaS可能通过调度算法，把应用实例调度到不同的资源上运行。通过资源层的隔离，尽可能地共享或平摊资源，以提高资源整体使用率，从而降低基础设施的投入。  PaaS的发展历史 早期公有云，主要是提供高效多语言多框架的开发与运维环境：
 2005年，Rackspace，提供托管PHP与.Net语言的Web应用，不支持多租户，API和自动伸缩。 2007年，Heroku/Force.com，支持Ruby语言，引进数据库，企业工作流服务，主要是支持托管CRM相关的应用。 2008年，GAE, Google发布面向WEB的开发和托管的平台，早期支持python、java语言。  开源PaaS成长期，主要是提供应用快速部署到基础设施上的能力：
 2008年，CloudFoundry，提供支持多语言，多框架的可移植的PaaS平台。2011年被VMWare收获，其后开源。 2010年，OpenShift，Redhat发布OpenShift，支持多种异构I层。受2011的CloudFoundry，也开源。 2010年，Cloudify，Gigaspace开始基于Java构建支持多种异构I层的PaaS，重点在应用部署，并开源。  在2014年之后，PaaS也不在仅仅是互联网的公有云玩法，而是百花齐放。软件开发管理模式正在PaaS技术的驱动下，经历一场新的变革：
 传统软件巨头份份杀人：Oracle，SAP，IBM，HP等发布云战略，构建PaaS平台，极力在其各自的传统领域打造云生态系统。 公有云PaaS呈现三国鼎立：AWS， Azure与GAE的PaaS平台走向成熟，构建方式呈现多层次，应用可以按需组合；并且在提供的服务数量，服务性能不断提升。 PaaS开源项目爆发：早期的CloudFoundry，OpenShift，Cloudify历经多个版本也走向成熟；轻量级的PaaS不断涌现，如Apache Stratos, Deio, Flynn等；面向应用与资源调度的PaaS开源抢占风头，Docker，CoreOS, Mesos, Kubernetes。  可以说，当前的PaaS也不在局限于NIST的经典定义，而是在大规模的云基础设施上，提供更多的高性能的云服务，更高效的资源使用方式。PaaS已经呈现多样形态，在灵活性和易用性上不断地提升。同时多形态并存，但也没有一个形态可以满足所有用户需求。
PaaS的发展趋势 随着新技术的出现，目前PaaS的发展趋势主是容器化，微服务化，分布式化。
 容器化  Docker简化了软件打包，形成了新的软件分发标准；同时解决了应用环境的一致性，加快了应用的部署，DevOps; Docker能更粒度地的资源分割。这些特性使得Docker技术快速应用，其技术以及生态的发展正对PaaS产生革命性的冲击与影响。基于Docker的PaaS平台也是层出不穷，如OpenShift，CloudFoundry，Deis与Flynn等，而公有云AWS， Azure，GCE与IBM等都份份支持Docker容器。
 微服务化  传统的集中式的三层架构，转变到微服务架构。应用由一组无状态，功能分离，可独立部署的小服务集组合而成。而每个服务又具体语言多样性，不同的开发团队可以选择其熟悉与场景适合的语言。服务间是解耦合的，每个服务内部可能快速上线，而不影响其它的服务。某个服务的故障只会影响到自己。微服务化架构下，PaaS平台要支持对微服务架构的应用平滑地演进。
 分布式化  传统PaaS面临着缺少大规模跨DC跨集群的管理能力；资源分配算法比较简单，不支持应用感知的多集群等资源分配需求；资源分配并行技术缺少在大量资源需求时验证，分配速度不理想。但无论是公有云还是私有云大规模地发展，都驱动了大规模集群管理与资源跨Region跨DC跨AZ调度。当前基于容器集群管理编排、资源调度技术还在不断地演进发展。
PaaS构建新目标 应用敏捷性，集中式朝分布式架构演进，构建PaaS时需考虑如下：
 PaaS支持应用渐进式地演进：构建基础通用技术共享平台（如微服务框架，DevOps流水线，通用中间件服务等），逐步迁移改造应用，让应用更好地Cloud Native。 PaaS支持应用的高用性：基于Design for failure理念，构建基础的可靠性工具集，通过软件来实现应用层的高可用性，支持跨DC，AZ等高用性部署；支持跨2地3中心的高可用性路由；支持应用分布式下事务管理，数据的一致性等。  大规模的基础设施建设，需要打通IaaS/PaaS，构建基于应用层的统一资源编排调度：
 全自动化：支持应用自动化部署，伸缩，灰度发布等；开发环境的自助式获取与应用自动化验证。 混合调度：支持基于物理机，虚拟机，以及容器在应用层的不同需求下的混合调度。  开放性才能让PaaS更具有生命力，PaaS需易集成，无锁定，让应用可以快速平滑迁移：
 多IaaS： 公有层场景下，可能由PaaS供应用商自建IaaS。但在私有云场景下，支持多IaaS对接是非常有价值的。 多运行环境： 微服务化，不同的服务可能采用不语言开发，这要求PaaS支持多语言的运行环境。 多服务：无论是平台本身提供的中间件云服务，PaaS还要能支持第三方传统服务的接入以供应用使用。 多工具：目前开源的自动化工具非常多，PaaS平台需要考虑支持可以集成多种工具，拉通现有应用的DevOps。 </content>
    </entry>
    
     <entry>
        <title>Design for Failure</title>
        <url>http://lanlingzi.cn/post/technical/2017/0216_dff/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 背景 故有的思维会影响创新，在传统的软件设计考虑高可靠性，主要方法论是”防“，处处保护，让系统的每一处能长时间运行，不中断地提供服务。事实上电信级高可用性（HA）也只能宣称达到5个9，这意味着一年也就只有5分半钟的中断时间。但每增加一个9却实施成本非常地高，有些是建立在硬件可靠基础之上，并且不少是实验数据或理论上支持。传统的思维认识，在泥沙上建房子不可靠的。但软件架构设计，即完全不一样，在不可靠的基础设施上构建上可靠的系统，那才是真正NB的。
依稀记得云计算刚出来时，大家都是持怀疑态度：性能下降的虚拟化技术、安全不可控的网络、变化复杂的资源管理，在其上如何构建可靠稳定的软件系统？事实上，Netflix完全基于AWS云基础设施，认为都有可能发生任何的故障（Failure），更何况资源也不掌握在自己手上。Netflix基于Design for Failure理念却构建出用户无感知的高可用系统，支撑他的业务飞速发展。事实上，故障无所不在，尤其是在云计算环境中：
 资源层次：电能失效，整个数据中心不可用；部分计算失效，网络不通，存储IO高等 应用层次：资源泄露；软件Bug；系统处理能力不足等 数据层次：数据丢失；数据不一致等  概念解读 既然故障不可避免，何不让故障尽早的暴露，尽快的恢复。设计时针对故障场景而设计，一切假定在故障失效下如何处理，局部的失效不影响整体的可用性。这就是Design for Failure的核心理念。这个设计理念其实也跟人类社会很像：一个人的细胞代谢，只要有新的细胞补上就行；一个组织中，高度细分工作，几个人的离开，不影响整体的运转。Design for Failure不仅仅是高可用性设计，而是一种新的设计理念，有别于传统，通过单点的可靠性达到整体的高可用性。以Netflix公布的数据来看，每个EC2实例平均生命周期只有36个小时，每个单点不断地重生，才能达到整体的高可用性。其关键实施要点总结如下：
 容错：当系统中出现了各种故障时，系统能够自动隔离故障而不影响系统对外的服务质量。 冗余：提供系统冗余配置，当系统发生故障时，冗余的快速介入并承担已发生故障的工作。  以一个运行在云环境中的应用为例，Design for Failure理念需要按如下步骤来考虑：
 每个应用程序组件必须部署在冗余的云组件/服务上，有很少或没有失败的共同点，即不存在单点故障； 每个应用组件必须对基础设施不作任何假设，它必须能够在不停机的情况下适应基础设施的变化； 每个应用程序组件应该是分区容忍，换句话说，它应该能够生存的网络延迟（或通信损失）的节点上； 借助于自动化工具，必须能编排应用程序，以便响应失败或其他基础设施的变化等等。  案例分析 一个单点的故障，我们可能针对性地很容易解决，这可能是头痛医头的做法。但一个系统软件往往没有那么简单，举例来说，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。 此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。这就是我们常说的雪崩效应。所以我们非常有必要分析系统中的各种依赖关系。不同的层次来Design for Failure，不同的技术组合来解决问题。
以Netflix的系统架构来简单分析一下，看它是如何分层解决问题的：
接入层： AWS ELB 典型的部署架构都是多地区（Region）、多可用区（Zone）的部署。负责四层负载分发，支持跨Region调用，它解决是当一个Region不可用的分发。
Zuul Zuul负责七层分发，提供动态路由，监控，弹性，安全等。Zuul可以通过加载动态过滤机制，从而实现以下各项功能：
 验证与安全保障: 识别面向各类资源的验证要求并拒绝那些与要求不符的请求； 审查与监控: 在边缘位置追踪有意义数据及统计结果，从而为我们带来准确的生产状态结论； 动态路由: 以动态方式根据需要将请求路由至不同后端集群处； 压力测试: 逐渐增加指向集群的负载流量，从而计算性能水平； 负载分配: 为每一种负载类型分配对应容量，并弃用超出限定值的请求； 静态响应处理: 在边缘位置直接建立部分响应，从而避免其流入内部集群； 多区域弹性: 跨越AWS区域进行请求路由，旨在实现ELB使用多样化并保证边缘位置与使用者尽可能接近； 金丝雀测试：金丝雀版本实现精确路由； 故障注入：结合故障注入工具，从前端自动注入故障；  服务层 Eureka Eureka为所有Netflix服务提供服务注册集中管理，当然它也是可以分Zone分Region集群部署的。它与Zookeeper不同是：Zookeeper侧重于CP，而Eureka侧重于AP；服务注册信息支持跨Region的复制。
 Eureka服务端用作服务注册，提供服务实例信息注册与同步； Eureka客户端用用服务发现，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。  Ribbon 由于Eureka是非强一致性，服务实例状态并非是实时性，服务调用可能失败或超时。所以Ribbon作为客户端组，配合Eureka一起使用，作为服务路由均衡的补充。
 Ribbon客户端提供一系列完善的配置选项，比如连接超时、重试、重试算法等， Ribbon内置可插拔、可定制的负载均衡组件，支持多种均衡策略：简单轮询负载均衡；加权响应时间负载均衡；区域感知轮询负载均衡；机负载均衡。  在选择服务器时，该负载均衡器会采取如下步骤：
 负载均衡器会检查、计算所有可用区域的状态。如果某个区域中平均每个服务器的活跃请求已经达到配置的阈值，该区域将从活跃服务器列表中排除。如果多于一个区域已经到达阈值，平均每服务器拥有最多活跃请求的区域将被排除。 最差的区域被排除后，从剩下的区域中，将按照服务器实例数的概率抽样法选择一个区域。 从选定区域中，将会根据给定负载均衡策略规则返回一个服务器。  Hystrix Hystrix提供分布式系统使用，提供延迟和容错功能，隔离远程系统、访问和第三方程序库的访问点，防止级联失败，保证复杂的分布系统在面临不可避免的失败时，仍能有其弹性。
 隔离模式：简单说就是为每个依赖调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队，加速失败判定时间。 熔断模式：目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。  上述两种模式的实施，是服务速错，服务降级的基础。
数据层 EVCache VCache是一个数据缓存服务，专门为Netflix的微服务提供低延迟，高可靠性的缓存解决方案。它是基于memcached的内存存储，专门为云计算优化，适合对强一致性没有必须要求的场合。它不需要处理全局锁，群体读写，事务更新，部分提交和回滚，和其他一些分布式一致性的复杂设计。
 跨区可用：一个地区的的会员切换到另外一个地区，会在新的地区缓存中没有老地区的数据，称为cold cache，缓存会保存着重新计算需要的临时数据，这些数据如果从持久层存储获得将会非常昂贵，所以这种数据写入到本地缓存，并必须复制到所有地区的缓存中，以便服务于各个地区会员使用。 复制延迟：在跨区域复制变慢的情况下，不会影响性能和本地缓存的可靠性，所有复制都是异步的，复制系统能够在不影响本地缓存操作情况下悄悄地短时间中断。不需要一个完美的复制系统，可以接受EVcache一定限度的延迟和不一致，只要能满足应用和会员的需要就行。  其它 Cassandra是一个NoSQL数据库，是购买一家商业公司的服务，主要是用于各种Session的存储，并且支持跨区的同步复制。S3主要用于数据的备份。
总结 Netflix在每层上都考虑了失效，如何处理，但它每一层都没有做到尽善尽美，但不同层次的组合，却做到几乎完美的高可用性。当然Netflix构建高用性的系统还不只是我上面所列出的组件或工具。列出关键的部分是为了表达出Design for Failure的理念是：故障不可避免，可以分层次的设计，通过多个技术方案组合应用，从而达到故障隔离，冗余恢复，实现整体的高可用性。
</content>
    </entry>
    
     <entry>
        <title>35还能做技术吗</title>
        <url>http://lanlingzi.cn/post/thoughts/2017/0208_35_change/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>程序员</tag>
        </tags>
        <content type="html"> 最近我司心声社区到处充斥着在40岁左右惯例的帖子，之前觉得这些觉得离自己很远。不经意发现自己今年也35岁了，惯例这一天迟早会来临，只是早晚而已，按目前现状，再为公司奋斗也不会有太多年了，你想奋斗关键公司不让你啊。最近也陆续听到之前曾经共事的同事，或由于身体原因，被沟通退休或离职；或由于绩效平平，合同到期不再续签；或由于种种原因，被进入战备预备队前途不明。公司主营业务已遇到瓶颈，整个行业暮色深沉，新的领域就开拓不足，公司高层也不断地发文要打粮食，熵减等等。总之：“山雨欲来风满楼”。
35岁应该是一个年富力强的年龄，不应该发出“今年35，还能做技术吗？”这样的话题，其中透露出一丝不自信。话说三十而立，但目前这个年龄段，我是上有老，下有小，身上还背着几百万的房贷，说没有压力不是可能的。作一名软件工程师，在国内来说其职业生涯是相当短的。而我一直从事软件相关的工作，目前虽是做软件架构设计，但还是喜欢写写代码，一直没有找到自己明确的发展方向，一方面有我自身的性格原因，一方面能力的确有些偏科。
我非常能理解公司最近一些HR政策，企业为了保持长期的活力，换血难免。不管这事是否有多么无情，站在企业的角度来说无疑是正确的，毕竟企业不是慈善机构。公司也不可能让一个上了年龄、有家室的人一直从事一线编码工作。公司注重的是流程管理，觉得编码也可以像产业工人一样批量地生产。而年轻人更能干得多，给予得少。即使最近提倡的工程师文化，也是很难真正地做到，越提倡说明越缺失。
先简单说一说我为什么走上软件开发这一条路的经历吧：
90年代还是读初中时，老爸单位就开始使用电脑记账，那时觉得电脑太神奇了。个人虽买不起电脑，而要求老爸买了学习机，当时按着说明书，用basic语言输出满屏幕的各种形状的图型，心中也被巨大的喜悦填满。目前我清楚地记得，我爷爷看到我能在学习机上打出全家的名字，觉得这个是怎么做到的而不可思议。
高考那一年，我一表哥从大学里寄来一本小说《第一次亲密地接触》，讲得就是网络交友，原来交朋友也可能通过互联网，当时觉得这个太好玩了。于是高考填写志愿，我报了某211计算机专业，可惜语文成绩刚及格，总分数不够（在本省就招3个，我排名第6，我爸通过关系才知道的）。还好有个第三志愿保底，并且填写可以调剂，于是我调转到另一所大学，学的是信息管理。妈蛋，到学校才知道，这个信息管理其实与计算机不太相关，虽然也会学些计算机原理，C语言编程等。但这不是主业，主业是信息检索，运筹学，是一个从图书馆管理发展起来杂学科，什么都学，什么都浅。
大学一年级第二学期就买了电脑，一买电脑，就没有心思学习了，第一年还拿奖学金，后面连课不上了。每天大部分时间都在折腾电脑，重装系统，Win系统不知安装了多少次；Linux当时还远没有现在好用，也折腾过蓝点，RedHat。除了折腾就是打游戏，或者泡在网上看各种论坛。计算机理论没有怎么学，但其间还是有些编程的基础，曾获得校编程比赛三等奖。后面也和同学搞搞网站，系网站还是我们整理的，界面虽然丑点，但蛮有满足感。
04年大学毕业后就来了深圳，开始家里就给我安排了一份工作，是做物业管理。但我不是这种菜，没有干一天，就辞职不做了，现在想想年轻就是任性啊。出来就自己开始找工作，找来找去，发现只有做网站的公司要我，于是第一年我就在一家当时在体育界还算小有名气的小公司做一名程序员，负责后台的程序开发，从此就踏上了软件开发这一条道路。后来05年华为大规模地招新四军，经过电话面试，当面做题，也没有怎么答好就稀里糊涂地来了华为，真还得谢谢当时的技面官。后面更没有想到的事，有些同学纷纷转行，中间也有过多次的机会离开，而我却一干就是12年了。
在华为一直干得比较辛苦，结婚生小孩之后，发现再不能跟小伙伴一直挑灯夜战了。之前也不是没有奋斗过：
 去国外出差，可以整夜不睡觉，为了就是调通一个功能，等着明天客户可以验收。而这样的状况是持续的，每天吃不好，睡不着，最后回来发现落下胃病。 可以持续一个多月每天晚上11:30下班，回到公司附近的出租屋倒头就睡，明天又接着干。 可以凌晨不知几点，一个电话把你叫醒，说日志发到你邮箱，尽快定位解决问题。 可以明知道不可能完成的任务，还是坚持答应下来，即使周末过来，也要加班加点把它做完。 &amp;hellip;&amp;hellip;  当过了三十多岁，的确现发现状态不如以前了，说一下感受吧：
 明显感觉体力不行了。以前定位解决问题，搞到凌晨三四点也没有什么睡意，第二天精神也不错。现在如果要搞到凌晨或通宵的话，后面两三天觉得身心疲惫。 亚健康状态，平时锻炼比较少。每年的体检都有不少的问题，坐久了时间就觉得腰，颈椎痛。 记忆力没有以前好了。以前看过的代码，长时间能记住，定位问题总是比其它人快速。看过的资料，吸收没有哪么快了，记得的东西有时突然就想不起来。 明显感觉脑力跟不上了。以前码代码非常地快，一周就写10K；现在写代码总是思前想后，生产率没有那么高，但现在质量可能更好一些。想问题时注意力容易被打断，打断之后再难回神。  当然这些年也积累了非常多的经验：
 尤其是攻关方面，我总是能解决问题，因为之前踩过不少的坑，看过不少的坑，也解决过不少的坑，问题总是本质一样的。写代码会本能地避免，定位总是会举一反三。 知道怎么去做方案设计，分解并指导新人完成一个系统。有些问题能轻车熟路，以前解决类似问题的方案可以拿来复用。 知道系统架构一些设计原则，理论基础，抽象建模，知道如何去权衡一些方案的利弊等。 知识不再局限于编程语言，知道从多角度，多层次来看待一些问题，也在尝试去提炼一些编程之外的东西。  热爱与钻研技术这个没有错，也不会随着年龄大了就不行了。虽然软件界的技术日新月益，编程语言层出不穷，各种框架各领风骚，但解决实现问题的经验与能力是非常重要的。现在你跟一群年轻人去拼体力拼时间，肯定是拼不过了，唯有作出转变。以前可能是“我能力强，效率高，部门的关键人物”，其实那是错的，不可替代性才是最有价值的。“人无远虑，必有近忧”，平时不妨努力提升自己，专注于某一领域，你能想到别人所想不到的，您能解决别人所处理不了的。编程只是一种解决问题的手段，技术也不仅仅只是编程。简单地说对于通用软件领域，当前主要的价值是如何构建分布式的架构体系统，以应对不断变化的商业模式与体量。
当然上面说的还是一条技术路线，更重要的是你想明白技术只是为了产品，为了商业模式服务的。要让自己增值，不再吃码农的青春饭，那就要改变自己的想法，以快速适应未知的变化。积累系统架构经验，积累技术把控能力，积累对商业的理解，积累发现机会的敏感，果敢地作出改变。
</content>
    </entry>
    
     <entry>
        <title>再说说微服务</title>
        <url>http://lanlingzi.cn/post/technical/2017/0207_msa_think/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>微服务</tag>
        </tags>
        <content type="html"> Why 我司从15年开始学习互联网的微服务构架，到今16年的全云化战略，微服务已作为架构体系的重要工作。但微服务看似美好，在IT界应用非常的成熟与成功，但这个本质没有革命性的技术架构，在我司却非常地难以落地。主要原因：传统的CT应用太过厚重，面临着软件交付模式完全不一样，历史包袱改造面临短期看不到收益的成本投入：
 IT界：软件是自运维，借助于微服务构架，DevOps工程化，以及相对扁平的组织结构。软件向微服务转变相对阻力比较小，按康威定律，组织决定架构，微服务构架与扁平化、轻小的、精英化的组织是完全匹配的。在微服务构架实施上可以快速迭代演进，同时形成回路反馈，架构更符合良性的发展。同时像BAT等公司，业务上爆发式的增涨，也会加速微服务构架软变与满足。 我司：软件非自运维，做的是产品卖给运营商，DevOps当前无法直接打通。微服务构架对交付与运维来说，没有直接带来价值，反而会带来更多的问题。运营商是不可能像IT界每日构建灰度升级的。当然运营商自己也在改变，但这个改变是基础设施平台化，上层业务应用会拉入IT厂商，反而像我司这类传统的设备供应商会被旁落。说起来，这是另一个更大沉重的话题，不就再展开了。  What 微服务架构转变当前遇到的各种问题，不是我们不实施微服务架构的理由。软件全云化，微服务这是趋势。再说说微服务对我们目前软件开发的核心价值吧：
 设计：微服务架构下，设计上可以重用已有微服务，反哺微服务仓库，达到软件功能更好的复用；同时由于微服务具有9大特性，使架构师能更好的守护软件架构。 开发：相比原来组件化架构，每个开发人员负责的代码量减少，更能把事件做精；微服务架构下，一般会有像JDF或HSF的服务框架，使开发难度降低；业务功能的细分，基于服务化接口契约，使并行开发变成可能，工期缩短；细粒度快速验证，单个微服务的更容易稳定。 部署：基于微服务的功能组合，可以按不同的特性交付，特性独立上线，而不原有的通过License开关控制；容量上可以按小颗粒度，自动化地伸缩，系统拥有更好的弹性。 运行：可以小颗粒度，自动化地故障隔离，故障影响范围可控；按服务的滚动升级。  有上面的这些理由，难道我们还不选择微服务架构吗？架构上是OK的，但我司的矩阵性管理，有项目经理，有产品管理，有服务人员，有部门经理，有成本管理等，他们会看到，会认可吗？会有产品上收益来支撑吗？遗憾是目前没有，所以仅仅是研发体系上的隐性收益很难快速地推进。
How 在我司，那如何地渐进式地推进微服务架构，从四个维度架构视图展开：
  逻辑视图：
 存量代码按特性功能进行分析梳理，优先有商业价值的特性功能重构 将老版本进程进行拆分与整合，对于相对稳定的原有组件尽量只服务化，而不微服务化 新增特性直接按照微服务架构设计，并优先考虑重用已有拆分的微服务 服务独立自治，多实例集群负荷均衡，可靠性服务内完成，服务内性能并发，服务使用者性能透明 去中心化治理，无全局控制节点，避免全局故障 服务划分原则：数据私有化，功能实例化，接口标准化，依赖最小化    部署视图：
 独立进程承载服务功能，在部署形态上做到可分可合 服务尽量部署独立数据库，在设计上考虑Schema的隔离 服务内的多进程统一服务控制节点管理 服务可靠性，并发性统一由服务控制节点管理 改造老进程新增服务接口，新老并存，调通后再去除老接口 新服务新进程承载，调通后替换老进程    开发视图：
 按照服务构建开发视图 按照服务构建测试工程 按照服务适配个人构建    能力视图：
 配置能力完善，包括基础架构，研发工具，人员能力 探索适合我司交付模式的微服务的开发模式    总之，微服务架构落地不可能一蹴而蹴，更不可能一场运行就能解决的。
</content>
    </entry>
    
     <entry>
        <title>Go性能优化小结</title>
        <url>http://lanlingzi.cn/post/technical/2017/0203_go_optimize/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 内存优化 小对象合并成结构体一次分配，减少内存分配次数 做过C/C&#43;&#43;的同学可能知道，小对象在堆上频繁地申请释放，会造成内存碎片（有的叫空洞），导致分配大的对象时无法申请到连续的内存空间，一般建议是采用内存池。Go runtime底层也采用内存池，但每个span大小为4k，同时维护一个cache。cache有一个0到n的list数组，list数组的每个单元挂载的是一个链表，链表的每个节点就是一块可用的内存，同一链表中的所有节点内存块都是大小相等的；但是不同链表的内存大小是不等的，也就是说list数组的一个单元存储的是一类固定大小的内存块，不同单元里存储的内存块大小是不等的。这就说明cache缓存的是不同类大小的内存对象，当然想申请的内存大小最接近于哪类缓存内存块时，就分配哪类内存块。当cache不够再向spanalloc中分配。
建议：小对象合并成结构体一次分配，示意如下：
for k, v := range m { k, v := k, v // copy for capturing by the goroutine go func() { // using k &amp;amp; v }() } 替换为：
for k, v := range m { x := struct {k , v string} {k, v} // copy for capturing by the goroutine go func() { // using x.k &amp;amp; x.v }() } 缓存区内容一次分配足够大小空间，并适当复用 在协议编解码时，需要频繁地操作[]byte，可以使用bytes.Buffer或其它byte缓存区对象。
建议：bytes.Buffert等通过预先分配足够大的内存，避免当Grow时动态申请内存，这样可以减少内存分配次数。同时对于byte缓存区对象考虑适当地复用。
slice和map采make创建时，预估大小指定容量 slice和map与数组不一样，不存在固定空间大小，可以根据增加元素来动态扩容。
slice初始会指定一个数组，当对slice进行append等操作时，当容量不够时，会自动扩容：
 如果新的大小是当前大小2倍以上，则容量增涨为新的大小； 否而循环以下操作：如果当前容量小于1024，按2倍增加；否则每次按当前容量1/4增涨，直到增涨的容量超过或等新大小。  map的扩容比较复杂，每次扩容会增加到上次容量的2倍。它的结构体中有一个buckets和oldbuckets，用于实现增量扩容：
 正常情况下，直接使用buckets，oldbuckets为空； 如果正在扩容，则oldbuckets不为空，buckets是oldbuckets的2倍，  建议：初始化时预估大小指定容量
m := make(map[string]string, 100) s := make([]string, 0, 100) // 注意：对于slice make时，第二个参数是初始大小，第三个参数才是容量 长调用栈避免申请较多的临时对象 goroutine的调用栈默认大小是4K（1.7修改为2K），它采用连续栈机制，当栈空间不够时，Go runtime会不动扩容：
 当栈空间不够时，按2倍增加，原有栈的变量崆直接copy到新的栈空间，变量指针指向新的空间地址； 退栈会释放栈空间的占用，GC时发现栈空间占用不到1/4时，则栈空间减少一半。  比如栈的最终大小2M，则极端情况下，就会有10次的扩栈操作，这会带来性能下降。
建议：
 控制调用栈和函数的复杂度，不要在一个goroutine做完所有逻辑； 如查的确需要长调用栈，而考虑goroutine池化，避免频繁创建goroutine带来栈空间的变化。  避免频繁创建临时对象 Go在GC时会引发stop the world，即整个情况暂停。虽1.7版本已大幅优化GC性能，1.8甚至量坏情况下GC为100us。但暂停时间还是取决于临时对象的个数，临时对象数量越多，暂停时间可能越长，并消耗CPU。
建议：GC优化方式是尽可能地减少临时对象的个数：
 尽量使用局部变量 所多个局部变量合并一个大的结构体或数组，减少扫描对象的次数，一次回尽可能多的内存。  并发优化 高并发的任务处理使用goroutine池 goroutine虽轻量，但对于高并发的轻量任务处理，频繁来创建goroutine来执行，执行效率并不会太高效：
 过多的goroutine创建，会影响go runtime对goroutine调度，以及GC消耗； 高并时若出现调用异常阻塞积压，大量的goroutine短时间积压可能导致程序崩溃。  避免高并发调用同步系统接口 goroutine的实现，是通过同步来模拟异步操作。在如下操作操作不会阻塞go runtime的线程调度：
 网络IO 锁 channel time.sleep 基于底层系统异步调用的Syscall  下面阻塞会创建新的调度线程：
 本地IO调用 基于底层系统同步调用的Syscall CGo方式调用C语言动态库中的调用IO或其它阻塞  网络IO可以基于epoll的异步机制（或kqueue等异步机制），但对于一些系统函数并没有提供异步机制。例如常见的posix api中，对文件的操作就是同步操作。虽有开源的fileepoll来模拟异步文件操作。但Go的Syscall还是依赖底层的操作系统的API。系统API没有异步，Go也做不了异步化处理。
建议：把涉及到同步调用的goroutine，隔离到可控的goroutine中，而不是直接高并的goroutine调用。
高并发时避免共享对象互斥 传统多线程编程时，当并发冲突在4~8线程时，性能可能会出现拐点。Go中的推荐是不要通过共享内存来通讯，Go创建goroutine非常容易，当大量goroutine共享同一互斥对象时，也会在某一数量的goroutine出在拐点。
建议：goroutine尽量独立，无冲突地执行；若goroutine间存在冲突，则可以采分区来控制goroutine的并发个数，减少同一互斥对象冲突并发数。
其它优化 避免使用CGO或者减少CGO调用次数 GO可以调用C库函数，但Go带有垃圾收集器且Go的栈动态增涨，但这些无法与C无缝地对接。Go的环境转入C代码执行前，必须为C创建一个新的调用栈，把栈变量赋值给C调用栈，调用结束现拷贝回来。而这个调用开销也非常大，需要维护Go与C的调用上下文，两者调用栈的映射。相比直接的GO调用栈，单纯的调用栈可能有2个甚至3个数量级以上。
建议：尽量避免使用CGO，无法避免时，要减少跨CGO的调用次数。
减少[]byte与string之间转换，尽量采用[]byte来字符串处理 GO里面的string类型是一个不可变类型，不像c&#43;&#43;中std:string，可以直接char*取值转化，指向同一地址内容；而GO中[]byte与string底层两个不同的结构，他们之间的转换存在实实在在的值对象拷贝，所以尽量减少这种不必要的转化
建议：存在字符串拼接等处理，尽量采用[]byte，例如：
func Prefix(b []byte) []byte { return append([]byte(&amp;#34;hello&amp;#34;, b...)) } 字符串的拼接优先考虑bytes.Buffer 由于string类型是一个不可变类型，但拼接会创建新的string。GO中字符串拼接常见有如下几种方式：
 string &#43; 操作 ：导致多次对象的分配与值拷贝 fmt.Sprintf ：会动态解析参数，效率好不哪去 strings.Join ：内部是[]byte的append bytes.Buffer ：可以预先分配大小，减少对象分配与拷贝  建议：对于高性能要求，优先考虑bytes.Buffer，预先分配大小。非关键路径，视简洁使用。fmt.Sprintf可以简化不同类型转换与拼接。
 参考：
 Go语言内存分配器-FixAlloc https://blog.golang.org/strings </content>
    </entry>
    
     <entry>
        <title>CloudNative初探</title>
        <url>http://lanlingzi.cn/post/technical/2017/0106_cloudnative/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag><tag>容器</tag><tag>软件架构</tag>
        </tags>
        <content type="html"> 随着日益普及的云计算，越来越多的传统应用迁移到云上。尤其是视频巨头NetFlix从2009年开始，放弃构建自己的数据中心，把所有应用迁移到AWS。NetFlix认为云环境下，everything will be failure。它基于微服务架构，以及Design for failure理论，构建出一系统非常成功的云应用（微服务），支持它的业务飞速发展。NetFlix认为他们比Amazon自己更懂得AWS。同时业界也提出了CloudNative概念，Netflix的应用也认为目前最为成功的CloudNative应用（参考Cloud Native at Netflix）。那什么是CloudNative？
概念 目前对CloudNative并没有明确的定义。15年，Google联合其他20家公司宣布成立了开源组织Cloud Native Computing Foundation（CNCF）。想通过开源的Kubernetes，在云计算领域占据主层地位。当然Kubernetes目前是一个以应用为中心容器编排，调度集群管理系统。它想做的是CloudNative Application的基石。从CNCF组织来看，CloudNative Application应该包含微服务，容器，CI/CD特征。
早在2010年，WSO2的联合他始人Paul Fremantle在业界最早提出CloudNative，认为有如下几个关键特征：
 Distributed/Dynamically wired，分布式/动态连接 Elastic，弹性；Scale down as well as up, based on load，基于系统负载的动态伸缩 Granularly metered and billed，粒度合适的计量计费；Pay per user，按使用量计费 Multi-tenant，多租户 Self service，自服务 Incrementally deployed and tested， 增量的部署与测试  CloudNative系统的效果： Better utilization of resources, faster provisioning, better governace。
在2013年，AWS的云战略架构师同时也是NetFlix的云架构师Adrian Cockcroft提出对CloudNative新的定义：基于不可靠的，易失效的基础设施(ephermeral and assumed broken components), 构建高度敏捷（high agile），高可用（highly available）的服务，包括如下几个方面：
 目标：Scalability，伸缩性；Availablility，可用性；Agile，敏捷；Efficiency，效率 原则：Separation of Concerns，关注点分离；Anti-Fragility，反脆弱性；High trust organization，高度信任的组织 特点：Public Cloud，基于公有云； Mirco-services，微服务；De-normalized data，反范式化数据；Chaos Engines，混沌引擎；Continues Deployment，持续部署；DevOps等等  在2015年，Pivotal的产品经理Matt Stine又对CloudNative关键架构特征进行补充：
 Twelve Factor App，十二因子应用 Mirco-services，微服务 Self Service Agile Infrastructure，自服务敏捷的基础设施 API Based Clolaboration， 基于API的协作 Anti-Fragility，反脆弱性  总结 总结起来，要实施CloudNative，包括三个维度：
 软件架构：基于敏捷基础设施，是整个Cloud Native的根基；基于微服务架构，微服务架构是Cloud Native的一个核心要素；基于Design for failure理论，构建高可用的系统；基于容器部署，确保环境一致性，应用快速启动终止，水平扩展。 组织变革：根据康威定律，如果要达到比较理想的云化效果，必须进行组织变革。一个合理的组织架构，将会极大提高云化的推行；推行DevOps文化，倡导开放、合作的组织文化。 软件工程：推行持续集成与持续交付，联合开发、质量、运维各个环节，打通代码，编译，检查，打包，上线，发布各个环节。全自动化，包括自动化部署，升级，灰度，以及运维。  CloudNative背后的软件架构需求：
 按需特性的伸缩 按特性持续演进 应用快速上线 系统的高用性 全面解耦合 系统自服务 支持多租户 异构公有云   参考：
 http://wso2.com/library/articles/2010/05/blog-post-cloud-native https://www.infoq.com/presentations/migration-cloud-microservices http://www.infoq.com/cn/articles/cloud-native-architectures-matt-stine 一篇文章带你了解Cloud Native </content>
    </entry>
    
     <entry>
        <title>Go依赖管理机制</title>
        <url>http://lanlingzi.cn/post/technical/2016/1120_go_deps_mgnt/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 无论何种语言，依赖管理都是一个比较复杂的问题。而Go语言中的依赖管理机制目前还是让人比较失望的。在1.6版本之前，官方只有把依赖放在GOPATH中，并没有多版本管理机制；1.6版本（1.5版本是experimental feature）引入vendor机制，是包依赖管理对一次重要尝试。他在Go生态系统中依然是一个热门的争论话题，还没有想到完美的解决方案。
看其它 我们先来看看其它语言怎么解决，例举两种典型的管理方式：
Java 开发态，可以通过maven和gradle工具编辑依赖清单列表/脚本，指定依赖库的位置/版本等信息，这些可以帮助你在合适的时间将项目固化到一个可随时随地重复编译发布的状态。这些工具对我来说已经足够优雅有效。但maven中也有不同依赖库的内部依赖版本冲突等令人心烦的问题。尤其是在大型项目中的依赖传递问题，若团队成员对maven机制没有足够了解下，依赖scope的滥用，会让整个项目工程的依赖树变得特别的巨大而每次编译效率低下。运行态，目前Java也没有很好的依赖管理机制，虽有classloader可以做一定的隔离，但像OSGi那种严格的版本管理，会让使用者陷入多版本相互冲突的泥潭。
Node.js npm是Node.js的首选模块依赖管理工具。npm通过一个当前目录的 package.json 文件来描述模块的依赖，在这个文件里你可以定义你的应用名称( name )、应用描述( description )、关键字( keywords )、版本号( version )等。npm会下载当前项目依赖模块到你项目中的一个叫做node_modules的文件夹内。与maven/gradle不同的是，maven最终会分析依赖树，把相同的软件默认扁平化取最高版本。而npm支持nested dependency tree。nested dependency tree是每个模块依赖自己目录下node_modules中的模块，这样能避免了依赖冲突, 但耗费了更多的空间和时间。由于Javascript是源码发布，所以开发态与运行态的依赖都是基于npm，优先从自己的node_modules搜索依赖的模块。
go get Go对包管理一定有自己的理解。对于包的获取，就是用go get命令从远程代码库(GitHub, Bitbucket, Google Code, Launchpad)拉取。并且它支持根据import package分析来递归拉取。这样做的好处是，直接跳过了包管理中央库的的约束，让代码的拉取直接基于版本控制库，大家的协作管理都是基于这个版本依赖库来互动。细体会下，发现这种设计的好处是去掉冗余，直接复用最基本的代码基础设施。Go这么干很大程度上减轻了开发者对包管理的复杂概念的理解负担，设计的很巧妙。
当然，go get命令，仍然过于简单。对于现实过程中的开发者来说，仍然有其痛苦的地方：
 缺乏明确显示的版本。团队开发不同的项目容易导入不一样的版本，每次都是get最新的代码。尤其像我司对开源软件管理非常严格，开源申请几乎是无法实施。 第三方包没有内容安全审计，获取最新的代码很容易引入代码新的Bug，后续运行时出了Bug需要解决，也无法版本跟踪管理。 依赖的完整性无法校验，基于域名的package名称，域名变化或子路径变化，都会导致无法正常下载依赖。我们在使用过程，发现还是有不少间接依赖包的名称已失效了（不存在，或又fork成新的项目，旧的已不存维护更新）。  而Go官方对于此类问题的建议是把外部依赖的代码复制到你的源码库中管理。把第三方代码引入自己的代码库仍然是一种折中的办法，对于像我司的软件开发流程来说，是不现实的：
 开源扫描会扫描出是相似的代码时，若License不是宽松的，则涉及到法律风险，若是宽松的，开源扫描认证确认工作也很繁琐。 如何升级版本，代码复制过来之后，源始的项目的代码可以变化很大了，无明显的版本校验，借助工具或脚本来升级也会带来工作量很大。 复制的那一份代码已经开始变成私有，第三方代码的Bug只能自己解决，难以贡献代码来修复Bug，或通过推动社区来解决。 普通的程序问题可能不是很大问题，最多就是编译时的依赖。但如果你写的是一个给其他人使用的lib库，引入这个库就会带来麻烦了。你这个库被多人引用，如何管理你这个库的代码依赖呢？  好在开源的力量就是大，Go官方没有想清楚的版本管理问题，社区就会有人来解决，我们已经可以找到许多不错的解决方案，不妨先参考下官方建议。
vendor vendor是1.5引入为体验，1.6中正式发布的依赖管理特性。Go团队在推出vendor前已经在Golang-dev group上做了长时间的调研。最终Russ Cox在Keith Rarick的proposal的基础上做了改良，形成了Go 1.5中的vendor:
 不rewrite gopath go tool来解决 go get兼容 可reproduce building process  并给出了vendor机制的&amp;quot;4行&amp;quot;诠释：
 If there is a source directory d/vendor, then, when compiling a source file within the subtree rooted at d, import &amp;ldquo;p&amp;rdquo; is interpreted as import &amp;ldquo;d/vendor/p&amp;rdquo; if that exists.
When there are multiple possible resolutions,the most specific (longest) path wins.
The short form must always be used: no import path can contain “/vendor/” explicitly.
Import comments are ignored in vendored packages.
 总结解释起来：
 vendor是一个特殊的目录，在应用的源码目录下，go doc工具会忽略它。 vendor机制支持嵌套vendor，vendor中的第三方包中也可以包含vendor目录。 若不同层次的vendor下存在相同的package，编译查找路径优先搜索当前pakcage下的vendor是否存在，若没有再向parent pacakge下的vendor搜索（x/y/z作为parentpath输入，搜索路径：x/y/z/vendor/path-&amp;gt;x/y/vendor/path-&amp;gt;x/vendor/path-&amp;gt;vendor/path) 在使用时不用理会vendor这个路径的存在，该怎么import包就怎么import，不要出现import &amp;ldquo;d/vendor/p&amp;quot;的情况。vendor是由go tool隐式处理的。 不会校验vendor中package的import path是否与canonical import路径是否一致了。  vendor机制看似像node.js的node_modules，支持嵌套vendor，若一个工程中在着两个版本的相的包，可以放在不同的层次的vendor下：
 优点：可能解决不同的版本依赖冲突问题，不同的层次的vendor存放在不同的依赖包。 缺点：由于go的package是以路径组织的，在编译时，不同层次的vendor中相同的包会编译两次，链接两份，程序文件变大，运行期是执行不同的代码逻辑。会导致一些问题，如果在package init中全局初始化，可能重复初化出问题，也可能初化为不同的变量（内存中不同），无法共享获取。像之前我们遇到gprc类似的问题就是不同层次的相同package重复init导致的，见社区反馈。  所以Russ Cox期望大家良好设计工程布局，作为lib的包不携带vendor更佳 ，一个project内的所有vendor都集中在顶层vendor里面。
后续 Go的包依赖问题依旧困扰着开发人员，嵌套vendor可以一定程度解决多版本的依赖冲突问题，但也引入多份编译导致的问题。目前社区也在一直讨论如何更好的解决，将进入下一个改进周期。这次将在Peter Bourgon的主持下正式启动：[go packaging proposal process](https://docs.google.com/document/d/18tNd8r5DV0 yluCR7tPvkMTsWD_lYcRO7NhpNSDymRr8/edit#heading=h.6fvzjp2juxex)，当前1.8版本特性已冻结，不知这个改进是否会引入到1.9版本中。
 参考：
[1] 理解Go 1.5 vendor
[2] Golang的包管理之道
</content>
    </entry>
    
     <entry>
        <title>思维图形化</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/1118_arch_drawing/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 曾经，我幼稚地认为：只有写好代码才能对产品最“大”的贡献。什么需求分析文档，架构设计文档，没有最终的代码落地，那就是一张张的空纸。那些职位高高在上的架构师们，就也是写写胶片，画画图，他们又不懂技术细节，天天开会讨论来，讨论去都是在空谈一切。没有我们这些屌丝写的代码，你让他们去实现，估计几年也搞不出来。我写代码的能力比他们顶上N个人；再看看人家老外，60/70岁了还在码代码。为什么我国到了30岁了，都不去写代码了，都去搞所谓的架构设计了。是他们写代码写不好才去干架构师活吗？
经过这么多年在产品中挖坑、填坑，发现我们的产品是越来越复杂，但使用上也是越来越复杂，问题也是越来越难理清。我们的问题到底是出在什么地方：
 数据不可靠，系统常出错 增加新需求困难，场景总是覆盖不全 系统之间集成各种问题难以轻易解决 交付不同局点，代码总是改来改去 每年代码量成倍增加，前辈的代码看不懂、改不动 &amp;hellip;  这其实是光写好代码是不能解决上述问题的。只有你经历过，感受到，才能认识到系统的架构是何其重要。作为曾经一名码农，这几年一直在设计部与架构部工作，总是羡慕那些高级别的架构师：
 他们思考问题角度完全不同，总能高屋建瓴概括总结 他们思考问题比较全面，又能抽象提炼，让人快速抓住要要点 他们们输出的胶片、图画非常简洁，优美，明了，无二义 他们画出来图来指导解决集成问题，往往能一针见血地说明关键之处 &amp;hellip;  为什么他们的图能画得那么好，胶片写得那么牛，而我们似乎绞尽脑汁也难画出一张满意的图，难写出几张像样的胶片，是什么原因？是画得太少，写得太少，经验不足，方法不对，无灵感，还是天赋？
看到采铜老师的文章才悄然大悟：原来，不仅是因为架构师需要丰富的实践经验、敏锐的分析能力，以及系统性的建模能力，更主要的是因为：
 日常我们通过文字/讲故事是线性叙述，是人和时间的结合；而画图，是人与空间结合，理有助于思维拓展
</content>
    </entry>
    
     <entry>
        <title>Archlinux on WSL</title>
        <url>http://lanlingzi.cn/post/notes/2016/1030_archlinux_wsl/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>WSL</tag>
        </tags>
        <content type="html"> 最近国庆某东活动，搞了一台HP的笔记本，系统是Win10。经过不断地折腾，在Win10上启用了Windows Subsystem for Linux（简称WSL），并在WSL上安装了Archlinux。加入Insider Preview会员计划，可以最快地获取Win10的最新内部版本，以便及时获取WSL的功能更新。
WSL Windows Subsystem for Linux是一个为在Windows 10上能够原生运行Linux 二进制可执行文件（ELF 格式）的兼容层。 WSL提供了一个微软开发的Linux兼容内核接口（不包含Linux代码）。它包含用户模式和内核模式组件，主要是由如下组成：
 用户模式会话管理器服务，处理Linux实例的生命周期； Pico（可编程输入输出）提供驱动程序（lxss.sys，lxcore.sys），通过转换的Linux系统调用模拟Linux内核； 承载未经修改的用户模式Linux的Pico进程，例如/bin/bash。  在用户模式Linux程序和Windows内核组件之间，通过将未修改Linux程序放入Pico进程，我们让Linux系统调用被引导至Windows内核。lxss.sys和lxcore.sys驱动转换Linux系统调用进入NT API并模拟Linux内核。
Bash on Ubuntu on Windows就是WSL的具体应用。它是由微软与Canonical公司合作开发，目标是使纯正的 Ubuntu 14.04镜像能下载和解压到用户的本地计算机，并且镜像内的工具和实用工具能在此子系统上原生运行。在最近的14959更新中，Ubuntu已是默认为16.04。
Bash on Ubuntu on Windows 作为一名ArchLinux忠实爱好者，自然想在WSL上运行ArchLinux。参考了一些网上的资料，我已把Win10升级到14955，首先还是先得安装Bash on Ubuntu on Windows：
 开启开发人员模式：设置-更新与恢复-针对开发人员-开发人员模式 开启WSL子系统：控制面板-程序和功能-启用或关闭 Windows 功能-适用于 Linux 的 Windows 子系统（beta） 安装Bash on Ubuntu on Windows: 命令提示符（cmd）-输入bash-按提示完成安装  由于需要下载Ubuntu需要从应用商店下载，在天朝的网络，可能会比较慢，甚至会连接不上，我就折腾好久。并且它居然没有断点续传，好几次下载到70%多，就断开了，真让人受不了。
由于后续把Ubuntu替换成Archlinux，需要使用到Archlinux的roofs。squashfs-tools工具是用于解压sfs文件的，所以先把Ubuntu的更新源替换成国内的，比如mirrors.163.com/ubuntu或mirrors.aliyun.com/ubuntu。
$ sudo apt-get update$ sudo apt-get install squashfs-tools Archlinux on WSL 首先从http://mirrors.aliyun.com/archlinux/iso/latest/下载最新的ArchISO。
从ArchISO中提取出/arch/x86_64/airoot.sfs文件放在Bash on Ubuntu on Windows 能读取的目录下。WSL系统会把Windows的磁盘挂载到/mnt目录下，如D盘则是/mnt/d。
在Ubuntu中把airoot.sfs解压，建议在当前Ubuntu的用户Home目录下执行：
$ sudo unsquashfs airoot.sfs 然后把Bash窗口关掉，通过Windows的文件资源管理器进行到C:\Users\&amp;lt;用户名&amp;gt;\AppData\Local\Lxss文件夹。由于AppData与Lxss都是隐藏目录，可以在地址栏上直接输入路径就可以直接进入，否则需要在文件夹选项 中把“隐藏受保护的操作系统文件”选项取消才能看到。
其中的rootfs文件夹就是Linux中的/，先把原有的rootfs修改其它名称备份，还把之前airoot.sfs解压的squashfs-root直接剪切到Lxss，重命名为rootfs。注意，squashfs-root不能在Windows下拷贝到Lxss\rootfs，由于在WSL与Windows对文件读写操作还是有区别，Windows下拷贝可能存在丢失文件。
先在命令提示符（cmd）用lxrun /setdefaultuser root 把默认的用户换成root。再输入bash进入Linux。
这个我们就把Ubuntu替换成Archlinux。我们就可以像使用Archlinux一样来在WSL中使用Archlinux。比如创建新的用户，设置locale，替换Archlinux的更新源。不过由于我最早是在14396版本中使用WSL，还是在使用过程遇到了几个问题：
 无法chroot，解决办法：  升级到14936或以后的Insider Preview版本。
 Archlinux无法更新或安装新的软件，由于keyringVerifying失败，解决办法:  # pacman-key --init # pacman-key --populate  locale-gen失败(找不到UTF-8的charmaps文件)，解决办法：  # cd /usr/share/i18n/charmaps # tar zxvf UTF-8.gz # locale-gen  编译Go语言程序失败（估计是系统调用没有实现，没有proc），解决办法：  升级到14959或以后的Insider Preview版本。
WSL终端 windows下命令提示符（cmd），输入bash可以直接进入WSL，但它的使用体验无法跟Linux中的终端相比。好在网上已有同学先贡献了终端模拟器，都是基于mintty，总算能找回一些在纯Linux中使用终端的感觉。若使用下msys2的同学应该对它比较熟悉。
 https://github.com/mintty/wsltty https://github.com/goreliu/wsl-terminal   参考：
[1] https://blog.yoitsu.moe/arch-linux/wsl_with_arch_linux.html
[2] http://tieba.baidu.com/p/4834742871
[3] https://linux.cn/article-7857-1.html
[4] https://linux.cn/article-7209-1.html
</content>
    </entry>
    
     <entry>
        <title>团队管理</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/1027_team_mgnt/</url>
        <categories>
          <category>笔记</category><category>感想</category>
        </categories>
        <tags>
          <tag>团队</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 最近由于Go语言项目，又带一个小团队。以前作为团队的Leader，总是遇到各种问题，尤其是如何管理好人很困惑。HW的组织相对是比较宽松的，内部号称是矩阵式，感觉一个团队的凝聚力个人还是来源于Leader的个人技术感召力。好吧，这个只是凭感觉的管理，这是远远不够的。
作为一个技术团队的小Leader，整体来讲，它面临”业务“，”人“，”事“这三个方面的工作展开。这些是来源公司内牛人们的一些总结，我把他们纪录下来，是为了我更好地开展工作。
业务 虽是一个技术团队，所交付是面向客户交付的软件。两个方面是需要思考的：
 价值贡献 满意度  我们常说”质量是我们最后尊严，业务价值是我们存在之本“，道理简洁朗朗上口，但也是最难做好的，做好又是一白遮百丑。
 面向业务：核心竞争力，价值识别与规划 面向业务&amp;amp;解决方案：领域级，变革项目级规划、运作 满意度管理：面向业务（客户，用户）；面向解决方案；面向部门；面向合作伙伴 Top产品，问题的攻关  人 人的运用，对于Leader来说，是一项非常具有挑战的事，这需要Leader有很高的EQ与IQ。总结起来选用育留四个字：
  选
 亲自招聘，选择合适的人 已有员工中骨干识别 非关键外包合作    用
  角色与岗位排兵布阵
  合作外包
  育
  能力引入：公司内部交流：经验总结交流分享；部门内外专家交流；业界交流：参加相关技术峰会；高级顾问培训交流
  能力培养：提升人员技能；组织能力建设
  全程关注：事前辅导，事中监控，事后总结
  留
  绩效辅导
  即时激励
  组织氛围：员工座谈，组织集体活动，员工关怀（问题员工识别管理，异常事件处理）
  岗位流动
  事 以前作为一个团队的小Leader，感觉一天都在忙，但不知在忙些什么。管事恨不得像孙猴子能分身出来，但健身乏术，如何正确合理地授权也是考验Lader的水平。
 TopN问题与任务跟踪管理 KPI管理：现状问题分析；改进计划（包括措施）；改进监控；达成评估 风险管理 技术持续改进：新技术引入；优秀实践； 质量持续改进：质量文化；质量监控，问题日清日结；质量回溯；质量改进 流程运作持续改进 知识管理 跨部门协同 </content>
    </entry>
    
     <entry>
        <title>软件变革下设计原则</title>
        <url>http://lanlingzi.cn/post/technical/2016/0910_soft_design/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件设计</tag><tag>设计原则</tag>
        </tags>
        <content type="html"> 传统大型软件系统 ，多以功能需求驱动设计与开发。在体系结构上是一个单体应用，变更修改往往是牵一而发动全身；在系统生态上是一个封闭系统，系统集成是大量定制开发。单体封闭的系统在交付中面临着越来越多的挑战，提升系统的竞争力首先是在软件架构上先行。软件系统发展也需像硬件一样不断地更新换代，软件架构设计需要输入新的思维。只有在思想上彻底地变革，才能摆脱原有的束缚与局限性。
体验为王 软件原本是一种信息技术发展不断地服务于各行各业，软件在实现上又是偏向技术性。如何让普通用户能够较好地使用软件，而不需要这方面的专业背景，需要思考软件减少数字与体验之间鸿沟。互联网思维一直讲求如何让用户感知到你对他的价值，而且把这个价值争取做到极致，超出用户的预期，这个就叫体验。只有用户产生体验之后，才能形成口碑。简而言之，体验的思想，就是从用户的感受出发，把它做到极致。
正如我们所见到的，iPhone的成功原因之一，就是注重用户的体验获得巨大的成功。今天，人们于弹指间操控丰富业务。无数应用，以碎片化的形式填满用户时间，连接起永远在线的数字生活。一个显见的事实是，“体验”正被尊奉为至高无上的法则，用户已重掌驱动行业发展的威权。
曾经一位领导说我们的软件系统发展应该先是“能用”，再是“好用”，最后是“易用”。这其实也是软件系统从功能为主朝用户至上，体验为王方向发展。套用阿里一句词：“让天下没有难用的软件”。
那如何能做到“体验为王”的软件设计呢？
作名一名架构师，首先要始终以用户和角色为中心，要从原有的我能为你提供什么功能，转变成用户最需要什么为出发点。首先要把自己当成用户，如果连自己都不去使用自己设计的系统，又如何把系统设计好呢。
有人说，软件架构设计不是UI/UE设计，架构设计是功能逻辑设计，是技术实现设计，是物理部署设计；而用户体验只是UI/UE都需要考虑的。UI设计，确切地说，用户使用界面上设计首先要考虑用户体验。但体验不仅仅是界面上的交互操作的易用性，心理感受等。试想，如果你浏览一个网页或使用一个App，虽UI设计非常符合用户的使用习惯，但响应速度却非常地慢。这也不会是好的体验。速度上需要零等待，存储上需要大容量，并发上需要高吞量。这些都需要在软件系统架构上着重设计。
软件架构设计要以需求的场景化、实例化驱动设计。无法场景化的需求往往是伪需求。真正的需求是满足目标用户在特定场景下的目标。作为架构设计师，要弄清其中两个关键因素：1）目标用户；2）特定场景下的目标。
平台为本 平台化分为技术支撑型平台和应用实现型平台。技术支撑型平台的用户为软件开发人员，提供者负责平台的维护和升级，用户负责基于平台的上层实现。这类平台包括软件中间件、开发工具、应用服务器等。应用实现型平台的用户为终端用户，提供者不但负责平台的维护和升级，还要负责实现基于平台的上层应用。
平台化首先需要在架构设计上考虑系统的开放性，通常的做法是系统功能服务化，API化。采用标准的通信协议，让系统易于被集成。系统具备更好的应用开发和维护的工具和接口，实施时可以迅速根据用户的特点进行部署和二次开发，用户可以最大限度地使用贴近自身特点来重新定义软件功能。
像Saleforce等SaaS平台一样，平台化使运行于上层的应用软件在某种程度上做到与技术无关，而是面向具体业务，提供更为领域化的DSL。平台化提供各种易于组装的套件，可定制修改的业务模板。这样才能面向合作伙伴，构建平台之上的工具链，生态社区等。
软件系统在研发和使用过程中需求变更不可避免。平台化的软件也在架构设计上，需地支持系统的平滑演进与对外接口兼容。这也需要在设计上考虑平台与上层业务之间的边界划分。上层的业务是最为变更频繁的，一是业务领域特性一般的变更不要侵入到平台。其二、平台的发展也不能影响上层业务的运行。当系统面对市场需要时，要评估这些需求是否需要在平台增加或改动哪些功能，平台软件是要随着客户需求而发展演进的。只有不断切合上层业务发展诉求的平台才具有更久的生命力。
内生敏捷 业务逻辑复杂多变，如何保证程序逻辑的代码稳定是架构师需要解决的问题，良好的模块划分和扩展性强的接口设计都是解决这个问题的利器。微服务化，大系统小做。系统分解的目标并不仅仅是搞出一堆很小的服务，这不是目标；真正的目标是解决系统在业务急剧增长时遇到的问题。
模块化，微服务化的让某一个功能足够内聚，足够小，代码容易理解、开发效率提高。服务之间可以独立部署，微服务架构让持续集成（CI），持续部署（CD）成为可能，基于数据化地构建软件生产流水线成为可能。各个服务之间可以在流水线上按功特性灵活组装。
软件的本质是要面对各种业务需求的变化，这需要系统高度地抽象化，以不变来应对万变。使用一切可以减少编码的技术，例如元数据驱动。软件系统设计已经发展到使用运行时引擎从元数据（即关于应用程序本身的数据）生成应用程序组件的阶段。在一个定义良好的元数据驱动的体系结构中，已编译的运行时引擎（内核）、应用数据、描述一个应用程序的基础功能的元数据，以及与每个租户的数据和定制相关的元数据之间有一个明确的分离。这些明显的边界使人们有可能独立更新系统内核，修改的核心应用程序，或定制租户的具体组成部分，虚拟意义上来说，几乎不会影响其他人。
数据驱动 数据驱动是系统内生的数据感知，基于系统运行数据进行系统的预测与资源优化。数据驱动的终极目标是希望利用数据能够直接在生产环境带来改变，提供价值。
数据驱动自动化干预，需要不断优化的分析算法，利用数据基础在特定领域完成基于算法的自动调整。算法线上部署除了对平台和算法本身的支持之外，还需要考虑：
 数据的及时性：实时数据和历史数据的组合，在特定周期下替换历史数据。 异常数据的容忍：线上算法的输入无法做到离线的清洗水平，需要更健壮的数据预处理模块。 算法的迭代：需要可靠的离线迭代平台来纠正线上算法运行过程中的误差和偏离。采集线上的数据到离线平台，通过离线平台调整参数和适应性。支持从离线平台推送新的算法。  一个系统的开放性，也体现在数据的开放性。系统架构上需考虑可被高层的系统，更深度的分析。不同维度与不同层次的分析，才能让数据变得更有价值。
原生云化 原生云化指“Cloud Native”，它是多种不同思想的一个集合，这些思想帮助软件系统转移到云平台。这些思想包括DevOps、持续交付、微服务、敏捷基础设施、康威定律等。“Cloud Native”没有标准的官方定义，但包括如下几个特征：
 可移植：应用层与物理层隔离。应用从开发环境迁移到物理环境无需改变环境配置。 自动化：通过持续集成和自我修复系统将IT基础设施的开发和部署进行自动化。 效率提升：通过引入全新方式来降低运维成本，让系统管理员可以有更多时间去改进系统，而不是把时间都用在维护系统上。 意识改变：DevOps的兴起以及运维和开发人员越来越多的共同协作发布服务，包括微服务和传统服务，让用户意识到服务发布的速度和敏捷性，已经和稳定性一样重要。  原生云化的系统也是具有12因子。原生云化首先考虑是的分布式一切。分布式架构可以以水平扩展，通过横向扩充节点，如一个节点扩充到多个节点，每个节点运行独立实例，节点与节点之间通过网络互连，随着节点扩充系统处理能力能够随之提升，单节点失效时，整个集群仍然可以对外提供服务。遵循12因子原则的应用程序，具有一致的架构接口。为了使创建的分布式应用马上就可以部署在云中，这些接口的构建采用一种无状态、面向进程的设计模式。
多租户也是云计算的基本属性之一，原生云化的系统也必定是多租户架构的系统。利用多租户带来资源上高度共享模式，提高资源资源利用率，降低单位资源成本。但是共享资源越多，会带来租户的隔离性难度越大，成本越高。在按隔离程序不同层次，可分为物理多租架构与逻辑多租架构，物理多租架构技术如采用虚拟化技术，Docker容器，以及应用容器技术来隔离租户资源。逻辑多租架构技术如应用程序进程间隔离，数据切割隔离。
原生云化的系统也是最大程度自动化。健壮自动化几乎能处理传统IT中需要手工处理的所有事情：当应用实例增减时更新路由器和负载均衡组件，部署应用所需的供应和联网服务，分配新的基础设施，设置监控和灾后恢复服务，日志聚合，当基础设施失效时重新部署应用。这些高级自动化实践，能把你从应对零日危险的痛苦中拯救出来：自动化采用滚动更新的方式，为每一个节点打上安全补丁，同时又保证服务一直在线。
</content>
    </entry>
    
     <entry>
        <title>Go map key类型分析</title>
        <url>http://lanlingzi.cn/post/technical/2016/0904_go_map/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 团队成员中大多是原来做Java，深受Java的影响，对于使用map问得最多的：map的key如何计算它的HashCode。下面试图通过讲解一些类型知识来解答。
map的key类型 map中的key可以是任何的类型，只要它的值能比较是否相等，Go的语言规范已精确定义，Key的类型可以是：
 布尔值 数字 字符串 指针 通道 接口类型 结构体 只包含上述类型的数组。  但不能是：
 slice map function  Key类型只要能支持==和!=操作符，即可以做为Key，当两个值==时，则认为是同一个Key。
比较相等 我们先看一下样例代码：
package main import &amp;#34;fmt&amp;#34; type _key struct { } type point struct { x int y int } type pair struct { x int y int } type Sumer interface { Sum() int } type Suber interface { Sub() int } func (p *pair) Sum() int { return p.x &#43; p.y } func (p *point) Sum() int { return p.x &#43; p.y } func (p pair) Sub() int { return p.x - p.y } func (p point) Sub() int { return p.x - p.y } func main() { fmt.Println(&amp;#34;_key{} == _key{}: &amp;#34;, _key{} == _key{}) // output: true  fmt.Println(&amp;#34;point{} == point{}: &amp;#34;, point{x: 1, y: 2} == point{x: 1, y: 2}) // output: true 	fmt.Println(&amp;#34;&amp;amp;point{} == &amp;amp;point{}: &amp;#34;, &amp;amp;point{x: 1, y: 2} == &amp;amp;point{x: 1, y: 2}) // output: false  fmt.Println(&amp;#34;[2]point{} == [2]point{}: &amp;#34;, [2]point{point{x: 1, y: 2}, point{x: 2, y: 3}} == [2]point{point{x: 1, y: 2}, point{x: 2, y: 3}}) //output: true  var a Sumer = &amp;amp;pair{x: 1, y: 2} var a1 Sumer = &amp;amp;pair{x: 1, y: 2} var b Sumer = &amp;amp;point{x: 1, y: 2} fmt.Println(&amp;#34;Sumer.byptr == Sumer.byptr: &amp;#34;, a == b) // output: false 	fmt.Println(&amp;#34;Sumer.sametype == Sumer.sametype: &amp;#34;, a == a1) // output: false  var c Suber = pair{x: 1, y: 2} var d Suber = point{x: 1, y: 2} var d1 point = point{x: 1, y: 2} fmt.Println(&amp;#34;Suber.byvalue == Suber.byvalue: &amp;#34;, c == d) // output: false 	fmt.Println(&amp;#34;Suber.byvalue == point.byvalue: &amp;#34;, d == d1) // output: true  ci1 := make(chan int, 1) ci2 := ci1 ci3 := make(chan int, 1) fmt.Println(&amp;#34;chan int == chan int: &amp;#34;, ci1 == ci2) // output: true 	fmt.Println(&amp;#34;chan int == chan int: &amp;#34;, ci1 == ci3) // output: false } 上面的例子让我们较直观地了解结构体，数组，指针，chan在什么场景下是相等。我们再来看Go语言规范中是怎么说的：
 Pointer values are comparable. Two pointer values are equal if they point to the same variable or if both have value nil. Pointers to distinct zero-size variables may or may not be equal.当指针指向同一变量，或同为nil时指针相等，但指针指向不同的零值时可能不相等。 Channel values are comparable. Two channel values are equal if they were created by the same call to make or if both have value nil.Channel当指向同一个make创建的或同为nil时才相等 Interface values are comparable. Two interface values are equal if they have identical dynamic types and equal dynamic values or if both have value nil.从上面的例子我们可以看出，当接口有相同的动态类型并且有相同的动态值，或者值为都为nil时相等。要注意的是：参考理解Go Interface A value x of non-interface type X and a value t of interface type T are comparable when values of type X are comparable and X implements T. They are equal if t&amp;rsquo;s dynamic type is identical to X and t&amp;rsquo;s dynamic value is equal to x.如果一个是非接口类型X的变量x，也实现了接口T，与另一个接口T的变量t，只t的动态类型也是类型X，并且他们的动态值相同，则他们相等。 Struct values are comparable if all their fields are comparable. Two struct values are equal if their corresponding non-blank fields are equal.结构体当所有字段的值相同，并且没有 相应的非空白字段时，则他们相等， Array values are comparable if values of the array element type are comparable. Two array values are equal if their corresponding elements are equal.两个数组只要他们包括的元素，每个元素的值相同，则他们相等。  注意：Go语言里是无法重载操作符的，struct是递归操作每个成员变量，struct也可以称为map的key，但如果struct的成员变量里有不能进行==操作的，例如slice，那么就不能作为map的key。
类型判断 判断两个变量是否相等，首先是要判断变量的动态类型是否相同，在runtime中，_type结构是描述最为基础的类型（runtime/type.go），而map, slice, array等内置的复杂类型也都有对应的类型描述（如maptype，slicetype，arraytype）。
type _type struct { size uintptr ptrdata uintptr hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg gcdata *byte str nameOff ptrToThis typeOff } ... type chantype struct { typ _type elem *_type dir uintptr } ... type slicetype struct { typ _type elem *_type } ... 其中对于类型的值是否相等，需要使用到成员alg *typeAlg(runtime/alg.go)，它则持有此类型值的hash与equal的算法，它也是一个结构体:
type typeAlg struct { // function for hashing objects of this type // (ptr to object, seed) -&amp;gt; hash hash func(unsafe.Pointer, uintptr) uintptr // function for comparing objects of this type // (ptr to object A, ptr to object B) -&amp;gt; ==? equal func(unsafe.Pointer, unsafe.Pointer) bool } runtime/alg.go中提供了各种基础的hash func与 equal func，例如：
func strhash(a unsafe.Pointer, h uintptr) uintptr { x := (*stringStruct)(a) return memhash(x.str, h, uintptr(x.len)) } func strequal(p, q unsafe.Pointer) bool { return *(*string)(p) == *(*string)(q) } 有了这些基础的hash func与 equal func，再复杂的结构体也可以按字段递归计算hash与相等比较了。那我们再来看一下，当访问map[key]时，其实现对应在runtime/hashmap.go中的mapaccess1函数:
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) // 1 m := uintptr(1)&amp;lt;&amp;lt;h.B - 1 b := (*bmap)(add(h.buckets, (hash&amp;amp;m)*uintptr(t.bucketsize))) // 2 ... top := uint8(hash &amp;gt;&amp;gt; (sys.PtrSize*8 - 8)) if top &amp;lt; minTopHash { top &#43;= minTopHash } for { for i := uintptr(0); i &amp;lt; bucketCnt; i&#43;&#43; { ... k := add(unsafe.Pointer(b), dataOffset&#43;i*uintptr(t.keysize)) if alg.equal(key, k) { // 3 v := add(unsafe.Pointer(b), dataOffset&#43;bucketCnt*uintptr(t.keysize)&#43;i*uintptr(t.valuesize)) ... return v } } ... } } mapaccess1的代码还是比较多的，简化逻辑如下（参考注释上序列）：
 调用key类型的hash方法，计算出key的hash值 根据hash值找到对应的桶bucket 在桶中找到key值相等的map的value。判断相等需调用key类型的equal方法  到现在我们也就有了初步了解，map中的key访问时同时需要使用该类型的hash func与 equal func，只要key值相等，当结构体即使不是同一对象，也可从map中获取相同的值，例如：
m := make(map[interface{}]interface{}) m[_key{}] = &amp;#34;value&amp;#34; if v, ok := m[_key{}];ok { fmt.Println(&amp;#34;%v&amp;#34;, v) // output: value }  参考：
[1] https://blog.golang.org/go-maps-in-action
[2] https://golang.org/ref/spec#Comparison_operators
</content>
    </entry>
    
     <entry>
        <title>Go VIM开发环境</title>
        <url>http://lanlingzi.cn/post/technical/2016/0903_vim/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>vim</tag>
        </tags>
        <content type="html"> 背景 个人最近一直使用VSCode&#43;Go插件来开发Go代码，虽然也觉得VSCode是目前最好用的Go的开发工具，但还是对VIM有点不可割舍，对我来说原因有三：
 VIM可以在控制台使用，适合远程登陆到Linux进行代码调试修改 配合Tmux使用，开启多个Pane各司其职，不同Pane之间快速切换 有Tagbar，团队内代码串讲，能先看出每个文件的大纲，代码跳转也非常方便  截图 第一张是自己截的，后两张是使用各插件官方的：
插件 我配置VIM主要用于Go语言开发，所以对VIM的配置是主要是集中于代码编写，Go语言的代码提示，格式化等。使用了如下主要插件:
Plugin &amp;#39;honza/vim-snippets&amp;#39; &amp;#34;快速插入代码片段snippets Plugin &amp;#39;scrooloose/nerdtree&amp;#39; &amp;#34;文件浏览，文件树目录 Plugin &amp;#39;scrooloose/nerdcommenter&amp;#39; &amp;#34;快速加减注释 Plugin &amp;#39;scrooloose/syntastic&amp;#39; &amp;#34;代码错误检测，其它应该也类似 Plugin &amp;#39;Xuyuanp/nerdtree-git-plugin&amp;#39; &amp;#34;Git插件 Plugin &amp;#39;majutsushi/tagbar&amp;#39; &amp;#34;标签列表 Plugin &amp;#39;kien/ctrlp.vim&amp;#39; &amp;#34;文件搜索,杀手级,重新定义了编辑器打开文件的方式 Plugin &amp;#39;vim-scripts/TaskList.vim&amp;#39; &amp;#34;快速跳转到TODO列表 Plugin &amp;#39;vim-scripts/SuperTab&amp;#39; &amp;#34;Tab代码提示 Plugin &amp;#39;fannheyward/rainbow_parentheses.vim&amp;#39; &amp;#34;括号匹配高亮 Plugin &amp;#39;tpope/vim-surround&amp;#39; &amp;#34;快速加环绕符 Plugin &amp;#39;tpope/vim-repeat&amp;#39; &amp;#34;配合使用增强版命令重复 Plugin &amp;#39;tpope/vim-sensible&amp;#39; &amp;#34;基本的Vim设置 Plugin &amp;#39;mhinz/vim-startify&amp;#39; &amp;#34;更改开始界面的插件 Plugin &amp;#39;fatih/vim-go&amp;#39; &amp;#34;GO语言 Plugin &amp;#39;bling/vim-airline&amp;#39; &amp;#34;状态栏 Plugin &amp;#39;junegunn/vim-easy-align&amp;#39; &amp;#34;方便的按分隔符对齐,比如=号 Plugin &amp;#39;ConradIrwin/vim-bracketed-paste&amp;#39; &amp;#34;插入模式下粘贴内容，不会有任何变形 :set paste Plugin &amp;#39;fholgado/minibufexpl.vim&amp;#39; &amp;#34;多文件切换，也可使用鼠标双击相应文件名进行切换 Plugin &amp;#39;SirVer/ultisnips&amp;#39; &amp;#34;宏定义补全 Plugin &amp;#39;Yggdroot/indentLine&amp;#39; &amp;#34;缩进虚线 Plugin &amp;#39;Shougo/neocomplete.vim&amp;#39; &amp;#34;自动补全 Plugin &amp;#39;Shougo/unite.vim&amp;#39; &amp;#34;文件或Buffer列表 Plugin &amp;#39;Lokaltog/vim-easymotion&amp;#39; &amp;#34;快速移动,杀手锏，跳转到光标后任意位置 Plugin &amp;#39;Raimondi/delimitMate&amp;#39; &amp;#34;自动括号补全  vim-go：已把Go的开发工具大包大揽了，非常省事。可以通过运行:GoInstallBinaries来自行安装 neocomplete.vim：非常轻量的基于缓存的代码补全，vim-go中已集成gocode来做代码联想，并能与neocomplete配合使用。 unite.vim：又一个神器，使用类似于SublimeText与VSCode的Go to xxx(快捷键:CMD&#43;P/Ctrl&#43;Shift&#43;P)功能，能快速列出最使用打开文件，当前目录下文件，Buffer列表等。 tagbar：标签列表，需要ctags，而Go的各元素能正常展示，则需要依赖于gotags，vim-go中已集成。  分享 个人的VIM的配置，已放入在Github上，若有需要的朋友尽管拿去使用，有问题欢迎反馈。
GitHub地址：https://github.com/xtfly/xvim
</content>
    </entry>
    
     <entry>
        <title>入园家长沟通会</title>
        <url>http://lanlingzi.cn/post/stories/2016/0829_kid_garden/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>育儿</tag><tag>家庭</tag>
        </tags>
        <content type="html"> 时间真是过得太快，转眼儿子要上幼儿园了。昨天是第一次参加儿子的入园家长沟通会。
上幼儿园的意义 上幼儿园是小孩步入社会第一步，是融入世界的起点。脱离原生家庭才能独立成长，幼儿园有孩子同龄的伙伴，可以让孩子收获不同的体验；幼儿园也有专业的老师，可以让孩子快乐自由的探索自己，认识朋友，体验世界。
我平时的工作都比较忙，基本都是早七晚九，白天小孩要么是跟他奶奶，要么是跟他外婆。还好他妈妈是小学老师，晚上能投入一些时间与他相处。大家居住环境比较封闭，邻里来往不多, 小孩基本都是呆在家里的时间居多。他对家的依赖比较多。虽他平时也会经常去他妈妈工作的小学玩，但还是在大家的完全监控下。养孩子的最终目的是为了看着他们独立，幼儿园是教孩子独立的第一步，也是教家长放手的第一步。
幼儿园与家长的关系 现在的媒体会经常报道一些幼儿园的老师是怎么不负责的，同时家长也不太可能放心让孩子在外面受丁点的苦。在幼儿园只要有些风吹草动，就会造成冲突。作为家长，先要信任，再及时沟通。
诚然，当今的社会的幼儿园也是一个趋利机构，在知识学习上急功近利，拔苗助长。我个人是不太在乎小孩在幼儿园是否能学到多少知识，而是关心他过得快不快乐。非常反感把小学生的学习任务强加到幼儿园孩子身上的做法，孩子的天性就是玩，在玩的过程得到性格、情感、心智的成长才重要。
爸爸妈妈永远是孩子最重要的人，哪怕这个世界真的有一所完美的幼儿园，也永远不要把所有责任都扔给幼儿园。毕竟，对爸爸妈妈来说，自己的孩子独一无二，对孩子来说，自己的爸爸妈妈也独一无二。
孩子上幼儿园并不是不需要再管孩子，而是更需要花更多的时间去侧面了解孩子，关心孩子，教育孩子。幼儿园是一个小社会，不同的小朋友来自不同的家庭。不同的家庭，有不同的价值观，不同的思维，不同的生活习惯。这些都会影响孩子的性格成长，生活习性。所以也需要家长投入更多的精力来关注孩子的成长。
家长如何做 小孩上幼儿园，小孩突然完全脱离了自己的控制，这尤其是对家长的一种考验。孩子的成长也需要家长一起成长，那家长如何做呢？总结起来，有五要，有五不要：
  五要：
  走路回家
  保持平静
  分享快乐
  主动沟通
  积极配合
  五不要：
  甜水等待
  刨根问底
  迁就放纵
  零食补偿
  偏信偏听
  </content>
    </entry>
    
     <entry>
        <title>Hexo NexT主题移植</title>
        <url>http://lanlingzi.cn/post/technical/2016/0828_hugo_next_theme/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>hugo</tag><tag>theme</tag>
        </tags>
        <content type="html"> 概述 我应该是一个喜欢折腾的技术党。从采用Hugo建静态blog以来，算上今天移植的这个，一共使用了三个主题：
第一个是修改自Hueman，它是一个Wordpress主题。第二个是修改自pacman，它是一个Hexo的主题。
这二个主题都是coderzh最早移植的，我只是在其上修改些布局，增加点功能，换个图片什么。这个过程让我弄清楚了Hugo中模板制作方法。
第三个则是从零开始，移植Github上人气最高的Hexo主题：NexT。正如你现在看到的，NexT是一款简洁又富有动感的主题，当前天我第一眼看到它时，就喜欢上它的风格。于是乎趁着周日，就开始NexT主题移植之旅。
功能  支持分类、标签索引 支持归档列表索引 支持分页栏 支持RSS 支持文章大纲（TOC） 支持分享，采用多说的分享 支持统计分析（目前支持百度统计，与REVOLEERMAPS） 支持评论系统（多说） 支持菜单定制 支持社区链接定制 支持外部链接定制 全配置化  分享 这个NexT主题是使用Hugo的模板语法，从零开始，经过差不多一天的时间折腾才完工。目前也应用到了我现在的这个Blog上，看起来还行:)。若有需要的朋友尽管拿去使用，有问题欢迎反馈。
GitHub地址：https://github.com/xtfly/hugo-theme-next
由于Hugo的模版引擎和Hexo有区别，部分Hexo的样式或功能暂时无法实现，它还没有像Hexo NexT那样能高度地配置定制。并且它也仅仅在自己的Blog简单测试过，可能并不一定完全适合您的定制，您可以根据需求调整。
注意 由于Hugo的.Summary只有70个字符，对于中文文章来说，实在是太短了，你可以在文档中任一地方增加&amp;lt;!--more--&amp;gt;来分割。
</content>
    </entry>
    
     <entry>
        <title>Go测试</title>
        <url>http://lanlingzi.cn/post/technical/2016/0824_go_testing/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go语言内置了测试框架，编写单元测试非常方便。
命名约定   测试代码位于以_test.go结尾的源文件中，一般与源码在同一个package中。
位于同一个package中的主要原因是：测试可以访问package中不可导出的变量，方法等元素。
  测试源码可以修改package名，带上_test结尾
修改的package名称，不需要再单独新建立目录，也与源码在一个目录下。参考标准库的bytes中的测试代码，方便使用被测试的元素，可以采用.来import测试的package：
package bytes_test import ( . &amp;#34;bytes&amp;#34; &amp;#34;io&amp;#34; ... )     以Test开头的功能测试函数
  以Benchmark开头的性能测试函数
  以Example开头的样例代码
func ExampleHello() { hl := hello() fmt.Println(hl) // Output: hello. } 示例函数无需接收参数，但需要使用注释的Output: 标记说明示例函数的输出值，未指定Output: 标记或输出值为空的示例函数不会被执行。go doc 工具会解析示例函数的函数体作为对应__包/函数/类型/类型方法__的用法。
示例函数需要归属于某个__包/函数/类型/类型的方法__，具体命名规则如下：
func Example() { ... } // 包的示例函数 func ExampleF() { ... } // 函数F的示例函数 func ExampleT() { ... } // 类型T的示例函数 func ExampleT_M() { ... } // 类型T的M方法的示例函数 // 多示例函数 需要跟下划线加小写字母开头的后缀 func Example_suffix() { ... } func ExampleF_suffix() { ... } func ExampleT_suffix() { ... } func ExampleT_M_suffix() { ... }   测试类型 功能测试 功能测试函数以*testing.T类型为单一参数t，testing.T类型用来管理测试状态和格式化测试日志。测试日志在测试执行过程中积累，完成后输出到标准错误输出。
常用方法:
  测试预期不符，使用t.Error()或t.Errorf()记录日志并标记测试失败
func TestToTitle(t *testing.T) { for _, tt := range ToTitleTests { if s := string(ToTitle([]byte(tt.in))); s != tt.out { t.Errorf(&amp;#34;ToTitle(%q) = %q, want %q&amp;#34;, tt.in, s, tt.out) } } }   测试预期不符，使用t.Fatal()和t.Fatalf()跳出该测试函数
func TestUnreadByte(t *testing.T) { b := new(Buffer) b.WriteString(&amp;#34;abcdefghijklmnopqrstuvwxyz&amp;#34;) _, err := b.ReadBytes(&amp;#39;m&amp;#39;) if err != nil { t.Fatalf(&amp;#34;ReadBytes: %v&amp;#34;, err) } ... }   记录日志， 使用t.Log()和t.Logf()
func TestFowler(t *testing.T) { files, err := filepath.Glob(&amp;#34;testdata/*.dat&amp;#34;) if err != nil { t.Fatal(err) } for _, file := range files { t.Log(file) testFowler(t, file) } }   跳过某条测试用例，使用t.Skip()和t.Skipf()
func TestZip64(t *testing.T) { if testing.Short() { t.Skip(&amp;#34;slow test; skipping&amp;#34;) } const size = 1 &amp;lt;&amp;lt; 32 // before the &amp;#34;END\n&amp;#34; part buf := testZip64(t, size) testZip64DirectoryRecordLength(buf, t) }   并发执行测试用例，使用t.Parallel()标记
func TestStackGrowth(t *testing.T) { t.Parallel() var wg sync.WaitGroup // in a normal goroutine wg.Add(1) go func() { defer wg.Done() growStack() }() wg.Wait() ... }   性能测试 性能测试函数以接收*testing.B类型为单一参数b，性能测试函数中需要循环b.N次调用被测函数。testing.B类型用来管理测试时间和迭代运行次数，也支持和testing.T相同的方式管理测试状态和格式化测试日志，不一样的是testing.B的日志总是会输出。
  启用内存使用分析，使用t.ReportAllocs()
func BenchmarkWriterFlush(b *testing.B) { b.ReportAllocs() bw := NewWriter(ioutil.Discard) str := strings.Repeat(&amp;#34;x&amp;#34;, 50) for i := 0; i &amp;lt; b.N; i&#43;&#43; { bw.WriteString(str) bw.Flush() } }   停止/重置/启动时间计值，使用b.StopTimer()、b.ResetTimer()、b.StartTimer()
func BenchmarkScanInts(b *testing.B) { b.ResetTimer() ints := makeInts(intCount) var r RecursiveInt for i := b.N - 1; i &amp;gt;= 0; i-- { buf := bytes.NewBuffer(ints) b.StartTimer() scanInts(&amp;amp;r, buf) b.StopTimer() } }   记录在一个操作中处理的字节数，使用b.SetBytes()
func BenchmarkFields(b *testing.B) { b.SetBytes(int64(len(fieldsInput))) for i := 0; i &amp;lt; b.N; i&#43;&#43; { Fields(fieldsInput) } }   并发执行被测对象，使用b.RunParallel()和*testing.PB类型的Next()
func BenchmarkValueRead(b *testing.B) { var v Value v.Store(new(int)) b.RunParallel(func(pb *testing.PB) { for pb.Next() { x := v.Load().(*int) if *x != 0 { b.Fatalf(&amp;#34;wrong value: got %v, want 0&amp;#34;, *x) } } }) }   测试执行  在某一包下执行测试: go test 执行指定的包测试: go test $pkg_in_gopath 执行某一目录下以及子目录下所有测试: go test $pkg_in_gopath/... 执行包下某一些用例: go test -run=xxx，-run参数支持使用正则表达式来匹配要执行的功能测试函数名 执行包下性能测试: go test -bench=. 查看性能测试时的内存情况: go test -bench=. -benchmem 查看每个函数的执行结果: go test -v 查看覆盖率: go test -cover 输出覆盖率到文件: 增加参数-coverprofile，并使用go tool cover来查看，用法请参考go tool cover -help  测试工具 IO测试 testing/iotest包中实现了常用的出错的Reader和Writer:
 触发数据错误dataErrReader，通过DataErrReader()函数创建 读取一半内容的halfReader，通过HalfReader()函数创建 读取一个byte的oneByteReader，通过OneByteReader()函数创建 触发超时错误的timeoutReader，通过TimeoutReader()函数创建 写入指定位数内容后停止的truncateWriter，通过TruncateWriter()函数创建 读取时记录日志的readLogger，通过NewReadLogger()函数创建 写入时记录日志的writeLogger，通过NewWriteLogger()函数创建  HTTP测试 net/http/httptest包提供了HTTP相关代码的测试工具
 httptest.Server用来构建临时的Server，测试发送与接收HTTP请求 httptest.ResponseRecorder用来记录应答  黑盒测试 testing/quick包实现了帮助黑盒测试
  Check函数，测试的只返回bool值的黑盒函数f，Check会为f的每个参数设置任意值并多次调用
func TestOddMultipleOfThree(t *testing.T) { f := func(x int) bool { y := OddMultipleOfThree(x) return y%2 == 1 &amp;amp;&amp;amp; y%3 == 0 } if err := quick.Check(f, nil); err != nil { t.Error(err) } }   CheckEqual函数，比较给定的两个黑盒函数是否相等
func CheckEqual(f, g interface{}, config *Config) (err error)   测试框架 stretchr/testify是个人觉得目前最好的测试框架，相比标准库中testing包支持如下特性：
 Easy assertions Mocking HTTP response trapping Testing suite interfaces and functions   参考：
[1] https://golang.org/pkg/testing
[2] https://golang.org/pkg/testing/iotest
[3] https://golang.org/pkg/testing/quick
[4] https://golang.org/pkg/net/http/httptest
[5] https://github.com/stretchr/testify
</content>
    </entry>
    
     <entry>
        <title>Goroutine Local Storage</title>
        <url>http://lanlingzi.cn/post/technical/2016/0813_go_gls/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 背景 最近在设计调用链与日志跟踪的API，发现相比于Java与C&#43;&#43;，Go语言中没有原生的线程（协程）上下文，也不支持TLS（Thread Local Storage），更没有暴露API获取Goroutine的Id（后面简称GoId）。这导致无法像Java一样，把一些信息放在TLS上，用于来简化上层应用的API使用：不需要在调用栈的函数中通过传递参数来传递调用链与日志跟踪的一些上下文信息。
在Java与C&#43;&#43;中，TLS是一种机制，指存储在线程环境内的一个结构，用来存放该线程内独享的数据。进程内的线程不能访问不属于自己的TLS，这就保证了TLS内的数据在线程内是全局共享的，而对于线程外却是不可见的。
在Java中，JDK库提供Thread.CurrentThread()来获取当前线程对象，提供ThreadLocal来存储与获取线程局部变量。由于Java能通过Thread.CurrentThread()获取当前线程，其实现的思路就很简单了，在ThreadLocal类中有一个Map，用于存储每一个线程的变量。
ThreadLocal的API提供了如下的4个方法：
public T get() protected T initialValue() public void remove() public void set(T value)  T get():返回此线程局部变量的当前线程副本中的值，如果这是线程第一次调用该方法，则创建并初始化此副本。 protected T initialValue(): 返回此线程局部变量的当前线程的初始值。最多在每次访问线程来获得每个线程局部变量时调用此方法一次，即线程第一次使用get()方法访问变量的时候。如果线程先于get方法调用set(T)方法，则不会在线程中再调用initialValue方法。 void remove(): 移除此线程局部变量的值。这可能有助于减少线程局部变量的存储需求。如果再次访问此线程局部变量，那么在默认情况下它将拥有其 initialValue。 void set(T value)将此线程局部变量的当前线程副本中的值设置为指定值。许多应用程序不需要这项功能，它们只依赖于initialValue()方法来设置线程局部变量的值。  在Go语言中，而Google提供的解决方法是采用golang.org/x/net/context包来传递GoRoutine的上下文。对Go的Context的深入了解可参考我之前的分析：理解Go Context机制。Context也是能存储Goroutine一些数据达到共享，但它提供的接口是WithValue函数来创建一个新的Context对象。
func WithValue(parent Context, key interface{}, val interface{}) Context { return &amp;amp;valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } return c.Context.Value(key) } 从上面代码中可以看出，Context设置一次Value，就会产生一个Context对象，获取Value是先找当前Context存储的值，若没有再向父一级查找。获取Value可以说是多Goroutine访问安全，因为它的接口设计上，是只一个Goroutine一次设置Key/Value，其它多Goroutine只能读取Key的Value。
为什么无获取GoId接口  This, among other reasons, to prevent programmers for simulating thread local storage using the goroutine id as a key.
 官方说，就为了避免采用Goroutine Id当成Thread Local Storage的Key。
 Please don’t use goroutine local storage. It’s highly discouraged. In fact, IIRC, we used to expose Goid, but it is hidden since we don’t want people to do this.
 用户经常使用GoId来实现goroutine local storage，而Go语言不希望用户使用goroutine local storage。
 when goroutine goes away, its goroutine local storage won’t be GCed. (you can get goid for the current goroutine, but you can’t get a list of all running goroutines)
 不建议使用goroutine local storage的原因是由于不容易GC，虽然能获当前的GoId，但不能获取其它正在运行的Goroutine。
 what if handler spawns goroutine itself? the new goroutine suddenly loses access to your goroutine local storage. You can guarantee that your own code won’t spawn other goroutines, but in general you can’t make sure the standard library or any 3rd party code won’t do that.
 另一个重要的原因是由于产生一个Goroutine非常地容易（而线程通用会采用线程池），新产生的Goroutine会失去访问goroutine local storage。需要上层应用保证不会产生新的Goroutine，但我们很难确保标准库或第三库不会这样做。
 thread local storage is invented to help reuse bad/legacy code that assumes global state, Go doesn’t have legacy code like that, and you really should design your code so that state is passed explicitly and not as global (e.g. resort to goroutine local storage)
 TLS的应用是帮助重用现有那些不好（遗留）的采用全局状态的代码。而Go语言建议是重新设计代码，采用显示地传递状态而不是采用全局状态（例如采用goroutine local storage）。
其它手段获取GoId 虽然Go语言有意识地隐藏GoId，但目前还是有手段来获取GoId：
  修改源代码暴露GoId，但Go语言可能随时修改源码，导致不兼容
在标准库的runtime/proc.go（Go 1.6.3）中的newextram函数，会产生个GoId：
mp.lockedg = gp gp.lockedm = mp gp.goid = int64(atomic.Xadd64(&amp;amp;sched.goidgen, 1))   通过runtime.Stack来分析Stack输出信息获取GoId。
在标准库的runtime/mprof.go（Go 1.6.3）中，runtime.Stack会获取gp对象(包含GoId)并输出整个Stack信息：
func Stack(buf []byte, all bool) int { if all { stopTheWorld(&amp;#34;stack trace&amp;#34;) } n := 0 if len(buf) &amp;gt; 0 { gp := getg() sp := getcallersp(unsafe.Pointer(&amp;amp;buf)) pc := getcallerpc(unsafe.Pointer(&amp;amp;buf)) systemstack(func() { g0 := getg() g0.m.traceback = 1 g0.writebuf = buf[0:0:len(buf)] goroutineheader(gp) traceback(pc, sp, 0, gp) if all { tracebackothers(gp) } g0.m.traceback = 0 n = len(g0.writebuf) g0.writebuf = nil }) } if all { startTheWorld() } return n } 从文件名就可以看出，runtime/mprof.go是用于做Profile分析，获取Stack肯定性能不会太好。从上面的代码来看，若第二个参数指定为true，还会STW，业务系统无论如何都无法接受。若Go语言修改了Stack的输出，分析Stack信息也会导致无法正常获取GoId。
  通用runtime.Callers来给调用Stack来打标签
代码参考：https://github.com/jtolds/gls/blob/master/stack_tags_main.go#L43
  通过内联c或者内联汇编
go版本1.5，x86_64arc下汇编，估计也不通用
// func GoID() int64 TEXT s3lib GoID(SB),NOSPLIT,$0-8 MOVQ TLS, CX MOVQ 0(CX)(TLS*1), AX MOVQ AX, ret&#43;0(FP) RET   开源goroutine local storage实现 只要有机制获取GoId，就可以像Java一样来采用全局的map实现goroutine local storage，在Github上搜索一下，发现有两个：
  tylerb/gls
GoId是通过runtime.Stack来分析Stack输出信息获取GoId。
  jtolds/gls
GoId是通用runtime.Callers来给调用Stack来打标签
  第二个有人在2013年测试过性能，数据如下：
 BenchmarkGetValue 500000 2953 ns/op
BenchmarkSetValues 500000 4050 ns/op
 上面的测试结果看似还不错，但goroutine local storage实现无外乎是map&#43;RWMutex，存在性能瓶颈：
 Goroutine不像Thread，它的个数可以上十万并发，当这么多的Goroutine同时竞争同一把锁时，性能会急剧恶化。 GoId是通过分析调用Stack的信息来获取，也是一个高成本的调用，一个字：慢。  不管怎么样，没有官方的GLS，的确不是很方便，第三方实现又存在性能与不兼容风险。连jtolds/gls作者也贴出其它人的评价：
 &amp;ldquo;Wow, that&amp;rsquo;s horrifying.&amp;rdquo;
&amp;ldquo;This is the most terrible thing I have seen in a very long time.&amp;rdquo;
&amp;ldquo;Where is it getting a context from? Is this serializing all the requests? What the heck is the client being bound to? What are these tags? Why does he need callers? Oh god no. No no no.&amp;rdquo;
 小结 Go语言官方认为TLS来存储全局状态是不好的设计，而是要显示地传递状态。Google给的解决方法是golang.org/x/net/context。
 参考：
[1] golang-nuts
[2] go-nuts-re-goroutine-local-storage-implementation
[3] jtolds/gls
[4] tylerb/gls
[5] 在golang中如何优雅地获取goroutineID？
</content>
    </entry>
    
     <entry>
        <title>理解Go Interface</title>
        <url>http://lanlingzi.cn/post/technical/2016/0803_go_interface/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 概述 Go语言中的接口很特别，而且提供了难以置信的一系列灵活性和抽象性。接口是一个自定义类型，它是一组方法的集合，要有方法为接口类型就被认为是该接口。从定义上来看，接口有两个特点:
 接口本质是一种自定义类型，因此不要将Go语言中的接口简单理解为C&#43;&#43;/Java中的接口，后者仅用于声明方法签名。 接口是一种特殊的自定义类型，其中没有数据成员，只有方法（也可以为空）。  接口是完全抽象的，因此不能将其实例化。然而，可以创建一个其类型为接口的变量，它可以被赋值为任何满足该接口类型的实际类型的值。接口的重要特性是：
 只要某个类型实现了接口所有的方法，那么我们就说该类型实现了此接口。该类型的值可以赋给该接口的值。 作为1的推论，任何类型的值都可以赋值给空接口interface{}。  接口的特性是Go语言支持鸭子类型的基础，即“如果它走起来像鸭子，叫起来像鸭子（实现了接口要的方法），它就是一只鸭子（可以被赋值给接口的值）”。凭借接口机制和鸭子类型，Go语言提供了一种有利于类、继承、模板之外的更加灵活强大的选择。只要类型T的公开方法完全满足接口I的要求，就可以把类型T的对象用在需要接口I的地方。这种做法的学名叫做&amp;rdquo;Structural Typing&amp;quot;。
方法 Go语言中同时有函数和方法。一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。所有给定类型的方法属于该类型的方法集。
type User struct { Name string Email string } func (u User) Notify() error // User 类型的值可以调用接受者是值的方法 damon := User{&amp;#34;AriesDevil&amp;#34;, &amp;#34;ariesdevil@xxoo.com&amp;#34;} damon.Notify() // User 类型的指针同样可以调用接受者是值的方法 alimon := &amp;amp;User{&amp;#34;A-limon&amp;#34;, &amp;#34;alimon@ooxx.com&amp;#34;} alimon.Notify() User的结构体类型，定义了一个该类型的方法叫做Notify，该方法的接受者是一个User类型的值。要调用Notify方法我们需要一个 User类型的值或者指针。Go调用和解引用指针使得调用可以被执行。注意，当接受者不是一个指针时，该方法操作对应接受者的值的副本(意思就是即使你使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作，而不是指针操作。
我们可以修改Notify方法，让它的接受者使用指针类型：
func (u *User) Notify() error 再来一次之前的调用(注意：当接受者是指针时，即使用值类型调用那么函数内部也是对指针的操作。
总结：
 一个结构体的方法的接收者可能是类型值或指针 如果接收者是值，无论调用者是类型值还是类型指针，修改都是值的副本 如果接收者是指针，则调用者修改的是指针指向的值本身。  接口实现 type Notifier interface { Notify() error } func SendNotification(notify Notifier) error { return notify.Notify() } unc (u *User) Notify() error { log.Printf(&amp;#34;User: Sending User Email To %s&amp;lt;%s&amp;gt;\n&amp;#34;, u.Name, u.Email) return nil } func main() { user := User{ Name: &amp;#34;AriesDevil&amp;#34;, Email: &amp;#34;ariesdevil@xxoo.com&amp;#34;, } SendNotification(user) } // Output: cannot use user (type User) as type Notifier in function argument: User does not implement Notifier (Notify method has pointer receiver) 上述代码是编译不过的，见Output，编译错误关键信息Notify method has pointer receiver。 编译器不考虑我们的值是实现该接口的类型，接口的调用规则是建立在这些方法的接受者和接口如何被调用的基础上。下面的是语言规范里定义的规则，这些规则用来说明是否我们一个类型的值或者指针实现了该接口：
 类型 *T 的可调用方法集包含接受者为 *T 或 T 的所有方法集 类型 T 的可调用方法集包含接受者为 T 的所有方法 类型 T 的可调用方法集不包含接受者为 *T 的方法  也就是说：
 接收者是指针 *T 时，接口的实例必须是指针 接收者是值 T 时，接口的实例可以是指针也可以是值  空接口与nil 空接口(interface{})不包含任何的method，正因为如此，所有的类型都实现了interface{}。interface{}对于描述起不到任何的作用(因为它不包含任何的method），但是interface{}在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。它有点类似于C语言的void*类型。
Go语言中的nil在概念上和其它语言的null、None、nil、NULL一样，都指代零值或空值。nil是预先说明的标识符，也即通常意义上的关键字。nil只能赋值给指针、channel、func、interface、map或slice类型的变量。如果未遵循这个规则，则会引发panic。
在底层，interface作为两个成员来实现，一个类型(type)和一个值(data)。参考官方文档翻译Go中error类型的nil值和nil。
import ( &amp;#34;fmt&amp;#34; &amp;#34;reflect&amp;#34; ) func main() { var val interface{} = int64(58) fmt.Println(reflect.TypeOf(val)) val = 50 fmt.Println(reflect.TypeOf(val)) } type用于存储变量的动态类型，data用于存储变量的具体数据。在上面的例子中，第一条打印语句输出的是：int64。这是因为已经显示的将类型为int64的数据58赋值给了interface类型的变量val，所以val的底层结构应该是：(int64, 58)。我们暂且用这种二元组的方式来描述，二元组的第一个成员为type，第二个成员为data。第二条打印语句输出的是：int。这是因为字面量的整数在golang中默认的类型是int，所以这个时候val的底层结构就变成了：(int, 50)。
func main() { var val interface{} = nil if val == nil { fmt.Println(&amp;#34;val is nil&amp;#34;) } else { fmt.Println(&amp;#34;val is not nil&amp;#34;) } } 变量val是interface类型，它的底层结构必然是(type, data)。由于nil是untyped(无类型)，而又将nil赋值给了变量val，所以val实际上存储的是(nil, nil)。因此很容易就知道val和nil的相等比较是为true的。
进一步验证：
func main() { var val interface{} = (*interface{})(nil) if val == nil { fmt.Println(&amp;#34;val is nil&amp;#34;) } else { fmt.Println(&amp;#34;val is not nil&amp;#34;) } } (*interface{})(nil)是将nil转成interface类型的指针，其实得到的结果仅仅是空接口类型指针并且它指向无效的地址。也就是空接口类型指针而不是空指针，这两者的区别蛮大的。
对于(*int)(nil)、(*byte)(nil)等等来说是一样的。上面的代码定义了接口指针类型变量val，它指向无效的地址(0x0)，因此val持有无效的数据。但它是有类型的(*interface{})。所以val的底层结构应该是：(*interface{}, nil)。
有时候您会看到(*interface{})(nil)的应用，比如var ptrIface = (*interface{})(nil)，如果您接下来将ptrIface指向其它类型的指针，将通不过编译。或者您这样赋值：*ptrIface = 123，那样的话编译是通过了，但在运行时还是会panic的，这是因为ptrIface指向的是无效的内存地址。其实声明类似ptrIface这样的变量，是因为使用者只是关心指针的类型，而忽略它存储的值是什么。
小结: 无论该指针的值是什么：(*interface{}, nil)，这样的接口值总是非nil的，即使在该指针的内部为nil。
接口变量存储的类型 接口的变量里面可以存储任意类型的数值(该类型实现了某interface)。那么我们怎么反向知道这个变量里面实际保存了的是哪个类型的对象呢？目前常用的有两种方法：
  comma-ok断言
value, ok = element.(T)，这里value就是变量的值，ok是一个bool类型，element是interface变量，T是断言的类型。如果element里面确实存储了T类型的数值，那么ok返回true，否则返回false。
  switch测试
switch value := element.(type) { case int: fmt.Printf(&amp;#34;list[%d] is an int and its value is %d\n&amp;#34;, index, value) case string: fmt.Printf(&amp;#34;list[%d] is a string and its value is %s\n&amp;#34;, index, value) ... element.(type)语法不能在switch外的任何逻辑里面使用，如果你要在switch外面判断一个类型就使用comma-ok。
  接口与反射 反射是程序运行时检查其所拥有的结构，尤其是类型的一种能力。Go语言也提供对反射的支持。
在前面的interface{}与nil的底层实现已提到，在reflect包中有两个类型需要了解：Type和Value。这两个类型使得可以访问接口变量的内容，还有两个简单的函数，reflect.TypeOf和reflect.ValueOf，从接口值中分别获取reflect.Type 和reflect.Value。
如同物理中的反射，在Go语言中的反射也存在它自己的镜像。从reflect.Value可以使用Interface方法还原接口值:
var x float64 = 3.4 v := reflect.ValueOf(x) // Interface 以 interface{} 返回 v 的值。 // func (v Value) Interface() interface{} // y 将为类型 float64 y := v.Interface().(float64) fmt.Println(y)  声明：本文是收集网上一些关于Go语言中接口(interface)的说明，是一篇学习笔记，文中多处引用，参考文章列表在最后，可直接访问了解详情。
参考：
[1] Go 语言中的方法，接口和嵌入类型
[2] 详解interface和nil
[3] Go语言interface详解
</content>
    </entry>
    
     <entry>
        <title>理解Go Context机制</title>
        <url>http://lanlingzi.cn/post/technical/2016/0802_go_context/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 什么是Context 最近在公司分析gRPC源码，proto文件生成的代码，接口函数第一个参数统一是ctx context.Context接口，公司不少同事都不了解这样设计的出发点是什么，其实我也不了解其背后的原理。今天趁着妮妲台风妹子正面登陆深圳，全市停工、停课、停业，在家休息找了一些资料研究把玩一把。
Context通常被译作上下文，它是一个比较抽象的概念。在公司技术讨论时也经常会提到上下文。一般理解为程序单元的一个运行状态、现场、快照，而翻译中上下又很好地诠释了其本质，上下上下则是存在上下层的传递，上会把内容传递给下。在Go语言中，程序单元也就指的是Goroutine。
每个Goroutine在执行之前，都要先知道程序当前的执行状态，通常将这些执行状态封装在一个Context变量中，传递给要执行的Goroutine中。上下文则几乎已经成为传递与请求同生存周期变量的标准方法。在网络编程下，当接收到一个网络请求Request，处理Request时，我们可能需要开启不同的Goroutine来获取数据与逻辑处理，即一个请求Request，会在多个Goroutine中处理。而这些Goroutine可能需要共享Request的一些信息；同时当Request被取消或者超时的时候，所有从这个Request创建的所有Goroutine也应该被结束。
context包 Go的设计者早考虑多个Goroutine共享数据，以及多Goroutine管理机制。Context介绍请参考Go Concurrency Patterns: Context，golang.org/x/net/context包就是这种机制的实现。
context包不仅实现了在程序单元之间共享状态变量的方法，同时能通过简单的方法，使我们在被调用程序单元的外部，通过设置ctx变量值，将过期或撤销这些信号传递给被调用的程序单元。在网络编程中，若存在A调用B的API, B再调用C的API，若A调用B取消，那也要取消B调用C，通过在A,B,C的API调用之间传递Context，以及判断其状态，就能解决此问题，这是为什么gRPC的接口中带上ctx context.Context参数的原因之一。
Go1.7(当前是RC2版本)已将原来的golang.org/x/net/context包挪入了标准库中，放在$GOROOT/src/context下面。标准库中net、net/http、os/exec都用到了context。同时为了考虑兼容，在原golang.org/x/net/context包下存在两个文件，go17.go是调用标准库的context包，而pre_go17.go则是之前的默认实现，其介绍请参考go程序包源码解读。
context包的核心就是Context接口，其定义如下：
type Context interface { Deadline() (deadline time.Time, ok bool) Done() &amp;lt;-chan struct{} Err() error Value(key interface{}) interface{} }   Deadline会返回一个超时时间，Goroutine获得了超时时间后，例如可以对某些io操作设定超时时间。
  Done方法返回一个信道（channel），当Context被撤销或过期时，该信道是关闭的，即它是一个表示Context是否已关闭的信号。
  当Done信道关闭后，Err方法表明Context被撤的原因。
  Value可以让Goroutine共享一些数据，当然获得数据是协程安全的。但使用这些数据的时候要注意同步，比如返回了一个map，而这个map的读写则要加锁。
  Context接口没有提供方法来设置其值和过期时间，也没有提供方法直接将其自身撤销。也就是说，Context不能改变和撤销其自身。那么该怎么通过Context传递改变后的状态呢？
context使用 无论是Goroutine，他们的创建和调用关系总是像层层调用进行的，就像人的辈分一样，而更靠顶部的Goroutine应有办法主动关闭其下属的Goroutine的执行（不然程序可能就失控了）。为了实现这种关系，Context结构也应该像一棵树，叶子节点须总是由根节点衍生出来的。
要创建Context树，第一步就是要得到根节点，context.Background函数的返回值就是根节点：
func Background() Context 该函数返回空的Context，该Context一般由接收请求的第一个Goroutine创建，是与进入请求对应的Context根节点，它不能被取消、没有值、也没有过期时间。它常常作为处理Request的顶层context存在。
有了根节点，又该怎么创建其它的子节点，孙节点呢？context包为我们提供了多个函数来创建他们：
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) func WithValue(parent Context, key interface{}, val interface{}) Context 函数都接收一个Context类型的参数parent，并返回一个Context类型的值，这样就层层创建出不同的节点。子节点是从复制父节点得到的，并且根据接收参数设定子节点的一些状态值，接着就可以将子节点传递给下层的Goroutine了。
再回到之前的问题：该怎么通过Context传递改变后的状态呢？使用Context的Goroutine无法取消某个操作，其实这也是符合常理的，因为这些Goroutine是被某个父Goroutine创建的，而理应只有父Goroutine可以取消操作。在父Goroutine中可以通过WithCancel方法获得一个cancel方法，从而获得cancel的权利。
第一个WithCancel函数，它是将父节点复制到子节点，并且还返回一个额外的CancelFunc函数类型变量，该函数类型的定义为：
type CancelFunc func() 调用CancelFunc对象将撤销对应的Context对象，这就是主动撤销Context的方法。在父节点的Context所对应的环境中，通过WithCancel函数不仅可创建子节点的Context，同时也获得了该节点Context的控制权，一旦执行该函数，则该节点Context就结束了，则子节点需要类似如下代码来判断是否已结束，并退出该Goroutine：
select { case &amp;lt;-cxt.Done(): // do some clean... } WithDeadline函数的作用也差不多，它返回的Context类型值同样是parent的副本，但其过期时间由deadline和parent的过期时间共同决定。当parent的过期时间早于传入的deadline时间时，返回的过期时间应与parent相同。父节点过期时，其所有的子孙节点必须同时关闭；反之，返回的父节点的过期时间则为deadline。
WithTimeout函数与WithDeadline类似，只不过它传入的是从现在开始Context剩余的生命时长。他们都同样也都返回了所创建的子Context的控制权，一个CancelFunc类型的函数变量。
当顶层的Request请求函数结束后，我们就可以cancel掉某个context，从而层层Goroutine根据判断cxt.Done()来结束。
WithValue函数，它返回parent的一个副本，调用该副本的Value(key)方法将得到val。这样我们不光将根节点原有的值保留了，还在子孙节点中加入了新的值，注意若存在Key相同，则会被覆盖。
小结 context包通过构建树型关系的Context，来达到上一层Goroutine能对传递给下一层Goroutine的控制。对于处理一个Request请求操作，需要采用context来层层控制Goroutine，以及传递一些变量来共享。
  Context对象的生存周期一般仅为一个请求的处理周期。即针对一个请求创建一个Context变量（它为Context树结构的根）；在请求处理结束后，撤销此ctx变量，释放资源。
  每次创建一个Goroutine，要么将原有的Context传递给Goroutine，要么创建一个子Context并传递给Goroutine。
  Context能灵活地存储不同类型、不同数目的值，并且使多个Goroutine安全地读写其中的值。
  当通过父Context对象创建子Context对象时，可同时获得子Context的一个撤销函数，这样父Context对象的创建环境就获得了对子Context将要被传递到的Goroutine的撤销权。
  在子Context被传递到的goroutine中，应该对该子Context的Done信道（channel）进行监控，一旦该信道被关闭（即上层运行环境撤销了本goroutine的执行），应主动终止对当前请求信息的处理，释放资源并返回。
  使用原则 Programs that use Contexts should follow these rules to keep interfaces consistent across packages and enable static analysis tools to check context propagation:
使用Context的程序包需要遵循如下的原则来满足接口的一致性以及便于静态分析。
  Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. The Context should be the first parameter, typically named ctx；不要把Context存在一个结构体当中，显式地传入函数。Context变量需要作为第一个参数使用，一般命名为ctx；
  Do not pass a nil Context, even if a function permits it. Pass context.TODO if you are unsure about which Context to use；即使方法允许，也不要传入一个nil的Context，如果你不确定你要用什么Context的时候传一个context.TODO；
  Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions；使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数；
  The same Context may be passed to functions running in different goroutines; Contexts are safe for simultaneous use by multiple goroutines；同样的Context可以用来传递到不同的goroutine中，Context在多个goroutine中是安全的；
   参考：
[1] https://blog.golang.org/context
[2] http://blog.golang.org/pipelines
[3] http://studygolang.com/articles/5131
[4] http://blog.csdn.net/sryan/article/details/51969129
[5] https://peter.bourgon.org/blog/2016/07/11/context.html
[6] http://www.tuicool.com/articles/vaieAbQ
</content>
    </entry>
    
     <entry>
        <title>为什么是Go</title>
        <url>http://lanlingzi.cn/post/technical/2016/0723_why_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>cloud</tag>
        </tags>
        <content type="html"> HW的执行力就是强，推广Go也是雷力风行，几乎目前是全员皆Go。作为一名其中的参与者，也知目前Go若大规模应用还是有很多的不成熟，风险也非常大。那为什么我司还是选择Go？也来谈谈我个人对为什么选择Go的认识，仅是个人拙见，不代表我司官方的观点。
背景 Go语言主创人员之是C语言与Linux的发明人，所以Go的语法在C的基础之上取众家之精华：
 主要继承了C(func, struct，指针) 包管理吸取自Java（package, import） 多态吸取自Python与Ruby(duck type) 并发吸取自Limbo(CSP模型)。  同时是一种多范式的编程语言，集众多编程范式之所长，并以自己独到的方式将它们融合在一起：
 面向过程（if，switch，for&amp;hellip;) 面向对象（部分支持）：封装（struct），继承（匿名组合），多态（隐式Interface，即duck type） 函数式（部分支持）：闭包，函数作为参数（入参，返回值）  Go语言打的组合拳:
 简单易用 vs Python 机器码性能 vs C/C&#43;&#43; 跨平台/标准库 vs Java 并发模型（goroutine/channel）vs Erlang 异步网络 vs Scala/Node.js 动态反射 vs Java 垃圾回收 vs Java  Go语言可能不是每一条都是No.1，但却是目前同时具备上述全部7点特性唯一语言，看似平衡中庸的组合拳往往威力强大。
而我司主要开发语言是C/C&#43;&#43;，Java，Python，可以说是若应用Go语言具有广泛的群众基础，同时Go语言兼具他们各自的一些优点，在不同的场景下，能一定的范围内可以代替他们。并且我司的程序员大多较底级，Go语言的简洁与工程化能可能大大提升产品研发效率与降低维护成本。
云计算 我司原是一个设备制造厂商，而不是一个软件开发厂商。但是云计算已正快速改变原有的生态，当软件定义一切，尤其是云计算的全面渗透，计算资源统一X86化。即使传统的网络设备也将网络功能虚拟化（NFV）。NFV化是趋势，若拒绝将是失去未来；只有及时拥抱，才能不被抛弃。
虚拟化/容器化显著的特点：
  不再依赖于专用硬件，跨平台跨硬件混合部署：
如传统的网卡直通，CPU绑定，内核零拷贝将在云计算下无法再发挥优势。而Go语言相比于C/C&#43;&#43;天生跨平台，引入内置Runtime，通过它来隔离与不同的系统调用。这让程序迁移到不同的OS或CPU架构成本非常低，程序只需要重新在目标平台上编译而已。
  物理资源更细粒度的分割，提高整体资源利用率：
Go语言相比于Java，在CPU、内存与磁盘大小占用方面相对比较低。尤其当前Docker等容器技术的兴起，细粒度的资源隔离。Go语言相比于Java动则上G的内存占用情况下，在资源上可能通过细粒度逻辑分割而达到充分灵活共享；而Go语言内置并发机制，并且Goroutine调度机制在设计上就充分考虑利用多核，让编写多核并发的程序变得更加的容易。
  快速上线开发与部署，缩短上线周期：
Go语言设计的一个主要目的是降代程序员的心智负担，设计哲学是大道至简，所以一开始就在可读性、模块化、编译速度、适合大型团队（工程优化）和语法简洁上下足了功夫。Go语言相比于Java与C/C&#43;&#43;，开发更简洁；内置丰富的标准库也能有效降低代码量。Go程序默认也是编译只是单个文件，减少了部署态的第三方依赖，这让应用上线部署非常容易。
  快速伸缩，故障隔离与自愈：
Go语言相比于Java与Python，不需额外的运行环境，编译为一个独立的执行文件；相对于C/C&#43;&#43;没有依赖动态库版本不一致的问题；Go语言程序相对于Java启动速度快，很适合于快速伸缩。而独立进程相比于Java中类Tomcat容器内多WebApp部署方式有更好的故障隔离；Go语言虽有异常（Panic），但可预知的错误建议采用error处理，引入了内置的error类型以及defer关键字来处理异常安全，这让程序员更容易写健壮的代码。
  在云计算环境下，只要是适合的场景产品（Go目前还不适合要求低时延，高实时的场景），如在面向管理控制、网络并发等领域，采用Go语言开发，用来代替部分C/C&#43;&#43;开发的系统应用；Java开发的网络或后端服务应用；Python开发的管理控制应用；可能极大提升产品的整体竞争力。
微服务 现在的应用程序规模越来越庞大，逻辑处理也是越来越复杂。在我司的电信领域，一个产品的研发也是动则几百号人的团队一起开发；系统上处理的数据规模，与接入的用户请求数也是几何级增加，在吞吐量、稳定性都会面临着极大的挑战；当前的业务尤其是面向移动终端用户的业务，需求变化快，业务不断推出与消亡，传统的单体架构根本无法适合频繁的变更，系统的可扩展性、定制性尤显得重要。当功能繁杂，结构混乱，以及人员变化等因素影响下，要解决这些问题，不得不在交付中不断地制定策略，演进架构：
随着云计算应用经验的不断积累，以及相关的工具链不断成熟，也伴随着微服务架构的出现。它通过将功能分解成多个独立的服务，以实现对解决方案或者复杂系统的解耦。微服务的诞生并非偶然:
 领域驱动设计指导我们如何分析并模型化复杂的业务； 敏捷方法论帮助我们消除浪费，快速反馈；持续交付促使我们构建更快、更可靠、更频繁的软件部署和交付能力； 虚拟化和基础设施自动化( Infrastructure As Code)则帮助我们简化环境的创建、安装； DevOps文化的流行以及特性团队的出现，使得小团队更加全功能化。这些都是推动微服务诞生的重要因素。  微服务通常有如下几个特征,也是与Go语言特征不谋而合：
  小：专注于做一件事情
小即是极多，这与Go语言遵循设计原则。保持简单性的方法就是：每种特性仅提供一种方法，减少重复、冗余，只提供一种方法做事情，把事情做到极致，这就是Go语言的原则。而微服务通常讲是两个Pizza能吃饱的团队来共用维护一个服务的代码。与”单一职责原则”类似，每个服务只做一件事情，并且把它做好。Go语言在语法特性简洁处理，编写相同的功能，相比于其它语言代码量很少。同时它提供高质量的标准库，让程序员减少对第三方框架选择与熟悉难题，让程序员更多的精力放在业务本身的逻辑上。
  独：运行在独立的进程中
当初接触Go语言时，发现它既然支持与C的调用，一直不太理解它为何不支持动态库（1.5版本部分支持）。但事实上，Go语言认为如果一项特性不带来显著的有益，那就不提供。其实动态库的版本当编译与运行时不一致导致程序崩溃一直是C/C&#43;&#43;开发的噩梦。Go编译单一执行文件，能一定程度缓和这个问题。另外Go一直追求生成代码优化，执行文件最小化。这也方便程序部署在Docker容器中，运行在一个独立的操作系统进程，拥有更好的故障隔离。
  轻：轻量级的通信机制
服务和服务之间通过轻量级的机制实现彼此间的通信。所谓轻量级通信机制，通常指基于语言无关、平台无关的这类协议，例如XML、JSON。Go语言的主要发力点之一就是网络编程，标准库内置了HTTP协议框架，同时也提供了对JSON、XML的序列化与序列化支持，结合它的Goroutine并发机制，开发一个Rest服务只须很少的代码。
  松：部署态与运行态松耦合
Go语言是一个强类型静态语言，可以把代码编译为本地机器指令。它的RUNTIME是会在编译时一起链接到执行文件中，这也就意味着我们不需要像JAVA那样装一个JVM。而且编译出的执行文件本身不依赖于其他动态库，完全可以做到轻松的发布。Go语言基于Channel来通讯，也会带来一定程序代码结构上的松耦合。
  当产品架构朝微服务架构演进时，Go语言语言特征与微服务不谋而合，采用Go语言在一定程度上会助力微服务架构实施与落地。单体应用拆分成众多微服务时，服务之间从传统的插件机制来获得扩展性，转化成分布式多进程通讯来扩展。Go语言在网络并发上的优势，使得微服务开发变得更为简单，性能上更有优势。
参考：
[1] 基于微服务架构，改造企业核心系统之实践
[2] Go在谷歌：以软件工程为目的的语言设计
[3] Why Go is not Good
[4] 说说Golang的使用心得
[5] go语言设计哲学
[6] 少即是极多 - Go 语言设计理念
</content>
    </entry>
    
     <entry>
        <title>Go语言不足</title>
        <url>http://lanlingzi.cn/post/technical/2016/0718_go_insufficient/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 最近公司是在疯狂地推广Go语言，我也是推广小组成员。Go语言的确很多的优点，这里并不想表扬Go语言，而是说说它的不足。
生态不成熟 一个语言的流行，都有其背后的推动者。Go语言是由Google公司创建与推动。最近我司的高层也亲自拜访了Go语言的主创人员。Google称目前已有100&#43;的App从Java转向Go。Google内部主要有三大语言（C&#43;&#43;、Java、Python），之前对Go语言的公司内部的政治意义大于它的实际使用。近两年来，语言的战略地位凸显，不断地在推动Go语言的应用。
目前主要使用Go语言的公司是一些创业公司或互联网公司。而这些公司采用Go语言非技术的因素主要有：
 公司软件资产积累少，不存在切换其它语言成本，使用Go语言可以轻装上阵； 互联网公司的技术人员流动大，Go语言面向开发简化，招人容易，上手快；  采用Go语言的技术因素主要有：
 Go语言在语言级通过Goroutine与网络IO的Netpoller的封装，能大在简化高并发的网络应用开发，而互联网的应用都以HTTP、网络通讯应用为主； Go语言标准库丰富，能满足互联网应用的常用应用场景：不需要太多的业务逻辑，偏网络接入；  Go当前很多的第三方开源框架，库都是最近一到两年内才诞生的，并且后面没有相应的大公司支撑，个人或小团体的维护的项目居多。这些框架，库的成熟需要时间来锤炼与稳定。
动态扩展机制不成熟 对于编译型静态语言，需要有一种机制来支持动态扩展。C/C&#43;&#43;是通过动态库来扩展，Java是支持Class动态加载，或基于JVM平台的其它脚本语言互通。Go语言长期没有支持动态库，Go语言的创始人曾明确表态：
 动态库的存在是一个系统的设计Bug
 但是在Go1.5版本又加入了动态库支持，对动态库支持采用一定的妥协，这也说明它确有它的应用场景。但目前只支持：Linux/AMD64，ARM平台（cgo·golang/go Wiki,WindowsDLLs·golang/go Wiki）。同时支持也是有限制：
 Go语言代码，可以生成动态库给C代码调用，也可能给Go代码调用，但他们使用也有区别，参考：Go1.5生成动态库 不支持运行时在代码中动态加载库  目前可行的解决方案：
 生成C语言动态库：通过动态加载生成C语言动态库，实现动态扩展，一个进程中，运行了多个“Go世界”（Go的Runtime）   这需要GCC编译器，所以严格来说并不支持Win下的纯DLL动态库（cywin之类的gcc没有验证过）   嵌入脚本语言，实现功能逻辑的动态扩展。   目前开源项目已有纯Go实现的Lua VM，也有通过CGo绑定C的Lua。也有开源项目通过Cgo绑定支持Python,Ruby等； 自创脚本脚本，或DSL脚本，采用Go来实现脚本解释。但如果对性能要高要求，需要支持对脚本的JIT，这是相当有难度，目前也未见有解决方案。   实现基于通信机制的插件模式   类似于VScode的语言服务插件机制，参考：通用语言协议 这本质是进程间的通讯，并不传统意义上的插件扩展机制。  不支持泛型 泛型是目前高级语言最常见的语言基础，Java1.5采用擦除法的泛型（并不像C&#43;&#43;一样的Template技术）也解放了不少生产力，能大大减少相似的代码。而Go语言官方团队相对是“民主集中制”，很难听取社区的意见，认为这个总是不紧急，并且他们也没有找到满意的实现方式（C&#43;&#43;/Java实现方式都不让他们满意：C&#43;&#43;是编译期间展示，生成不同的代码，对编译速度与生成文件大小都有影响；而Java是擦除法，只是语法糖，生成Bytecode变成Object对象，并没有本质变化）。
从目前来看，Go语言在1.0规范发布之后，语法特性几乎没有什么变化，围绕是性能优化与跨平台支持。至少在Go2.0之前，极可能不会引入这个语言特性。
目前可行的解决方案
 interface{}   类似于C的void*，Java的Object，但这会增加代码的可读性差与安全危险，又与Go的简单哲学不相符   Go generate   参考：Golang generate 草案   Go泛型编程库：gen   gen 项目目的是为 Go 语言带来了类似泛型的函数，灵感来自 C# 的 LinQ 和 JavaScript 的 Array methods 以及 underscore 库。操作包括过滤、分组、排序等等。  Goroutine性能陷阱 Goroutine简化了并发编程，但它并不能消除并发问题（资源竞争，原子性操作），只是把线程的调度预置到了它的Runtime中，让上层应用代码变得很少。它的坑也主要体现在它的调度不可控制上。
下面阻塞不会创建新的调度线程：
 网络IO阻塞 Channel阻塞 Sleep，同步锁阻塞 基于底层系统异步调用的Syscall  下面阻塞会创建新的调度线程：
 磁盘IO阻塞 CGo方式调用C语言动态库中的调用IO或其它阻塞  这些情况下会导致线程数量爆涨，从而导致系统性能下降，而Goroutine通过go func就能产生一个Goroutine，犯错的成本低，容易被滥用。这需要开发人员熟悉Goroutine内部机制，并小心地避开这些坑。期待Go官方将来能重点解决这些问题。
参考：
[1] goroutine背后的系统知识
[2] golang的goroutine是如何实现的
[3] goroutine与调度器
</content>
    </entry>
    
     <entry>
        <title>Go语言在线书籍收集</title>
        <url>http://lanlingzi.cn/post/technical/2016/0717_go_book/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Effective Go 在线阅读：
 http://www.hellogcc.org/effective_go.html  Go语言圣经 Go语言圣经，《The Go Programming Language》 中文版本  项目主页：http://github.com/golang-china/gopl-zh 项目主页：http://bitbucket.org/golang-china/gopl-zh 原版官网：http://gopl.io  在线阅读：
 http://gopl-zh.b0.upaiyun.com/ http://docs.ruanjiadeng.com/gopl-zh/ http://shifei.me/gopl-zh/ http://2goo.info/media/html/gopl-zh-gh-pages/ http://docs.plhwin.com/gopl-zh/  Go Web 编程 Go Web 编程，《Build Web Application with Golang》国内首个讲解Go Web编程的在线书籍。 在线阅读：
 English 中文  雨痕学习笔记 在线下载：
 https://github.com/qyuhen/book  The way to Go 《The Way to Go》中文译本，中文正式名《Go入门指南》
在线阅读：
 https://github.com/Unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md  Network Programming with Go 在线阅读：
 https://jannewmarch.gitbooks.io/network-programming-with-go-golang-/content/index.html </content>
    </entry>
    
     <entry>
        <title>Pandoc&#43;Mardown生成Web Slide</title>
        <url>http://lanlingzi.cn/post/notes/2016/0716_pandoc_md_ppt/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Markdown</tag><tag>Slide</tag>
        </tags>
        <content type="html"> 背景 在我司PPT被称为胶片。一层层的汇报都是胶片承载，胶片也是做得非常漂亮。像我所在领域，架构师主要产出也是胶片，俨然无胶片就无架构。一方面个人非常羡慕胶片写得好（内容与外观）的人，另一方面觉得像使用MS的PowerPoint几乎要把一半的精力放在外观而不是内容上。甚至感觉到为了一个格式、一个颜色，调整都需要老半天时间。大家的胶片都做得漂亮，而你不可能也就只草草准备，尤其是给领导的胶片，人在江湖，身不由已。但做一名技术人员，内心还是比较抵触形式大于内容的胶片。昨天，一名同事给我展示了一个由Markdown生成Slide，给人感觉是耳目一新。
Markdown是一种内容与形式的分享的轻量级标记语言，受到越来越多的人喜欢，只要只简单的文本编辑器，都能书写文本内容。那有什么工具能快速方便地生成Slide呢。Markdown本身是为了方便输出到HTML格式。而HTML&#43;CSS&#43;JS是一个开放的，可扩展的技术。自然Markdown也可以通过工具生成像PPT一样可以上下翻页的HTML Slide，同样借助CSS与JS的结合，Slide一样可以做得像PPT一样格式漂亮，动作酷炫。
Pandoc Pandoc 则是一款非常优秀的开源文本格式转化神器。Markdown转换为HTML Slide也自然不在话下。Pandoc是由Haskell开发，Pandoc作者John MacFarlane一位来自美国加州大学伯克利分校的哲学教授。Haskell是一种函数式编程语言。而文本格式转换，看似简单，其实非常麻烦。Haskell干这脏活、累活的最恰当选择，Pandoc也的确成功了，并已成功在短期内构建一个完整的生态链。
安装 个人PC使用的Macbook，所以安装比较简单：
$ brew install pandoc  检验 $ pandoc --version pandoc 1.17.1 Compiled with texmath 0.8.6.3, highlighting-kate 0.6.2. Syntax highlighting is supported for the following languages: abc, actionscript, ada, agda, apache, asn1, asp, awk, bash, bibtex, boo, c, changelog, clojure, cmake, coffee, coldfusion, commonlisp, cpp, cs, css, curry, d, diff, djangotemplate, dockerfile, dot, doxygen, doxygenlua, dtd, eiffel, elixir, email, erlang, fasm, fortran, fsharp, gcc, glsl, gnuassembler, go, hamlet, haskell, haxe, html, idris, ini, isocpp, java, javadoc, javascript, json, jsp, julia, kotlin, latex, lex, lilypond, literatecurry, literatehaskell, llvm, lua, m4, makefile, mandoc, markdown, mathematica, matlab, maxima, mediawiki, metafont, mips, modelines, modula2, modula3, monobasic, nasm, noweb, objectivec, objectivecpp, ocaml, octave, opencl, pascal, perl, php, pike, postscript, prolog, pure, python, r, relaxng, relaxngcompact, rest, rhtml, roff, ruby, rust, scala, scheme, sci, sed, sgml, sql, sqlmysql, sqlpostgresql, tcl, tcsh, texinfo, verilog, vhdl, xml, xorg, xslt, xul, yacc, yaml, zsh ...... 可见，Pandoc支持多种语言的高亮显示，程序员不愁写PPT了。
样例 % Markdown &#43; Pandoc % lanlingzi % 2016-07-16 ## Web-based slideshow  - is a slide show which can be played (viewed or presented) using a web browser - is typically generated to or authored in HTML, JavaScript and CSS code (files) - are generated from presentation software - offer templates allowing the slide show to be easily edited and changed. ## Features  - Keyboard navigation - Slide transitions and animations - Auto-play/timed transitions - Displays a table of contents - Nested slides - Separate slide notes for the speaker - Full screen support, with automatic text and images resizing to fit full screen - ..... Pandoc对分级标题、列表、插入图片等标准的Markdown语法均被支持，和平常用Markdown记笔记写博客无异。在文本开头需要包含三行以%打头的元信息：标题、作者和日期。
默认情况下每个二级标题是一张独立的幻灯片，所以，注意把每个二级标题下的内容控制在适当的长度。列表的显示效果可以人为设定，例如在幻灯片演示的时候逐条渐入。也可以直接在文本中嵌入HTML，用于显示Markdown等标记语言不支持的表格，或控制字体大小，以及进行其他更加复杂的排版。当然，如果用到的HTML标签过多，这不是Markdown这些轻量级标记语言的错，也许是做幻灯片的方式出了问题。因为演示本身要传达的是内容，复杂的排版没有任何意义。
命令 $ pandoc -s -i -t slidy demo.md -o demo.html  其中-t slidy是生成Slide采用样式框架，目前Pandoc包含了对五种HTML Slide框架的支持:
 DZSlides Slidy S5 Slideous revealjs  其中-i表示渐进显示，即控制列表的显示效果（逐条渐入）。
后记 采用Pandoc把Markdown转化为Slide也不是万能的。受限于Markdown的标签表达能力，其中的表格、复杂公式、多国语言、上下标、交叉引用、图表对齐较多的场合，它并不适合。使用Pandoc，只是喜欢Slide的样式，不用去辛辛苦苦的做PPT， 也有PPT的展示效果，何乐而不为呢？
</content>
    </entry>
    
     <entry>
        <title>Goroutine陷阱</title>
        <url>http://lanlingzi.cn/post/technical/2016/0703_goroutine/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go在语言层面通过Goroutine与channel来支持并发编程，使并发编程看似变得异常简单，但通过最近一段时间的编码，越来越觉得简单的东西，很容易会被滥用。Java的标准库也让多线程编程变得简单，但想当初在公司定位Java的问题，发现很多的同学由于没有深入了解Java Thread的机制，Thread直接New从不管理复用，那Goroutine肯定也要面临这类的问题。
Goroutine泄漏问题 Rob Pike在2012年的Google I/O大会上所做的“Go Concurrency Patterns”的演讲上，说道过几种基础的并发模式。从一组目标中获取第一个结果就是其中之一。
func First(query string, replicas ...Search) Result { c := make(chan Result) searchReplica := func(i int) { c &amp;lt;- replicas[i](query) } for i := range replicas { go searchReplica(i) } return &amp;lt;-c } 在First()函数中的结果channel是没缓存的。这意味着只有第一个goroutine返回。其他的goroutine会困在尝试发送结果的过程中，如果你有不止一个的重复时，每个调用将会泄露资源。为了避免泄露，你需要确保所有的goroutine退出。一个不错的方法是使用一个有足够保存所有缓存结果的channel。
func First(query string, replicas ...Search) Result { c := make(chan Result,len(replicas)) searchReplica := func(i int) { c &amp;lt;- replicas[i](query) } for i := range replicas { go searchReplica(i) } return &amp;lt;-c } 另一个不错的解决方法是使用一个有default情况的select语句和一个保存一个缓存结果的channel。default情况保证了即使当结果channel无法收到消息的情况下，goroutine也不会堵塞。
func First(query string, replicas ...Search) Result { c := make(chan Result,1) searchReplica := func(i int) { select { case c &amp;lt;- replicas[i](query): default: } } for i := range replicas { go searchReplica(i) } return &amp;lt;-c } 你也可以使用特殊的取消channel来终止workers。
func First(query string, replicas ...Search) Result { c := make(chan Result) done := make(chan struct{}) defer close(done) searchReplica := func(i int) { select { case c &amp;lt;- replicas[i](query): case &amp;lt;- done: } } for i := range replicas { go searchReplica(i) } return &amp;lt;-c } 为何在演讲中会包含这些bug？Rob Pike仅仅是不想把演示复杂化。这么做是合理的，但对于Go新手而言，可能会直接使用类似代码，而不去思考它可能有问题。
Goroutine Race问题 Go语言支持函数中定义函数，看下一个例子：
func saveRequest(request *Request) { …. go func() { request.Users = []{1,2,3} … db.Save(request) } } 很多情况下，由于程序员对goroutine了解不够深入，又由于goroutine使用很容易。为了性能，很容易把一个同步函数变成异步函数，但这违背了go”不要通过共享内存来通信，相反应该通过通信来共享内存“的原则。即上述的例子中起了一个goroutine，并修改了request指针指向的对象。即使对request只读，也可能不是安全，因为你无法保证request指针不在其它goroutine中修改。
在本质上讲，goroutine的使用会增加了函数的危险系数，尤其是函数参数传递指针时。任何一个对象的操作，如果没有加上锁，当项目比较庞大时，可能不知道这个对象是不是会引起多个goroutine竞争。
什么是goroutine race（竞争）问题？官网的文章 Introducing the Go Race Detect给出的例子如下：
package main import( &amp;#34;time&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; ) func main() { start := time.Now() var t *time.Timer t = time.AfterFunc(randomDuration(), func() { fmt.Println(time.Now().Sub(start)) t.Reset(randomDuration()) }) time.Sleep(5 * time.Second) } func randomDuration() time.Duration { return time.Duration(rand.Int63n(1e9)) } 这个例子看起来没任何问题，但是实际上，time.AfterFunc是会另外启动一个goroutine来进行计时和执行func()。由于func中有对t(Timer)进行操作(t.Reset)，而主goroutine也有对t进行操作(t=time.After)。 这个时候，其实有可能会造成两个goroutine对同一个变量进行竞争的情况。
那什么才是goroutine的使用正确姿势，怎么理解“通过通信来共享内存”来避免Race问题？先看一个例子：
type SimpleAccount struct{ balance int } func NewSimpleAccount(balance int) *SimpleAccount { return &amp;amp;SimpleAccount{balance: balance} } func (acc *SimpleAccount) Deposit(amount uint) { acc.setBalance(acc.balance &#43; int(amount)) } func (acc *SimpleAccount) Withdraw(amount uint) { if acc.balance &amp;gt;= int(amount) { acc.setBalance(acc.balance - int(amount)) } else { panic(&amp;#34;杰克穷死&amp;#34;) } } func (acc *SimpleAccount) Balance() int { return acc.balance } func (acc *SimpleAccount) setBalance(balance int) { acc.balance = balance } type ConcurrentAccount struct { account *SimpleAccount deposits chan uint withdrawals chan uint balances chan chan int } func NewConcurrentAccount(amount int) *ConcurrentAccount{ acc := &amp;amp;ConcurrentAccount{ account : &amp;amp;SimpleAccount{balance: amount}, deposits: make(chan uint), withdrawals: make(chan uint), balances: make(chan chan int), } acc.listen() return acc } func (acc *ConcurrentAccount) Balance() int { ch := make(chan int) acc.balances &amp;lt;- ch return &amp;lt;-ch } func (acc *ConcurrentAccount) Deposit(amount uint) { acc.deposits &amp;lt;- amount } func (acc *ConcurrentAccount) Withdraw(amount uint) { acc.withdrawals &amp;lt;- amount } func (acc *ConcurrentAccount) listen() { go func() { for { select { case amnt := &amp;lt;-acc.deposits: acc.account.Deposit(amnt) case amnt := &amp;lt;-acc.withdrawals: acc.account.Withdraw(amnt) case ch := &amp;lt;-acc.balances: ch &amp;lt;- acc.account.Balance() } } }() } 上面的例子，SimpleAccount所有方法，当多goroutine操作是不安全的，而通过ConcurrentAccount封装，所有处理都统一通过channel通信到listen开启的goroutine，即只有一个goroutine能操作SimpleAccount中成员变量，那也就不会发现Goroutine Race问题。
</content>
    </entry>
    
     <entry>
        <title>第八届中国云计算大会简纪</title>
        <url>http://lanlingzi.cn/post/technical/2016/0519_cie_cloud/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag>
        </tags>
        <content type="html"> 第一次参加由电子协会举办的云计算大会，这届是在北京国家会议中心举行，据说这一届参加的人数有1.4W人。主题为“技术融合 应用创新”。云计算走到今天，已不在是什么新概念，在中国已大规格地使用起来。作为一名技术从业者，有幸参加，虽可能得不到干货，但可听一听，看一看，启发思路。
云计算是产业变革的推进器 第一场是来自工业和信息化部副部长怀（进鹏）部长致辞，领导果然是领导，带病撑着拐杖登台。整个过程是滔滔不绝地精彩分享，作一名学术官员，能脱稿是我发挥，说明他这个领域的真正专家。核心观点：
 云计算是解决方案，助推产业变革。给我们日常生活变化，也给我们产业带来新结构调整 云计算与大数据互为孪生兄弟，助推企业、行业和信息化解决方案起到了特别的支撑作用 云计算提供低成本便捷的IT资源，提供数字均衡发展，降低数字鸿沟，大幅度降低创业门槛  云计算的产业快速发展，带动硬件基础设施的发展，也带动了软件产业的发展，也带动了应用领域不同行业的发展,也迎来了新发展中的问题:
 技术方面的问题：面向工业互联网仍然有大量未知问题，在大数据分析和处理能力仍然需要发展；可靠性、安全性、系统能力方面不断加强；核心技术面对新的挑战需要不断地进行优化和完成。 标准方面的问题：通过推动标准，推动各类云计算系统互联互通，共享创造为更多应用有效服务的应用内容。 产业变革的总是：建立有效的人才培养和产业发展的环境，来推动产业有序、健康和快速的增长以推动产业结构的调整，同时建立有效的安全环境和有效的机制，以保障信息的安全、个人隐私安全和云数据交换交流当中所提供的安全保护机制。  点评：传统产业正面临云计算的冲击，谁先拥抱云计算，对产业信息化调整，谁就有可能先抢占新的机会。工业云、智能制造、工业互联网和工业大数据将推动产业发展和技术进步。
云计算挑战与机遇并存 第二场是IFIP主席Mike Hinchey致辞，英文不好，不太听懂。第三场是工信部信息化和软件服务业司司长谢少峰的演讲，全程都是念稿子，整个过程比较枯燥。开始是介绍我国云计算产业发展的现状，一堆的数字，没有太仔细听。后面是谈一下当前云计算发展面临的挑战：
 公有云的安全性和可靠性和可迁移性，行业对公有云的顾虑，政务、金融采购公有云服务的还面临着政策、标准等障碍。（PS：个人觉得不是什么问题，云计算也有细分市场，公有云，私有云，混合云都会发展） 产业规模小，技术产品服务仍需提高。（PS：这的确是一个总是，目前国内的云计算针对行业来说，没有形成成熟的解决方案，这也说明这一块的发展空间很大） 标准体系和认证测评体系不完备。（PS：中国的流氓公司太多，个人隐私数据保护法律法规有待健全啊）  云计算产业发展的未来趋势展望：
 中国制造2025年和互联网&#43;战略的不断推进，行业迫切需要通过云计算系统助推行业转型升级发展。（PS：行业转型会有阵痛） 开源技术推动云计算的发展。开源将是事实上的标准。（PS：对于我们这种屌丝程序员来说，参与开源也是提升自己的职业空间） 混合云将成为云服务业态的重要方向，私有云和公有云之间需要高效对接和无缝的切换。（PS：云集成将又是一片蓝海） 大数据的整合。云计算与大数据的深度融合，才能发挥更大的作用。（PS：马云早就说过已进入DT时代）  云计算这十年 这个分享个人觉得非常精彩，内容比较多。云计算已经成为我们互联网创新的一个主要的基础设施。计算理论和技术方法随着网络化、泛载网络智能化，形成新模式和新思维方式。面向未来我们基于物三元社会在整个信息社会推动之下的融合也需要我们云计算提供基本的技术和基础设施的支撑。云资源管理全面走向软件定义，我们可以对规模化的资源进行高效的管理，这是软件定义技术基于虚拟化和管理编程综合的体现，我们涉及到软件定义计算，软件定义网络，软件定义的存储。
过去云涌十年分成三个阶段：
 概念探索期：争论云到底是什么，主要的是一些专业实践 技术落地期：技术落地基本上形成共识开始呈现对云计算的大众化。 应用繁荣期：各个领域各个行业都会大量基于云计算搭建它的服务。  未来云计算发展趋势以及展望，三化一提升：
  应用领域化
在领域化基本里面能不能对这种各种的应用，我们提供面向领域的按需开发，面向特定的领域需求提供支持云涌开发运行的API解决方案及其他一体化的解决方案，支撑更多的应用，是云未来发展在应用繁荣面临非常重要的挑战。
云感知的软件服务正在成为一种新形态，我们可以看到软件服务提出已经很久了，在软件服务的早期，以前系统是紧偶合一体化的，SOA出现出现双偶合分布式应用，基于云所提供的服务或者微服务进行构建，感知云环境各种资源的变化，充分利用提供的各种API。
  资源泛载化
客户端软件资源、硬件资源、能耗资源，和服务端软件资源、硬件资源、能耗资源可以在两端合理分布，数据两端分布成熟，以及两端独特资源的共享，这样云端不仅是我们现在移动互联网支撑智能手机端，甚至包含物联网所承担的各种各样的联网设备，这样态势之下我们可以看到未来面临一定的挑战。存在万物互联的阶段，各种端上的设备能不能在云平台形成统一管理模式，这是云端面临的挑战。
  系统平台化
正在走向云操作系统的概念。操作系统是什么？向下管理资源，向上提供服务。单机操作系统基本构成，管理资源、管理作业、我们现在云管理系统主要管理云的资源，上面支撑各种操作系统运行，未来云操作系统除了管理云资源之外，还要管理云上面各种各样的作业，把操作系统的理念在整个云环境中间进行一次复制。
云操作系统可能面临这么一系列的挑战，一个是复杂多样的应用需求、传统应用可能怎么实现无缝的云化，支持基于互联网多终端的交互，云内海量资源的管理。
  服务质量的提升
服务质量的提升，用三个字概括，更高、更快、更强壮。高意味着支持高吞吐，需要聚合大规模资源提供海量处理能力实现高吞吐并发访问。快响应就是提供高吞吐的同时能够盘活降低请求的响应机制，能够降低我们所有请求的机制，也就是形成一种新的提升用户的体验，提升他的服务质量。更强壮体现在可靠可用，像云计算和规模复杂度的快速增长，要求更为全面质量保证，数据中心规模不断增长大规模部署成为事实，高吞吐的云计算环境大家看到增加的故障越来越多，故障损失很大。
  点评：三化一提升还是很有高度地概括性的。
云网将为运营商带来新的融合和创新 国内互联网的企业做云计算从08年就开始了，而运营商开始进入到云计算领域在2012年末到2013年开始，是后来者。十年前左右开始的趋势是，网络和内容服务商开始崛起，这让运营商与做SP的赚了不少钱。但互联网的发展，尤其是移动互联网的发展，但运营商变成了管道，OTT长尾业务都被其它赚走了运营商就开始坐不住了。
从分享的内容来看，中国电信的云计算来停留建设数据中心的阶段，做自己定位为云服务商，也就是提供基础设施供应商，帮助客户完成互联网&#43;。其中谈到行业系统云计算化面临两点挑战，我个人非常赞同：
 行业应用的IT系统的迁移，迁到云上面有非常大的工作量，甚至迁移的工作量比我们新建一套还要大。 需要一个服务型的工具，不能两套人马两套班子维护这么一个东西。还有一个层面是安全，安全变得异常作用。  应用和数据的特征，变得多样化。不同的应用当都移的云上去的时候，要求也不一致，服务无法提供标准化。未来面临都做混合云，混合云对于网络或者一体化部署的要求远远会超过原来我们单做一个私有云或者说我们仅仅是去面临一个相较而言可靠性、安全性没有那么高的公有云服务不同。业务的迁移服务变成了本身云服务其中的一个内容。理想的云服务商应该具备什么特征，五个方面：
 网络基础设施 产品研发 运营安全 营销和服务 定制和实施  当前运营商提供云服务的长板：
 在网络的基础设施，尤其是咱们的基于客户贴身营销和服务方面，运营安全方面有优势 原有的运营商的基础网络之上，继续把这个网络变得更强健。如通过CDN让业务流量都发生在它的身边，提升服务。又如去做基于冷数据、温数据以及热数据，根据目前的地理敏感的要求重新设计我们目前的资源部署。  运营商提供云服务的短板：
 在研发、和定制实施方面有短版。 除云资源的安全，数据的安全之外，以及网络安全方面。 可定制的服务，重新定制化服务自己作为的定制化一朵云。  点评：主要观点，运营商来讲依然应合作双融的驱动继产业链之力满足客户端到端的优势，产业合作方面应该做更多的一些事情。基础能力的合作伙伴，最终给客户提供一个针对性、整体性的服务。
</content>
    </entry>
    
     <entry>
        <title>Golang Web开发</title>
        <url>http://lanlingzi.cn/post/technical/2016/0515_go_web/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>web</tag>
        </tags>
        <content type="html"> 标准库[net/http] 采用Golang来开发Web应用或Rest接口的应用还是比较容易的。golang标准库就提供对Http协议的封装，主要涉及到net/http包，它包括了HTTP相关的各种函数、类型、变量等标识符。标准库的net/http是支持HTTP1.1协议，而目前Go1.6也支持HTTP2.0，包放在 golang.org/x/net/http2,后续可能会移到标准库。
net/http库中主要涉及到如下几个类型与接口：
Request结构体 封装了HTTP的请求消息，其结构如下，可以很方便的地取出Method，Header与Body。
type Request struct { Method string URL *url.URL Proto string ProtoMajor int ProtoMinor int Header Header Body io.ReadCloser ContentLength int64 TransferEncoding []string Close bool Host string Form url.Values PostForm url.Values MultipartForm *multipart.Form Trailer Header RemoteAddr string RequestURI string TLS *tls.ConnectionState Cancel &amp;lt;-chan struct{} } Response结构体 封装HTTP的响应消息，其结构如下，Response会关联Request。
type Response struct { Status string StatusCode int Proto string ProtoMajor int ProtoMinor int Header Header Body io.ReadCloser ContentLength int64 TransferEncoding []string Close bool Trailer Header Request *Request TLS *tls.ConnectionState } Handler接口 用于构建Response。应用开发就编写各种实现该Handler接口的类型，并在该类型的ServeHTTP方法中编写服务器响应逻辑。
type Handler interface { ServeHTTP(ResponseWriter, *Request) } ResponseWriter接口 即应用通过各种Handler操作ResponseWriter接口来构建Response。ResponseWriter实现了io.Writer接口，可以写入响应的Body，WriteHeader方法用于向HTTP响应信息写入状态码，但必须先于Writer方法调用。若不调用WriteHeader，使用Write方法会自动写入状态码http.StatusOK。
type ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(int) } ListenAndServe函数 启动HTTP服务，需要构建Server对象，并调用该Server的ListenAndServe方法，Server是HTTP服务的主控器。期结构定义如下，应用可以设置HTTP监听的地址，配置TLS，以及一些其它参数配置。
type Server struct { Addr string // TCP address to listen on, &amp;#34;:http&amp;#34; if empty Handler Handler // handler to invoke, http.DefaultServeMux if nil ReadTimeout time.Duration // maximum duration before timing out read of the request WriteTimeout time.Duration // maximum duration before timing out write of the response MaxHeaderBytes int // maximum size of request headers, DefaultMaxHeaderBytes if 0 TLSConfig *tls.Config // optional TLS config, used by ListenAndServeTLS TLSNextProto map[string]func(*Server, *tls.Conn, Handler) ConnState func(net.Conn, ConnState) ErrorLog *log.Logger disableKeepAlives int32 // accessed atomically. nextProtoOnce sync.Once // guards initialization of TLSNextProto in Serve nextProtoErr error } Server需要关注如下几个方法，从方法名就可能知道它的用途。
func (srv *Server) ListenAndServe() error func (srv *Server) Serve(l net.Listener) error ServeMux结构体 用于HTTP路由配置，其结构体定义如下：
type ServeMux struct { mu sync.RWMutex m map[string]muxEntry hosts bool // whether any patterns contain hostnames } ServeMux有如下几个方法，用于配置HTTP与URL的映射关系。其实ServeMux也是实现ServeHTTP接口，其ServeHTTP方法完成了ServeMux的主要功能，即根据HTTP请求找出最佳匹配的Handler并执行之，它本身就是一个多Handler封装器，是各个Handler执行的总入口。
func (mux *ServeMux) Handle(pattern string, handler Handler) func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) ServeMux的路由功能是非常简单的，其只支持路径匹配，且匹配能力不强，也不支持对Method的匹配。net/http包已经为我们定义了一个可导出的ServeMux类型的变量DefaultServeMux。net/http包也提供了注册Handler的方法，它其实也是操作DefaultServeMux：
 调用http.Handle或http.HandleFunc实际上就是在调用DefaultServeMux对应的方法。 若ListenAndServe的第二个参数为nil，它也默认使用DefaultServeMux.  第三方库[fasthttp] 说到Golang的http，也不是只有标准库一家，Github也有人开源了fasthttp，并号称比net/http包快10倍，上面介绍的echo，底层同时支持net/http与fasthttp，其性能测试对比如下： 但是由于fasthttp的API与net/http完全不同，这使得无法重用目前基于net/http开发的路由，Handler等工具，这也让人在选择它时不得不面临考虑的问题。
工具或框架 由于Golang提供了标准库net/http，使得开发Go的Web框架变得很简单，在Github上可以搜索到各种不同层次的框架。
路由工具  gorilla/mux julienschmidt/httprouter  Handler工具  gorilla/handlers codegangsta/negroni  轻量框架  echo，底层支持绑定fasthttp，号称10倍快于其它框架。 goji，借鉴了Sinatra了思想。 martini，提供了丰富的中间件。 goin，借鉴了Martini，号称比它更快。 macaron，其思路来自martini，个人感觉API比martini方便很多。  全功能框架  web.go，其思路来自web.py。 beego，其思路来自Tornado, Sinatra与Flask框架。 revel，其思路完全来自Java的Play Framework。 </content>
    </entry>
    
     <entry>
        <title>Oracle Cloud Day见闻简纪</title>
        <url>http://lanlingzi.cn/post/technical/2016/0414_oracle_cloud_day/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Oracle</tag><tag>Cloud</tag>
        </tags>
        <content type="html"> 今天有幸参加Oracle举办的cloud day。Oracle从开始对云计算不敏感，到后来的大力投入，并购与产品整合，目前Oracle在云计算领域已涵盖IaaS，PaaS，SaaS。Oracle正借助于云计算，把帮助企业把传统的应用产品搬迁到云计算上。Oracle应用产品发发展战略三个核心阶段：
 无极限的应用产品支持：对所有目前使用Oracle OP部署方式的应用产品客户提供持续支持。 下一代“云”应用产品的开发以及战略并购：基于统一标准的PaaS平台，并购整合并开发下一代的，最优的基于云的产品。 切实可行的”云”之路：为客户提供各种服务和商务方案使客户以最小的投资风险采用Oracle云服务。  从上也可以看出Oracle在云计算野心，它虽相对起步晚，但它由于在传统IT领域的优势，通过整合基础设施，平台与中间件，以及社交资源，是在云计算领域内少数几个能针对企业各种业务提供一套完整的解决方案，涵盖如下领域：
 客户关系管理：销售管理（Sales），市场管理（Marketing），服务管理（Service），电子商务（Commerce），社交媒体（Social）  供应链管理：产品创意与研发，供应认证与寻源，采购管理，物流管理，销售管理，计划管理，生产管理 财务及人力资源：财务管理，差旅报销，财务报告与分析，见血预算管理，项目管理，人力资源管理    Oracle的云应用具有如下特点：
 完整：一个云平台支持所有业务动作 一流：基于Oracle在企业领域的最佳实践 现代：数据驱动的业务执行与管理； 个性：个性化的“云”应用体验，提供SaaS（来ERP，HCM）来定制用户体验，提供PaaS来丰富与创建新的应用 集成：提供iPaas与集成能力来连接与协作已有资产 安全：大使级的安全性和兼容，支持传统的多租户的安全数据隔离，以及SaaS的便利  今天的cloud day也是从上述几个方面的展开的，我感兴趣的是他们的PaaS平台。确切地说，Oracle的PaaS是一个较泛的统称，今天主要介始的包括如下：
 应用开发云：提供代码配置库（git/svn）集成，支持直接从github同步代码，基于Maven等代码构建能力，有限地支持DevOps。 应用部署云：提供企业级的Java云服务，它是基于Weblogic的Java应用，每个WebLogic部署在一个虚拟机内。也提供支持其它JEE的应用环境，如scala, groovy, jypthon, jruby, 它们基于Docker容器部署。也支持对Node应用的部署。 数据库云：提供Oracle 11g与12c的数据库服务。 集成云：集成平台即服务(iPassS)，其中包括了Oracle集成云服务(ICS)、Oracle SOA云服务以及Oracle Cloud中的Oracle SOA套件与Oracle API Manager Cloud Service。 内容和协作云平台：个人感觉是就支持审批流程管理的文档管理云平台，像云盘一个共享文档，基于流程编排来文档审批。 移动云：提供统一的App开发MAF，针对多种平台，只需编写一个应用，可以运行在iOS、Android，支持本地或混合开发。  一天下来，感觉Oracle的垂直整合能力太强了，即使在PaaS领域，你也要什么，它就能给你什么。相比与我司的企业BG，在企业云整合能力与之相差太远了，不知要追赶多少年。可见预见，未来在云计算领域，公有云的领导者是AWS，私有云的领导者或许就是Oracle。IBM呢？Pure System与BlueMix在Oracle面前，感觉有点小打小闹了。
</content>
    </entry>
    
     <entry>
        <title>制作Archlinux Docker基础Image</title>
        <url>http://lanlingzi.cn/post/notes/2016/0410_archlinux_docker_images/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>Docker</tag>
        </tags>
        <content type="html"> 想在Mac本上使用Docker来运行Archlinux，家里安装的是长城宽带，无奈从docker hub下载Archlinux基础Image网速无法忍受。在国内的alauda.cn镜像中心搜索到有Archlinux基础Image，可能由于在Docker使用Archlinux国内人比较少，估计alauda.cn的CDN也没有缓存Archlinux基础Image，下载同样也是龟速，下载多次超时就放弃了。
正好个人还有一台老的笔记本安装了Archlinux，那何不自己做一个基础Image。说真的，还没有从零开始做过基础Image。在Docker hub搜索时发现有一个已有的脚本mkimage-arch.sh，于是把它做了些改造，制作过程记录一下：
 源修改为国内的阿里Archlinux镜像源，这个速度快，超赞。  默认安装openssh软件，可以通过ssh来连接Container。 增加一个入口脚本run.sh，在此脚本主配置sshd，并启动sshd。    这个过程看似简单，不过还是遇到一些坑，毕竟Archlinux最小系统与自己已安装的Archlinux在使用sshd上有些区别，不得不反复修改脚本，Build Image与Run Container来验证：
 先是采用systemd来启动sshd，在run.sh使用systemctl enable sshd是OK的，但systemctl start sshd却无法启动报找不到文件。 是systemd的配置问题，也没有再去深究，放弃systemd，于是又直接使用/usr/bin/sshd -D来启动sshd，发现还启动失败报没有sshkey。 再使用ssh-keygen来生成系统的ssh_host_*_key。 终于sshd可以正常启动了，但使用ssh -p &amp;lt;port&amp;gt; root@&amp;lt;host&amp;gt;来连接Container，发现报无权限。 于是又得修改/etc/ssh/sshd_config，让root可以ssh登陆。  修改之后的脚本已提交到个人github上，可以在这里下载，使用方式如下：
 前提Archlinux中也安装了docker引擎  # pacman -S docker # systemctl enable docker # systemctl start docker  以root用户执行mkimage.sh脚本  # ./mkimage.sh  制作完成之后，使用docker images查看，生成一个名为archlinux的images  # docker images REPOSITORY TAG IMAGE ID CREATED SIZE archlinux latest dc54036acaa4 About an hour ago 337.2 MB  使用如下命令生成一个container，容器名为arch1  # docker run -d --name -arch1 -p 2222:22 archlinux /run.sh  使用ssh登陆验证，ssh -p &amp;lt;port&amp;gt; root@127.0.0.1，默认密码是123456。 也可以使用命令docker exec -it arch1 bash来执行bash进入container操作。 </content>
    </entry>
    
     <entry>
        <title>软件架构一些感想</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/0319_arch_diathesis/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag>
        </tags>
        <content type="html"> 软件架构 软件系统架构不只是软件本身架构，它是一个全系统、全网络的架构，从层次上由低到高分为：
 程序架构 系统架构 产品架构 生态、商业模式的架构  任何一个架构师，都是需要重点解决某方面的尖锐问题，同时避免在不合适的场景下，一种技术、一类框架或一种架构模式被滥用。架构就需要对整体框定好范围与约束。
架构设计不可能面面俱到，要解决或是发挥关键路径上的资源合理有效的最大价值。一个好的架构，不会随着时间或业务的变换，而需要进行大的破坏性的变化。
架构演进 从互联网公司的角度来看，他们认为架构都是在实际应用过程中的生长，一开始就设计和实施面面俱到的架构是不符合互联网快速交付的方式的，不要过度设计，谁也不知道业务上线后业务量将会是一个什么量。
架构的演进过程基本是围绕着性能，可靠性，扩展性，安全性，容灾展开。而对于可靠性，他们认为故障是不可能避免的，失败可能是常态，核心是如何地减少故障对用户或系统产生的影响范围。要提供有损服务，在故障的情况下，保证核心服务，可能放弃一些其它的服务。
相对于电信业务，互联网公司的业务更侧重于用户体验，极致的响应速度与简单易用的体验是第一个设计原则。而电信业务传统是更侧重于可靠性，甚至零无损。
架构师素质 架构师要能充分理解用户需要，充分协调和利用资源，满足需求； 具备基本的方法论，敏锐的观察力，善于对事物的抽象，提炼，简化。同时由于架构涉及到范围广，需要能快速学习新知识，善于学习关键点，不能由于过多限于细节而影响精力分配。
架构师很多时间是技术决策，需要能勇于应对变化，积极改变，敢于挑战。能够将方案落地，从解决系统的具体问题出发，能解决别人看不清的问题，也同时需要具有战略眼光，看得更远。
架构是上层建筑，影响深远，所以架构师需要善于识别和消除高风险，要广泛地吸收不同的意见，头脑风暴，风险识别、评估。对于风险进行排序，对于高风险点进行原型验证，切不可纯理论的架构，做成空中楼阁。
 注：以上观点收集于公司内网某同事的输出，在此表示感谢。
</content>
    </entry>
    
     <entry>
        <title>Grub引导Win10</title>
        <url>http://lanlingzi.cn/post/notes/2016/0313_grub_win10/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>Win10</tag><tag>grub2</tag>
        </tags>
        <content type="html"> 个人有两台笔记本电脑，一台Sony安装Win10，平时给岳父上上网，自己使用比较少；另一台是MBA，自己在捣腾点代码，写点东西。今天心血来潮，想体验一个KDE的plasma 5，于是又来折腾Sony安装双系统。由于在使用MBA之前，也在Sony上安装过Archlinux，不过后来安装Win10，又把Archlinux删除了。这次的双系统，Linux还是选择Archlinux。
安装Archlinux按照Wiki一路下来很顺利，最后安装plasma，使用了一下，感觉也不够如此，可能是使用Mac OSX时间长了的原因。后面发现想回到Win10，发现Grub默认没有生成Win10的引导菜单。
我的Sony本本比较老，并不支持UEFI，所以系统选择安装Grub来引导。
# grub-install --target=i386-pc --recheck /dev/sda # grub-mkconfig -o /boot/grub/grub.cfg  采用grub-mkconfig生成的grub.cfg并没有引导Win10的菜单，解决方法如下。为了实现多系统启动，需要安装os-prober。进入到/etc/grub.d/目录下，发现存在30_os-prober文件，说明os-prober是安装的（pacman -S grub会自动安装）。
我的Windows分区是/dev/sda1。首先，找到Windows系统分区的UUID(bootmgr存放其上)。
# mount /dev/sda1 /mnt # grub-probe --target=fs_uuid /mnt/bootmgr 70B235F6749E84AE # grub-probe --target=hints_string /mnt/bootmgr --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  接着，将下面的代码添加到/boot/grub/grub.cfg中，注意替换其中的fs_uuid，即70B235F6749E84AE。保存grub.cfg文件，重启系统，在gurb菜单就可以看到Windows 10 (loader) (on /dev/sda1)项了。选择，成功进入win10。
### BEGIN /etc/grub.d/30_os-prober ### menuentry &#39;Windows 10 (loader) (on /dev/sda1)&#39; --class windows --class os $menuentry_id_option &#39;osprober-chain-70B235F6749E84AE&#39; { insmod part_msdos insmod ntfs set root=&#39;hd0,msdos1&#39; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 70B235F6749E84AE else search --no-floppy --fs-uuid --set=root 70B235F6749E84AE fi parttool ${root} hidden- drivemap -s (hd0) ${root} chainloader &#43;1 } set timeout_style=menu if [ &amp;quot;${timeout}&amp;quot; = 0 ]; then set timeout=10 fi ### END /etc/grub.d/30_os-prober ###  注：后经验证，grub-mkconfig无法扫描到win10，是由于少安装了os-prober。
# pacman -S os-prober  参考：GRUB_(简体中文)
</content>
    </entry>
    
     <entry>
        <title>软件设计原则</title>
        <url>http://lanlingzi.cn/post/technical/2016/0306_arch_principle/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件设计</tag><tag>软件架构</tag><tag>设计原则</tag>
        </tags>
        <content type="html"> 软件也像人一样，具有生命力，从出生到死亡，会经历多种变化。软件架构设计也不是一蹴而就的，是不断地演进发展。但为了能较好的发展，在软件设计时需要考虑一些原则。
清晰原则：使用简洁接口，简单部件组合  编程的本质就是要控制复杂度，后期维护会占用大部分的时间。 降低整体复杂度，用清晰的接口把若干简单模块组合成一个复杂的系统。 对外隐藏细节，“不要与陌生人说话”。 多数问题局限天一个局部，不要影响到全局。  小结：本质是分而治之，复杂问题简单化，抽象框架，有序组全。
清晰原则：清晰胜于机巧  代码直白易懂，代码是给人看的，不是给机器看的。 维护代码的人，其中也你包括你自己，善待代码，就是善待自己。 不要了一点性能提升而引入复杂的算法，不要为了炫耀技能而编写晦涩难懂的代码。 复杂晦涩的代码是Bugs的温床，高昂的维护成本将抵消可怜的性能提升。  小结：代码简洁晚懂，谨慎引入复杂度。
简洁原则：设计简洁，降低复杂  复杂问题简单化是一个设计者的能力体现，避免不必要的使用问题复杂化的因素。 在市场导向下，在不良的架构上很容易堆砌花哨无用的新特性，导致软件趋于复杂。 在进度压力下，不会做出各种折中的个性与不和谐的新特性开发。  小结：过滤排序需求，追求稳定简洁。
组合原则：组合，接拼，编排  把复杂问题分解为一条程序处理链条。 程序之间可以通信，前者的输出是后者输入。 通信方式尽量采用简单协议，并且与语言无关。 组合程序之间无内部状态依赖，互相独立，处理链上下游不做假设，可替换。  小结：面向微服务的设计。
透明原则：设计与实现分离可见  设计简单，包括流程、数据结构、接口，在代码级别容易理解。 支行时刻可通过输出信息或者接口查询运行状态，可控制程序是否正确运行。 执行调试链、健康状态可跟踪、可分析。  小结：简单设计，简明实现，状态监控。
吝啬原则：除非别无它法，不要编写庞大的程序  程序庞大包括两个方面：程序体积大与程序复杂而维护困难。 模块和函数尺寸都有一个上限，比如单模板代码10K，单函数100L。 导致程序庞大的因素：先天设计不良，后天维护增加新特性。  小结：合理设计，考虑扩展性，对庞大保护警惕。
吝啬原则：有的放矢，按需分配资源  若可能，当一个事情发生时候再分配资源，而不是预先分配，初始化时静态分配最小资源，随着业务动态增加资源分配。 异步消息环境下，消息通信带来上下文切换，代价高昂。 必要时对消息数据合并，打包发送，减少对网络资源的消耗。 业务处理与消息发送分离，数据组织独立，统一打包发送。 控制并发实例的数据，分批处理，防止下游过载各实例之间的恶性竞争通信资源。  小结：按需分配资源，珍惜消息通信机会。控制并发，避免消息突发。
健壮原则：健壮源于透明与简洁  软件在超过设计者设想的意外场景下也能够运行良好。 Bugs是一种异常，复杂性和特殊处理都是Bugs的温床。 逻辑透明，接口简单有助于减少Bugs，即使出现Bugs也容易排除。 软件设计时要考虑异常输入，边界条件，和过载场景。 软件模块之间要处理流程上考虑能务匹配，流控，过载保护。  小结：简单透明，处理能力匹配；考虑异常场景，提升健壮性；匹配上下游处理能力，闭环控制为主，开环控制为辅。
表示原则：把知识叠入数据，简化统一处理逻辑  数据抽象建模，使用数据之间的关联关系来体现业务逻辑，或者领域知识，使得业务处理逻辑代码简单一致稳定。 可通过修改数据模型可以支持新业务，逻辑处理代码不用修改。  小结：领域模型驱动设计，数据数据提练来描述业务本质。
缄默原则：只输出有用的信息  保持沉默，良好的行为是默默地工作，决不唠唠叨叨，碍手碍脚，程序也是如此。 输出大量无用的信息会耗费资源，淹没重要信息，干扰维护人员定位问题。  小结：沉默是金，惜时亦如金。输出的信息是必要的，有用的，不重复的。
补救原则：异常时候，干净退出，输出详细信息  当程序出现异常时，输出必要信息，使用简单方法结束。 宽容地接受，严格地发送，提升程序的容错能力。 程序要么正确执行，要么响亮倒塌。  小结：看待这个问题一分为二，选择异常恢复方法要保证对用户的业务逻辑影响最小为基本原则。因此并不是说所有的异常都是进程退出重启，有时可以告警，事件通知，让管理员来处理，给出明确的修复方案说明。
经济原则：宁花机器一分钟，不花程序员一秒  对于一个问题，选择算法的时候宁愿选择一个简单，但可能是效率低一些的算法，也不要选择一个性能好但复杂度很高的算法。 硬件的进步来弥补性能的下降，换来的是程序简单可靠，维护成本低。  小结：辩证地看问题，选择简单，把复杂留给机器，解放程序员。
生成原则：避免手工Hack，让程序去生成代码  人最不适合干大量重复细致的工作，或多或少都会出错，因此导致Bugs。 与此相反，计算机最适合干规则明确，重复枯燥的工作，而且不会出错。 对于一个规则明确的工作，一种可行的办法就是编写一个我程序，根据输入规则生成代码，让生成的代码去解决问题。  小结：分析规则，能按照规则生成代码，可检查发现问题。
优化原则：雕琢前先有原型，跑之前先学会走  90%的功能能够实现，比100%功能永远不能实现要好得多。 先求可行，再求正确，最后求快。 原型可能有效地解决关键技术，保证系统是可以实现的。 让客户看到可以执行的原型，对需求的理解更为准确，防止做无用功。 过早优化是万恶之源，过早地优化会破坏程序结构，代码与数据结构杂乱无章；过早优化不清晰系统瓶颈，局部优化破坏整体优化。  小结：性能是设计出来，不是优化来出来。
多样原则：拒绝封闭和唯一  系统开放，只有开放，才能进步，才能得到最为广泛的验证。 开放，可扩展，用户可定制，符合实际需求和获到高可靠性。  小结：系统开发，留给用户定制空间，毕竟需求具体多样性，我们不能穷尽，最终只有用户才能准确理解自己的需求。
同源原则：避免重复，数据同源  重复的代码不仅仅是浪费，也是Bugs的滋生之地。 出现大段代码重复，说明开发者缺少对代码控制与抽象提炼能务，优秀的工程轻易不会在进度压力下让步。 数据重复危害更大，一则浪费存储空间，二则容易出现不一致。 在性能允许的情况下，尽量共享数据或者按需订阅，避免全量订阅。 如果上述条件不具备，那么采用数据同源技术和一致性校验来保证数据的一致性。  小结：拒绝重复，必须重复的时候考虑通过工具同源和一致性校验。
扩展原则：设计时着眼未来，未来总比想象来得快  对于一个一次性的程序来讲，架构和设计只会带来成本上升，复杂度提高，与性能的下降。 当开发一个支持多种产品的软件平台，其生命周期可能是十年以上。用户的需求是不断地变化，硬件环境也是不断地变化。 只有适应变化，不能拒绝变化，可扩展性是软件非功能属性中，在大部分情况下排在可靠性，高性能之前  小结：不对外界进行假设，这些假设在时间面前都是脆弱的。
扩展原则：给雪球寻找一个核心  雪球都有一个内核，尽管可能是一粒不起眼的小石头。 常说软件要内聚，内聚需要核心。 微内核，插件化机制。框架即核心，框架之上定制好插件，构建系统。 从问题知识域发现稳定部分进行抽象提升，成为系统的框架。  小结：从框架的角度来看系统，框架之间的有机组合构建系统，系统的演化就是在框架稳定情况下增加替换相关的插件。
扩展原则：扩展就是少修改  软件可扩展性是有前提和应用场景的，不存在可以随意扩展的软件。 增加新功能做到不修改既有软件，代码无需修改，通过修改数据模型或者重新配置获得新特性。 修改集中在新增加的软件之上，也就是说在增加新特性时，对老代码封闭，对新代码新特性开放。  小结：系统开闭原则，修改对系统稳定不构成影响。
 注：以上内容参考了公司设计原则。
</content>
    </entry>
    
     <entry>
        <title>使用tmux</title>
        <url>http://lanlingzi.cn/post/notes/2016/0221_mac_tmux/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>Shell</tag>
        </tags>
        <content type="html"> 什么是tmux tmux是一个支持多会话独立运行的优秀的终端复用软件。它类似GNU Screen，自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。
tmux的使用场景 Mac自带的Iterm2很好用啊。既支持多标签，也支持窗体内部Panel的分割，为什么还要用tmux？
 与VIM配合使用，打造出更高效、更优雅的终端工具。尤其是在当前大屏幕显示器下，多标签和分割窗体，无缝跳转。既可使用vim来写代码，也可使用tmux来查询代码编译与支行结果。 提供了一个窗体组随时存储和恢复的功能。调试程序，开了一堆窗口。出去吃了个饭，发现SSH超时了，如果使用tmux就attach就能找回原来打开的那些窗口。  tmux的基本概念 tmux的主要元素分为三层：
 Session会话： 一组窗口的集合，通常用来概括同一个任务。session可以有自己的名字便于任务之间的切换。 Window 窗口： 单个可见窗口。Windows有自己的编号，也可以认为和ITerm2中的Tab类似。 Pane 窗格： 被划分成小块的窗口，类似于Vim中 C-w &#43;v 后的效果。  安装 在Mac环境下，先安装Brew，使用Brew安装tmux命令如下：
brew install tmux  使用 安装完成之后，在终端中直接敲入tmux就可启动一个 tmux 的会话。退出会话敲入 exit 即可退出当前会话Pane。可以使用 tmux detach 命令断开已有的会话。也可以使用快捷键 Ctrl-b d 断开会话
tmux 默认使用 Ctrl-b 作为激活快捷键的开关,开关开启后就可以通过快捷键迅速调用大量的功能。快捷键参考如下：
基础  ? 获取帮助信息  Session管理  s 列出所有会话 $ 重命名当前的会话 d 断开当前的会话  window管理  c 创建一个新窗口 , 重命名当前窗口 w 列出所有窗口 % 水平分割窗口 &amp;quot; 竖直分割窗口 n 选择下一个窗口 p 选择上一个窗口 0~9 选择0~9对应的窗口  pane管理  % 创建一个水平窗格 &amp;quot; 创建一个竖直窗格 h 将光标移入左侧的窗格* j 将光标移入下方的窗格* l 将光标移入右侧的窗格* k 将光标移入上方的窗格* q 显示窗格的编号 o 在窗格间切换 } 与下一个窗格交换位置 { 与上一个窗格交换位置 ! 在新窗口中显示当前窗格 x 关闭当前窗格&amp;gt; 要使用带“*”的快捷键需要提前配置  其他  t 在当前窗格显示时间  配置 像VIM一样，可以定制你的tmux。tmux默认会先从 /etc/tmux.conf 加载系统级的配置项，然后从 ~/.tmux.conf 加载用户级的配置项。也可以启动tmux时使用参数 -f 指定一个配置文件。配置包含如下几个配置项：
 自定义各种快捷键 自定义屏幕下方的状态条  如配置激活快捷键：
set -g prefix ^k unbind ^b  默认的tmux风格比较朴素甚至有些丑陋。如果希望做一些美化和个性化配置的话，建议使用gpakosz 的tmux配置。它的本质是一个tmux配置文件，实现了以下功能：
 基于powerline的美化 显示笔记本电池电量 和Mac互通的剪切板 和vim更相近的快捷键  </content>
    </entry>
    
     <entry>
        <title>软件架构设计</title>
        <url>http://lanlingzi.cn/post/notes/2016/0215_about_soft_arch/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>软件架构</tag>
        </tags>
        <content type="html"> 什么是软件架构设计 依稀记得公司的软件架构培训材料中说到软件架构=组件&#43;交互。最近读温昱的《软件架构设计》才知道这只是其中一大阵营的观点。而软件架构在定义上分为“组成派”和“决策派”两大阵营。“组成派”认为软件架构是将系统描述成计算组件及组件之间的交互；而“决策派”认为软件架构包含了一系列的决策。事实上，从我司实际操作来看，两种观点并不是互斥的，而是相辅相成。两种观点只是站在不同的角度来看待软件架构。架构师在分割组件模块时，选择备选方案时，也是会不得不去作出各种决策，架构没有最完美的，只有在特定场景需求下最合适的。
“组成派”的两个明显的特点：
 关注架构实践的客体——软件，以软件本身作为描述对象。 分析了软件的组成，说明软件不是一个‘原子’意义上的整体，而是有不同的部分经过特定的接口进行连接组成的一个整体，这对软件开发来说很重要。  “决策派”的两个明显的特点：
 关注软件架构中的实体——人，以人的决策为描述对象。 归纳了软件架构决策的类型，指出架构决策不仅包括关于软件系统的组织、元素、子系统和架构风格等几类决策，还包括关于众多非功能性需求的决策。  按照“组成派”的观点，软件架构关注的是软件整体的分割和交互，之所以分割，是因为不同的部分在逻辑或物理上相对独立，通过“分而治之”的原则进行分割可以更好的理解整个系统，把握用户的需求，但是虽然整个软件可以分割成多个模块或子系统，但是模块和子系统之间的通信和交互也是很重要的。按照这种观点，架构师的主要任务是将软件分割成不同的模块，并定义模块之间的接口。
按照“决策派”的观点，软件是一个在很多限制下产生的产品，这些限制包括用户和技术两方面，用户方面包括功能需求、性能需求、硬件需求等，技术方面包括技术选择、可扩展性、可重用性、可维护性等。按照这中观点，架构师的主要任务就是作出上述个各种限制作出选择或决策，是一系列的有层次的决策。
软件架构设计的质量属性 按照“决策派”的观点，软件架构并不仅仅关注软件本身的结构和行为，还注重其他特性：使用、功能性、性能、弹性、重用、可理解、经济以及技术的限制和权衡等。
软件架构设计中需要考虑软件的质量属性，也是上述所说需要权衡与决策的。质量属性可归类为三类：
 软件系统本身的质量属性：可用性，可维护性，高性能，安全性，可测试性，易用性。 软件系统的商用属性：上市时间，成本与收益，目标市场，生命周期，系统生态。 架构本身的质量属性：概念完整性，正确性，可理解性，可构建性。  如何描述质量属性需求呢？一般采用质量属性场景作为一种规范。 质量属性场景是一种面向特定的质量属性的需求。它由六部分组成：
 刺激源：这是某个生成该刺激的实体（人、计算机系统或者任何其他刺激器）。 刺激：该刺激是当刺激到达系统时需要考虑的条件。 环境：该刺激在某些条件内发生。当刺激发生时，系统可能处于过载，或者运行，也可能是其他情况。 制品：某个制品被刺激。这可能是整个系统，也可能是系统的一部分。 响应：该响应是在刺激到达后所采取的行动。 响应度量：当响应发生时，应当能够以某种方式对其进行度量，以对需求进行测试。  软件架构设计的原则  全面解耦合原则：对业务进行抽象建模，业务数据与业务逻辑解耦，软件件与硬件解耦，平台与产品解耦，系统各部件之间解耦。 服务化、组件化原则：以服务，数据为中心，构建服务化，组件化的架构，具备灵活，按需组合的能力。 隔离与自治原则：通过接口隐藏服务、组件的实现细节，服务与组件之间只能基于接口交互，接口契约化、标准化。跨版本兼容；服务、组件可独立发展，独立发布，独立升级。服务自治，可视，可管，可控，可测，可维，故障自愈。 弹性伸缩原则：构建全分布式云化架构，或借鉴云化架构思想，每个服务具备横向扩展能务，支持按需使用、自动弹性伸缩，可动态替换，灵活部署，支持高性能、高吞吐量、高并发，高可用业务场景。 安全可靠原则：构建最小的权限、纵深防御、最小公共化、权限分享、不轻信、开放设计、完全仲裁、失效安全、保护薄弱环节、安全机制经济性、用户接受度以及加强隐私保护的安全体系，确保系统、网络、数据的机密性，完整性、可用性、可追溯。业务系统零故障为导向，按需构建分层分级的可靠性，通过故障的预测、预防、快速恢复，避免故障的发生。 高效开发原则：创建支持迭代、增量、持续交付的架构，支持部件可独立开发，自动化编译构建、测试、集成验证，并易于高效修改与持续优化；支持开发组织小型化、扁平化，支持小团队独立高效并行开发。 持续演进原则：架构并非一蹴而就，需要有效地管理架构需求，持续构建和发展架构，适应业务需求变化，适时引入业界最佳实践，及时重构，确保架构生命力和竞争力。   参考材料：
 温昱的《软件架构设计》 软件体系结构的质量属性 华为产品架构设计原则  </content>
    </entry>
    
     <entry>
        <title>软件开发知行合一</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/0131_unity_knowledge_action/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 最近在走读团队的代码，有时实在是看不下去。不是因为他们的代码编写有很多Bugs，而是没有设计实现太复杂了。当面对众多的需求需要快速实现，没有几个人会去思考代码怎么写结构才更合理，而是在不断去搬砖垒需求。当我去咨询他们为什么要这样实现时，每个人能只能说出一，不知其二。即使自己写的代码，也不知道当初为什么这么实现。
同时，我们团队中不乏有各种兴趣小组。例如学习新的技术框架，交流设计模型，讨论重构技巧、性能优化经验。而实际在操作层面上，代码却正如前面所讲，有时真的不堪入目。由于这近在看王阳明传，突然想到我们没有知行合一啊。
知 ：一方面是我们对技能掌握，如程序语言知识，设计模式，框架类库等；另一面是我们对需求理解，如场景梳理，用例分析，关键指标等。 行 ：能根据掌握的知识技能，以及对需求的认识应用于项目中，能过代码转化为实际客户所需的产品。
结合按王阳明的学说，做为一名合理的软件工程师，则需要格物致知，知行合一，良知和致良知。
  格物致知 ：
  格需求。对需求不断地格，才能知道客户真正需要什么。因为客户的提出需求时，往往是感性的，非技术化的描述，也可能是模糊不清晰的。那就需要我们不断去交流与探讨，才能明白客户的痛点，进而知行合一，指导你编码，做出满足客户真正需要的东西。
  格技术。软件开发会涉及到很多的知识，尤其是大型的项目。我们面对操作系统，各种框架程序，以及各种软件工程方法。我们需要不断地格，去深入探本究源，明白什么场景下，使用什么技术是最优的。
  知行合一 ：
  知而为行。知行合一很好理解了，简单的就是“知”和“行”统一。理论与实践想结合，一切的实践行动又必须有理论支撑。所想即所写，所写即所需。你能编写出来的代码才是真正知道的需求，你真正知道的需求你就一定能编写出来代码。
  行而促知。我们不断地学习与交流，本身没有什么问题。其实如果没有实践的切身体验，是难以有较深的认知的。往往是学完也说不出一个所以然。知行合一，学习必须时刻结合实践行动，这样才能真正的掌握并不断的进步。
  良知和致良知 ：
 良知。良知是人内心深处的心声。软件开发的良知是程序员做事的标准。显然，不断地只按需求去垒代码不是标准，能跑起来的代码也不是标准。软件开发的标准可能很多，不同的人有不同的看法。但一个团队一定要代码编写标准化，开发流程标准化。没有规矩成不了方园，标准化才能提高我们的效率。 致良知。找到标准（良知），然后去做到知行合一（致良知）。如果程序的良知是优秀的代码，那致良知就是我们不断地为实现优秀的代码去努力。优秀的代码涵盖代码的可读性，可理解性，同时还需要兼顾代码的可扩展性，可维护性。不要对自己编写的代码放任不理，识别代码的坏味道，编程的过程实际是一个不断重构改进的过程。古人说“三日省吾身”，编程也需要不断地反思。   </content>
    </entry>
    
     <entry>
        <title>重构已死</title>
        <url>http://lanlingzi.cn/post/technical/2016/0123_refactor_death/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件重构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 上周在食堂吃饭，遇到同事聊起最近的系统重构，她说这一批的新员工不如13年的一批，就一个看似简单的问题也是折腾很久，重构的周期越拉越长。我作为这次的重构的特性SE，可以说也是硬着头皮上。我是越来越反感重构，尤其是涉及到多个模块的重构。在新年的聚餐上，我说我给你挖了坑，你来填坑，让我感到非常惭愧的，即又不得做这些事。
在现阶段项目交付变得越来越难，一方面我们面对众多的需求，做还是不做并不是你能轻易决定的；而另一方面我们又想从架构上解决可以快速满足需求。但本质的是这几个月内，人的技能与意识没有根本性的变化。在大家没有主人翁的精神下，说来说去也是为了需求在垒代码。即使你想从代码结构上重新设计，让系统更松的耦合性，更好的扩展性。受于项目进度冲击，以及代码实现者的被动，最终也会变得让你不想回头多看一眼。
编程如果仅仅越考虑短期实现项目需求目的肯定是不好的，但想通过强制的管理手段，或重构手段来想延长它的生命周期也并一定能行得通。当同一份代码是多人开发与维护，并在领导眼中的谁有时间谁就上的话。本意可能是想通过多人的备份，或共同完成以期缩短工期。其实这种做法无疑更是加重了代码朝腐化之路上走的趋势。
重构有很多的手法或方法理论，其核心都会有提到不改变软件的外部行为，是对软件内部结构进行修改与调整。这实际上是非常难以做到的，我们是如何去评估不改变软件的外部行为，充分的测试能保证吗？显然就我们目前的测试能力来看，这简单是非常美好的梦想。尤其是具有一些年头的代码，或者又是人员变化较频繁的代码，看上去并不清爽的代码，至少还能正常的工作，一旦重构不知会丢失多少其中通过各种手段修改出来的小功能点。
今天的软件交付，可能说由于整体的需求是具有多变性，给软件开发带来不确认性。不确定就会产生怀疑和恐惧，我们经常会说，软件架构是要架构未来，不是解决当下问题。当不确定性还不算太多的时候，我们还在架构层面上来推演，整个软件系统的大致方向可以被预测，然后在此基础上不断地演化。而当不确定性实在太多的时候，对软件的要求就变成了可丢弃。换句话说，你开发的所有软件，从一开始，你就应该做好很快被丢弃的准备。
  采用开源：尤其是Github让开源的推广与使用变得越来越简单，开源软件在商用软件领域成为了越来越主流。即使你开发的是非常重要的商用软件也不需要自己从头开始，自己实现并一定比开源实现的好。
  平台框架：平台软件的目的是让通用的能力重用与沉淀。业务领域更倾向于采用面向领域的DSL描述简化开发，代码量要求是越来越少。目前各种基础框架越来越成熟，基于基础构架上构建，可以在最短时间内以最少代码量做出一个符合要求的软件。并且业务层不需要过多的设计，因为大部分设计已经蕴含在框架内。
  职责单一：可以把系统拆多功能单一的服务，符合单一职责原则，做且仅做一件事。这样代码量就不会太多，也不需要频繁地添加新的功能，变化少就不不会导致不稳定，所以这样代码烂也烂不到哪里去。另一方面功能单一，在其上的工作团队成员也会很少，四五个人能搞定的代码，它的也不会因为多人的经手变得不可维护。
  在面对需要快速迭代交付的项目下，软件开发变得越来越轻量化下。尤其是在微服务架构下，软件开发其实可以不需要重构，该烂的就让它烂掉。对于单个微服务或单个小的模块内的代码重构意义也变得越来越小。如果这个微服务真的到了无法满足需求情况下，那没有必要对它进行重构，重写一个就行了。所以在这样的情况下“重构已死”，其实又是系统中另外一种“重生”，就像人的身体一样，做换只手的手术可能影响非常地大，如果只是细胞不断地死去，新的又产生替换，你是感觉不到有什么影响。
</content>
    </entry>
    
     <entry>
        <title>Taipei-Torrent源码分析</title>
        <url>http://lanlingzi.cn/post/technical/2016/0117_torrent_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Torrent</tag><tag>Go</tag><tag>P2P</tag>
        </tags>
        <content type="html"> 提到P2P，总会少不了BitTorrent。BitTorrent是一种P2P协议。BitTorrent协议是由程序员Bram Cohen在2001年四月份设计的，最终版本在2008年确定。
BitTorrent协议简介 一个BitTorrent的文件在网络传输过程，由以下几个部分组成：
 WEB服务器 文件元信息(metainfo) BitTorrent Tracker 原始资源发布者 目的端用户浏览器 目的端用户下载者  其中原始资源发布者与目的端下载者都称为Peer，而Tracker主要用于获取不同的Peer信息信息，BitTorrent把要下载文件虚拟分成大小相等的块，并把每块的索引信息与Hash验证码等元数据信息写到一个.torrent文件中，即种子文件。种子文件采用B编码格式，它本质是一个文本。Peer与Tacker或DHT节点通讯也采用B编码格式。根据获取Peer信息的途径不同，又分为两种。
 有的Tracker结构  [WebServer] | | torrent file | [ Peer ] ---Get Peers --- [TrackerServer] \ \ Download&amp;amp;Upload(TCP) \ \ [ OtherPeer ]  Trackerless的DHT结构  [WebServer] | | torrent file | [ Peer ] ---Get Peers --- [DHT Nodes] \ \ Download&amp;amp;Upload(TCP) \ \ [ OtherPeer ] Trackerless的DHT结构解决了Trakcer中心故障的问题，是一个更去中化的结构。DHT结构中，每个peer都可能是一个tracker。DHT是基于Kademila协议的，并且在UDP协议基础上实现。
每个节点都有一个全局唯一的标识符，称为节点ID。距离度量用来比较两个节点或者节点与infohash之间的远近程度。节点必须维护一个含有少量其他节点联系信息的路由表。ID越靠近自身ID时，路由表越详细。节点知道很多离它很近的节点，只知道少量离它很远地节点。
在Kademlia中，距离度量采用异或计算，结果解释成一个无符号整数。 distance (A,B)=(A ~| B)，值越小，距离越近。每个节点维护一个路由表，由它所知道的好节点组成。路由表中的节点被用作在DHT中发送请求的起点。当其他节点查询时，就返回路由表中的节点。
开源实现 C&#43;&#43;语言 实现BitTorrent协议最有名要算两个C&#43;&#43;的实现：
 rakshase 版本：他来源于Mozilla NSS的项目，LICENSE是GPL，使用它的客户端亦rtorrent等，基于Posix接口开发，可以在兼容Posix系统中编译使用，也支持HDT。这个项目已有12年了，目前还在发展，可以是非常的稳定与成熟，据说是速度之王。 rasterbar(arvidn/libtorrent)版本，GitHub上有两个地址，另一个是libtorrent/libtorrent。前者是还是发展，后者已停止开发了。rasterbar版本是基于boost asio编写的，跨平台不存问题。默认有Python与Ruby的绑定接口。并且具有良好扩展性，例如有uTP，DHT安全扩展  Go语言 由于个人爱好的原因，一真想找是否有Go语言实现版本，于是在GitHub上寻寻觅觅，也找到两个不错的实现：
 Taipei Torrent：它一个较轻量的，基于命令行接口的Torrent客户端，主要功能有支持多Torrent文件，Magnet链接，DHT，UPnP/NAT-PMP打洞，也提供简单的tracker服务。 anacrolix/torrent: 它实现了BitTorrent协议相关功能包，以及提供较丰富的命令行工具集。支持加密协议，DHT，PEX，uTP以及多种扩展。从代码结构来说，anacrolix/torrent比Taipei Torrent更容易做二次开发。  Taipei Torrent 首先它的名字比较有意思，项目开始于作者在台北的旅游，所以取名为Taipei Torrent。它的代码量比较不多，像Bencode，DHT，NAT-PMP，网络工具包都采用第三方库。
代码结构 Taipei-Torrent git:(master) tree ├── main.go ├── queryTracker.bash ├── resolveBindIP.go ├── resolveBindIP_test.go ├── test.bash ├── testData │ ├── a.torrent │ └── testFile ├── testdht.bash ├── testswarm.bash ├── testtracker.bash ├── torrent │ ├── accumulator.go │ ├── accumulator_test.go │ ├── bitset.go │ ├── cache.go │ ├── cache_test.go ....... │ ├── upnp.go │ ├── uri.go │ └── uri_test.go └── tracker ├── tracker.go └── tracker_test.go 源码分析 花了一个下午走读它的代码，代码简洁易懂，主要功能都在torrent目录下。每个Peer对一个torrent文件会产生一个会话，在我的笔记本记，使用Docker搭建了6个节点，发布下载77M的go的安装包，是秒级速度。如下所示：
2016/01/17 12:13:13 Starting. 2016/01/17 12:13:13 Listening for peers on port: 7777 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Tracker: [], Comment: , InfoHash: 556871e1ada306c2da5033e8fe0d4f077edbe6f7, Encoding: , Private: 0 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Computed missing pieces (0.35 seconds) 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Good pieces: 0 Bad pieces: 1223 Bytes left: 80147269 2016/01/17 12:13:13 Created torrent session for go1.5.3.linux-amd64.tar.gz 2016/01/17 12:13:13 Starting torrent session for go1.5.3.linux-amd64.tar.gz 2016/01/17 12:13:14 [ go1.5.3.linux-amd64.tar.gz ] Peers: 0 downloaded: 0 (0.00 B/s) uploaded: 0 ratio: 0.000000 pieces: 0/1223 作为Peer Client，主要代码逻辑在torrent\torrentLoop.go的RunTorrents方法中，它充分利用了Go的channel机制。实现步骤如下：
 根据命令参数，开启Peer连接端口（TCP）。若不指定端口，则采用随机端口。目前是绑定在所的IP上，如果是内网，可以做NAT转换。 根据MaxActive参数，开启Session（对象为TorrentSession）数，如果同时下载torrent多余MaxActive则排队处理 如果设置参数useDHT，或torrent文件中没有Tracker服务，则会开启DHT，而DHT是采用UDP，端口与第1步的相同。 如果设置useLPD（Use Local Peer Discovery），则又会通过组播在同一个网段内相互发现，组播地址为239.192.152.143:6771。 当完成上述初始化之后，在mainLoop主要根据事件来处理： 1. 如果是Session创建成功，则异步执行TorrentSession.DoTorrent方法开始启动下载 2. 如果是有Session下载结束，则从排队中取出未处理的torrent文件加入到Session处理。 3. 如果是收到退出信号，则等下载结束退出。 4. 如果是收到其它Peer的连接请求，根据Infohash来判断是否存在相应的Session，如果存在，则提供给其它的Peer下载数据。 5. 如果是收到DHT Peer的请求结果，则处理其它的Peer地址，根据地址从其它Peer下载数据。 6. 如果是收到其它Peer的组播请求，则处理其它的Peer地址，根据地址从其它Peer下载数据。  另一个核心代码逻辑是在torrent\torren.go的DoTorrent方法中，实现步骤如下：
 如果设置了内存缓存或硬盘缓存数，则根据torrent文件中元信息（块个数，整个大小）初始化缓存。 开启几个定时器，每隔1秒心跳检查，每隔60秒连接KeepAlive，如果采用Tracker服务，每隔20秒与Tracker服务列表请求，直到有Tracker服务有咱应。 如果是DHT，则从DHT Peer获取其它的Peer地址。 处理各种Channel的消息。  还一个重要的torrent\torren.go的DoMessage方法，它用于是产生协议的消息，与一个peer建立TCP连接后，首先向peer发送握手消息，peer收到握手消息后回应一个握手消息。握手消息是一个长度固定为68字节的消息。消息的格式如下：
[pstrlen][pstr][reserved][info_hash][peer_id]    参 数 含 义     pstrlen pstr的长度，该值固定为19   pstr BitTorrent协议的关键字，即“BitTorrent protocol”   reserved 占8字节，用于扩展BT协议，一般这8字节都设置为0。有些BT软件对BT协议进行了某些扩展，因此可能看到有些peer发来的握手消息这8个字节不全为0，不过不必理会，这不会影响正常的通信   info_hash 与发往Tracker的GET请求中的info_hash为同一个值，长度固定为20字节    对于除握手消息之外的其他所有消息，其一般的格式为：
[length prefix][message ID][payload] length prefix（长度前缀）占4个字节，指明message ID和payload的长度和。message ID（消息编号）占一字节，是一个10进制的整数，指明消息的编号。payload（负载），长度未定，是消息的内容。
  keep_alive消息：[len=0000]
keep_alive消息的长度固定，为4字节，它没有消息编号和负载。如果一段时间内客户端与peer没有交换任何消息，则与这个peer的连接将被关闭。keep_alive消息用于维持这个连接，通常如果2分钟内没有向peer发送任何消息，则发送一个keep_alive消息。
  choke消息：[len=0001][id=0]
choke消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。
  unchoke消息：[len=0001][id=1]
unchoke消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。客户端每隔一定的时间，通常为10秒，计算一次各个peer的下载速度，如果某peer被解除阻塞，则发送unchoke消息。如果某个peer原先是解除阻塞的，而此次被阻塞，则发送choke消息。
  interested消息：[len=0001][id=2]
interested消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。当客户端收到某peer的have消息时，如果发现peer拥有了客户端没有的piece，则发送interested消息告知该peer，客户端对它感兴趣。
  not interested消息：[len=0001][id=3]
not interested消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。当客户端下载了某个piece，如果发现客户端拥有了这个piece后，某个peer拥有的所有piece，客户端都拥有，则发送not interested消息给该peer。
  have消息：[len=0005][id=4][piece index]
have消息的长度固定，为9字节，消息长度占4个字节，消息编号占1个字节，负载为4个字节。负载为一个整数，指明下标为index的piece，peer已经拥有。每当客户端下载了一个piece，即将该piece的下标作为have消息的负载构造have消息，并把该消息发送给所有与客户端建立连接的peer。
  bitfield消息：[len=0001&#43;X][id=5][bitfield]
bitfield消息的长度不固定，其中X是bitfield(即位图)的长度。当客户端与peer交换握手消息之后，就交换位图。位图中，每个piece占一位，若该位的值为1，则表明已经拥有该piece；为0则表明该piece尚未下载。具体而言，假定某共享文件共拥有801个piece，则位图为101个字节，位图的第一个字节的最高位指明第一个piece是否拥有，位图的第一个字节的第二高位指明第二个piece是否拥有，依此类推。对于第801个piece，需要单独一个字节，该字节的最高位指明第801个piece是否已被下载，其余的7位放弃不予使用。
  request消息：[len=0013][id=6][index][begin][length]
request消息的长度固定，为17个字节，index是piece的索引，begin是piece内的偏移，length是请求peer发送的数据的长度。当客户端收到某个peer发来的unchoke消息后，即构造request消息，向该peer发送数据请求。前面提到，peer之间交换数据是以slice（长度为16KB的块）为单位的，因此request消息中length的值一般为16K。对于一个256KB的piece，客户端分16次下载，每次下载一个16K的slice。
  piece消息：[len=0009&#43;X][id=7][index][begin][block]
piece消息是另外一个长度不固定的消息，长度前缀中的9是id、index、begin的长度总和，index和begin固定为4字节，X为block的长度，一般为16K。因此对于piece消息，长度前缀加上id通常为00 00 40 09 07。当客户端收到某个peer的request消息后，如果判定当前未将该peer阻塞，且peer请求的slice，客户端已经下载，则发送piece消息将文件数据上传给该peer。
  cancel消息：[len=0013][id[=8][index][begin][length]
cancel消息的长度固定，为17个字节，len、index、begin、length都占4字节。它与request消息对应，作用刚好相反，用于取消对某个slice的数据请求。如果客户端发现，某个piece中的slice，客户端已经下载，而客户端又向其他peer发送了对该slice的请求，则向该peer发送cancel消息，以取消对该slice的请求。事实上，如果算法设计合理，基本不用发送cancel消息，只在某些特殊的情况下才需要发送cancel消息。
  port消息：[len=0003][id=9][listen-port]
  port消息的长度固定，为7字节，其中listen-port占两个字节。该消息只在支持DHT的客户端中才会使用，用于指明DHT监听的端口号，一般不必理会，收到该消息时，直接丢弃即可。
 注：Taipei Torrent未实现此消息
   extension消息：[len=0009&#43;X][id=20][payload]
extension消息消息的长度不固定，消息Id为20， Taipei Torrent来来与其它的Peer交换torrent文件的元数据信息（每块Pieces的信息），同样采用B编码格式。
 </content>
    </entry>
    
     <entry>
        <title>软件分发加速</title>
        <url>http://lanlingzi.cn/post/technical/2016/0116_speed_sw_distribute/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag><tag>Multicast</tag><tag>P2P</tag>
        </tags>
        <content type="html"> 背景 在云环境下，服务器（物理机）或虚拟机越来越多，存在同一个应用软件需要大规模地部署场景。传统的方式下是搭建一个软件仓库，由物理机或虚拟机节点直接从软件仓库下载。如果采用sftp或http协议，则只能做到从一个中心软件仓库分发软件包给其它的节点，若给上百台的节点同时分发同一软件包，则存在受带宽、负载限制等因素，导致分发的速度就会比较慢。
常用技术 组播 传统的IP通信有如下三种方式：
 单播（Unicast）：源主机与目的主机之间点对点的通信。 广播（Broadcast）：源主机与同一网段中所有其它主机之间一点对多点的通信。 组播（Multicast）：源主机与一组目的主机之间一点对多点的通信。与广播不同的是组播组中的所有接收者都可收到同样的数据拷贝，并且只有组播组内的主机可以接收该数据，而其它主机则不能收到。  组播技术有效地解决了单点发送、多点接收的问题。所以组播非常适合运用在云环境下的软件分发场景，单点到多点的高效数据传送，能够大量节约网络带宽、降低网络负载。
一般情况下，在二层网络中，交换机会默认开启组播，但会对组播带宽进行抑制，防止网络风暴造成的影响。在实现应用中可以在交换机上设置合适的组播带宽。如果组播需要跨二层网络，需要在路由器上开启组播路由协议。
组播组内的所有主机共享同一个地址，这种地址称为组播地址。组播地址是范围在224.0.0.0~239.255.255.255之间的IP地址。此范围内的所有地址的前4个二进制为都是“1110“。组播地址也被称为D类IP地址，与其它的A类、B类和C类地址相区别。组播组是开放的，主机可以在任何时候进入或离开组。 IANA(Internet Assigned Numbers Authority)组织负责分发永久组播地址。
由于组播地址是开放的，在实现组播服务，需要在上层设计加入组播的认证机制，如采用IP白名单，或在自定义上层协议，会话协商时进做登录认证。
组播是采有UDP，与单播UDP不同，前者必须考虑TTL(Time to live)值，它用IP数据包的头部的一个字节表示。 TTL通过限制IP包被丢弃前通过的路由器数目，来决定IP包的生存时间。IP包每通过一个路由器，TTL就减一，当TTL变为0，这个包就被丢弃。 TTL的一个作用是防止配置有误的路由器把包在路由器之间无限的来回传递，还有一个作用是限制组播的地理范围。
由于UDP不可靠，会存在丢包的情况，在设计组播服务需要考虑对传包个数与内容的校验，以及重传机制，或者在最坏的情况，采用TCP的补偿传输。通常的做法是在另开TCP连接来控制组播的传输质量，而UDP是负责数据流。
Java在1.7中，已支持MulticastSocket API。API比较低层，需要结合NIO一起使用，另外JGroup与Netty也对组播有更高层的封装。
P2P P2P(Peer to Peer)端到端传输模型，与传统的C/S（Client-Server）模型相对应的。P2P与C/S都是单播。但C/S是集中由Server端来分发中转，所以当多个节点从Server下载软件时，对Server的流量与性能影响最大。而在P2P网络中，每个节点都是对等的。网络中的每个节点既能充当网络服务的请求者，又对其它节点的请求作出响应，提供资源和服务。
P2P组网按是否有中心索引节点来分有三种：
 集中式P2P：存在中心服务器，保存所有节点信息与资源信息，其它节点通过它找到需要连接的节点与资源。 无结构化P2P：节点同时作为客户端和服务器端，无中心服务器，无中心路由器。 结构化P2P： 将网络中所有资源整理成一张巨大的表，表内包含资源的关键字与存入节点地址，这张表裸眼分割分别存储到网络中每个节点中。结构化组网常见有三种：  DHT结构 树形结构 网状结构    在实现P2P技术中，需要考虑如下几点：
 可控性：由于P2P流量特征具有上下行流量对称的特性，这使得直接面向用户的接入网络需要相应提高所能承载上行流量的能力。 安全性：P2P相对随机的端口号，难以实话实行有效地监测和管理，加大了日常维护的难度。 效率性：对等的节点需要尽快地得到所需要文件块，需要有机制查找出节点已有文件块信息。 可靠性：不能存在文件块永久丢失的情况，必须存在源节点是可靠的。  所以，在私有云环境下的软件分发，需要同时考虑安全与可靠性。一般是采用集中式P2P，存在中心服务器，只不过这个中心服务器可以是集群的。每个节点与中心服务器建立控制连接，什么节点下载什么软件，从哪些节点来下载软件，由中心服务器根据不同节点的负载来做出决策。利用近播原则、分域调度的思想来尽可能控制P2P流程对网络节点的影响。
实施建议 在我们的实际测试中，一个400M软件包，100个节点的分发场景下，组播速度大约是P2P的5倍右右。但组播只能在一个二层网络中，如果跨二层网络需要在路由器上开启组播功能。而一般出于安全等多因素考虑，路由器会禁掉。P2P在安全与可靠性更难以控制，以及会对网络节点的产生影响，甚到会影响节点的业务正常的性能。所以优先是选择组播，如果存在跨二层网络，可以部署多套软件仓库。P2P可以运用在组播不能使用，以及节点并发初始部署软件时，而节点上已运行业务时，则需要从P2P网络退出，不能长期做来提供服务的节点。
</content>
    </entry>
    
     <entry>
        <title>如何看待Docker</title>
        <url>http://lanlingzi.cn/post/technical/2016/0107_docker/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag>
        </tags>
        <content type="html"> 从国内来看，从14年的发迹，到15年的红火。基于Docker的国内创业公司不停的涌现，Docker的概念不断地炒作。软件界似乎人人在谈论Dcoker，给我的感觉就像中国大妈跳广场舞一样，歌声大，动作乱，到底有没有用，难说。毕竟Docker只是一项技术，技术是否能成功应用，给你的产品带来价值才是最重要的。下面是个人一些对Docke的看法与见解，可能有不对之处，望交流赐教：
标准化是基础 从对Linux的贡献角度来说，Docker并没有什么技术创新。但为什么它会得到如此众多的追捧，主要他得益它制定了标准。尤其是我所在电信行业感受最深，真是得标准得天下：
 容器镜像：软件的交付件标准化，使得软件在云环境中的构建，发布，运行，迁移，复制等软件分发变得更加容易。 容器引擎：容器操作方式标准化，提供标准的Rest API，使得对容器的创建，删除，启停等生命周期管理更简单。  简单就是生产力 我们再来看Docker的诞生，它是来源于Docker公司前身dotCloud的实践，出发点是为了解决如何帮助开发人员实现软件的快速打包，部署。其实也就是目前大家都在说的CICD，通过统一的格式来提升打包，测试，部署的效率。所以大家看到Docker宣传的“Build，Ship，Run”，也就说它最大的特点，简化了开发到部署操作，极大地提高的软件开发验证效率。
会带来什么价值 除前面的提高软件的开发验证效率，它还能给出我们带来什么价值？首先，Docker屏蔽了软件运行环境差异，这个怎么理解呢？因为它的镜像具有便携性，一致性的特点。这极大地简化了软件在部署过程由于环境的差异带来的不确认性。其次Docker本身就是一种OS容器技术。而OS容器是基于操作系统内核的虚拟化，是一种轻量的虚拟化。相比于Hypervisor的虚拟化技术，它没有指令转化这一层，只是共享主机内核，划出不同的Namesapce。在计算能力上它是没有什么性能损耗的。容器可以运行在物理机或虚拟机之上，不依赖于虚拟化软件。所以它的价值主要体现在两大方面：
降成本（相比Hypervisor）  基于Hypervisor虚拟化的应用性能下降比较高，尤其是IO密集型，同等性能指标需要消耗更多的资源。 采Hypervisor虚拟化技术，License费用支出高，虚拟化管理软件也有成本支出。 Hypervisor虚拟化对资源划分粒度比较大，而容器可以更细粒度你分割资源，可以提整体资源利用率。 虚拟机镜像大（以G为单位），启动慢（分钟级）；而容器镜像相对小（以M为单位），启动快（秒级），应用可以快速伸缩，降低维护成本 容器能快速创建与销毁，可以应用在一些短任务的业务（如大数据分析），长短任务的业务混合部署，错峰填谷来提升资源利用率。  加速创新  改变软件的交付模式：CICD变得更加容易，可以使软件快速开发、上线、验证。软件开发迭代周期缩短，试错风险小，加速业务的创新能力。 改变软件的架构模式：容器即完整执行环境，可以使用软件“微”服务化，服务之间能够快速组合和重构，提升业务的创新能力。  网络与存储 相对于传统的虚拟化来说，包括三个方面，计算虚拟化，网络虚拟化，存储虚拟化。映射到容器技术上来说，计算能力就是Docker引擎，而网络则是容器网络管理，存储则是容器卷管理。Docker在容器管理上是相对比较成熟的，但在网络方面目前还是相对比较弱，Docker现有的网络模型主要是通过使用Network namespace、Linux Bridge、Iptables、veth pair等技术实现的。Docker提供了四种网络模式：
 host模式： 容器和宿主机共享Network namespace。没有网络隔离，多容器需要规划端口，适合不需要动态调度的静态部署使用Docker。 bridge模式： Bridge模式是Docker的默认模式，即NAT方式，容器网卡从docker0网桥所在的IP网段中选取一个未使用的IP，容器端口映射到主机上。性能下降15~20%，对网络性能与时延敏感的应用不适合。 container模式： 容器和另外一个容器共享Network namespace。kubernetes中的pod就是多个容器共享一个Network namespace。这些方式有它特定的应用场景。 none模式：容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。这些方式适合通过Libnetwokr方式扩展。  目前Docker释放出Libnetwork，旨在将Docker的网络功能从Docker核心代码中分离出去，形成一个单独的库。 Libnetwork通过插件的形式为Docker提供网络功能。用户可以根据自己的需求实现自己的Driver来提供不同的网络功能。 Libnetwork引入了容器网络模型（CNM）:
 Network Sandbox：容器中一个网络配置的隔离环境 Endpoint：在某个网络上进行网络通讯的接口，Endpoint可以加入一个network，同时，多个Endpoint也可以在一个网络沙盒中共存。 Network：一个唯一的、可识别的endpoint组，组内endpoint可以相互通讯。  Libnetwork从Docker1.7开始，目前整体来说，还是属于起步阶段。由于网络是一个绕不开的话题，网络方案热度很高，目前各个企业在使用Docker时也是有各自的解决方案，他们各所有长，没有包打天下的方案。Docker 1.9发布，已把libnetwork合入，号称已Production Ready，实际还是底层调用OVS或Vxlan。OVS与Vxlan在性能上都存在损耗。
容器卷的管理相对网络来说，热度比较低。Docker之前可以通过Monut主机的目录来解决数据持久存储的问题，由于容器的特点是便携，本地数据肯定存在数据迁移的问题。Docker 1.9重新设计的一套完整存储卷管理系统，也像网络一样，支持能过插件形式来为Docker提供卷功能，实现自己的Driver来提供不同的卷管理功能。卷管理这一块走在前面是Flocker，其它没有看到较成熟的产品。
Docker开放网络与卷管理扩展能力，可能是出于建立生态考虑。毕竟即使开源，如果系统的开放性不够，就会导致商业可能为黑寡妇，最终伤害也是自己的利益。
使用方式 正如前面所说的，容器涉及到计算，存储，网络。而目前网络与存储相对不是很成熟，也是影响着大家使用Docker的方式，目前主要有几种形态：
 IaaS &#43; Docker：在虚拟机或物理机上是使用容器，容器是对资源进一步的分割与隔离。目前是主流，应用较成熟。 轻量虚拟机 &#43; Docker：主要是虚拟化技术厂商为准，借助虚拟化在存储，网络，安全的能力。像Vmware的Photon，创建虚拟机时同时拉起容器。其它代表有Intel的ClearLinux，国内的Hyper.sh。目前还实验阶段。  目前大家还是把Docker当工具使用，因为整个工具链还不太成熟。容器编排与调度领域目前有K8S与Mesos/Marathon，Docker自家也有compose与swarm，但明显Google在这一领域更有发言权（Borg的成熟应用），也主导了CNCF。将来Google领导的K8S可能是容器编排的事实标准。
而传统的虚拟化厂商明显感到来自Docker的挑战，所以也顺适而为，摧出轻量虚拟化&#43;Docker结合技术，来继续巩固已有的虚拟化市场，这真是一个有意义的现象。
标准之争 CoreOS不满于Docker在容器技术一家独食，发起了AppC的容器规范，并实现该规范RTK与其竞争。其后在15年6月大家握手言和，成立了OCI（Open Container Initiative）组织。RunC就是Docker贡献出来的，按照该开放容器格式标准（OCF, Open Container Format）制定的一种具体实现。而Docker公司也很不情愿地把LibContainer以RunC方式贡献出来。从使用量来看，目前RKT使用很少，Docker是事实标准。值得一提的是，我司也在标准这块发挥着重要作用，并发布了OCT，一个基于开放容器规范的测试框架。
</content>
    </entry>
    
     <entry>
        <title>7秒时光</title>
        <url>http://lanlingzi.cn/post/stories/2016/0103_7s_time/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>休闲</tag>
        </tags>
        <content type="html"> 三天的元旦时间很快就过去，前两天是窝在家搞我这个网站。今天怎么也得出去走走，于是老婆约上她的几位好友，说去莲塘边的罗湖5号绿道感受一下大自然。天公有点不作美，一直下着毛毛细雨，但是我们还是意识坚定，风雨无阻。当我们一行7人踏上路程，蓦然发现朦胧细雨下的水库与5号绿道，别有一番诗情画意，望着不远的仙湖与梧桐山，他们就像一幅幅山水水墨画，恨不得把她们都收入到相机中。
一路上我们有说有笑，完全忘记了天气的不适。虽已是深冬，但深圳的冬天却还是花开的春天般。我们一行中有一位博学的动植物学老师，一路上的花花草草，她都能讲解得恰当时机，本是由于下雨无趣的路程，给增添了不少的知识与乐趣。不知不觉我们就到达了我们的目的地，梧桐山下的大望艺术小镇。正值中午，一路的能量消耗，也需要新的补充，她提议去她在杭州开会认识一位朋友的小店，说她家做的东西非常好吃。作为吃货的我们，自然是欣然答应。
在大望艺术小镇内，七拐八拐才找到她，她仿如世外桃园，不与商业争艳。这不是一家普通的店，而是一家颇具文艺气息的休闲别院。店有一个非常诗意的名字：七秒时光。当我们推开门，经过一段门廊，映入我们眼帘是一座极具风情的别院：树，小溪，茶亭，书，钟表，留声机。一切充满了文艺，轻松的气息。而正门墙上的一段文字也深深地吸引了我：
 这也是我的天涯。进，看不见幸福，退，看不见你。止于此。春便还是春，夏便还是夏。爱止于此，心也止于此，风止于秋水，我止于你。
 店名的也是别具深意，在这个繁华的世界，你我学会放下烦恼，只要拥有你，便能止于此：
 传说鱼的记忆只有七秒 七秒一过，它们就会忘记所发生的事情,每一刻都是崭新的，一点也不会疲惫，这样快乐总有理由&amp;hellip;
 是的，我们的痛苦，大多是来自我们虚无空洞的追求。愿做一条七秒鱼，安顿身心，把每一刻活出崭新。这或许是2016年元旦最大的收获。
 推荐阅读：我是一条只有七秒记忆的鱼
</content>
    </entry>
    
     <entry>
        <title>新年新目标</title>
        <url>http://lanlingzi.cn/post/stories/2016/0101_new_year/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 韶华易逝，往昔不再。时间已翻到2016年，在15年的12月份，忽然做了一个决定，注册了lanlingzi.cn这个域名，开始鼓励自己写写东西。原由是在15年的下半年，工作上做一个重大的调整，暮然发现自已写东西有时真让人费解。这个域名上已有的文章，是我之前在CSDN上一些记忆，以及自已电脑上留下的文档。虽然在公司也会写写技术博文，但那些更倾向于技术的细节与程序语言，对问题的思考与见解少了一些。
在16年的计划目标是每个月一到两篇，争取多写些有思想，有见解的干货。经过这几天的梳理，才有了这个网站。发现写东西是一个比较费时费脑力的事儿，甚至比写起代码来还难。苦于自己的文思，文笔，写完之后，有时连自己都看不下去，一堆的错别字，语句不通顺。有时，脑子中是飞快地转，好似有千言万语，下笔时却不知从何写起。
不管怎么样，我已经开始写了，我也开始享受写作的过程，整理文字，就是整理自己的思绪。可以把零星的，模糊的想法，通过这个网络串起来，记录下来。我不求有人会去欣赏，孤芳自赏也是一种自娱。也许，每每自己回头阅读自己的文字，也是阅读自己的回忆。有会也许会觉得自己一些想法，见解，观点是那么的幼稚、怪诞，可笑。这或许也是自我的一种成长历程吧。
16年不再年轻，而技术却是日新月异，既然今年放弃了带团队，专走技术这一线，那就坚持吧。16年加油，技术不会随着年轮越走越窄，无论是编写代码，还是做设计方案，只要能沉下心来，专心专意去付出，就会又有收获。
15年在思想上虽有一些波折，但整体还是圆满，要感谢的人太多太多。感谢家人的理解与支持，感谢领导与同事的器重，感谢大家的宽容与谅解。那些往事，那些经历，一路上有你们的支持，才能有我每年的成长。学会感恩，让自己的内心更加的平静，更加的强大。
 16年加油，让生活更美好！
</content>
    </entry>
    
     <entry>
        <title>虚拟与现实</title>
        <url>http://lanlingzi.cn/post/stories/2015/1231_debian_ian_die/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>Debian</tag>
        </tags>
        <content type="html"> 万万没想到，在即将迎来2016年时，微信，科技新闻中都在传“Debian创始人Ian Murdock离奇死亡，曾发推表示要自杀”。作为一个对Debian系Linux的忠实爱好者，有种莫名的感伤，对大神的离去表示衷心的哀悼。
30日Debian社区正式发表了悼念声明如下：
 我们怀着沉重地心情哀悼刚刚离我们而去的 Ian Murdock，开源软件的坚定支持者，父亲，儿子，和 Debian 中的 &amp;ldquo;ian&amp;rdquo;。
Ian 从 1993 年8 月开始启动 Debian 项目，并在同一年的稍晚时间正式发布了它的第一个版本，Debian 还会一直坚定不移地继续努力，成为流行世界、亿万人受惠的通用操作系统，不管是嵌入式设备还是太空站，都能看到它的身影。
Ian 一直非常关注在创建一个发行版和开源社区文化的过程中做正取的事情，不管是技术上，还是道德上。每一次准备好的系统发布，都包含着对自由软件和自由精神立场的坚定支持。
Ian 对开源的忠诚奉献一直引导着他的工作，不管是在 Debian 还是在后来的年月里，一直伴随他朝着最好的未来。Ian 的梦想一直都在发扬和纪旭，Debian 社区仍然非常活跃，成千上万的开发者们用数不清的工作时间带给世界一个安全可靠的操作系统。
这段特殊时期，Debian 社区的精神会一直陪伴着 Ian 的家庭，会陪伴一起共度难关。
他的家庭同时也请求大家在这个艰难的时刻留给他们一些隐私空间，我们对此非常尊重，同时也号召大家尊重 Ian 家人的愿望，来自 Debian 社区和开源社区的关心他的人们的慰问，可以发送到这个专属邮箱，Debian 社区会保存这份善意，并存档。
 Debian的诞生本来就是一件很浪费的事，理想主义，追求纯粹，不包含非自由软件，充满激情，同也是非常的沉稳。Debian也是目前Linux发行版本中，最为彻底，最为忠实，践行开源精神的版本。它曾经是一个符号，一面旗帜。
Debian的名称也据说来源一个美丽的爱情故事（Deb来自于前女友Debra，Ian来自他自己的名字），Ian长期担任Linux基金会的首席技术官，他的成就在自由软件，开源社区是一个了不起的传说。
逝者已往，愿Ian安息，这位把自己的浪漫书写在了Debian和OpenSource的传奇人物，一路走好，我们会永远记住您！
他能在软件开源这个虚拟世界中，一呼百应呼风唤雨，但在现实世界也是一个普通人。作为一名程序员，或许不经意的创作，能改变世界科技的发展。开源摧动了技术的发展，使得知识更容易获取，使得技术更容易创新。但他们却可能不是这个过程中最大的获利者。在虚拟的技术世界中，我们敬奉他们为大神，而在现实世界中，很少有人能获得像政要，企业家的社会地位，甚至不如某国一名歌坛明星。即使面对一名小警察，或许只能通过自杀来表达诉求或无奈。
</content>
    </entry>
    
     <entry>
        <title>参加ArchSummit北京站感受</title>
        <url>http://lanlingzi.cn/post/technical/2015/1227_bj_archsummit/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>北京</tag>
        </tags>
        <content type="html"> 参加ArchSummit北京站已有一周时间，一直没有时间来梳理一下。整体来说，这次的北京之行，不是很满意，可能是这类会议听多的原因，感觉ArchSummit的质量是越来越差了，没有什么新鲜感，觉得不值那6K的价格。
组织不足 12月份的北京已是非常的干冷，可能由于我在南方呆久了，一到北京是极其地不适应，在北京三天多的时间，嘴唇开裂，到现在还没有完全好干净。离开北京的那一天，正好又感受了一下北京正宗的霾，帝都的人们活得真不容易啊。
为什么说ArchSummit组织不足呢？InfoQ也算是组织过多次大型会议的公司，但这一次比我之前参加InfoQ组织的任何会议都差，更无法与阿里组织的云栖会议相比。一个是以组织会议赚钱，一个是以个会议来打造生态。这次的ArchSummit是在北京国际个会议中心举行，每个分会场我都差不多的参加过，明显感觉组织不足:
 每个分会场演讲时，大门紧闭，空间质量非常的差，又没有充足的通风设备，感觉非常的窒息。 工作人员能力不行，第一天下午，有几个分会议室由于投影没有准备好，拖时半个多小时，也不见中途主持人来了说一声，最后连声道歉都没有。 几个分会场的投影效果差，灰蒙蒙的看不清楚。 连个矿泉水瓶上都是广告，并且不是每个位置都摆放好水，而是需要自己去指定位置去拿。有的分会场甚于连矿泉水都没有见到，准备的份数太少，6K的价格连个水都喝不到。 就餐地方太小（又是自助餐），效率低下，大量的人员挤在走廊上，我是差不多等了30多分钟才能进餐厅吃饭。大量的人员挤在一起存在安全风险。  两天的ArchSummit大会日程比较紧凑，再加上大多数时候有六个专题在并行，因此每个人能够真正去听的课程不会太多。我们也是只能选择地去听，但是每个演讲介绍不足，有些演讲名字高大上，听了之后，感觉有点上当，部分讲师存在水分，这里就不直说了。
 不过，参加ArchSummit大会，还是听到一些业内公司的技术分享，尤其是互联网企业，在应用新技术方面还是比较超前的。相对我们电信行业来说，我们遇到的问题有些是相似的，甚至部分问题的解决办法也与我们曾经想过的一些方案类似，只是他们早已经落地并且做到极致了。有很多东西对我们值得参考，可以说从开源使用、技术形态，运作方式，远远走在我们的前面了。
PaaS平台 目前稍具规模的互联网公司，都会自建数据中心。而互联网的业务又有如下特点：
 业务需要快速上线，唯快不破 业务形态众多，迭代周期快 数据处理量大，海量请求和高并发的挑战  支撑业务的发布，上线，运维，都需要对业务应用的全生命周期管理，各个公司都有一套平台，他们或多或少都能称得上内部的PaaS平台。而PaaS平台核心：
分布式框架 首先是《蚂蚁金服金融级PaaS平台构建之道》分享，阿里在国内技术一直算是走到前列。这次带来的演讲，蚂蚁金服的分布式服务注册中心（DSR），与阿里其它系的Dubbo，HSF都差不多。他们的目标都要解决应用服务化后，服务注册发现问题，可以说是未来PaaS平台中，服务注册发现将成来PaaS的核心中的核心。
后一场听了《主流容器SDN技术与微服务架构实践》，来自七牛的分享。虽然演讲的内容是容器的SDN技术（算不上大范围的SDN），也同时点到微服务架构。虽然他们所讲的容器方案都说是自研的，但整体上感觉与K8S的设计是相似，甚至像Pod之类的概念来也是借鉴来的。在容器环境下的同时也要解决分布式的服务发现问题，他们采用是DNS机制。服务路由上支持L4与L7的负载均衡，对业务无侵入。基于安全组的服务Discovery，虽然没听太明白，感觉跟K8S的Proxy机制是差不多的。
中间件服务 在《蚂蚁金服金融级PaaS平台构建之道》中初步介绍了分布式消息(DMS)、分布式数据源（DDS），分布式事务（DTS）的一些使用场景与技术特点。在云环境下，中间件服务必不可少，让业务应用只关注自己的业务逻辑。中间件服务要面对的是一个复杂、不断变化的计算环境。抽象出业务的公共能力服务化。使用中间件服务，可以简化业务应用在一些通用技术的成本，如数据一致性，安全控制，高性能，可靠性等。而中间件技术正在呈现出业务化、服务化、一体化的趋势发展。高可用性，自管理性，业务适应性是当前中间件服务面临的挑战。
弹性扩展 在云计算中，引入虚拟化技术，采用弹性伸缩是老生常谈了，一键式按需弹性，基于性能采集的自动弹性。听了《微众银行基于自主可控技术的分布式架构实践》，给我对弹性带了新的思考。互联网&#43;的应用是：海量用户，海量交易，海量数据。这要求对系统在架构设计上充分考虑容量的扩展性，性能的扩展性。
微众的架构特点是分布式松耦合架构&#43;一主两从节点强制同步的架构。在分布式松耦合架构是按客户群来水平分割，一个节点上涵盖多个客户业务。分布式多节点是分散风险，如果有节点受损，也是部分客户有影响。而每个节点上又采用一主两从节点强制同步，来提高整个系统的冗余。整个系统以客户为单元可控分布，将客户量、交易频繁度与系统负载之间的关系解耦。随着客户量增加或客户交易频繁度的增加,系统负载也会随着增加：
 横向扩展(Scale Out)解决用户量增加 纵向扩展(Scale Up)解决交易频繁度增加  并且严格要求，横向扩展只能解决用户量问题，不能通过纵向扩展来解决用户量问题，反之亦然。
容灾备份 云计算环境下，容灾备份也是需要重点考虑的，容灾设计强调的是系统对外界环境影响具备快速响应能力，尤其是当发生灾难性事件并对IDC节点产生影响时，能够具备节点级别的快速恢复能力，保障系统的持续可用。像微众介绍IDC2.0中提到的：
 数据库三中心集群化部署 三数据副本强同步 应用多中心多活部署 应用多中心多实例多活部署  蚂蚁金服金服提到的：
 两地三中心 异地多活  支付宝有一个专题《支付宝的高可用与容灾架构演进》，我觉得有意思的是其中的单元化与容灾。单元化应该是微服务化中一种具体运用吧。什么是支付宝的单元化：
 核心业务,核心剥离：数据按照UserID拆分,多机房部署,调用封闭,部分数据,不共享 非核心业务,长尾独立：不能按照UID拆分，核心不依赖长尾  单元化的实现思路：
 水平拆：交易、支付、账务等,每个单元只有部分数据 上层单元化改造：从DB层往上延伸水平拆分概念,包括应用层到入口层  在容灾同步上，是基于单元化的多中心同步，这已打破我们对原有容灾备份的认识，基于单元化的容灾同步，可以细粒度的控制，解决数据一致性和时效性问题：
 基于DB同步的数据复制：延时非敏感业务的异地复制方案;部分业务数据,可忍受3s时效性延迟(比如大部分的配置 数据) 基于消息系统的数据复制：对于延时非常敏感的业务,更低延时的实现方案;上层基于应用进行复制,减少延时。底层 DB主备同步同时进行  高效运维 开发团队快节奏的版本迭代，以及服务的快速上线的要求，驱动着PaaS平台要提供出更为高效的运维服务。高效运维的思路是建立以 应用服务 为核心的管理标准体系。把运维能力服务化(API)，使运维的能力无处不在。高效运维，综合几个公司的介绍主要需要如下几个系统设计：
 发布系统：负责应用服务的上线，应用服务的资源管理，扩容，权限管理，支持Beta发布，灰度升级。 监控系统：通用&#43;自定义监控配置,运维&#43;开发可以时刻关注自己的服务状态和质量。 全链路系统：复杂的分布式系统，一次点击，几十次的RPC调，需要全链路跟踪，出了问题,如何快 速定位到故障点。 限流与降级：限流,Web层,防止被流量打垮；降级,App层(服务化),保障核心应用 容量评估：基于全链路的压测手段、数据分布的模拟方法、关键场景调用量预估 蓝绿发布：即多站点的灰度。具体操作流程：切流（将待发布机房流量切走）-&amp;gt; 机房发布（待发布机房全应用并行发布）-&amp;gt; 引流验证 （逐步按规则引流至100%）-&amp;gt; 流量交换（将全部流程切换到已发布机房）-&amp;gt; 机房发布（另一个机房全应用并行发布）-&amp;gt; 分流还流（分流规则还原，两机房各50%）  服务化 今年IT界是对服务化异常的火爆，系统的稳定和流畅依赖好的应用架构，服务化治理如何规划和落地，是众多厂商系统的痛点。
首先是来自1号店订单系统对SOA化的分享，SOA是一种架构模式,是设计原则,不是技术规范。狭义的SOA：Service化， 标准化、模块化、组件化。广义的SOA：模式、原则、思想。
  Service化：1）分层结构，基础Service不含业务逻辑,只封装基本的数据操作。业务(聚合)Service封装业务逻辑甚至是全部的业务逻辑。2）Service层次调用，上层可以调用下层、下层不可调用上层、同层间可互相调用，调用链长度不超过3级、不循环调用。
  服务粒度划分：1）迷你裙定律。2）细粒度的服务(fine-grained)提供相对较小的功 能单元,或交换少量的数据。细粒度的服务使服务更容易被组装。3）粗粒度的服务(coarse-grained)则是在一个抽象 的接口中封装了独立的业务/技术能力,减少服务请求交互的次数。粗粒度的服务适合更广泛的需求。
  再次是来自Twitter的服务化思路分享：
 单体：牵一发而动全身 分拆：把单体分成多个模块 服务化：把模块按功能服务化 平台化：模块功能中部分服务化为通用服务，通用服务提供一般化服务，平台化  Docker 在不断寻求性能更好、速度更快、成本更低的云计算核心技术中，容器技术是目前最吸引人注意的技术之一。尽管除去效率、速度和成本等方面的优势以外，容器技术还存在一些安全上需要斟酌的问题，但是其实际表现仍然得到了肯定。还是借用其中的分享内容来说明一下Docker。
在遇到Docker之前：
 混乱的环境：Java, Golang, Ruby 混乱的配置：Upstart, authorized_keys, dependency, 各种脚本 混乱的监控：ErrorReporter, Message 混乱的资源：计算资源与预估不匹配  导致的结果是：
 环境不匹配导致,测试跟生产不一致 配置混乱导致事故频发 监控不统一导致运维难上加难 资源效率低导致成本很高却达不到相应目标  而Docker具有如下特点：
 构建快：应用&#43;运行环境 = 镜像 启动快：容器相比于虚机,更轻量级 迁移快：应用以容器的方式标准化交付,标 准化运行  去年Docker主要是在吵作概念，而今年很多的互联网厂商已在使用Docker，本次Docker中都分享各自针对Docker的一些定制化修改及踩过的各种坑，所遇到的困难和走过的弯路。
当然这些坑不是阻当我们不使用Docker的理由，Dockerk只是一个系统架构优化的承载体。来自Coding.net的分享最后总结的比较好，Docker会对软件，流程带入变革与影响，是否采用Docker，系统都需要关注如下三个方面，只是Docker让你不得不关注他们：
 软件架构的升级：微服务、无状态、数据执行分离 研发体系、环境管理理念的升级：容器化、代码化、自动化 资源管理理念的升级：Pet vs Cattle，多留点富余量，迁移能力比压榨能力更重要 </content>
    </entry>
    
     <entry>
        <title>我为什么喜欢GoLang</title>
        <url>http://lanlingzi.cn/post/technical/2015/1113_why_love_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 从8月份到现在，一直在公司尝试用Go写点东西。虽然我们几乎是清一色的Java开发，但我还是愿意在同事之间推广Go，有时间还是学学Go吧。
认识Go 我大概是一个不太执着的语言控，什么语言喜欢玩玩，在大约在12年时，就开始自学Go，但仅仅是看看语法，写写Helloword之类的小程序而已。在13年底，我被抽去分析Cloud Foundry的架构与实现机制。当时的CF是V2版本，其中的GoRouter，HM9000已采用Go重写，另外消息总线NATS也有Go语言版本。而我又重点分析了NATS，HM，以及部分GoRouter的Go源码。发现居然Go能写出如此简练的代码。性能验证时，又发现Go版本的NATS比Ruby版本的强得不是一点点，我们在单板上测试出有50万&#43;的QPS。14年做融合架构，又把我们原有的消息中间件RabbitMQ换成了NATS。当时的出发点主是能与CF通过NATS融合拉通，另外是看重它的高性能。而RabbitMQ是erlang写的，部门熟悉erlang人几乎没有，维护成本高。当然到现在来看，NATS太简单了，并不是个消息队列，很多的特性都没有。
14年的Docker以席卷全球之势火了一把。在15年，我又投入到平台集成Docker的分析，于是又开始了Go语言之旅，重点研究了Docker Distribution的代码，以及由其它部门开发的Index等相关部件的代码（都是基于Go）。自己也是顺便练练手，如把系统中Java的通用加解密库（是基于AES与HamcSHA256之上的封装库），转换Go实现。经测试发现原来在Java对于HamcSHA256迭代6W&#43;次数时需要差不多一分钟，而Go只需要几秒。由于系统需要对接Docker的API，涉及到Http Hijack，于是又得去分析Docker源码中这一块是怎么实现的，把它的实现转换成Java（虽有开源的Java Client API，但不能满足我们的要求）。所以差不多就是干些Java转Go，Go转Java的体力活。整个版本开发中也协助定位一些Docker相关的问题，需要走读Docker代码。整体来说，我写的Go代码不是太多。
曾经的痛苦 C&#43;&#43; 十多年的编码经验,一半是做C/C&#43;&#43;开发，一半是Java。目前还记忆犹新的是，在08年写的一个消息缓存中间件，大量使用了共享内存、内存分片技术、大文件操作，以及缓存淘汰算法（主要与业务特性相关）。原本只是一个消息缓存&#43;持久化，但后来做着做着已不再是一个纯粹的缓存，参杂着业务复杂的逻辑，最终也导致代码质量不可控。一出问题就是踩地址（用于大消息缓存，原本设计是小消息），CoreDump文件分析困难。现在来看，其实如果只是做纯粹的缓存与持久化，Redis也能满足当时的需求，可惜那时开源没有现在这么火，更没有听说有Redis，连Memchached都没有听过。后来在09年与10年，又负责过另一个产品的版本稳定与性能提升。在那段日子里，我与另一个兄弟不知解决多少个CoreDump问题，现在还记得一个踩栈地址的问题整整花了我一周时间，通过猜测CoreDump中的地址信息加上反复走读代码才找到问题的原因。为了压榨单板的性能，在做优化时真是极其语言的偏门用法，尤其是在老的代码上为了发挥并发多线程的能力，代码写得真是惨不忍睹（那时也接触过erlang，发现erlang进程模型是多美好）。目前我司还有很多产品为了提高性能与降低时延，甚至是在内核做了一些修改，如零拷贝技术。这些性能上极致的代码也只能是少数人能看得懂。10年还做一件非常痛苦的工作，就是把跑到Linux上代码移植到Window，主要用于做开发验证仿真工具。即使采用MGWin，也是苦不堪言，其中的困难是谁做谁知道。
Java 10年底开始做云计算，又开始做Java开发（之前也开发过Java，主要是JNI）。使用C开发时，没有什么开源框架可选，但Java的框架是一大堆，J2EE，OSGI，Spring&amp;hellip;无论是哪种，框架都是又臭又硬，太厚重了。大量使用第三方的开源Jar管理也是非常困难。即使我们采用Maven来做工程管理，也是相当的复杂，尤其是对一个大型系统，全编译构建时间都可以与原有C/C&#43;&#43;有得一拼（我之前经历过的C/C&#43;&#43;写的系统，全编译要花差不多一天时间，拿现的DevOps理念是不可想象的），也尝试使用过Maven的并行编译，但由于部分的Mavne插件不支持也放弃了，只能换成多台机器分布式编译。Java运行环境到14年我们才换成JDK8，之前一直采用JDK6，写多了就觉得Java的语法是硬伤，太不灵活，尤其是一堆的Getter与Setter（采用lombok简化），什么都得先定个interface，总之代码看起不是清爽简洁。Java的打包发布更是一个噩梦，虽有Maven管理，但对于一个大型系统，差不多一百号人的开发团队，系统整体打包是差不多2G的压缩包。我们是花了不少时间去清理不同版本的第三方Jar包（公司要求同一产品依赖的版本要归一），每次做版本升级，换一个Jar的版本会牵出一堆的Jar依赖要升级，也是苦不堪言，其中的痛苦是谁做谁知道。经过不断地努力，目前整个团队使用第三方Jar登记还有100&#43;，整体打包差不多1G的压缩包，对于严格的电信行业说，任何第三方Jar包要做内部开源扫描认证，这是一项浩大的工程。在06年做Java时，为了性能比拼，JVM的性能参数调优也是一个非常要有技术的活，吞吐量与时延两者不能兼顾。
再来说Go 缘由 我为什么喜欢Go，最重要的原因是我目前从事云计算领域的研发。总结之前说了这么多的痛苦，对于C/C&#43;&#43;:
 开发效率低，定位问题复杂，对开发者技术要求高 C/C&#43;&#43;偏底层，对系统依赖度高，系统迁移困难 开源框架少，系统API只向后兼容，维护成本高  那Java呢：
 框架臃肿庞杂，反而简单问题复杂化 规范繁多，实现框架也多，选择太多，产品容易被框架绑定 语法啰嗦，全OOP化不灵活  技术特征 当然，无论是C/C&#43;&#43;还是Java，如果项目决策需要，我还是会继续使用他们。他们的成功有他们成功的原因，纯粹的语言比较都有各自的优缺点。我在这也不是为了说喜欢Go而去有意贬低他们，只是列一下个人觉得遇到痛苦。为什么我喜欢Go，主要原因还是它在云计算相关产品的发力，像Google的K8S，Docker，CoreOS，CloudFoundry等等都大规模地使用Go。在学习与使用Go的过程中，被他的设计理念所折服，它是一个面向工程而简化的语言。从语言学上来说，他可能不是最好的语言，但对于大多数的系统，一般都需要兼顾开发效率，运行性能，维护成本。而Go似乎在这几个方面能做到很好平衡。
 开发效率  语法简单，学习曲线低 代码简洁，格式统一 静态类型，编译期检查 内置GC，Runtime期识别 标准库丰富，网络库简单易用   运行性能  编译为机器码，不依赖其它库 语言层面并发模型，可充分利用多核 内嵌C支持，可直接利用C的资产 启动快，执行效率高，内存占用低 标准库质量高，针对性优化   维护成本  没有什么语法糖，高级特性少，格式统一，阅读方便 自带工具链完善，如代码格式化，代码检查，性能分析等工具 默认编译为单个执行文件，部署简单，超赞 标准库跨平台支持，迁移成本非常低    不足 当然Go在工程方面也不是很完美，就目前个人使用经验来看：
 缺少Go工程的依赖库版本管理，尤其是使用第三方开源不好控制（注：1.5引入 go vendor） 错误机制采用返回值，真是满眼的if来判断错误，代码相似度高 接口与实现未分离，对于商用产品，想只提供接口定义来保护知识产权操作不方便 Goroutine调度切换不能由程序控制，需由上层有严谨的设计，维护困难，容易修改出问题   如果你也是在云计算领域，或会从事服务端的应用开发，如中间件，分布式，网络通讯的系统开发，有时间不妨学习学习Go，他简单易学，多掌握一语言，多一门求生技能。
</content>
    </entry>
    
     <entry>
        <title>Mesos与K8S的区别</title>
        <url>http://lanlingzi.cn/post/technical/2015/1020_k8s_mesos/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag><tag>k8s</tag><tag>mesos</tag>
        </tags>
        <content type="html"> 最近经常有同事问道，mesos与k8s有什么不同？平时对k8s要研究多一些，对mesos仅限于一些网上的了解。前一段时间去参加阿里云栖大会，正好也有一场是由于Mosos及Mesosphere公司的人来现身说“法”，听了之后对mesos算了解更深一点吧。
Mesos Mesos是倾向于是IaaS层上的 资源管理器。Mesos不要求计算计算是物理服务器还是虚拟机，只要是Linux操作系统计算资源就可以，Mesos可以理解成一个分布式的Kernel。所以讲师强调DCOS一个OS(阿里云栖讲师的分享)，而不是一个调度器。Mesos只分配集群计算资源，不负责任务调度。基于Mesos之上可以运行不同的分布式平台，如Spark，Storm，Hadoop，Marathon，Chronos等。
Mesos中的核心是DFS，即资源管理策略 Dominant Resource Fairness。Mesos能够保证集群内的所有用户有平等的机会使用集群内的资源，这些资源包括 CPU，内存，磁盘等等。Mesos只做一件事，就是分布式集群资源分配，不管任务调度。Mesos只要你给出CPU、Memory参数就能分配资源，用于你的计算。
Mesos 是一个双层调度器。 在第一层中，Mesos 将一定的资源提供（以容器的形式）给对应的框架或应用程序。在第二层中 ，应用程序将收到的资源进一步分配给内部的任务。但是资源分配器智能化程度不同，mesos是基于resource offer的调度机制，包含非常少的调度语义，他只是简单的将资源推给各个应用程序，由应用程序选择是否接受资源，而mesos本身并不知道各个应用程序资源需求。
Mesos是Apache的开源项目，起源于UC Berkeley的一个研究项目。而背后的商业运作公司是Mesosphere，主要产品是基于Mesos构建的DCOS(datacenter operation system)。Mesos的商用程度很高，在国外的Airbnb, Apple, Uber, Twitter在使用，其中Apple的语音助手 siri是基于DCOS部署，有6000&#43;节点。而国内有携程，爱奇艺在使用。
Mesos与Docker 没有Dokcer之前，物理机，虚拟机都可以作为Mesos的集群节点，引入Docker之后，对资源的管理与分配粒度更细，更能提高对资源的利用率。但Mesos只负责资源的分配，对Docker的调度需要上层的调度器，而马拉松Marathon框架就是解决这个问题。当前Mesos &#43; Marathon 基本上是现在最成熟的分布式运行框架。
K8S 与Mesos最大的不同就是，Kubernetes(K8S)一开始设计是 面向应用的，而Mesos是 面向资源的 。Kubernetes是应用的集群管理工具。它是构建Docker技术（也可支持其它的容器技术，如Rocket）之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。
Kubernetes重新实现了Google在构建集群应用时积累的经验。这些概念包括如下内容：
 Pods：一种将容器组织在一起的方法 Replication Controllers：一种控制容器生命周期的方法（Replication Controller确保任何时候Kubernetes集群中有指定数量的pod副本(replicas)在运行） Labels：一种可以找到和查询容器的方法 Services：一个用于实现某一特定功能的容器组  K8S和Borg系出同门，基本是Borg的开源改进版本，吸收了包括Omega在内的容器管理器的经验和教训，label, annotaion等功能的加入让容器分类检索信息标记管理更加便捷。目的就是将Borg最精华的部分提取出来，使现在的开发者能够更简单、直接地应用。K8S是在Google内部积累发展10年的容器及集群管理专家经验基础上开源实现，有其自身的独特优势来构建容器应用部署、可伸缩可扩展，多平台兼容的容器集群管理体系。可以说，K8S的出现，也是为容器而生。
使用K8S你就能够简单并快速的启动、移植并扩展集群。在这种情况下，集群就像是类似虚拟机一样灵活的资源，它是一个逻辑运算单元。打开它，使用它，调整它的大小，然后关闭它。
Mesos与K8S Mesos与K8S都起源于Borg，Mesos和K8S的愿景差不多，但是它们在不同的生命周期中各有不同的优势。Mesos 虽更多的是侧重在资源管理上。而Mesos&#43;Marathon与K8S存在竞争关系，他们在容器调度编排上有些交叉，后续如何发展，还需要看社区的走向。目前K8S是可以运行在Mesos上。
如何选型  Mesos更适合做跨DC的资源管理，对于大数据领域，大量存在短任务，可以采用Mesos&#43;上层调度器来解决大数据的资源池化调度问题。 K8S更适合当应用的集群管理，它解决大规模应用部署的问题，而它的集群的热升级，动态伸缩，负载均衡，服务发现等特性可以让你的应用的更可靠。 </content>
    </entry>
    
     <entry>
        <title>成都映象记</title>
        <url>http://lanlingzi.cn/post/stories/2015/0926_chengdu/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>成都</tag>
        </tags>
        <content type="html"> 风味十足的四川话，风姿卓然的川妹子，麻辣干香的风味菜，是我是对成都的初步映象。有“天府之国”、“蜀中苏杭”美誉的成都蓉城，在小说与故事中都有耳闻，向往已久。在上高中时，就想报考虑成都的高校，无奈分数不够高，被调济到北方。这次作为招聘技术面试官出差来了一趟成都，了却了一桩十几年前的心愿。
作为面试官，我们必须西装革履，多年的散慢习惯，反而不太适当。我们下榻的酒店，环境与生活还算不错，但是地理位置有点偏，即使晚上空闲下来，也难以感受到成都的气息。招聘其实是个苦差事，连续二天集中的面试时间，已让我有些疲倦。第三天中午面试完最后几个之后，下午忽然空闲下来。秘书说下午面试预约已结束，我们几个来自深圳的同事可以去成都逛逛。
背上背包，一路朝南，寻找成都的古迹。步行街、杜甫草堂、武侯祠，锦里古街，古香古色，即使仿古，也别有风味。在锦里，见到是当地老头老太，倒上一怀茶，四个人摆起麻将旧，忘记的游人带给这个城市的喧嚣。深深的巷子里，不管是一条宽的还是一条窄的，人们总是贪恋的过着闲趣的生活。而我也妄想在某个旧的巷子里头，旧的墙砖缝里，寻找历史的一点蛛丝马迹。
人最大的享受之一就是吃喝。来到成都，自然少不了品尝一下当地的小吃美食。“棒棒鸡”、“怪味兔”、“张飞牛肉”，总是映入到你的眼帘，从一品天下，到锦里古街，还是秘书安排的晚宴，我觉得我想吃的东西太多，但发现只要吃上一种，就有种会上瘾的感觉。即使我带回给儿子的牛皮糖，他也是爱吃得不了。
成都的生活的确是安逸的，哪怕是现在。它始终是一个生活的好地方。也始终是令人憧憬或向往的。回到深圳，望着车流川息，感觉是从一个世界到另一个世界，快节奏的生活，超熬贵的房价，让我们无法去轻触着这个城市的生活轨迹。
</content>
    </entry>
    
     <entry>
        <title>参加CNUTCon全球容器大会感受</title>
        <url>http://lanlingzi.cn/post/technical/2015/0902_bj_cnutcon/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag><tag>北京</tag>
        </tags>
        <content type="html"> 由于最近一直在从事Docker相关的工作，所以有机会参与这次的CNUTCon全球容器大会。名字比较“高格”，虽有少量的外国人分享，大部分还是中国的互联网企业在宣传，忽悠。除去这些，整体来说这次大会还是非常不错的，门票也不算太贵，目前看来应该还是值的。我司还是这次大会的钻石赞助商，也说明我们在容器这一块的发力程度。
整体感受 Docker是这这两年成长最快的技术，受到资本市场的热捧。Docker技术以势不可挡地席卷全球。参考这次大会，整体感受是：
 Docker已不再是概念，已进入互联网企业的实际生产环境中 Docker的创业公司多，有远见的想在这次的浪潮中分享红利 大公司借Docker东风，亦想在云计算领域中拿下更多话语权 容器技术处于战国群雄，完整的生态还比较混乱技术栈不成熟  看国外 这次的CNUTCon，居然没有请求正牌的Docker公司，而是请到他的死对头CoreOS，其次还有RedHat，Google，以及Rancher。
第一天的首场分享是来自RedHat副总裁，印度英语原来在公司就听到不少的印度同事，虽说听不太清楚，却有一股莫名的亲切感。由于是副总裁人物，讲的东西也是太High了，主要是分享OpenShift为什么要使用Docker，以及对Docker的认识。可以说在技术上空洞无物，对我来说“然并卵”。过程中的演示貌似险出了岔子。总之，他是来宣传OpenShift。
其次是来自CoreOS产品负责人分享，不过也没有什么干货，可能他对国内Docker技术应用程度还不太了解，还停留在宣传概念阶段。主要讲了两组项目：一个是Chubby&#43;Borg，之后是etcd&#43;k8s。并分别对比了Chubby以及etcd，最后是基于etcd的使用演示，Demo放到了Git上。只能说这个Demo是对etcd相当的入门级。总之，他是来宣传etcd。
可以说，第一天的两场分享，其实跟Docker，或容器技术关联不是很大，看来InfoQ请错人了。
第二天的来自国外的分享，有Google的华人美女工程师分享了“Kubernetes和Borg的设计哲学”。这一场还是不错的，虽也是比较High Level的介绍，不过让我这种屌丝有机会了解一下Google十多年前就开始的容器管理理论，感觉是真是简单实用：
 declarative &amp;gt; imperative Control loops Simple &amp;gt; Complex Modularity Legacy compatible Network-centric No grouping Cattle &amp;gt; Pets Open &amp;gt; Closed  再次是来自Rancher Labs的秦总分享的“Rancher Labs 企业级私有容器服务平台解决方案分析”，并且他还跟我一起在现场的另外一个同事是之前的同事。干货比较多，演讲者虽说不懂技术，但Rancher给我带来是思维，尤其是后面介绍的“RancherOS”，在会场没有听太明白什么是“Dockerized OS”，后面查询一些资料，发现它除了内核之后，PID1就是Docker，其它的系统服务都Dockerized，并且在发行包的大小做到了极致，只有20M。能把Linux的系统服务通过Docker容器来管理，不得不说这这一项不错的创意，如果能实现应用在生产中，这不知又会对Linux产生什么样的深远影响。
小结 由于只有四场，OpenShift与CoreOS是来做广告，我也曾经想在OpenShift免费空间上搭建Go的Web环境，发现真TMD的难用，OpenShift又想借Docker打个翻身仗，PaaS本身的体验不解决，Docker也“然并卵“。而CoreOS在容器中扮演着是一个搅局者，对防止Docker一家独大是益的，但它的RKT差不多落后Docker一年半，但是ETCD还是不错的。
Google是老牌的容器使用者，他在这一这方面的经验可能是最具有发言权的。他也乘着Docker之势，迅速摧出K8S。并极力去构建Container Orchestration，ContainerInfrastructure，ContainerManagement的生态。虽说K8S目前还是很成熟，但在未来在容器界K8S必定举足轻重，甚于可能是Container Orchestration的事实领导者。
看国内 在国内，自然少不了BAT，以及后之秀京东。商业的成功驱动他们在技术上必定走在前列。第一天下午几场都使来自大厂的分享。
首位是京东云平台的分享，京东最初的希望是通过一个平台，将物理机，虚拟机，容器，三种资源统一管理，随后的演化中，容器逐渐成为了一等公民。一种是容器直接在VM上，一种是让VM看起来像容器。开始是采用“胖容器”的模式，这一思路与我们的不谋而合，首先是要把容器使用起来，不管它是容器还是虚拟机；再次是业务的纯容器化。如何把容器中融合到已有系统中是目前大家遇到的最大挑战。
其次是来自大众点评的分享，同样对容器的使用，也是使得容器看起来像虚拟机。重点介绍了在网络方面的经验，如通过新创建的br0网桥与eth连接，使得docker 容器可以有自己独立的IP。最后也分享在使用容器过程中一些坑。
再次是阿里百川的TAE Docker全架构分享，干货是相当的多，信息量是相当的大的。Docker只是TAE中非常小的一部分，目前还是把Docker当做工具来用，重要介绍不是为了Docker而Docker，Docker并不等于容器。在实践的过程中，Docker的优势，基于Docker的全架构的PaaS平台，才兼具IaaS的灵活性和PaaS的易运维性。其实也说明Docker技术拉低了云平台的技术门槛，像原有的IaaS只有大投入才能玩得起，而Docker让你使用云资源变得更轻捷。
再次是也来自腾讯的在游戏上，Docker实践：现状、经验及展望。其中有意义是在网络上的改造，目前Docker在网络上是很弱的。像点评一样，不得不面对网络打通的问题。一般来说，游戏业务的生命周期长短不一，这需要弹性的资源管理和交付。相比于虚拟机，容器更加轻量，效率更高，资源的交付和销毁更快。可能说像Docker的应用可对针对游戏业务提升资源的利用率，降低运营成本，也是Docker的魅力之一。
第二天是来自百度的分享，感觉百度对于容器的实践比较牛逼，在docker没出来之前，他们就学Google都着眼于容器技术了。对于大企业来说，在资源调度上面对的困难是如何错峰填谷，如何将服务与机器解耦、预算调度，资源精细分配，统一池化，如何解决混合部署带来问题。而基于容器技术构建的Matrix平台，直接是在cgroup （划出一个资源框）namespace（内部的话只需要部分）的基础上定制操作。再通过agent来把这些所谓的“容器”启动起来，架构上有统一的container操作接口。其次是百度对于容器的安全性也有了很多实践，其实所说的安全性就是让容器上的代码不会跳到主机上去，让host上的代码不会逃逸出去。分享的内容很多，整体来说，百度应该是在国内互联网企业研究容器技术比较深的，而不仅仅是Docker的简单使用。
小结 大公司的docker实践更有发言权，实际上他们对于docker的实践才是真正切合实际的，在实践过程中也是对于原有业务的相关性迁就比较多，不是为了容器而容器。各个公司解决方案，定制的过程，玩法，基本上是各有各的招。如遇到的网络的改进，渐进式的使用，某种程度上把docker当成虚拟机的来用。究其原因，还是因为业务解耦，平台自由，容器化的过程并没有那么简单。
看编排调度 这次会议上有几个都在分享K8S，Swarn的技术。由于一直关注K8S，我只是选择都听了一下。谈到K8S，大家都要说说mesos swarm，对比一番。后也听了我司的线超博对Swarn分享。整体来说，像K8s这种，还是理念较新的技术，大公司没有看到一个在采用，一是它出来太新了，二是在性能及稳定上存在问题。只有新创业的一些公司，赶上打着这些的旗号。一些散户玩玩还行，但对一企业级的业务，如何彻底地服务化，如何灵活地容器调度，原有业务如何契合，明显还有很长的路要走。而swarm更是不适合在生产环境中使用，并且docker公司想一家独食的原因，又要在编排上分一怀羹，目前大家都不看好它。另外swarm在设计上缺乏集群管理的视角，也难以在生产环境中发挥调度的优势。个人认为K8S在编排调度上会完胜Swarn。
</content>
    </entry>
    
     <entry>
        <title>配置与定制</title>
        <url>http://lanlingzi.cn/post/technical/2015/0813_cfg_vs_cus/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 作为一个软件人员，我们会经常遇到各种各样的需求，有时为了避免定制，通常的做法是提供更多的配置选项，以通过配置出满足不同的特定需求。
原因是而当你开发定制代码来修改或扩展一个功能需求时，有可能会导致软件不能正常的工作，必须通过严格的测试与验证。在重大的版本升级情况下，定制是苛刻的和耗时的。甚至会面临无法修复的功能可能会被重构，从零开始。因此，一些做法是通过采越来越多地选择配置，来解决由于开发定制代码引入的问题与软件带来的成本。
因此配置与定制之间的区别是：
 配置：使用现有的数据来配置系统以满足您的业务需求 定制：将定制或使系统适应业务需求，涉及到定制开发流程。  作为一名开发或设计人员，重要的是要了解不同的配置和定制的区别，差异的关键是复杂度。配置使用的软件具有固有的灵活性，如添加字段，更改字段名称，修改下拉列表，或添加按钮。配置是使用强大的内置功能集。而定制是包括代码更改以创建出不可通过配置解决的功能。定制可能是昂贵的，并且可能会使软件的升级复杂化，因为由于代码变更可能不会很容易迁移到新版本。像“修改”或“扩展”往往意味着不同的东西，存在不确认的风险。
要避免定制，提供的一些配置工具并不总是一个较简单的选择。但这些配置选项如何配合业务运行时，也会让运维人员无所事从，太多的配置选项最终变成谁也不敢去使用，因为无法去评估配置带来的运行期的影响。一种方式是提供向导驱动的配置，但同样面临没有在初始部署时掌握他们的细节和晦涩深奥的设置。
</content>
    </entry>
    
     <entry>
        <title>微服务与SOA</title>
        <url>http://lanlingzi.cn/post/technical/2015/0516_microservice_soa/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>微服务</tag>
        </tags>
        <content type="html"> 我司学习一个新的技术，往往是搞得轰轰烈烈，比如数字化转型，向互联网技术学习。其中一个非常重要的方向就是学习互联网的服务化体系架构。国内的阿里，京东，腾讯在服务化，确切地说是微服务应用取得非常大的成功。而国外的Netflix的微服务架构更是成为我们必定的样板教材。你做设计，谈方案，不说说微服务都不好意思。如果你不说这样，说明你思维落后陈旧了。任何一项技术都有一段疯狂期，虽这近一次在搞架构重构，领导遇到你，总是关心地问到：“服务化进展怎么样了”。甚至还得跟一些不太懂的领导解释什么是微服务。
10年前差不到了SOA也像今天的微服务一样火爆。那微服务与SOA的关系或区别是什么？是不是SOA的旧洒换新瓶？软件界的大牛 Martinfowler的《微服务》更是像一部微服务的圣经，无奈是E文，大家都有各自的理解。在我司更是大家对这个各抒己见，谁都可以说上几句服务化的原则是什么，微服务成了领导专家们口里的口头禅。如果我们的系统不是微服务化，都怀疑我们系统的先进性。想当初，大家也都谈SOA，也极力推广SOA。似乎到了今天，微服务与SOA两者是势不相容。SOA是传统的IT架构，而微服务是当今互联网架构，微服务似乎比SOA更“逼格”。甚至这样的争论成了不同兄弟的心头痛。
那先来看看Martinfowler怎么说的：
 微服务风格也与SOA所提倡的一些优势非常相似。尽管如此，问题在于SOA意味的太多不同的东西了，因此通常时候我们谈的所谓“SOA”时，它与我们谈论的风格不一致，因为它通常是指在整体风格应用中的ESB。
 从试图使用ESB隐藏复杂性，到集中治理模式抑制变更，这种面向服务的风格是复杂的，没有ESB什么都不是。互联网的发展，利用简单的协议方法，让它从这些经验传达的出来。可能说对SOA集中式标准中的一种反模式，而SOA需要用一个服务来管理你的所有的服务，你就知道这很麻烦。
 SOA的这种常见行为让微服务的提倡者拒绝打上SOA的标签，尽管有人认为微服务是从SOA中发展而来的，或许面向服务是对的。无论如何，事实上SOA表达这么多的含义，它给一个团队清醒的认识到这种构架风格就已经值的了。
 至少Martinfowler在面向服务体系中，微服务是从SOA发展出来的，只是大家受到SOA的伤害而不太愿意打上SOA的标签。他们本质与出发点是相同的。微服务是细粒度的SOA，你不用去关心“庞大的”ESB，也不用去熟悉大堆的WS-*术语。当服务变得微小（micro）时，服务可能是由规模恰当的团队（12个人）制定的，也可能是单个人制定的。
我们没有办法对微服务进行准确的定义，怎么去划分服务，什么算是微服务？两个比萨能吃饱的团队（12个人）也说得太抽象了，在面对具体的实践来说，到底怎么才是SOA中微小服务，我们又如何去分析与设计？以为团队中的成员能力来划分，学是以业务功能集来划分，再去组织团队？这些问题都是我们在实践中面对的挑战。
微服务架构中的“微”体现了其核心要素，即服务的微型化，就是每个服务微小到只需专注做好一件事。 这件事紧密围绕业务领域，形成高度内聚的自治性。
微服务架构强调“微”，与之前有些采用了SOA服务化架构思想的系统搞出很多胖服务来说，一点也不微，这依然带来耦合。 这一点只能依赖系统架构师的服务化建模能力了，但微服务架构强调每个服务一个进程， 使用进程为边界来隔离代码库至少让同一应用系统不同层次的开发人员享有自己完全自治的领地，每个微服务都有一个掌控者。
《Building Microservices》一书对实施微服务架构有系统性的描述和很多业界案例的简单引用描述，这里不展开讲实施细节，那样就太长了。简单总结下实施的要点：
 自动化文化与环境：自动构建、自动测试、自动部署。 围绕业务能力建模服务，松耦合、高内聚、暴露接口而隐藏实现细节。 服务协作模型：中心化（乐队模型：中心指挥）和去中心化（舞蹈模型：群舞自组织），各自场景不同。 服务交互方式：RPC/REST/WS 技术很多但考虑统一。 服务部署：独立性、失败隔离性、可监控性。 服务流控：降级、限流 服务恢复：多考虑故障发生如何快速恢复而非如何避免发生故障。 服务发布：灰度。 服务部署：一服务一主机模型，需要虚拟化(Hypervisor)、容器化(LXC, Docker)等技术支持，实现硬件资源隔离。 服务配置：中心化配置服务支持 康威定律：任何设计系统的组织，最终产生的设计等同于组织之内、之间的沟通结构。系统架构的设计符合组织沟通结构取得的收益最大。 伯斯塔尔法则：服务健壮性原则 —— 发送时要保守，接收时要开放。   注：部分参考 《微服务架构实践感悟》
</content>
    </entry>
    
     <entry>
        <title>架构重构</title>
        <url>http://lanlingzi.cn/post/technical/2015/0430_arch_refactor/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件重构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 最近一直在做系统架构上重构工作，理论不能不学习啊，只有在思想上把自己武装起来，才能减少我们工作上的错误。之前参加过或亲自操刀过多次的代码局部或模块重构，但这一次架构重构是范围波及最广，收获颇多。
什么是重构  重构是指在不修改代码外在行为的前提下，对代码做出的修改，以改进程序的内部结构，提高其可理解性，降低其修改成本。
 这是来自马大神的《重构》一书对重构释义。重构可以改进软件设计；使软件更容易理解；使软件更容易维护；帮助找到软件Bugs；帮助提高编程效率。重构按对系统修改的粒度层次可以分为如下：
 局部代码重构，操作与实施比较容易，《重构》一书中介绍了大量经典的方法。 模块级代码重构，可能涉及到模块之间的接口重构，操作与实施难度相对适中。 架构重构，是对整个系统架构层次的重构，牵系相当的广，操作与实施难度比较高。  重构风险 无论何种层次的重构，都必须要有一个可靠的测试环境，即自动化测试环境。因为频繁的代码修改可能会引入更多的缺陷，只有执行自动化测试并回归所有用例，才能保证及时发现这些缺陷，最大限度地降低重构的风险。
 局部的不良代码，可以通过小范围的重构来优化。但是对于架构上重构，因为重构影响范围过大，在实践中仍然存在绪多的困难。 架构上大的重构，至少几十人的投入，更需要半年到一年的开发周期。在老软件不能停止维护的前提下，这对开发人力将产生巨大冲击。 新架构虽然先进，但历史经验表明，新软件的成熟与稳定需要时间。在沉重的交付压力下，风险需要做很多的预防控制。  为什么要重构 给老大说明重构的意义往往很难，尤其不是技术出身的管理者，即使是，也需要面临交付上的考虑。从技术上讲，为什么要重构：
 不论如何先进的软件架构也不可能预见到几年甚至十几年后的需求，并预先设计 随着新功能的不断增加，以及新成员的加入，软件架构必然逐渐腐化 虽然强力的架构看护制度可以延缓架构腐化的速度，但不可能看护到实现细节 重构则提供了软件持续优化的机会，从而使软件更容易适应新的需求，同时及时地改进不合理的部分  重构与重写 对于一次重构来说区别不大，只是力度不同，重构侧得局部优化，也会重用现有的资产，重构的极端就是重写。他们的主要区别是重构强调的是持续的，随时的优化，而重写强调的是一次性的天翻地覆的改造。那我们如何判断是要重构还是重写？
 重构是持续的，并不是等到极端恶心才开始优化，所以坚持持续的重构可以代价更小的达到优化的目的 若已经极端恶化的模块，重写也是一种解决方式，但要注意避免失控，须在设计、测试、管理、人员能力等多方面要做好准备  何时重构 何时重构，因项目因人员能力而异：
 不同粒度层次的重构，重构的时机选择应该是不同的 不同粒度层次的重构，实施的节奏也必然不同的 关键技术需要提前原型验证，风险评估 对于模块级，架构级重构，通常在添加新功能或特性之前充分考虑，留出部分空档期来重构 制定重构计划，步步为营，切忌全面开花，导致风险不可控  同时在重构时，需要平衡重构与交付：
 为了交付而不重构，是恶性循环，最终交付的压力会越来越大，质量会越来越差 对于模块级，架构级重构，应该是有计划地落入到迭代版本中 可以采用冬虫夏草的方式重构，逐步重构或替换，随时（至少每个迭代）可以保证系统的完整性 注意控制每次迭代重构的范围，要分析并划分合理的重构边界  重构人员 重构最终落实还是人员能力，对于参与的人员能力要求：
 知道重构的意义，重构需要有个人强烈的意愿，才能有所突破 对现有的组件流程与实现非常地清楚 针对性强，能够熟练地运用各种重构方法 能够察觉出实现的问题，能提出改进（重构）建议（方案） 经验是基础，对构架本身的体系有较为深厚的理解和应用经验 不同层级的重构，需要不同的参与，不同阶段投入  重构中有哪些角色，他们职责是什么
 SA/SE（系统架构师，系统设计师）：负责按照架构正确地设计与分解需求，能清楚系统中的痛点，以及各组件的主要问题 SE/MDE（系统设计师，模块设计师）：负责某个组件整体看护，设计组件内疗实现机制，系统约束等 SWE（软件工程师）：在软件架构的基础上，负责具体的功能实现。 TE（测试工作师）：补充用例，执行自动化测试，及时发现系统中的缺陷，并与SWE结队处理问题。   总之，重构要务实，务实就是尊重现实，基于现实情况分析与实施，不断地推进演化。架构重构不仅需要充分的设计，切实有效的重构操作方法也非常地重要。架构重构，抛开代码搞理论上的重构不行；充分利用代码，但又不能掉进“代码泥潭”。无论怎么重构，一定要构建夯实的测试防火墙，快速反馈重构中的问题。
</content>
    </entry>
    
     <entry>
        <title>OSGi的缘起缘灭</title>
        <url>http://lanlingzi.cn/post/technical/2015/0422_remove_osgi/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>OSGi</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 什么是OSGi 维基百科：
 OSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。
 我们所说的OGSi，通常讲的是Java语言实现的OSGi，但也是有其它语言实现过OSGi，由于没有Killer应用，几乎是无人知晓。
2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。Eclipse的成功让人认识到OSGi的优秀与魅力，也把OSGi带到众多的程序员面前。
缘起 正好10年底开始转型做云计算，当时选型的开发语言是Java，这没有错，看看目前Java在云计算中应用程度，说明我们是选对了。同时我们也选型开发框架。我当时受到Eclipse的基于OSGi的插件机制成功影响，是极力推荐使用OSGi的。当然最终决策采用OSGi的不是我，但我的确在其中起了摧动作用。当时采用它的主要原因我想有如下：
 模块化，模块之间基于服务接口通讯。 插件化，Bunlde可以动态加载。 组件化，面向服务的组件，组件由多个服务组成。 生命周期管理，相比普通Jar包，我们可以更细粒度的管理 &amp;hellip;  我们使用OSGi，采用两种框架，一个是Apache的Felix，使用它主要是看重它很小，用于开发主机代理，在其上开发各种采集插件。一个是Spring的Spring DM，即后面的Eclipse Virgo。使用它主要是看重它集成了Spring，用于开发后端服务，采用Spring DM来简化OSGi的服务发布与引用，以及能较好地使用Spring的其它能力。
可以说从11年到14年，我都是在基于OSGi做开发，从早期喜爱到最后的放弃，个中的滋味真不知怎么说。期间我在整个团队做了不少关于OSGi的推广，写过些文档介绍，规范要求，定位过稀奇的问题，最后大家都觉得我是这一方面的专家，只有搞不定的问题就来找我，我才逐渐意识到OSGi的理念虽好，但要真的把它使用得很好，真是不简单啊。
OSGi虽解决了本地的服务访问的问题，但云系统是一个分布式的系统，所以在后面又折腾过DOSGi，使用是的CXF实现的DOSGi，这个更难使用。先只有少数一两个服务在尝试使用它，期间遇到的问题更多，最后也不得不在13年初就放弃了。我不得不搞出另一个RPC的框架出来。
缘灭 在去年的时候就开始讨论是否去OSGi，连最早鼓吹使用OSGi的阿里，也花了很大精力去OSGi，不过他们的动作早在12年就开始了，Spring也在12年摒弃OSGi，把Spring DM捐献给Eclipse。我们更是受项目进度与人力不足限制，去OSGi也只是停留在讨论中，有点“不破不修”的意思，OSGi凑合着使用。
15年软件界最火爆的两个词可能是：微服务，Docker。去年平台定位发生变化，从偏IaaS转型偏应用的PaaS，原有的架构存在些问题；而今年的微服务概念也直接点然了系统架构重构的火把，而我又是这次架构重构实施落地的组长。这真是有点戏剧性啊！“出来混迟早要还的”，当初我是团队中使用OSGi的带头人，今天又是团队中OSGi的埋葬人。老大们要求我们把架构重构，目标是系统解耦合，轻量化，利于团队分工。自然去掉OSGi，朝分布式微服务化演进在设计考虑的范围中。的确，微服务化与OSGi也不冲突，为什么要去OSGi呢：
 OSGi的门槛太高，学好用好它对程序员要求高，而团队新人比例高 很多第三方组件不是Bundle，需要Bundle化，增加维护成本 使用到其它部门的中间件也宣称不支持OSGi，越来越处于孤立 多版本管理问题，在同一套环境中，相同的第三方Jar存在多个版本，版本无法归一，增加维护成本 基于OSGi的服务接口测试难度高，LLT测试时依赖于OSGi环境，测试成本高 OSGi的服务接口只是本地接口，而云计算中恰恰需要分布式服务调用框架 ClassLoder问题，导致很多的开发兄弟考虑不足出问题，经常是运行期抛ClassNotFound Virgo， Felix其实也很重，多个组件部署在同一套环境中，隔离性差，不适合微服务理念 Bundle的动态替换就是伪命题，从来没有用过 用于做插件机制，动态加载的ClassLoder问题 JRE在Virgo环境下会出现死锁，需要升级JRE到8才能解决，还不知会有其它问题，社区支持不足 大环境下，OSGi已成明日黄华，不再是宠儿 &amp;hellip;  从上面可以看出，OSGi的面向接口编程，服务化，模块化理念在单体应用来说虽不错，在面对分布式的应用时，它带的益处远比它的本身的机制带的问题更多。所以OSGi留得越久，越是技术债务，早去掉早解脱啊。
</content>
    </entry>
    
     <entry>
        <title>软件开发中缺陷管理</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0901_soft_dev_dt_trace/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 在我司，我发现大家很擅长把一个东西到极致，但极致可能是过犹不及了，例如测试并不是发现越来越多的Bug就越好，如果把很多的时间消耗到一些不重要的点，反而不可取，软件只要你去测试，怎能发现一些Bug，如要面对这些就非常纠结。作一名开发，说这话肯定会被一批的测试人员拍砖死了。在此表达一下不同的观点，不一定正确，请轻拍。
在我司的各种度量工具很牛X，缺陷跟踪分析每个迭代阶段就会做，形成一些报告。对于软件质量来说，统计所有过去的Bugs是没有多大用的，相对来说，一些更实际的工作可能更重要，在Douglas Hubbard的《How to Measure Anything: Finding the Value of Intangibles in Business》(如何衡量任何事：寻找商业无形资产的价值)中，把这种现象解释成衡量倒置(Measurement Inversion)：衡量一个东西的经济价值与它通常所受到的关注度多少成反比。
一种较有说服力的观点是缺陷跟踪方便人们发现缺陷的趋势，对流程的改变很有一些效果，如提前做些缺陷预防。对于管理者来说，他们需要缺陷跟踪报告可能了解软件的质量状况。但可能实际却不是这样的，单单根据DI值来判断软件质量，这跟由湿度来判断天气是否好坏一样不太靠谱。
质量是什么，尤其是软件的质量是什么？是看软件的缺陷率吗？比如我现在比较喜欢荣耀手机，我会关注荣耀手机DTS中的单有多少吗？在消费者的眼中，质量就是对他有价值的东西。如果客户是快乐的，存在一些漏洞也是问题不大的。如果客户抱怨，跟有多少Bugs是无关的。
前几年在摧广敏捷时，提到做刚刚好的系统，也提到了零缺陷：符合已确定之要求，一次做对。第一次把正确的事情做正确，包含了三个层次：正确的事、正确地做事和第一次做正确，三个因素缺一不可：
 正确的事：辨认出客户的真正需求，从而制定出相应的战略。 正确地做事：软件开发中所必需的全部活动都符合客户和市场的客观要求。 第一次做正确：防止不符合要求的成本产生，从而降低质量成本，提高效率。  什么是软件的缺陷，在软件程序中存在任何一种破坏正常运行能力的问题，都可能叫作缺陷，Bugs。但生产软件的最终目的是为了满足客户需求，如果以客户需求作为判断软件质量的标准，软件的缺陷可以包括如下几个因素：
 软件未达到客户需求的功能与性能要求； 软件出现客户需求不能容忍的错误； 软件的使用未能符合客户的习惯或工作环境。  软件测试其实并不只是要发现问题，如果我们进行非常变态的测试，的的确确能发现很多的问题，但是有可能此类问题根本不可能出现，或是在软件生命周期内也永远不会出现，没有这么复杂的使用场景。在做异常测试，虽然一定要以发现缺陷的心态挖掘测试，但也不应该是一种无所欲为的测试。还好，公司已积累了不少的故障模式库供参考分析。但是像可服务性，可维护性，易用性应该做到什么样的程度却在实际项目操作中很难把握。任何缺陷的修改都是有成本的，一旦控制不好，可能把有限的精力都浪费在不重要的点了，这也是开篇所说的过犹不及。
测试人员认为某种情况是缺陷，但开发人员认为又不是，而现实就是所争议的情形在需求中也没有明确地描述。公说公有理，婆说婆有理，说不清，道不明的。开发与测试的争执由此开始，矛盾也由此产生，不和谐的气氛由此理下种子。出的原因可能有多种：
 需求澄清不清，需求描述太过于简单，离最终的客户又远。 对于原始需求没有进行评审，整理，并书面化归档。其实需求文档也要测试验证的。 开发与测试存在理解上的偏差； 需求本身的定义存在二义性。  面对这种问题，无论开发与测试人员需要知道：
 要知道任何的争论解决不了问题，争论不要存在个人感情色彩(其实这个很难做到)； 出现问题，首先从自身找问题，有时往往是因为我们的简单思维导致。 人非圣贤，有错就改，并不失面子。讨论对事不对人。  可能在很多的部门，把缺陷做为开发或测试的绩效指标，这种简单而粗暴管理，直接的结果就是让开发和测试从此不和谐，彼此斗角。要相信办法总是比问题多，每一个问题都有至少一个解决的办法，愿开发与测试都能朝同一个目标，把软件做到刚刚好，事成人爽。
</content>
    </entry>
    
     <entry>
        <title>软件开发与中医理论</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0804_soft_dev_tcm_theory/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 最近一段时间，看了些的版本迭代开发数据。有CI中QDI，FindBugs，重复率，复杂圈度；也有迭代的Story实现率，IR分解率，DI值;也有测试用例，覆盖率，执行时长，入门用例比等。反正各种度量数据多得是，从各个方面来反馈项目的质量。俗话说：有人的地方就有江湖。有江湖的地方就有纷争。有度量数据就有晒马排名，有排名的地方就有政治任务。我们的流程辅助度量工具多了，但这些真能带动我们的质量上去了吗？
小儿已一岁多，现在回顾他做的一些体检。前三个月每月一次体检，一岁之前每3个月一次，一岁之后是每6个月一次。体检的项目有称体重、量身高、量头围、量胸围、验视力、测听力、检查动作发育、口腔检查、评价智能发育、验血、骨骼检查、心肺与心率检查、大便和血红蛋白。体检医生一上来就是开各个体检单，采用是西医的方式，看指标数据，再评测，体检应该是医院最好的生财路之一。个人也明白，正如我妈说的，我小时候哪有什么体检，也不是好好的吗？现在带小孩去体检，也是图个安心，提早预防。
那说这些跟软件开发有什么关系？西医是基于实验科学，从实验走向临床，再到应用，它关注对外界变化的认知，比如发现了细菌，就有了抗生素；发现了病毒，就有了疫苗；发明了人工心脏，就可以做植入心脏。西医的研究对象是外界。强调对症下药，看的是病。而中医以阴阳五行为基础，将人体看到气，形，神的统一。聚焦于人本身，就是人的经络，阴阳，五行等。通过中药、针灸、推拿、按摩、食疗、拔罐等多种手段来达到人体的阴阳调和而康复。强调调和平衡，看的是人。西医通过相同的病因数据，药物使用可能复制到不同的人。而中医需要通过医生的非常经验，开出不同的药方。所以年纪越老的中医越是历害。
现在的软件工程，也似乎像西医一样，试图通过固化流程，工程手段，指标数据来统一所有项目的开发。典型的是CMM，它关注项目本身，往往忽略了项目中的人。一个C版本三个月，我们个人并没有在这短短的三个月里边发生什么实质性的变化。一个本来连计划变更都要审批，还要被QA严格审计的受控团队，有时又变成一个居然可以什么都自己估算，和中途临时领取需求任务的自组织的团队，不可不谓一个相当疯狂的举动。最后项目管控就看是各种指标数据，个中变化指标能看到什么呢？即使各种指标细化，能真实的反应项目的实情吗，这要大大地打个问号了。也有人会说，数据好的项目并不一定好，但数据差的项目一定是不好。好吧，我认这一条。
外界的敏捷开发，应该是强调项目中人的本身吧，快速适合各种变化。管理以人为本，时刻进行相应的调整，尽可能地发挥个体的能力。一个被各种指标数据盯着的团队能放下这些，快速适合变化，快速响应客户的需求吗？软件的开发过程也不可能固定不变，因人而异，因项目而异，一两种软件工程学能搞定所有的项目吗？
</content>
    </entry>
    
     <entry>
        <title>做一名好的开发人员</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0729_better_developer/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 我在上一次的新员工交流会议上，问新员工对全栈工程师了解不，我们的目标是成为一名全栈工作师，而不是做一名只会写代码的码工。最近遇到一些不开心的事，可能是在华为呆久了，发现到底都要会学扯皮。而我性情不太喜欢做一些自认为这些是无意义的事情。虽然有前辈告诉我，扯皮可能的效果会让你少加班几个月。说着说着，有点偏了，扯皮其实是沟通成本。项目越大，沟通成本越高。带个项目的人都会意识到，项目中的人力是1&#43;1&amp;lt;2的，人越多效率越低。因为沟通是需要成本的，不同技术的人各说各话，前端和后端是一定会掐架的。每个人都会为自己的利益而战，毫不为已的人是不存在的。
减少沟通成本，我们需要全栈工程师，因为各种技术都懂，胸有成竹，自己就全做了。即使是在团队协作中，与不同技术人员的沟通也会容易得多。懂你的，你懂的，相互理解，也就少了很多的时间在扯。
那什么是全栈工程师：通俗地讲，掌握多种技能，并能利用多种技能独立完成产品的人。打外比方，全栈工程师就是一个能独立盖一幢10层小洋楼的人，而普通工程师，则是可以和一群人盖一幢摩天大楼的人。较搞地讲，全栈工程师=**丝战斗机=系统&#43;网络&#43;研发&#43;DBA&#43;架构&#43;安全=没女朋友/没男朋友，拿一份工资做三份事情，公司的奋斗者，其它人眼中的牛人，傻X。有人说了，你再牛X，你懂五种技术，你能干五个人的活吗？全栈工程师并不是说一个人能干几个人的活，而是要从多个方面来看这个问题。
我们遇到了什么问题？产品在报怨平台；开发在报怨SE没有搞清需求，规格写得不清不楚，不了解系统实现；测试在报怨开发，问题太多，Story写不好，自测试不充分；开发在报怨测试，不了解系统，机械提单，单的质量低，场景不符合业务。听多报怨，人也会变成急躁不安。心平气和，放下争端，谁都想开心上班，开心下班。报怨也是解决不了问题，反而是有摧卸责任之嫌。
那在华为，全栈工程师能解决上面的问题吗？不能！首先，在华为，细化的分工很难培养出全栈工程师，那你还提全栈工程师有什么用。一名的好的开发者，能缓和一些项目中的扯皮矛盾。好的开发者，即使不是全栈，也要融会贯通多种技术。我从来不认为一个只专精一种技术的人有可能成为好的开发者。从广度和深度的组合看，我认为好的开发者大概有两种类型：__1)手术刀;2)代码专家(来自《人月神话》)。__手术刀是业务驱动的，最需要全栈的人；他们的核心价值在于：懂业务，技术全面，都能拿的起来，而且能选择最合适的技术。代码专家是技术驱动的，即使不够全栈也可以用，但是技能树点的越多当然有好处。
如果你现在是一名开发，那我如何做。而在技术选择上以“关注商业目标”和“关注用户体验”为原则。脱离商业目标的技术都不会得到长期的认可，脱离用户体验的产品终究被淘汰掉。在华为，你做一名开发，首先要__主动关注前期需求分析__。发现问题，洞察需求，才能设计出实现方案，最终的实现也不太大的偏离。我一直比较反感我们想需求，觉得应该是这样的。或者做些用户根本不会使用的需求。但现在组织结构决定了我们不能向客户靠近太多。那我们能做的就是多与SE讨论，规格是一种载体，把问题讨论清楚，澄清准确是关键。开发也要意识到需求分析，设计不仅仅是SE的事。不懂设计的开发也不是一名合格的开发。
__吃自己的狗食。__真正的工程师是能真正明白软件开发不单单只是编码，还更要明白整个软件工程。只明白或是只喜欢编码的，那只是码农，不能称之为工程师。程序员要干几乎有的事，从需求分析，设计，编码，集成，测试，部署，从头到尾。如果你不能切身体会到自己干的烂事，自己的痛苦，你就不会有想要去改进的动机。没有痛苦，就不会真正地去思考，没有真正的思考，就没有真正的进步。
__学会测试与体验。__只有了解了测试的难度，你才明白怎么写出可测试的软件，怎么去做测试的自动化和测试系统。只有自己去使用自己的系统，你才明白用户的反馈，用户的想法，和用户的需求。开发如果都不知道怎么做测试，那还能期望测试能帮助你测试？开发人员本来就要测试自己写的软件，如果开发人员不懂测试，或是对测试不专业，那么这就不是一个专业的开发人员。开发人员了解整个软件的设计和开发过程，开发人员是最清楚应该怎么测试的，这包括单元测试，功能测试，性能测试，回归测试等。开发人员知道怎么测试是最有效的。开发人员的技术能力知道怎么才能更好的做测试。
__切忌摇摆不定。__我们学习技能和知识，不是为了成为某个领域的专家；而是完成自己目标所需要的。今天学C，明天学Java；今天搞Cloudify，明天搞CF。主张“先精后广，一专多长”的流程来学习，不要左右摇摆，先做一件事件再说。你所学，所使用的是要切合当前业务目标的。当然也要清楚地认清任何技术只是服务于市场的，在市场发生变化，如果程序员不能顺应发生变化，就有被淘汰的风险。人的角色也是不断变化的。8/2定律在哪都适用，全掌握20%常用技能的人，但这20%的技能会有80%的几率被用到，剩下那80%不常用的，让我们Google吧。另外具体经验也是相当的重要，任何的项目，你可以思考一下我学到什么经验。更重要的是思维方式和学习能力。项目中总会遇到各种问题，问题摆在那里你就需要去解决，而无论这要求你去钻研什么。这就是我所说的学习能力。
我不生产博文，只是互联网的搬运工。以上观点与内容来源于互联网，感谢伟大的互联网。
</content>
    </entry>
    
     <entry>
        <title>Git SSH设置</title>
        <url>http://lanlingzi.cn/post/notes/2014/0322_github/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>git</tag>
        </tags>
        <content type="html"> Git HTTPS 和 SSH 的区别：
  前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。
  https url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。
  首先检查是否已经有 SSH key 运行 git Bash 客户端，输入如下代码：
$ cd ~/.ssh $ ls 这两个命令就是检查是否已经存在 id_rsa.pub 或 id_dsa.pub 文件，如果文件已经存在，那么你可以跳过步骤2，直接进入步骤3。
创建一个 SSH key $ ssh-keygen -t rsa -C &amp;#34;your_email@example.com&amp;#34; 参数含义：
-t 指定密钥类型，默认是 rsa ，可以省略。
-C 设置注释文字，比如邮箱。
-f 指定密钥文件存储文件名。
以上代码省略了 -f 参数，因此，运行上面那条命令后会让你输入一个文件名，用于保存刚才生成的 SSH key 代码，如：
Generating public/private rsa key pair. # Enter file in which to save the key (/c/Users/xiao/.ssh/id_rsa): [Press enter] 当然，你也可以不输入文件名，使用默认文件名（推荐），那么就会生成 id_rsa 和 id_rsa.pub 两个秘钥文件。
接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），
当然，你也可以不输入密码，直接按回车。那么push的时候就不需要输入密码，直接提交到github上了，如：
Enter passphrase (empty for no passphrase): # Enter same passphrase again: 接下来，就会显示如下代码提示，如：
Your identification has been saved in /c/Users/xiao/.ssh/id_rsa. # Your public key has been saved in /c/Users/xiao/.ssh/id_rsa.pub. # The key fingerprint is: # 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com 当你看到上面这段代码的收，那就说明，你的 SSH key 已经创建成功，你只需要添加到github的SSH key上就可以了。
添加你的 SSH key 到 github上面去   首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制。
  登录你的github账号，从又上角的设置（ Account Settings ）进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。
  点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。当然，上面的 Title 所对应的输入框你也可以输入一个该 SSH key 显示在 github 上的一个别名。默认的会使用你的邮件名称。
  测试一下该SSH key 在git Bash 中输入以下代码
$ ssh -T git@github.com 当你输入以上代码时，会有一段警告代码，如：
The authenticity of host &amp;#39;github.com (207.97.227.239)&amp;#39; can&amp;#39;t be established. # RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. # Are you sure you want to continue connecting (yes/no)? 这是正常的，你输入 yes 回车既可。如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码，如：
Enter passphrase for key &amp;#39;/c/Users/xiao/.ssh/id_rsa&amp;#39;: 当然如果你密码输错了，会再要求你输入，知道对了为止。
注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。
密码正确后你会看到下面这段话，如：
Hi username! You&amp;#39;ve successfully authenticated, but GitHub does not # provide shell access. 如果用户名是正确的,你已经成功设置SSH密钥。如果你看到 “access denied” ，者表示拒绝访问，那么你就需要使用 https 去访问，而不是 SSH 。2
设置全局git账号 git config --global user.email &amp;#34;your_email@example.com&amp;#34; git config --global user.name &amp;#34;your name&amp;#34;  参考文档：https://help.github.com/articles/generating-ssh-keys
</content>
    </entry>
    
     <entry>
        <title>优秀程序员</title>
        <url>http://lanlingzi.cn/post/thoughts/2013/1113_good_programmer/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 关于什么是一名合格的程序员，优秀的程序员，这些讨论从来没有停止过，标准各不相同。有人说优秀程序员追求简洁的代码，优秀的框架结构，新的技术技能。我们不是在讨论什么是业界大牛，我心中的一名优秀程序具备如下几个素质：
  简洁高效
优秀的程序员会使用整洁，易于理解的方式解决实际的问题，任何不必要的复杂代码均不会出现，简单比复杂更具有价值。能通过简洁的方式把复杂的问题解决掉。
    开放心态
不要盲目自信，自负，在IT这个领域，新知识层出不穷，你永远不可能全部掌握，在某些领域，你一定会是低人一等。教条、狭隘与不切实际的表现往往让你变得越来越自负，也会越来越陷入一个很小的框框内。
  切合实际
软件开发，不是理念的教堂，也不是技能的校场。忽略实际情况，再精妙的代码解决不了问题，也只是一纸空文。优秀程序能打破常规，找到问题的本质，快速地，简洁地解决问题。
  质量保证
态度明确，能一直以我交付的代码一定要是高质量的目标。对代码负责，会不停地优化与重构自己的代码。对代码充分的测试与验证，极少的Bugs。只会写代码，不会测试的程序员不是优秀的程序员。
  积累分享
平时注重通过研究新的技术，新的软件工程方法，来为以前无法解决的一些软件问题提供更优的方法。能对软件开发中的实践进行总续与升华，将自己所掌握的东西转成显式的知识，并能通知多种方式进行分享。知识的传承的重要性远远大于代码本身。
  热爱编程
不要做只会编码的码农，热爱生活，才能享受编程带来的快乐。热爱编码，热爱自已的职业。如果对编码没有热情，只是一种谋生手段，那最终在编程这一条路也不会走得太深。
  沟通反馈
在软件开发领域，尤其是大的系统开发，不可能是单打独斗。学会在团队中沟通，与同事协作一起完成任务。同时也要识别不合理的需求，懂得拒绝别人，学会Say No。在项目中，要明确自己的计划，明确自己的职责。要学习与同事，项目经理及时反馈。
   </content>
    </entry>
    
     <entry>
        <title>HW八年总结</title>
        <url>http://lanlingzi.cn/post/thoughts/2013/0909_hw_8years/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>总结</tag>
        </tags>
        <content type="html"> 白驹过隙，进入公司已是八年，一路学习一路收获。往后回首，一些经历回想起来还历历在目：经历过一线比拼的激情，经历过产品上线的喜悦，经历过多个项目的变换，经历过持续熬夜的艰辛；写过不少的代码，带过一些徒弟，负责过团队开发，一直在公司从事基层的研发工作。一路走下来，也得到部门领导，公司同事的帮助、指导与鼓励，能让我一直坚持下去，过程中我也得到一些很高的认可，感触多，收获多。在此我先感谢大家！
团队成功才能成就个人 还记得进入公司做的第一个项目，就是上海电信的XXX规范比拼项目，在上海一呆就是3个月之久。之后从09年开始到现在，我应该遇到一个不错的机遇，时逢部门的产品在欧洲开花结果，并且我非常有幸地参加了其中的多个项目，TLF比拼、VDF比拼、SFR比拼、O2的交付，DT比拼，有去一线出差现场操作，也有在家持续熬夜支撑。后又参与平台非常重要的新项目C3的构建，见证它从无到有，到多个局点的交付，目前C3在VDF交付。所以说是 只有团队的成功，才能有个人的成就 。我作为一个普普通通的软件工程师，有机会参加了这么多的高端比拼与交付，也可能实属我人生中为数不多，以后可能值得会拿出来说一下的事儿。当然参与这些项目对我自身也是一项非常大的挑战，尤其是在比拼项目中亦时候不知熬了多少个夜晚，甚至彻夜难眠，也不知当面对客户苛刻的验证时的紧张感，心跳加速多少次。但始终相信我是在做一件有意义的事情这就是对的，虽然过程肯是辛苦的，结果可能不理想的。有时甚至还害怕而抵触过，抱怨过。但只要一旦接受了也就始终没有放弃过，把分给我的工作尽自己最大的努力做好做实，做到问心无愧 。
做适合自己做的事 人贵有自知之明，熟悉自己的性格缺陷，搞明白自己擅长什么，这其实也非常地难做到，尤其是在面对一些机会时做决策。当初大学毕业时，家人就安排我在深圳益田村做物业管理，最后也没有做下去，原因是不适合。像我这种人，我不喜欢指挥人去干活。如果去做市场肯定打不开局面，不太会说动别人。如果去搞财经也肯定搞不好，看到一大堆的数据比较头疼。如果去搞前台设计也肯定搞不好，从小就没有什么艺术细胞。最后发现搞搞后台技术可能凑合着，也符合我个人的性格，能安静地做事。所以即使来到公司这么多年了，还是对技术情有独钟。事实上，很多岗位不一定要最优秀的，但必须是要最合适的。 每个人都有优缺点，金无足赤，人无完人，在合适的岗位上做自己擅长的事 。
居安思危，适应变化 信息爆炸的时代，外部形势与内部因素都无时无刻都在变化，对个人来说，时刻可能都面临挑战。从在公司的几年来看，我个人的工作内容也一直在变化着，人传统的智能网到源于互联网的云云计算，从窄带智能网到宽窄带融合，从话音控制到消息内容，从单体大型服务到分布式集群应用，从C&#43;&#43;语言到Java语言。真是变化太快，每次转变，都需要去适应它。面对变化，自己需要时常有点危机感，不断地去学习。比如说去年带头做E2E一键部署时，需要了解的东西很多：要做界面，没有使用过Java Swing；虚拟化部署，没有使用过Power Shell，都需要快速学习，所有事情搞定。可以说每个人都有业务短板，你不可能是一个天才，这种对无法胜用的危机感导致不敢放松自己。缓解危机感往往需要的是应对实际困难的技能或技巧。时常有了危机感，才会促我去主动学习，主动思考，主动改变。我不是一个力求完美的人，但在工作中往往会尽最大的努力与热情来了解各种专业技能，把手头上的事情做对做好。
兴趣，好奇心 记不得是哪个名人说过兴趣是最好的老师，我觉得应该是最好的向导。如果你对某件事感兴趣，它会牵引你去主动学习、行动与思考。 我一直对各种新技术比较好奇，以前下班之后回到家经常去逛一些技术网站与论坛。好奇心是一个研发人员的基本素质，据说做学问成功的第一要素既不是天赋，也不是勤奋与激情，也不是靠你努力就一定出得来的，而可能是好奇的灵光。好奇心驱使我去了解一些技术细节，技术动向，如之前对C&#43;&#43;比较执迷，经常请教同事一些较偏的用法，下班回家喜欢写点代码验证一下想法。又如当时GAE刚出来，我就利用周末开发GAE应用玩玩，后被墙掉访问不方便才没有继续玩了；又如之前开心网种菜火爆时，马上抓包分析写偷菜外挂；我也可能是一个刷机控，从09年开始的M8刷成Android，之后的iPod, iPad, iPhone, SAMSUMG手机没有少被我折腾过，刷成不同版本的定制系统。平时这些技术多猎奇可能看似对工作起不了直接帮助，但它们能扩展的视野，丰富我的知识，强化我的动手能力。若在工作中遇到类似问题时，可能举一反三，找到解决问题办法。关注技术但不要陷入技术，本质是用技术来提升认知问题，分析问题，解决问题的思想高度。
耐得住寂寞 来深圳有不少的高中，大学同学，以及亲朋好友。大家大学毕业都差不多十年了，在坚持做技术是越来越少，尤其是从事软件开发的。以前大学同学每年的聚会，问的最多的问题是你还在HW啊？还在写代码？现在已经不问了。的确，在国内做软件开发的大环境相对不是很好，尤其是上了三十岁的人还从事一线编码工作，会觉得你是没有上进心的人。在外部，我好几个同学转行了，有些创业，做得还不错。在公司内部，也见到越来越多的同事，习惯于风风火火到处开会。这是很危险的，会使我们的杂乱信息越来越多，功底越来越浅。佛家中有一项坐功是讲你你定力修为，HW的研发人员也需要一种定力，任何一件事情的极致需要持续的积累才能达到。我想我还一直在从事基层的研发，一方面源于我的兴趣爱好，另一方面也符合我的性格。从另一方面来说，要能持续把一个简单的事情做好做对，也需要面对各种诱惑而得住寂寞的能力，心无杂念去做事。
知识管理，思考总结 如今是信息爆炸的时代，各种各样杂乱无章的信息迎面扑来。如何将众多的信息提炼，转化为知识对于提升个人能力尤显相当地重要，有时不得不感慨：山中方一日，世上已千年。人与人之间的竞争，从某种意义上讲，可能也是个人运用知识快慢，正确与事的竞争力。大凡成功的人士，都少不了对知识的合理管理。
对于太多数人来说获取过程也是收集过程，记录的知识可能是一些零碎的片段，即使分类也是杂乱的、没有关联的，不利于管理，更难形成体系。时间长了，如果没有好的工具搜索出来，也是前功尽弃。在实际工作中，我们更多是遇到类似的问题，才去搜索，搜索之后就是Ctrl&#43;C与Ctrl&#43;V，多半会被遗忘掉。所以在获取知识以后是积累，积累以后是实用，实用以后是分析，分析以后是总结。这样才能把知识转成一种能力。总结最好的方式是写出来，与人交流，写与说的过程一方面可以督促自己完善想法，加深认识，说不定还会擦出创新的火花。 所以我就一直尝试去写一些东西，虽然文笔很烂，坚持下去也会收获不少，今天一看，在公司的Hi3MS平台已写一百多篇的技术博文了。
 回头再看，浓缩一下：“持续学习，实践行动，思考总结”，这几个可能概括出我这几年的经历吧。想起姜育恒的《再回首》歌词来做结尾吧：不管明天要面对多少伤疼和迷惑，曾经在幽幽暗暗反反复复中追问，才知道平平淡淡从从容容是最真，再回首恍然如梦，再回首我心依旧，只有那无尽的长路伴着我。
</content>
    </entry>
    
     <entry>
        <title>Java线程使用建议</title>
        <url>http://lanlingzi.cn/post/technical/2013/0424_java_thread_suggest/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> 最近Review团队内一些的代码，发现不少地方在使用线程池，但使用比较乱，针对问题建议如下：
  线程不能调用Thread.stop来停止它，我见过有新员工就这么干过哦，而是需要设置一个标识位，在run方法中判断此标识位退出循环。用interrupt也是可以考虑的，但线程的run方法中要捕获InterruptException。
  所有线程需要设置Name，主要是方便线程dump出来之后定位问题。这可是编程军规，我们很多的兄弟没有遵守。
   大多直接是使用Exectors.newXXX直接new线程池，没有设置队列的大小，默认是整型的最大值，一旦有线程处理阻塞，队列上涨，内存不可控制啊。
  最好不要使用newCachedThreadPool，曾经有个模块这么干，在工作线程处理慢时，线程线会不断上涨没能及时回收。这个模块出现异常，线程dump之出来发现有2000多个由它产生的线程，内存超高。
  所有线程都要受管理，不允许直接new Thread就直接start就不管了。同样所有从Exectors.newXXX创建的线程池，当bundle去激活时，一定要shutdown。
  线程个数设置多少合适？不是越多越好，多了竞争资源反而效率低。建议配置的线程数=可用的CPU数/(1-阻塞系数)。阻塞系统在0到1之间，所谓阻塞系数就是发生的IO操作，如读文件，读socket流，读写数据库等占程序时间的比率。这个数值每个系统肯定不一样，可通过分析工具或java.lang.managementAPI来确定这个值，也可以做个估计，然后测试逐步往最佳值靠拢。如果线程不是瓶颈所在，那么大概估一个值就好了。
  不要在多线程中共享数据，最佳的实践是无锁编程。所谓有锁编程，就是当你需要共享数据的时候，你需要有序的去访问，所有改变共享数据的操作都必须表现出原子的语义，在无锁编程中，并不是说所有操作都是原子的，只有一个很有限的操作集是原子的。采用wait-free 和lock-free 的算法，基于FIFO 的队列和LIFO的栈，或者更复杂的优化级队列、 hash表及红黑树的lock-free 算法以达到无锁编程。
  定时器中Runnable一定要catch所有异常，否则会由于异常导致定时不再执行。
  如果你在多个线程之间共享数据了，且采用锁了。那一定要防止出现死锁，什么是死锁：线程A加锁锁a，等待线程B已加锁的锁b释放，而线程B却也要锁a才很能释放锁b，就会发生死锁。平台基于monitor会定时检查死锁，一旦存在死锁，平台会自动重启。
  不要在构造函数中启动线程，这个会引起什么问题呢？如果有个类B继承了类A，依据java类初始化的顺序，A的构造函数一定会在B的构造函数调用前被调用，那么thread线程也将在B被完全初始化之前启动，当thread运行时使用到了类A中的某些变量，那么就可能使用的不是你预期中的值，因为在B的构造函数中你可能赋给这些变量新的值。也就是说此时将有两个线程（构造线程与新启线程）在使用这些变量，而这些变量却没有同步。
  你确认你的业务真的需要使用线程池吗？并发异步处理才需要，单线程无阻塞也是效率很高的。多线程在多CPU多核下才有它的真正价值。我们去分析优化时系统时，首先要考虑是减少阻塞，而不是一上来先加几个线程呗。
 </content>
    </entry>
    
     <entry>
        <title>[WebApp沙箱]SecurityManager运用</title>
        <url>http://lanlingzi.cn/post/technical/2011/0212_java_sandbox_sm/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> 在JRE类白名单能控制类的使用权限（请点击），但控制不了一些资源的访问权限。如默认情况下可访问机器下的任意资源，如读取、删除一些文件，网络操作，创建进程与线程等。必须对Web容器下的WebApp进行资源权限访问控制。
Security Manager Java从JDK 1.0开始就实现一套安全架构，主要用于Applet。在这种体系下Java Code的执行环境被严格划分为两部分，本地代码可以访问计算机的所有资源，而远端代码（Remote Code，主要是Applet）只能支行在严格限制的沙箱里面。安全管理器（SecurityManager）作为一个子系统来决定哪些资源允许沙箱中程序访问。这是一种运行期的安全检查。
SecurityManager是一个API级别的，可自定义的安全策略管理器，它深入到Java API中，在各处都可以见到它的身影。默认情况下，Java应用程序是不设置SecurityManager实例的（意味着不会起到安全检查），这个实例需要我们在程序启动时通过System.setSecurityManager来设置。一般情况下，检查权限是通过SecurityManager.checkPermission(Permission perm)来完成的。外部程序通过创建Permission实例，传递给前面的check方法。Permission是一个抽象类，需要继承它实现不同的权限验证，比如FilePermission，代表对某个文件的读写权限。new FilePermission(&amp;quot;test.txt&amp;quot;, &amp;quot;read&amp;quot;)；将这个实例传给SecurityManager，检查是否要读test.txt这个文件。
但SecurityManager也是一个全局管理类，一旦设置，则同容器中所有代码将会受到影响。但我们需要仅仅是对WebApp运行期的资源安全访问控制检查。
检查Permission时机 所以在设计方案时必须考虑对WebApp进行的资源授权只针对WebApp，不能影响Web容器其它代码运行。由于检查权限是通过SecurityManager.checkPermission(Permission perm)来完成的，如果在checkPermission实现很复杂的逻辑会对性能造成影响。所以需要分二个层次来设计Security Manager的设置：
 当Web容器启动时不设置任何的SecurityManager WebApp支行时采用新的SecurityManager类，在部署它时指定新SecurityManager类与Policy,在自定义的Filter中init方法中实现  重载java.security.SecurityManager(假定子类名定为CustomSecurityManager)。它主要是重载如下几个方法：
 checkPermission(Permission perm) checkPermission(Permission perm, Object context) checkAccess(ThreadGroup g) checkAccess(Threa t)  在两个checkPermission方法中主要是判断不是不WebApp的工作线程，如果是再做授权检查，使用自定义的Permissions。否则不做任何的处理.
在两个checkAccess方法中，对Thread权限如创建做一些检查特殊处理,如检查 RuntimePermission(&amp;quot;modifyThread&amp;quot;)与RuntimePermission(&amp;quot;modifyThreadGroup&amp;quot;)。
如果判断WebApp执行线程？由于不允许WebApp创建新的线程，那一个WebApp的一次http请求在Servlet的service方法实现的逻辑肯定只会在一个线程调用栈中。在Servlet的service方法入口前设置当前线程名到系统环境量Value为true，在service方法出口后设置当前线程名到系统环境量Value为false，为了能把上面的Permission只限制在WebApp中使用。需要在CustomSecurityManager.checkPermission根据当前线程名在系统环境量Value是否为true来判断是否需要做Permission检查。
如何在Servlet的service方法入口设置环境变量？Servlet规范中的Filter机制可以使得Web请求在交给Web Servlet处理前进行对请求的预先处理，以及Web Servlet处理完成之后响应后处理。也就是说在相同的URL请求下，容器会优先由Filter处理，再给Web Servlet处理，利用这个特性完成对当前线程名在系统环境变量中的设置。
同样，在Filter的init方法也就可以对CustomSecurityManager注册到系统全局的SecurityManager中。
自定义Permission 配置WebApp安全策略的Permission，可以基于Policy文件配置，以不同的CodeBase来区分不同的权限。由于配置Policy文件时，并不知道WebApp war包解压的具体目录。以Jetty为例，默认会把War解压在java.io.tmpdir目录下，那对WebApp的CodeBase可设置为java.io.tmpdir，否则根据部署实际目录来调整。
另外，需要对容器的其它jar文件的代码权限授权。由于类动态加载的原因，WebApp ClassLoder会委托它的双亲加载。如果不设置，也会在WebApp的工作线程中，会导致在Servlet运行时报一些权限禁止，如SecurityPermission。通过不同的CodeBase来进行不同的授权，除WebApp的Class之外，假定可以考虑是AllPermission。
那如果WebApp的工作线程调用系统平台提供一些API，而平台API要求可以读写文件，开启特定的端口等，这也与WebApp在同一个线程调用栈中，同样也没有权限，那就又何处理？需要两步来完成对平台API的权限授权：
 平台的API Jar包不能放在WebApps目录下，应用与WebApp的War属于不现的保护域（ProtectionDomain） 在平台的API的入口需要加上对AccessController.doPrivileged设置，这样是在调用doPrivileged的方法相关联的保护域拥有执行被请求的操作的权限，AccessController将立即返回，不再在栈的下层继续检查操作权限（也就是说它的代码主休是享受“privileged”特权），它单独负责对它的可使用的资源的访问请求，而不管这个请求是由什么代码所引发的。 </content>
    </entry>
    
     <entry>
        <title>[WebApp沙箱]JRE类白名单运用</title>
        <url>http://lanlingzi.cn/post/technical/2011/0311_java_sandbox_cl/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> ClassLoader JVM类加载器层次结构：
 Bootstrap ClassLoader | Extension ClassLoader | System ClassLoader  JVM一启动，会先做一些初始化的动作。一旦初始化动作完成之后，就会产生第一个类加载器，即所谓的Bootstrap Loader, Bootstrap Loader是由C&#43;&#43;写成，这个BootstrapLoader所做的初始化中，除了做一些基本的初始化动作之外，最重要的就是加载定义在sun.misc命名空间下的Launcher.java之中的ExtClassLoader(因为是innerclass，所以编译之后会变成Launcher$ExtCjassLoader.class)，并设定其Parent为null,代表其父加载器为BootstrapLoader。然后再加载定义于sun.misc命名空间下的Launcher.java之中的AppClassLoader(因为是InnerClass，所以编译之后会变成Launcher$AppClassLoader.class)，并设定其Parent为之前产生的ExtClassLoader实例。AppClassLoader这一层我们也称之为SystemLoader。AppClassLoader会加载CLASSPATH目录下定义的Class。
每一个自定义ClassLoader都必须继承ClassLoader这个抽象娄，而每个ClassLoader都会有一个Parent的ClassLoader，我们可以看一下ClassLoader这个抽象类中有一个getParent()方法，这个方法用来返回当前ClassLoader的Parent。这个Parent不是指的被继承的类，而是在实例化该ClassLoader时指定的上层ClassLoader。
ClassLoader有两种载入类方式：
 pre-loading：预先载入，载入基础类。 load-on-demand：按需求载入，动态载入。  当JVM载入Java类的时候，需要经过三个步骤，装载、连接、初始化。装载就是找到相应的Class文件，读入JVM。连接分三步：
 验证Java类是否符合规格 准备，就是为类变量分配内存同时设置默认初始值 解释，而这步就是可选的，解释就是根据类中的符号引用查找相应的实体，再把符号引用替换成一个直接引用的过程。  每个ClassLoader加载Java类的过程如下：
 检测此Java类是否载入过（即在Cache中是否有此Java类，包括所有Parent的ClassLoader已载入的Java类），如果有到第8步，如果没有到第2步 如果Parent ClassLoader不存在(没有Parent，那Parent一定是Bootstrap Loader)，到第4步 请求Parent ClassLoader载入，如果成功到第8步，不成功到第5步 请求JVM从Bootstrap Loacler中载入，如果成功到第8步 寻找Class文件（从与此classloader相关的类路径中寻找）,如果找不到则到第7步 从文件中载入Class，到第8步 否则找不到，抛出 ClassNotFoundException 返回Class类  这个过程就是双亲委托模式，一是可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次；二是出于考虑到安全因素，避免覆盖基础类。例如无法随时使用自定义的String动态替代java核心api中定义String类型。其中第5、6步我们可以通过覆盏ClassLoader的findClass方法来实现自己的载入策略。
Thread Context ClassLoader Java 2中引入了线程上下文(Thread Context)类ClassLoader的概念，每一个线程有一个ContextClassLoader。这个Context ClassLoader是通过方法Thread.setContextClassLoader()设置的，如果当前线程在创建后没有调用这个方法设置Context ClassLoader，则当前线程从他的父线程继承Context ClassLoader。此Context ClassLoader默认的是System ClassLoader。
利用这个特性，我们可以“打破”ClassLoader委托机制，父ClassLoader可以获得当前线程的Context ClassLoader，而这个Context ClassLoader可以是它的子ClassLoader或者其他其他的ClassLoader，那么父ClassLoader就可以从其获得所需的Class，这就打破了只能向父ClassLoader请求的限制。
这个机制可以满足当我们的classpath是在运行时才确定，并由定制的ClassLoader加载的时候，由System Loader(即在JVM classpath中)加载的Class可以通过Context ClassLoader获得定制的ClassLoader并加载入特定的ClassLoader（通常是抽象类和接口，定制的ClassLoader中实现），例如web应用中的Servlet就是用这种机制加载的。
Class Instance 一个java类只有要实例化时，才会被ClassLoader动态载入，未使用并不会载入。而动态载类又分为两种方式：
 Implicit隐式，即利用实例化才载入的特性来动态载入类，如new-个类的对象。 Explicit显式方式，又分为两种使用java.lang.Class的forName()方法与使用java.lang.ClassLoader的loadClass()方法。  当java类加载时，有一个Class类（JRE中基础类）与每个其它的Java类相关，每个被ClassLoader加载的class文件，最终都会以Class类的实例被程序引用，我们可以把Class类当作是普通类的一个模板。JVM根据这个模板生成对应的实例，最终被程序所使用。某个类的所有实例内部都有一个栏位记录着该类对应的Class的实例位置。java类对应的Class实例可以当作是类在内存中的代理者，所以当要获得类的信息（如有哪些类变量，有哪些方法）时，都可以让类对应的Class实例代劳。java的Reflection机制就大量的使用这种方法来实现。每个java类都是由某个ClassLoader(ClassLoader的实例)来载入的，因此Class类别的实例中都会有栏位记录他的ClassLoader的实例。
WebApp Class WhiteList 对于WebApp，不管是Web容器采用Jetty还是Tomcat。他们都针对每个WebApp Context自定义ClassLoader。为了能达到白名单检查的功能，我们可能在这个自定义ClassLoader的实现对类进行检查(如不在白名单内的类load时报ClassNotFoundException)。
  一种方案是重载ClassLoader.loadClass方法，不允许load此类，也不会在Cache中存在。但这种方案会带来很大的性能问题。每次运行时实例化一个Java类，在Cache中肯定不会存在此java类的Class类。那又会去调用loadClass尝试加载此java类，那又会再一次去检查一下白名单列表，而且白名单列表会很多，遍历会损耗性能。另外，WebApp自己创建的ClassLoader，没有办法重载loadClass方法。
  另一个方案是在WebApp Context的ClassLoader.defineClass方法中修改从Class文件中读取的WebApp中每个类的字节码。使用ASM工具来解释与修改字节码，如果发现此Class的方法中在调用有不在白名单内中的类，则插入抛出NoClassDefFoundError代码。这种方案可以只在第一次加载WebApp类时，判断了它依赖的类是否有不在白名单内中。这种相对前一种方案可以提高性能。同样，WebApp自己创建的ClassLoader，没有办法重载defineClass方法。
  对于ClassLoader.defineClass方法的实现：
  一种方案重载Web容器的WebApp Context自定义ClassLoader.defineClass方法，这要求Web容器支持插件方式替换已有WebApp Context ClassLoader。
  另一种方案是采用JVM的Instrumentation功能。在JVM级别，以插件的方法动态AOP切入JVM或JRE类中已有的实现。正好Instrumentation提供一种机制切入到每个ClassLoader.defineClass方法之前。应用只需要实现接口java.lang.instrument.ClassFileTransformer。在transform方法实现对类字符码的转换。此方法的原型为
byte[] transform(ClassLoader loader, String className, Class&amp;lt;?&amp;gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegaIClassFormatException 转换器ClassFileTransformer利用Instrumentation.addTransformer注册之后，在定义每个新类和重定义每个类时都将调用该转换器。对新的类定义的请求通过ClassLoader.defineClass进行。对类重定义的请求通过Instrumentation.redefineClasses方法进行。转换器是在验证或应用class文件字节之前的处理请求过程中进行调用的。
如果实现的方法确定不需要进行字节码转换，则将返回null。否则它将刨建一个新的byte[]数组。将输入classfileBuffer连同所有需要的转换复制到其中，并返回新数组。
  采用第二种方案是不个不错的选择，即使用Instrurnentation功能。在transform方法扫描类的字节码，检查类的方法中是否有非白名单中的类。如果有，则插入抛出NoClassDefFounclError代码。
实现简介   定义-个类实现premain接口，做为Instrumentationa机制的入口。并在MANIFEST.MF文件中指定Premain-Class为此类．premain接口如下，顾名思义，它是在main方法之前调用：
public static void premain(String agentArgs, Instrumentation inst);
  实现ClaSsFileTransformer接口。并在premain方法中调用Instrumentation.addTransfanner注册此接口。
  当每个ClassLoader加载字节码时，会回调ClaaaFileTransfonner.transform方法，它实现主要逻辑：
   判断是加载类的ClassLoader是否Web容器中WebAppCantext ClasaLoader。对于WebAppContext ClassLoader可以通过类名在判断。对于webApp创建的新ClassLoader。需扫描字节码，获取类的类型继承列表是否属于ClassLoader，并记录下来。    如果加载类的ClasaLoade不是应用的ClasSLoader，直接口返回null
  如果是，使用ASM工具对字节码进行分析与重写:
  第一遍扫描类的所有方法字节码，如果Visit到类的类型在不在白名单列表中，则在原有方法中直接插入抛NoClassDefFoundErro代码。满足如下条件：
  调用黑名单列表类的方法
  调用黑名单列表类的属性
新的代码类似如下：
//插入抛NoClassDefFoundError代码，调用一个类的静态方法 //原代码     WebApp可能创建的自己实现的ClassLoader。第二遍扫描类的所有方法字节码，判断Visit到类的类型是否URLclassLoader，SecureClassLoader，ClassLoader其中的一个，或者是否继承自他们。则插入记录这些ClassLoader名的代码。自己实现的ClassLoader满足如下条件：
  任何一个新创建的ClassLoader，肯定会在它的调用父类的构造方法，那在此方法中它的字节码肯定会调用URLClassLoader，SecureCldaaLoader，ClassLonder其中一个构造方法；
  另外还可能使用URLClassLoader.newinstance(…）来创建新的classloader；
上述两种方法新创建的ClassLoader，它的双亲ClassLoader可能不是WebAppContext的Classloader(构造方法或newinatance没有指定参数parent，那parent默认为System ClaaSLoader)，修改字节码时需要修改为调用有参数parent的方法，并且把parent指向WebApp Context的ClasSloader。
    WebApp也可能使用反射机制来访问类。第三遍扫描类的所有方法字节码，判断所Visit到类的类型与Viait到方法，满足如下条件：
  类型为java/lang/reflect/Method，调用方法为invoke
  类型为java/lang/reflect/Field，调用方法为getXXXX/setXXXX等方法
  类型为java/lang/reflect/Constructor，调用方法为newinstance;
  类型为java/lang/Class，调用方法为newlnstance.
当满足上面条件时，修改原有这些方法调用，则在原有方法中插入检查反射的target对象的类型是否不在白名单列表中。新的代码类似如下
void setBoolean (Field f, Object a, final boolean value) { ／／插入检查obj是否有访问权限（配合Securtiy访问控制） ／／插入检查obj是否在黑名单列表中 ／／再加上原有的f.setBoolean(obj，value)； }      </content>
    </entry>
    
     <entry>
        <title>远离罪恶</title>
        <url>http://lanlingzi.cn/post/stories/2011/0122_believe_god/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>宗教</tag>
        </tags>
        <content type="html"> 今天在回家的车上，遇到一个上帝的信徒，在宣传上帝的故事，对着一个高中生大讲特讲信上帝不是一种迷信。举了很多的例子，比如人们熟知的爱因斯坦，牛顿等是上帝的忠实信徒，一边搞学问一边翻圣经，学问做不去了，就去问圣经。也讲宇宙是什么，是上帝创造了宇宙万物，人类就是大海中一粒沙一样存在整个宇宙之中，人类是渺小的。无论人类科技多么的发展，也不能在其它星球上创造生物。最后在快下车的时候，给每人发一张卡片，劝说人们多去教堂感受一下。身体只是一个灵魂的载体，每个灵魂需要远离罪恶，前往永远与罪恶无关的福乐美地。
她所说的前大部分都是废话，最一后说灵魂远离罪恶才是基督的精髓。无论上帝是否存在其实都不重要，或许在人类达到不到地方，就是上帝存在的地方。这个上帝不是一个神，还是人类敬畏的未知领域。在这个物欲横流的糟糕社会，在一堆诱惑的面前，人们的灵魂又有几个能真正地远离罪恶，教堂成了人们忏悔的地方，宗教是一种精神的寄托。有时人有种寄托其实也很幸福的。
</content>
    </entry>
    
     <entry>
        <title>德国出差记</title>
        <url>http://lanlingzi.cn/post/stories/2010/1020_german_travel/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>旅游</tag>
        </tags>
        <content type="html"> 到达德国的Frankfurt法兰克福大约是19号早晨的６点半左右。这边的天还没有亮，取得托运行李，再过完签证检查之后已是７点左右，天还是没有亮。这次还好，去年过境德国，被安检人员问了一堆的问题。这次可能我事先跟海关检查人员打了声招呼“Morning”，他居然什么都没有问，直接盖上大章就说“Pass”。出了Airport，外面非常的冷清，11月的德国已经开始很冷，有点冬的味道。
我要去的目的地是一个叫Darmstadt达姆斯塔特的小城。在Airport的外面bus stations逛了一圈，终天在Terminal 2 E8找到Darmstadt的air line。等了大约２分钟的时光，Bus准时到来，我向司机打了声招呼，示意让我上车。在车上他说了一堆的德语，可惜我一句也没有听明白，我只能用生硬的英语说“I want to go to Darmstadt, how much is the ticket?”或许大家都能听明白Darmstadt。于是他在电子售票机上打了一张票给我，电子屏上显示7.3欧。
我开始以为Darmstadt离Frankfurt比较近，一路坐车走高速过去，发现还是坐了25分钟左右。诺大的Bus上，只有三个人，除了我之外，还是两个本地人吧。我坐在第一排，看着司机很惬意地开着车，经常活动一下上身，偶尔也摇晃一下脑袋。到了Darmstadt，司机好像对我说了些什么，我只听见到Darmstadt，于是我就下了车。外面还是没有放亮，不过街道上开始有人在等公交车上班了。事先同事告诉我公司在Darmstadt火车站附近。还好，下了Bus之后，前面就是Hanptbahnhof，看到DB标识的火车站。
按着同事事先给我的Google地图，穿到火车站左拐一条街，下了电梯，出门之后再也找不到北了，按Google地图，公司办事处就应该在火车站200m附近，可惜我逛了一圈根本没有看到HW的标识，无奈又回到火车站，又开始用生硬的英语问了一个清洁工叔叔，可能也没有完全听懂我说什么，telephone应该在拉丁语系中都发声差不多，加之我的手势。他完全知道我要找公用电话。我是对德语一点不懂，他所说的我一句也没有听清楚。顺着他所指的方向，终天找到了T-Service的公用电话。在一处德语显示的公用电话屏上，我尝试了几次，终于打通同事的电话，涮涮地2.7欧贡献给了电话。
与同事约好见面的地点，再等了约5分钟左右，终于见到我的同事，我的心也开始悬下来了。
今天到德国的初映像就是冷，到达同事住的宿舍里，不得不把秋衣秋裤换上。洗漱一把之后，一点睡意没有，可能是在飞机上差不多朦胧睡了10个小时左右。Darmstadt是一个宁静的小城，一切显得得比较安详。我站在宿舍向外看，绝对见不到任何超过10层的建筑，路面宽阔干净整洁。
公司的办公地点其实离火车站的确很近，走2分钟就到了。据说附近都是一些高科技企业。Darmstadt也是一教育与高新企业云集的小城。公司在这的办公室一共租用两层，大约有近100间的办公室。我们这个项目四波人马分散在各个办公室里，这里没有人认为你是新来的，会怎么怎么样。
我去得比较早，开始公司没有什么人，到9点半之后，才陆续有人来上班。前台是一个来自湖南的MM，正在与我们项目组内一同事fall in love中。她也是这边唯一的女性。这边的工作员工本地德国人也不很多，大部分来自国内，大都也不是常住，随项目而移动。到达公司之后，住宿都没有安排就投入了工作，第一天基本是开了一整天的Test Case Guide的评审会议，一直搞到晚上8点多。
在这边工作，最大的不便是吃饭问题。公司没有食堂，附近也没有快餐站，连麦当劳也没有。同事们都是回宿舍自己做东西吃。我们项目组一波人基本上定在一起做东西吃。吃的问题基本上也算解决了，虽然基本上每餐都是煮些面条吃。
下午从前台MM处领到我住宿钥匙，我们项目组的同事都分散住在不同的地方。而我住的地方更远。住宿已不在Darmstadt，叫一个Griesheim的小城（小镇？）上的Gerh.-Hauptmainn街上，坐有轨电车大约要5分钟左右。晚上9点离开公司，开始我与另一个同事去寻找我的宿舍。
德国的交通系统是非常发达的，公共交通有火车，有轨电车（像火车有多个车箱），Bus，大城市还有地铁，但你见不到Taxi，这边的Taxi是预约的。这些公共交通是相当地准时，站排上写着什么时候到站，就是什么时候。如果不准时，肯定会发现大撞车，因为bus与有轨电车很多的路段都在同一条线上。任何的公共交通是无人售票的，基于人的基本诚信。票的类型单次票，单天票，周票，月票。除单次票之外，其它都是不限次数。并且不限路线与车次，同一张票即可坐有轨电车，也可以坐Bus。像我买的月票，活动范围可以在Darmstadt与Griesheim两个区域，价格比较贵，是47.40欧。
我的宿舍从Darmstadt到Griesheim，一共有5站，最后一站刚好是进Griesheim的第一站。下了有轨电车，东拐西拐地走到宿舍还有15分钟左右。幸亏有同事带路，一个人还是真难找到这个地方。这个宿舍是公司长期租的，它不是hotel(酒店)，更不可能是house（住宅），是apartment（公寓），在德语中叫appartementhaus。这个apartment一共有三层，占地面积很大，应该有几百间房间。附近的环境也很不错，整个Griesheim都是住宅区。除了apartment之外，都是一栋栋的house，相当国内的别墅，家家屋前屋后有车库或花园。这才是人理想居住的环境啊。这些house一般都是两层或三层，富裕的人家可能大一些，穷人可能小一些。没钱的流浪汉才住Darmstadt的街上。在Griesheim是见不流浪汉。
我的入住房间是一室一厅，带独立的厨房与卫生间，这个房间相比其它的apartment算是比较大了。一室中两张床，床是相当的小，可能就一米M宽。如果来了胖子，滚下床的机率应该很大。房间的设施是很全，你住在这里绝对的舒服，有暖气，有热水，有冰箱，有厨具，有网络，有电视。地面是不错的地毯，看来欧洲人喜欢在家铺这个。虽然有两个床铺，但只有一个人入住。
</content>
    </entry>
    
     <entry>
        <title>印度同事记</title>
        <url>http://lanlingzi.cn/post/stories/2010/0716_indian_counterparts/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>印度</tag>
        </tags>
        <content type="html"> 项目组由四地员工组成：深圳，南京，印度，土耳其。印度研究所设在班加罗尔（Bangalore），由于这次项目的重要性，把一堆的印度同事也拉到了深圳集中办公，也把部分的土耳其同事拉到了深圳。
今天有两个印度同事说要回家结婚了，准备回印度，于是他们昨天发了一封mail说要我join us for dinner。盛情难却，于是我说I&#39;m glad to go，我就参加了他们的一次聚会。
在去之前，我在想印度同事们来中国，他们能请什么客。出乎我的意料之外，他们一行10多人把我带到一家火锅店，莫非他们想尝尝中国的火锅？印度人大多是猪肉、牛肉，羊肉都不能吃，想吃火锅也难吧。他们拿着菜单，看图点菜，有点搞笑，点几盘的金银馒头，二盘的大盘鸡，也点了三种鱼（水煮鱼，炸鱼，清蒸鱼），我开始还以为他们很能吃鱼，发现上菜之后，根本不合他们的胃口。我感觉像领了群刚从难民营回来的人，在一家火锅店教着他们拿筷子，吃着馒头，啃着大盘鸡，场面真是极其搞笑。更有几个比较逗的印度同事，不停地在学中国话，用生硬的汉语叫喊着“服务员，纸巾，王老吉”，搞得我与其它两个中方员工脸色极其难堪。总得来说，印度同事还是很好相处的，来自社会底层，乐观而又安于现状。
印度同事给我们的印象还是比较正面的。中文员工自然是深受华为文化的影响，做事情是任劳任怨的。印度人大都比较温顺，有点喜欢跟你讨价还价，但只要确认的事情，是会按时按量完成，哪里他们私下加班加点完成。记得有一天周未，印度同事集体去东部华侨城玩，由于遇到紧急问题需要处理，被我们电话叫回。虽带些不高兴，回来公司还是跟我们一起奋斗到凌晨解决欧洲现场问题。
相比之下，项目组的土耳其人却完全不是一样了，一个字来形容：“懒”。TNND的，拿的薪水比我们多很多，却什么都不会做，也什么都不会愿意做，一点积极性与主动性都没有。老大给三个土耳其人让我带，真是把我折磨死了。一是交流是困难，二是安排他们的工作是能拖则拖，又说他们不得。从与他们打交道，或有所思：一个能任劳任怨的民族才有可能伫立于世界民族之林，土耳其永远不可能，印度还有可能吧。
</content>
    </entry>
    
     <entry>
        <title>团队文化</title>
        <url>http://lanlingzi.cn/post/notes/2010/0111_team_culture/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>团队</tag>
        </tags>
        <content type="html"> 今天晚上在部门的公告牌上看到一个另部门的项目做的总结，觉得后面几句话不错：
  树立团队荣誉感：
如何树立团队荣誉感，没有什么好方法，我的理解就是带领团队不断地打胜仗，克服一个个困难，另外就是获得应该有的荣誉，这样你的团队才能有荣誉感。
  角色认知，系统化思考：
你是代表部门在做这项工作，需要也可以站得更高角度来系统化，有计划地操作这项工作，你也可以行使你应有的权力。
   面对不增值的事：
其实在工作中我们总会遇到不少此类的重复又不增值的事情，从个人来讲，可能得不到技能上的提升。但对组织，对团队是非常有益的，需要你无条件地服从，不要去报怨。很多时候，这种忍耐，坚持会帮助你脱颖而出。
  面对困难的事：
如果你所带的团队在最困难的时候，一个团队已经差到谷底了，这时不论住哪个方向走都是往上走。团队的困难时期正是我们做出变革的最佳时机。所以对团队来讲，困难和挫折是福，把一个团队从弱势带到强势的时候，这过程所积累的经验，以及团队的战斗力是无可比拟的。
  积极主动，追求卓越：
有些事情不是组织强制就能做好的，如果没有组织约定我们就不做事了吗，需要我们积极思考推动，价值思维，系统考虑，全力共赢，树立标杆，营造氛围，不断突破。
 </content>
    </entry>
    
     <entry>
        <title>2010</title>
        <url>http://lanlingzi.cn/post/stories/2010/0106_summary/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 日子就这一样日复一日地消逝着，
在不经意间，
时间滑到2010。
无意与时间赛跑，
在时间面前，
我们永远都是一个输者。
回首2009，
一个充满辛苦的一年，
一个压力倍增的一年。
去了一趟欧洲，
去了一趟南京。
工作走到十字路口，
有更多的人生盲点。
回首2009，
一个没有时间的一年，
一个不懂风情的一年。
当同学渐已结婚，
当朋友比燕双飞。
爱情没有收获秋季，
发现自己不懂恋爱。
展望2010，
将继续在压力中前行，
再大的压力也得扛着。
将持续在学习中历练，
再大的阻碍也得迈过。
不要放弃，
也不要抛弃，
更不要逃避。
展望2010，
从分享快乐开始，
在成长中追逐。
学会懂得珍惜，
学会懂得尊重。
心的方向，
快乐着生活，
享受着快乐。
</content>
    </entry>
    
     <entry>
        <title>秩序</title>
        <url>http://lanlingzi.cn/post/stories/2009/1106_rule/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 昨天下班回来，当过马路时，我一个人在等红绿灯，忽然有一个人在喊我：”走啊，你们这群年轻还没有我们胆子大啊，现在都没有车“，我回头一看，是一个大约40~50岁的人，应该是我们公司供应商的员工。而我，已经习惯了过马路时等红绿灯，在我们公司附近，大家都这样做，即使没有车也会静静地在等着灯亮，这可能是榜样的力量吧。
后来我追上喊我的人，跟他聊起来，我对他说，我刚才是在遵守交通秩序，而不是胆小。他不屑地对我说，都没有什么车穿过，用不着在哪傻等吧。你们这年轻人怎么也爱犯教条主义，那用管这么多的条条框框。
我笑笑了，我知道，我跟他多说无益，因为思想决定境界。在中国传统文化之下，人总喜欢去破坏秩序，并且还自认有理。也有人会说，秩序是死的，人是活的。如果现在年轻人还都这样认为，那中国人的素质还真是没有什么希望。
</content>
    </entry>
    
     <entry>
        <title>青青世界</title>
        <url>http://lanlingzi.cn/post/stories/2009/1004_qingqing/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>旅游</tag>
        </tags>
        <content type="html"> 少年时，一首青青世界的歌曲在春晚上唱红南北。歌里描绘的是一个梦幻世界，是我一直梦想的世界，一副有山有水的清净世界，歌词的作者天才乔羽现在是否还安好？听我们的老大们讲，乔老创造这首歌时，本来是我们公司请他来为公司写企业主题歌，就他住进了当时公司的培训与生活基地青青世界（那时青青世界刚开没有多久，资金运营上有困难，所以把酒店都包给公司）。精明的青青世界台湾老板自然是不会放过送上门来的文坛泰斗，于是就有了后来的青青世界这着歌，也让青青世界这个旅游景点火一把。
今天，歌声已逝，这首歌也成了记忆中的记忆。同学与我开车再次来到青青世界，重温一下记忆中的记忆。青青世界一直打着城市农夫的定位，虽然景点相对小而且没有新的旅游项目，今天依旧少不了一些童年的元素，80年代人的都玩的滚铁环，滚轮车在这里你可以随处玩。漫步在飘着细雨的雨林，可以忘却一切都市的压力。看着水车，踩在木板路，仿佛又回到了十多年前的那个乡村。我本是一农家仔，看着这些都是那么的亲切，早已厌倦了刚筋水泥墙，能亲近原生的自然多好啊。
</content>
    </entry>
    
     <entry>
        <title>家有老人</title>
        <url>http://lanlingzi.cn/post/stories/2009/0906_grandpa/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>家庭</tag>
        </tags>
        <content type="html"> 昨天去一了趟广州小叔那，我去看爷爷。岁月催人老，一晃我爷爷马上80岁了。我差不多每一年才与他见面一次，主要是回家过年时。每次见到他，都感觉他越来越苍老，不过今年他的身体还不错，希望他能健康百岁。
老人真像小孩一样，有时也会拿我开涮一下，他说他与奶奶在一起有60年了，正好有一花甲了。他说这一次要在广州多呆一段时间，要看广州这边国庆热闹。国庆之后，一定要做飞机回去，说一辈了还没有坐过飞机，总爱喜欢问一些关于飞机上的事，我只得一一回答。这次老人在广州呆着还是很愉快的，说广州比家里热多了，他喜欢天天呆在有空调的房子里不爱出去。他喜欢渴点酒，一天总是端一个杯子，我就劝他少渴点，也总是笑着对我说润润嘴巴。
</content>
    </entry>
    
     <entry>
        <title>读史小记</title>
        <url>http://lanlingzi.cn/post/notes/2009/0822_history_think/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>历史</tag><tag>宗教</tag>
        </tags>
        <content type="html"> 战乱多 自从买了个诺基亚的大E之后，在手机上看书的时间越来越多了，最近一连看了好几本历史相关的书籍。原来中国的历史并非课本上写的那么简单。两千年来，中国历史能值得我们骄傲的并不多，对于普通百姓来说，一直是充满着无知与无奈。对于官员来说，一直是充满着虚伪与争斗，对于帝王来说， 一直是充满着荒唐与淫乱。在历史长河，没有几个太平盛世，没有几个有作为的帝王，没有几个能臣干将。整个中原民族也是不断地受到外族侵略，也不断的融合其它的民族。李世民是鲜卑族，成吉思汗是蒙古族，康熙是满族。强大的政权往往是由外族创建，而后才慢慢融合到汉族中。
杀功臣 一个人一旦成了皇帝，真的成了孤家寡人了，父亲儿子可以杀，那么下面的臣子更不用说了，中国历史上开国皇帝杀功臣的太多了。
汉朝的刘邦怕韩信功高盖主，杀之。唐朝李世民对开国功臣处理比较得当，没有什么杀戮。宋朝赵匡胤对开国功臣采用较和平的方式，让他们回家养老，重文不重武，明朱元璋对开国功臣则是一率的赶尽杀绝，做事做绝。清朝由于前期左右势力均衡，才把顺治推上历史舞台，但其叔父多尔衮却杀了不少他的政敌（也有一些是开国功臣）。
现代企业也普遍存在这种情况，尤其是在国有企业。一个企业的老总，就是这里的皇帝，整一个人太容易。随他一起创业的功臣，老总对他们忌惮太多，这可能也是中国很多企业昙花一现的原因之一。
两极化 中国人的宗教生活不应该分成儒、佛、道三家，更确切地说，应当分成两个等级。即:普通百姓为一个等级，学者(学优而仕，中国古代没有独立的学者，学者即官员)为一个等级。
普通百姓崇拜古代的、佛教的、道教的及其他来源的诸神和自然物。学者们却只信奉皇帝和祖宗，有时也敬奉孔子、佛陀、老子和几位伟大的历史人物，但从不信奉其他神灵。
普通百姓相信占星术，历书、释梦、泥土占卜、巫术、骨相学、手相术、招魂术、各式算命、符咒、魔术以及各种迷信；学者们很少相信这些玩艺。
普通百姓经常出入各类庙宇和神殿；学者们则回避这些地方，只光顾圣堂、孔庙和祠堂，有时也去历史伟人的庙地。
普通百姓认为宗教仪式是神秘的；学者们认为纯属形式而已。
普通百姓多是宿命论者，认为祸福均由神灵直接支配；学者们却不相信命运。
普通百姓敬神，主要是为了求神赐福，尤其是为了求神保佑子女平安，保佑他们生活富裕，长命百岁；学者们的崇拜，并不企求神灵恩赐，只是为了表示敬意。
所以中国不会有绝对的宗教信仰，不会为其献身，宗教对百姓来说只是一时的精神依寄、安慰，学者可能是一种的统治手段、形式。
</content>
    </entry>
    
     <entry>
        <title>性能设计</title>
        <url>http://lanlingzi.cn/post/technical/csdn/perform_design/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件设计</tag>
        </tags>
        <content type="html"> 无论Java还是C&#43;&#43;都有不少的性能优化工具。公司曾有人把一个系统从几十TPS优化到上千TPS，真是让人佩服到五体投地。但是由于架构的原因导致性 能问题，那就不好下手优化了。
在软件项目设计前期，不可不能考虑性能设计。要确定好的性能要求，必须识别项目约束、确定软件将执行的服务并指定软件期望的 负载。但也不要过于注重性能设计。太注重往往会陷入设计的误区。有时甚至为了性能而牺牲功能，那是大错特错了。
项目交付时首先是功能是否满足，其它才是性 能。换句话说软件首先要能工作，其次才是否能高效率的工作。性能设计必须依托测试结果。不要我以为这样做法性能会好。而现在很多的所谓的系统分析设计师却 喜欢我以为，爱拿以前的经验做依托，更喜欢拿其它项目成功的性能设计套用，岂知此系统非彼系统。
性能基准测试应尽早开始，以便在问题被引入软件时就将它们识别出来。将后续的基准测试与初始的软件性能基准进行比较，确定性能是进步了还是退步了。执行这样的测试时不要做不必要的改动（如更改硬件），以便可以对 连续测试得出准确的比较结果。同样，性能障碍越早发现改起来越省开销，而且也更容易克服。
当然，要提高性能需付出代价。虽然可以针对任何给定的问题空间生成高性能应用程序，但主要代价是每个事务的成本。有时有必要通过牺牲性能来控制成本。这又说到性能与成本的关系了。性能设计也不可不能权衡提高性能对成本的影响。在成本的约束下确定性能要求。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之名字空间namespace</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_namespace_usage/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> C开发人员会经常使用#define即宏来声明常量，但宏却是全局的，对大的工程来说是很难维护，经常是导致名字冲突。还好，C&#43;&#43;给我们带来了namespace名字空间。它的使用如下，名字空间可以把一组逻辑分组，同时名字空间也是一种作用域。
namespace outspname { const int CVAR1 = 1; const char* const CVAR2 = &amp;#34;33333&amp;#34;; void test(); namespace inspname { enum { A, B, C}; class Klass { }; } } 但即使一个简单的名字空间，其中也有不少的玄机。
  当某个名字在自己的空间之外使用，在反复地在前面加上名字空间作为限定词， 如:
const int local = outspname::inspname::A 这样写是不是很令人烦。在某个小的局部作用域内，我们可以通过一个使用声明。如:
{ using outspname::inspname::A; const int local = A; }   通过一个使用指令把该名字空间下所有的名字变成可用。
如下所示，与第一点的用法区别，是using 后面有个namespace。同样只在转换时，或者在一个小的局部作用域内使用using namesapce，否则也会带来名字的污染。
{ using namespace outspname; const int local2 = CVAR1; const int local2 = inspname::B; { using namespace inspname; Klass* p = new Klass(); } } 但使用using namespace这种用法时，要注意下面一点，如在某个.h中声明了有testname::test的方法。
namespace testname { void test(int param); } 在其.cpp中，不能使用如下这种方式，test方法只是此编译单元的一个局部方法，并非testname名字空间的test方法实现。
using testname; void test(int param) { } 正确的使用方式是:
namespace testname { void test(int param) { } } 或者是
void testname::test(int param) { }   名字空间的别名，当名字空间很长或嵌套很深时，我们可以使用名字空间别名，用法如下：
namespace oin = outspname::inspname;   无名名字空间，无名名字空间主要是保持代码的局部性，使用如下：
namespace { const int CVAR1 = 1; void test(); } 但一定要注意的一点是，在C&#43;&#43;编译器实现时，无名名字空间其实是有名字的，这个隐含的名字跟它所在编译单元名字相关。所以基于这一点，我们不能跨编译单元使用无名名字空间中的名字。上面的声明等价于:
namespace $$$ { const int CVAR1 = 1; void test(); } using namespace $$$; 其中$$$在其所在的作用域里具有惟一性的名字，每个编译单元里的无名名字空间也是互不相同的，usingnamesapce $$$只是当前的编译单元的隐含名字，所以不能跨编译单元使用无名名字空间中的名字。假设上面的test方法在是a.h与a.cpp中定义与实现的，但在b.h或b.cpp中就不能直接使用test方法或CVAR1。因为在b的这个编译单元中链接的是b这个编译单元中的test符号，并非a编译单元中的test符号，也就会出现未定符号。
  要避免名字空间使用很短的名字，也不能太长，更不能嵌套太深了，个人觉得不要超过4层。
 </content>
    </entry>
    
     <entry>
        <title>面向对象的设计原则</title>
        <url>http://lanlingzi.cn/post/technical/csdn/oo_design_principle/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>软件设计</tag>
        </tags>
        <content type="html"> 如何同时提高一个软件系统的可维护性和可复用性是面向对象的设计要解决的核心问题。
导致一个软件设计的可维护性较低，也就是说会随着性能要求的变化而“腐烂”的真正原因有四个：
 过于僵硬 过于脆弱 复用率低 黏度过高  一个好的系统设计应该有如下的性质，这三条性质就是一个系统设计应当达到的目标。
 可扩展性 灵活性 可插入性  软件的复用的好处有：
 较高的生产效率 较高的软件质量 恰当使用复用可改善系统的可维护性  在面向对象的语言中，数据的抽象化、继承、封装和多态性是几项最重要的语言特性，这些特性使得一个系统可以在更高的层次上提供可复用性。数据的抽象化和继承关系使得概念和定义可以复用；多态性使得实现和应用可以复用；而抽象化和封装可以保持和促进系统的可维护性。
在一个设计得当的系统中，每一个模块都相对于其它模块独立存在，并只保持与其它模块的尽可能少的通信。这样一来，在其中某一个模块发生代码修改的时候，这个修改的压力不会传递到其它的模块。
常见的设计原则有：
  “开闭”原则（Open-Closed Principle）
“开闭”原则讲的是：一个软件实体应当对扩展开放，对修改关闭。其英文原文是：Software entities should be open for extension,but closed for modification.满足开闭原则的设计可以给一个软件系统两个无可比拟的优越性：1.通过扩展已有的软件系统，可以提供新的行为，以满足对软件的新需求，使变化中的软件系统有一定的适应性和灵活必。2.已有的软件模块，特别是最重要的抽象层模块不能再修改，这就使变化中的软件系统有一定的稳定性和延续性。
  里氏代换原则（Liskov Substitution Principle）
里氏代换原则指一个软件实体如果使用的是一个基类的话，那么一定适用于其子类，而且它根本不能察觉出基类和子类对象的区别。里氏代换原则是继承复用的基石。只有当衍生类可以替换掉基类，软件单位的功能不会受到影响时，基类才能真正被复用，而衍生类也才能在基类的基础上增加新的行为。
  依赖倒转原则（Dependency Inversion Principle）
依赖倒转原则要求客户端依赖于抽象耦合，依赖倒转原则的表述是：抽象不应当依赖于细节；细节应当依赖于抽象。（Abstractions should not depend upon details,Details should depend upon abstractions）依赖倒转原则的另一种表达是：要针对接口编程，不要针对实现编程。（Program to an interface, not an implementation）
  接口隔离原则（Interface Segregatioon Principle）
接口隔离原则，指一个类对另外一个类的依赖性应用是建立在最小的接口上的。
  组合／聚合复用原则（Composition/Aggregation Principle）
组合／聚合复用原则，就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新的对象通过向这些对象的委派达到复用已有功能的目的。另一个更简短的表述：要尽量使用合成／聚合，尽量不要使用继承。
  迪米特法则（Law of Demeter）
迪米特法则又叫做最少知识原则（Least Knowledge Principle），就是说，一个对象应当对其它对象有尽可能少的了解。迪米特法则有很多表达方式，较有代表性的有：只与你直接的朋友们通信（Only talk to your immediate friends）。不要跟“陌生人”说话（Don&amp;rsquo;t talk to strangers）。
   本文上述均节选摘抄自阎宏博士的《Java与模式》一书
</content>
    </entry>
    
     <entry>
        <title>[C&#43;&#43;] STL容器中erase方法的不同陷阱</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_erase_fault/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> STL中的容器都有erase方法，容器的存储分为顺序存储(如vector)与链式存储(如list,map)。先以map为例:
typedef std::map&amp;lt;std::string, std::string&amp;gt; TStrMap; typedef TStrMap::iterator TStrMapIter; TStrMap strmap; TStrMapIter iter = strmap.find(&amp;#34;somekey&amp;#34;); strmap.erase(iter); 这样使用erase方法没有任何问题，删除一个单结节之后，stl中的iterator都是与其中的数据元素关联的，关联的元素删除之后，iter已就失效，iter理解为指向元素的指针，那删除之后可以简单理解为已是一个野指针。
但有时我们一不注意，却会这样使用，这是错误的:
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();&#43;&#43;iter) { if (&amp;#34;somevalue&amp;#34; == iter-&amp;gt;second ) { strmap.erase(iter); } } iter所指的元素删除之后，&#43;&#43;iter是错误的，会导致程序的未知结果，iter一般是不会移到指向下一个元素。
对于map与list这样的链式存储结构。我们一般可以有两种解决办法:
方法一 使用erase(iter&#43;&#43;)，因为iter2 = iter&#43;&#43;是iter先移到指向下一个节点，而iter2还是指向当前的节点。注意理解iter&#43;&#43;与&#43;&#43;iter的区别。
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();) { if (&amp;#34;somevalue&amp;#34; == iter-&amp;gt;second ) { strmap.erase(iter&#43;&#43;); } else { &#43;&#43;iter; } } 方法二 erase的返回值会指向下一个节点，记把下一节点赋给一个变量。
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();) { if (&amp;#34;somevalue&amp;#34; == iter-&amp;gt;second ) { iter = strmap.erase(iter); } else { &#43;&#43;iter; } } 但对于顺序存储的vector也可以使用上述两种方法吗？很遗憾，第一种用法却是错误的，但第二种用法是正确的。因为顺序存储的容器一旦erase时，会涉及到数据移动，iterator所指的位置还是那个位置，但元素却移动了，iter&#43;&#43;之后已不再你想要的元素位置了。
void test_vector_erase() { typedef std::vector&amp;lt;int&amp;gt; TIntVec; typedef TIntVec::iterator TIntVecIter; TIntVec vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); vec.push_back(4); for (TIntVecIter iter = vec.begin(); iter != vec.end();) { std::cout &amp;lt;&amp;lt; *iter &amp;lt;&amp;lt; std::endl; if (0 == *iter % 2) { vec.erase(iter&#43;&#43;); } else { &#43;&#43;iter; } } } 它输出的结果却是未知的，我的测试环境为&amp;quot;1，2，4，4&amp;quot;。你可能发现原因，当删除2元素时，3往前移了，而iter&#43;&#43;不是指到3，还是指到4了。当你使用STL容器中erase方法，那是一定要小心再小心，我也是被它戏弄了一下之后，才明白其中容易被忽视的这些细节。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;的仿函数与动态语言的闭包</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_closure_pkg/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 什么是闭包，我们先来用ruby看个例子：
sum = 0 10.times{|n| sum &#43;= n} print sum 其中{}就是闭包的内容，代码看起来是不是很清爽与简单。
我们还来看看Python写的闭包：
def addx(x): return lambda y: x &#43; y add8 = addx(8) print add8(100) 用Python写就没有那么好看。
闭包（Closure）是词法闭包（Lexical Closure）的简称。对闭包的具体定义有很多种说法，这些说法大体可以分为两类：
 一种说法认为闭包是符合一定条件的函数，闭包是在其词法上下文中引用了自由变量的函数。 另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。比如参考资源中就有这样的的定义：在实现深约束时，需要创建一个能显式表示引用环境的东西，并将它与相关的子程序捆绑在一起，这样捆绑起来的整体被称为闭包。  这两种定义在某种意义上是对立的，一个认为闭包是函数，另一个认为闭包是函数和引用环境组成的整体。虽然有些咬文嚼字，但可以肯定第二种说法更确切。闭包只是在形式和表现上像函数，但实际上不是函数。函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。所谓引用环境是指在程序执行中的某个点所有处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。那么为什么要把引用环境与函数组合起来呢？这主要是因为在支持嵌套作用域的语言中，有时不能简单直接地确定函数的引用环境。
什么是仿函数，我们先用C&#43;&#43;来写个例子：
struct comparer { bool operator()(int a, int b) const { return a &amp;gt; b; } }; int main(int, char**) { std::vector&amp;lt;int&amp;gt; vec; std::sort(vec.begin(), vec.end(), comparer()); return 0; } 函数(functor)之所以称为仿函数，是因为这是一种利用某些类对象支持operator()的特性，来达到模拟函数调用效果的技术。从上面你也可以看出来，仿函数实现的内容其实就像动态语言闭包实现的方式差不多，形式不一样，效果是一样的。至于语言本质是什么，就让语言学家去争论吧。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之栈变量的析构应用</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_stack_usage/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 栈变量有一个好处，就是它退栈时会自动析构，并且在栈上对象生成比在堆上分配效率高很多。但每个线程的栈空间是有限的(创建线程时可以设置)，所以一般的临时小对象都会在栈上分配。
struct Test {}; void test() { Test stack_var; // a stack var; Test stack_var2; //a stack var; int *heap_var = new int; // a heap var } 上述的例子，stack_var与stack_var2都是一个栈变量，当然stack_var与stack_var2谁先从栈中分配，不的操作系统，内存管理方式也略有区别。更深一点讲，heap_var这个指针值也是一个栈变量承载，但heap_var所指的地址内容才是从堆上分配的内存空间。当退出test这个函数时，stack_var与stack_var2都会先调用Test的析构，再把其所在的内存空间回收到线程栈中。
在一些场景下，我们可以利用栈变量当退栈时会自动析构这特性，下面我将举两个应用例子。
析构方法释放内存 从堆上面new出来的对象，在一个方法条件分支比较多的情况下，很容易在某个分支少写delete，就会造成内存的泄漏。于是我们可写一个这样的类，在它的析构方法中调用delete回收内存。
template &amp;lt;typename T&amp;gt; class ScopePtr { public: ScopePtr(T *&amp;amp; pT) : m_pT(pT) { } ~ScopePtr() { if ( NULL != m_pT ) { delete m_pT; m_pT = NULL; } } private: typedef ScopePtr&amp;lt;T&amp;gt; TScopePtr; ScopePtr(const TScopePtr &amp;amp;) {} TScopePtr&amp;amp; operator = (const TScopePtr &amp;amp;) {} T *&amp;amp; m_pT; }; // 使用方式如下： void test_scope() { Test* p = new Test; ScopePtr&amp;lt;Test&amp;gt; tempScopePtr(p); } 析构方法打印日志 做软件，写debug日志是一个好的习惯，出问题时可以方便定位问题的发生源。下面的例子是实现是能记录函数在哪一行进入，在哪一行退出。如果函数某个地方抛异常了，则可以根据进入行与退出行相同一看便知。没有抛异常，也很方便查出是在哪个分支退出的。
#define LOG(fmt, ...) printf(fmt, __VA_ARGS__) #define __FUNC_TRACE__ class FuncTracer { public: FuncTracer(const char* func, const char* file, const int line) : m_func(func), m_file(file), m_line(line) { LOG(&amp;#34;Enter [%s][%d][%s]./n&amp;#34;, m_file, m_line, m_func); } ~FuncTracer() { LOG(&amp;#34;Exit [%s][%d][%s]./n&amp;#34;, m_file, m_line, m_func); } inline void updateLine(const int line) { m_line = line; } private: const char* m_func; const char* m_file; int m_line; }; #ifdef __FUNC_TRACE__ #define FUNC_TRACER() FuncTracer __oFuncTracer(__FUNCTION__, __FILE__, __LINE__) #define FUNC_RET(retVal) do { __oFuncTracer.updateLine(__LINE__); return retVal; } while(0) #define FUNC_RET_VOID() do { __oFuncTracer.updateLine(__LINE__); return; } while(0) #else #define FUNC_TRACER() #define FUNC_RET(retVal) return retVal; #define FUNC_RET_VOID() return; #endif 上述的__FUNCTION__，__FILE__与__LINE__是编译期间的宏，是一个字符串常量，分别表示函数名，文件名与当前行数。但__FUNCTION__并非标准中定义的，各个编译器命名不同，更通用的宏可以使用boost中BOOST_CURRENT_FUNCTION。其中的__FUNC_TRACE__宏开关表示是否编译时开启函数跟踪。使用方式如下：
int test_trace() { FUNC_TRACER(); if(...) { switch(...) case 1: FUNC_RET(1); defualt: FUNC_RET(0); .... } FUNC_RET(1); } </content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之operator操作符</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_operator/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 这篇博文是以前很久写的，贴在我的早期一个blog中，今天google一下，发现还真有不少人转载，可惜并不注明出处。那时觉得operator比较好玩。C&#43;&#43;有时它的确是个耐玩的东东。operator它有两种用法，一种是operator overloading（操作符重载），一种是operator casting（操作隐式转换）。
operator overloading C&#43;&#43;可以通过operator 重载操作符，格式如下：类型T operator 操作符 ()，如比重载&#43;，如下所示
template&amp;lt;typename T&amp;gt; class A { public: const T operator &#43; (const T&amp;amp; rhs) { return this-&amp;gt;m_ &#43; rhs; } private: T m_; }; 又比如STL中的函数对象，重载()，这是C&#43;&#43;中较推荐的写法，功能与函数指针类似，如下所示
template&amp;lt;typename T&amp;gt; struct A { T operator()(const T&amp;amp; lhs, const T&amp;amp; rhs){ return lhs-rhs;} }; operator casting C&#43;&#43;可以通过operator 重载隐式转换，格式如下： operator 类型T ()，如下所示
class A { public: operator B* () { return this-&amp;gt;b_;} operator const B* () const {return this-&amp;gt;b_;} operator B&amp;amp; () { return *this-&amp;gt;b_;} operator const B&amp;amp; () const {return *this-&amp;gt;b_;} private: B* b_; }; A a;当if(a)，编译时转换成if(a.operator B*())，其实也就是判断if(a.b_).
</content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]自己实现的queue</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_self_impl_queue/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 周末在家，自己用C&#43;&#43;练一下手，用顺序存储与链表存储实现了队列queue。queue是一种先进先出的结构，有很多的应用，比如消息队列。
顺序存储实现： template&amp;lt;typename T, size_t SIZE&amp;gt; class Queue { public: Queue() : m_front(0), m_rear(0) { } ~Queue() { } void clear() { m_front = 0; m_rear = 0; } const bool empty() const { return m_front == m_rear; } const int size() const { int s = (m_rear - m_front &#43; (int)SIZE) % (int)SIZE ; return s; } bool push(const T&amp;amp; t) { int pos = (m_rear &#43; 1) % (int)SIZE; //printf(&amp;#34;/n m_rear = %d&amp;#34;, pos); if (pos == m_front) { return false;// it&amp;#39;s full } m_rear = pos; m_data[m_rear] = t; return true; } T&amp;amp; pop() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;#34;Overflow&amp;#34;); } m_front = (m_front &#43; 1) % (int)SIZE; //printf(&amp;#34;/n m_front = %d&amp;#34;, m_front); return m_data[m_front]; } T&amp;amp; getfront() { return m_data[m_front]; } // 遍历所有的节点 void traverse( void (*func)(T&amp;amp;) ) { if ( empty() ) { return;} for (int idx = m_front &#43; 1; idx != m_rear &#43; 1; idx&#43;&#43;) { if ( idx == (int)SIZE) { idx %= (int)SIZE; } //printf(&amp;#34;/n idx = %d&amp;#34;, idx); func(m_data[idx]); } } private: T m_data[SIZE]; int m_front; int m_rear; }; 链表存储实现： template&amp;lt;typename T&amp;gt; struct QNode { QNode() : m_pNext(NULL) { } T m_data; QNode* m_pNext; }; template&amp;lt;typename T&amp;gt; class LQueue { typedef QNode&amp;lt;T&amp;gt; TQNode; public: LQueue() { TQNode* pTemp = NULL; NEW(pTemp, TQNode() ); m_pFront = m_pRear = pTemp; m_size = 0; } ~LQueue() { clear(); DELETE(m_pFront); } void clear() { TQNode* pTemp = m_pFront-&amp;gt;m_pNext; while(NULL != pTemp ) { TQNode* pTemp2 = pTemp-&amp;gt;m_pNext; DELETE(pTemp); pTemp = pTemp2; } m_pFront-&amp;gt;m_pNext = NULL; m_size = 0; } const bool empty() const { return m_pFront == m_pRear; } const int size() const { return m_size;} bool push(const T&amp;amp; t) { TQNode* pTemp = NULL; NEW(pTemp, TQNode() ); if ( NULL == pTemp) { return false;} pTemp-&amp;gt;m_data = t; pTemp-&amp;gt;m_pNext = m_pRear-&amp;gt;m_pNext; m_pRear-&amp;gt;m_pNext = pTemp; m_pRear = pTemp; m_size&#43;&#43;; return true; } T pop() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;#34;Overflow&amp;#34;); } TQNode* pTemp = m_pFront-&amp;gt;m_pNext; T t = pTemp-&amp;gt;m_data; m_pFront-&amp;gt;m_pNext = pTemp-&amp;gt;m_pNext; if (NULL == m_pFront-&amp;gt;m_pNext) { m_pRear = m_pFront; } DELETE(pTemp); m_size--; return t; } T&amp;amp; getfront() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;#34;Overflow&amp;#34;); } TQNode* pTemp = m_pFront-&amp;gt;m_pNext; T t = pTemp-&amp;gt;m_data; return t; } // 遍历所有的节点 void traverse( void (*func)(T&amp;amp;) ) { if ( empty() ) { return;} TQNode* pTemp = m_pFront-&amp;gt;m_pNext; while(NULL != pTemp) { func(pTemp-&amp;gt;m_data); pTemp = pTemp-&amp;gt;m_pNext; } } private: TQNode* m_pFront; TQNode* m_pRear; int m_size; }; 测试代码： void print_queue(int&amp;amp; a) { printf(&amp;#34;%d/t&amp;#34;, a); } void test_queue() { LQueue&amp;lt;int&amp;gt; queue; //Queue&amp;lt;int, 4&amp;gt; queue; queue.push(1); queue.push(2); queue.push(3); queue.pop(); queue.pop(); queue.pop(); queue.push(1); queue.push(2); queue.push(3); printf(&amp;#34;/n1 : size: %d /n&amp;#34;, queue.size() ); queue.traverse(print_queue); queue.pop(); printf(&amp;#34;/n2 : size: %d /n&amp;#34;, queue.size() ); queue.traverse(print_queue); queue.push(4); printf(&amp;#34;/n3 : size: %d /n&amp;#34;, queue.size() ); queue.traverse(print_queue); queue.clear(); printf(&amp;#34;/n4 : size: %d /n&amp;#34;, queue.size() ); queue.traverse(print_queue); } </content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之断言Assert</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_static_assert/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 断言的应该是一种编程的常见技巧。我所应用的断言有两种，一种是动态断言，即大家所熟知的C标准库的assert()宏，一种是C&#43;&#43;中的静态断言，即在编译期间检查。
动态断言： assert宏的原型定义在&amp;lt;assert.h&amp;gt;中，其作用是如果它的条件返回错误，则终止程序执行，原型定义：
#include &amp;lt;assert.h&amp;gt; void assert( int expression ); assert的作用是先计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条出错信息，然后通过调用abort 来终止程序运行。
大家要注意是，其中的表达式为假时，会终止程序运行，包括我在内经常会写错代码，断言一个指针是否为空，往往写成了 assert(!p);其实应该写成assert(p);。
assert是运行期的判断，并且会强制终止程序，一般要求只能用于debug版本中，是为了尽可能快的发现问题。尤其在我所从事的电信软件产品中，assert是要从release版本中去掉。所以一般开发会重新定义assert宏。
静态断言： 在新的C&#43;&#43;标准中C&#43;&#43;0x中，加了对静态断言的支持，引入了新的关键字static_assert来表示静态断言。
使用静态断言，我们可以在程序的编译时期检测一些条件是否成立。但这个关键字太新了，没有几个编译器是支持的(好像VC2008支持，我用VC很少，主要是在linux下C&#43;&#43;编程)。
于是可以使用C&#43;&#43;现有的模板特性来实现静态断言的功能。boost中也已有BOOST_STATIC_ASSERT宏的实现，有兴趣的同学可以down下来仔细研究一下，它的断言信息更丰富，下面为我的简单实现：
// declare a tempalte class StaticAssert. template &amp;lt;bool assertion&amp;gt; struct StaticAssert; // only partial specializate parameter&amp;#39;s value is true. template &amp;lt;&amp;gt; struct StaticAssert&amp;lt;true&amp;gt; { enum { VALUE = 1 }; }; #define STATIC_ASSERT(expression) (void)StaticAssert&amp;lt;expression&amp;gt;::VALUE 原理是，先声明一个模板类，但后面仅仅偏特化参数值为true的类，而为false的类则一个未定义的类，即是一个未完整的类型,编译期间无法找到StaticAssert&amp;lt;false&amp;gt;::VALUE类型。举例如下：
STATIC_ASSERT(4 == sizeof(long) ); //在 32bit机上OK STATIC_ASSERT(4 == sizeof(long) ); //在 64bit机上NG，long为8字节 静态断言在编译时进行处理，不会产生任何运行时刻空间和时间上的开销，这就使得它比assert宏具有更好的效率。另外比较重要的一个特性是如果断言失败，它会产生有意义且充分的诊断信息，帮助程序员快速解决问题。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之宏Macro应用</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_macro_rule/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html">   宏不要用来定义常量，因为宏变量是没有类型安全，也没有名字空间约束，会造成名字的污染。
  宏的展开是一行，所以宏中的注释不能使用//，只能使用/* */。宏的代码也不能gdb跟踪，宏中代码逻辑要尽量简单。
  宏的参数一般情况下使用时要用()括起来，如: #define MAX(a, b) a /2 &amp;gt; b ? a /2 : b MAX(3,4)使用没有问题，但MAX(3&#43;4, 4)却有问题，因为宏的参数仅为符号替换。 应用定义为#define MAX(a, b) (a) / 2 &amp;gt; (b) ? (a) /2 : (b)
   宏的连接符分为#与## #表示一个符号直接转换为字符串，如 #define CAT(x) &amp;quot;First &amp;quot;#x &amp;quot; Third&amp;quot; const char * pszStr = CAT(Second); str的内容就是&amp;quot;First Second Third&amp;rdquo;，也就是说#会把其后的符号直接加上双引号。 ##符号会连接两个符号，从而产生新的符号(词法层次)，例如： #define NAME( x ) name_##x char* NAME( szlanny ); 宏被展开后将成为：char* name_szlanny;
  宏中如有存在if等语句产生的分支，要使用do{}while(0)包起来，如 #define TEST(a ) if ( 0 == a ) dosomething() 如果在下面使用是会存在问题
  if ( 1 == b) TEST(a ): else { dootherthing(); } 那当代码展开之后，宏中的if与外面的else是一起匹配，而不是else与if ( 1 == b)匹配。 所以上述宏要修改为
#define TEST(a ) do {/ if ( 0 == a ) { dosomething(); } }while(0) 对于可变参宏，可以使用__VA_ARGS__，GCC支持它，但并非所有的编译器支持，如果你的代码要跨平台，慎用。  #define LOG( format, ... ) printf( format, __VA_ARGS__ ) LOG( &amp;#34;%s %d&amp;#34;, str, count ); __VA_ARGS__被自动替换为参数列表。
 宏不能嵌套使用，如: #define TEST( x ) ( x &#43; TEST( x ) )，编译器展开过程中发现第二个TEST，那么就将这个TEST当作一般的符号。
  当宏的逻辑比较多时，可以考虑宏中使用模板方法来代替宏的逻辑实现。
 </content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]自己实现的stack</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_self_impl_stack/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 还是前一段时间需要任职资格考试，自己练习一下栈stack的简易实现，今天把它贴出来，暴露的接口与STL类似，没有实现iterator迭代器。实现有两种方式， 基于顺序存储与链式存储。栈的特点是“后进先出”，在数学表达式运算，编译语法分析中，程序函数调用时最为常见。
公用的宏与异常类:
#define NEW(var, T) do { / try { / var = new T; / }catch(...) { / var = NULL; / } / }while(0) #define DELETE(var) do { / if(NULL != var) / { / delete var; / var = NULL; / } / }while(0) template&amp;lt;typename T&amp;gt; struct Error { Error(const char* pszInfo = &amp;#34;Overflow&amp;#34;) { printf(&amp;#34;/nThrow a error, Info :%s/n&amp;#34;, pszInfo); } }; 顺序存储，模板实现，其中参数T为栈的存储类型，参数SIZE表示最大存储的个数。
template&amp;lt;typename T, size_t SIZE&amp;gt; class Stack { public: Stack() : m_size(0) { } ~Stack() { } bool push(const T&amp;amp; t) { if (m_size == SIZE) { return false; } m_data[m_size] = t; m_size&#43;&#43;; return true; } T&amp;amp; pop() { if (0 == m_size) { throw Error&amp;lt;T&amp;gt; (&amp;#34;Overflow&amp;#34;); } else { T&amp;amp; t = m_data[m_size]; m_size--; return t; } } void clear() { m_size = 0; } const bool empty() const { return 0 == m_size; } const size_t size() const { return m_size; } // 遍历所有的节点 void traverse(void(*func)(T&amp;amp;)) { if (empty()) { return; } for (size_t idx = 0; idx &amp;lt; m_size; &#43;&#43;idx) { func(m_data[idx]); } } private: T m_data[SIZE]; size_t m_size; }; 链式存储，也是模板实现，内部结构为一单向链表。入栈的元素加到链表的表头。
template&amp;lt;typename T&amp;gt; struct SNode { T m_data; SNode* m_pNext; SNode() : m_pNext(NULL) { } }; template&amp;lt;typename T&amp;gt; class LStack { typedef SNode&amp;lt;T&amp;gt; TNode; public: LStack() : m_size(0) { NEW(m_pTop, TNode()); if (NULL != m_pTop) { m_pTop-&amp;gt;m_pNext = NULL; } } ~LStack() { clear(); DELETE(m_pTop); } void clear() { if (NULL == m_pTop) { return; } TNode* pTemp = m_pTop-&amp;gt;m_pNext; while (NULL != pTemp) { TNode* pTemp2 = pTemp-&amp;gt;m_pNext; DELETE(pTemp); pTemp = pTemp2; } m_pTop-&amp;gt;m_pNext = NULL; m_size = 0; } const bool empty() const { return (NULL == m_pTop || NULL == m_pTop-&amp;gt;m_pNext) ? true : false; } const size_t size() const { return m_size; } bool push(const T&amp;amp; t) { if (NULL == m_pTop) { return false; } TNode* pTemp = NULL; NEW(pTemp, TNode()); if (NULL == pTemp) { return false; } pTemp-&amp;gt;m_data = t; pTemp-&amp;gt;m_pNext = m_pTop-&amp;gt;m_pNext; m_pTop-&amp;gt;m_pNext = pTemp; m_size&#43;&#43;; return true; } T pop() { TNode* pTemp = m_pTop-&amp;gt;m_pNext; if (NULL == pTemp) { throw Error&amp;lt;T&amp;gt; (&amp;#34;Overflow&amp;#34;); } T t = pTemp-&amp;gt;m_data; m_pTop-&amp;gt;m_pNext = pTemp-&amp;gt;m_pNext; DELETE(pTemp); m_size--; return t; } // 遍历所有的节点 void traverse(void(*func)(T&amp;amp;)) { if (empty()) { return; } TNode* pTemp = m_pTop-&amp;gt;m_pNext; while (NULL != pTemp) { func(pTemp-&amp;gt;m_data); pTemp = pTemp-&amp;gt;m_pNext; } } private: TNode* m_pTop; size_t m_size; }; 测试代码：
void print_stack(int&amp;amp; a) { printf(&amp;#34;%d/t&amp;#34;, a); } void test_stack() { printf(&amp;#34;stack test /n&amp;#34;); //Stack&amp;lt;int, 4&amp;gt; stack; LStack&amp;lt;int&amp;gt; stack; stack.push(1); stack.push(2); stack.push(3); stack.pop(); stack.pop(); stack.pop(); stack.push(1); stack.push(2); stack.push(3); printf(&amp;#34;/n1 : size: %d /n&amp;#34;, stack.size()); stack.traverse(print_stack); stack.pop(); printf(&amp;#34;/n2 : size: %d /n&amp;#34;, stack.size()); stack.traverse(print_stack); stack.push(4); printf(&amp;#34;/n3 : size: %d /n&amp;#34;, stack.size()); stack.traverse(print_stack); stack.pop(); printf(&amp;#34;/n4 : size: %d /n&amp;#34;, stack.size()); stack.traverse(print_stack); stack.clear(); printf(&amp;#34;/n5 : size: %d /n&amp;#34;, stack.size()); stack.traverse(print_stack); } </content>
    </entry>
    
     <entry>
        <title>用C&#43;&#43;模板来展示new与delete操作符原理</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_new_delete/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> C&#43;&#43;中的new与delete可以认为是C中的malloc与free的升级版本。new包含两部分:
 第一部分是与malloc功能相同，是从堆上面申请内存块 第二部是调用类的构造方法来初始化刚申请的内存。  delete是new的逆过程，先调用类的析构方法来反初始化，再把刚申请的内存还给堆。
new []与delete []是针对数组操作符，要注意是通过new []分配的对象，不能用delete来释放对象，否则会有内存泄漏。当然通过new分配的对象，不能用delete[]来释放对象。后面我会通过代码来说明为什么。
下面是C&#43;&#43; 中的new与delete函数原型，申请内存失败会抛出异常bad_alloc
void* operator new(std::size_t) throw (std::bad_alloc); void* operator new[](std::size_t) throw (std::bad_alloc); void operator delete(void*) throw(); void operator delete[](void*) throw(); 使用举例:
int* p1 = new int(); delete p2; int* p2 = new int[5]; delete [] p2; 终于到了用模板来模拟new与delete操作符，代码中有注释说明，其中对于调用类的构造方法，采用一种C&#43;&#43;标准中称作in-place construtor的方式。使用原型为T* = new(pbuff) T()，直译的话就是在pbuff这块内存构造T类，而不用再去堆上面申请内存。这种技巧大量应用在对象池的实现中，即pbuff这块内存可以挂在链表中反复地使用（这里先不展开说了）。
/** * A simulation of c&#43;&#43; new T() &amp;amp; new T(param) operation */ struct NewObj { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { // allocate memory form heap void * pBuff = malloc(sizeof(T)); // call constructor pObj = new (pBuff) T(); } template &amp;lt;typename T, typename P&amp;gt; inline void operator()(T*&amp;amp; pObj, const P&amp;amp; param) { // allocate memory form heap void * pBuff = malloc(sizeof(T)); // call constructor, pass one param pObj = new(pBuff) T(param); } }; /** * A simulation of c&#43;&#43; delete T operation */ struct DeleteObj { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { if ( NULL == pObj ) { return ;} // call destructor pObj-&amp;gt;~T(); // free memory to heap free((void*)pObj); pObj = NULL; } }; /** * A simulation of c&#43;&#43; new T[N]() operation */ struct NewObjArray { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj, unsigned int size) { // save the number of array elements in the beginning of the space. long * pBuff = (long *) malloc (sizeof(T) * size &#43; sizeof(long)); *((unsigned int *) pBuff) = size; pBuff&#43;&#43;; // change pointer to T type, then can use pT&#43;&#43; T * pT = (T *) pBuff; // save the pointer to the start of the array. pObj = pT; // now iterate and construct every object in place. for (unsigned int i = 0; i &amp;lt; size; i&#43;&#43;) { new((void *) pT) T(); pT&#43;&#43;; } } }; /** * A simulation of c&#43;&#43; delete [] T operation */ struct DeleteObjArray { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { unsigned int size = *((unsigned int *) ((long *) pObj - 1)); T * pT = pObj; // call destructor on every element in the array. for (unsigned int i = 0; i &amp;lt; size; i&#43;&#43;) { pT-&amp;gt;~T(); pT&#43;&#43;; } // free memory to heap. free ((void *) ((long *) pObj - 1)); pObj = NULL; } }; 测试代码:
struct TestClass { TestClass() : mem1(0), mem2(0) {} TestClass(int m) : mem1(m), mem2(0) {} int mem1; long mem2; }; void test_new_delete() { TestClass* p1 = NULL; NewObj()(p1); printf(&amp;#34;%p/n&amp;#34;, p1); DeleteObj()(p1); // TestClass* p2 = NULL; NewObj()(p2, 0); printf(&amp;#34;%p/n&amp;#34;, p2); DeleteObj()(p2); // TestClass* p3 = NULL; NewObjArray()(p3, 5); printf(&amp;#34;%p/n&amp;#34;, p3); DeleteObjArray()(p3); }   测试环境为eclipse&#43;cdt&#43;ubuntu&#43;gcc，注意头文件需要#include&amp;lt;new&amp;gt;，使用#include&amp;lt;stdlib.h&amp;gt;会导致编译不过，因为in-place construtor是C&#43;&#43;中的新玩意。
</content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]常见的几个排序算法</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_aglos/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 前一段时间需要任职资格考试，于是又拿起丢了几年的数据结构书看了看，温习了一下常见的几个排序算法。今天特把我写的学习代码贴了出来。排序的算法常见有插入排序，选择排序与交换排序，较复杂一点还有归并排序与基数排序，概念性的东西我就不多说了，大家可以找一本严老师数据结构书看看。读大学时不觉得怎么样，现在再来看看，又结合这几年的编程经验，通过C&#43;&#43;风格函数子造了一遍轮子。
排序算法  先来一个排序中的比较函数子，实现是左值小于右值。  template&amp;lt;typename T&amp;gt; struct CmpFuctor { bool operator()(const T&amp;amp; lhs, const T&amp;amp; rhs) { return lhs &amp;lt; rhs; } };  交换排序中用到的交换两个元素的函数。  template&amp;lt;typename T&amp;gt; void swap(T* lhs, T* rhs) { T tmp = *lhs; *lhs = *rhs; *rhs = tmp; }  排序前后，我们自然要观察前后元素的顺序，那也少了下面这个函数。即遍历整个数组，再回调函数指针func，把元素通过引用传递出来。  template&amp;lt;typename T&amp;gt; void traverse(T* pArray, const int size, void (*func)(T&amp;amp;) ) { for(int idx =0; idx&amp;lt; size; idx&#43;&#43;) { func(pArray[idx]); } }  我们先来看一个最简单的插入排序。  template&amp;lt;typename T, typename CMP &amp;gt; void insertsort(T* pArray, const int size, CMP cmp) { for(int idx =0; idx&amp;lt; size; idx&#43;&#43;) { T temp = pArray[idx]; int pos = idx -1; while( pos &amp;gt;= 0 &amp;amp;&amp;amp; cmp(temp, pArray[pos]) ) // &amp;lt; { pArray[pos&#43;1] = pArray[pos]; pos--; } pArray[pos&#43;1] = temp; } }  再对上面的插入排序改进，查找为折半插入排序。  template&amp;lt;typename T, typename CMP&amp;gt; void binaryinsertsort(T* pArray, const int size, CMP cmp) { for(int idx = 1; idx &amp;lt; size; idx&#43;&#43;) { int left = 0; int right = idx -1; T temp = pArray[idx]; while( left &amp;lt;= right) { int middle = (left &#43; right) / 2; if ( cmp(temp, pArray[middle] )) // &amp;lt; { right = middle - 1; } else { left = middle &#43; 1; } } int j = idx-1; for(; j &amp;gt;= right&#43;1; j--) { pArray[j&#43;1] = pArray[j]; } pArray[right&#43;1] = temp; } }  再来一个改进版的插入排序。  是希尔排序。希尔排序的基本思想是：先将整个待排记录序列分割成若干小组（子序列），分别在组内进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。
template&amp;lt;typename T, typename CMP&amp;gt; void shellsort(T* pArray, const int size, CMP cmp) { int j = 0; int d = size / 2; // 通过增量控制排序的执行过程 while( d &amp;gt; 0 ) { for(int i = d; i&amp;lt; size;i&#43;&#43;) { j = i - d; while(j &amp;gt;= 0) { // 对各个分组进行处理 if ( cmp(pArray[j&#43;d], pArray[j]) ) { swap(&amp;amp;pArray[j], &amp;amp;pArray[j&#43;d]); j -= d; } else { j = -1; } } } d /= 2; //递减增量d } }  下面是一种简单选择排序算法。  template&amp;lt;typename T, typename CMP&amp;gt; void selectsort(T* pArray, const int size, CMP cmp) { for(int idx = 0; idx &amp;lt; size; idx&#43;&#43;) { for(int pos = idx &#43; 1; pos &amp;lt; size; pos&#43;&#43;) { if( cmp(pArray[pos], pArray[idx]) ) // &amp;lt; { swap(&amp;amp;pArray[pos], &amp;amp;pArray[idx]); } } } }  交换排序中最简单的冒泡排序。  template&amp;lt;typename T, typename CMP&amp;gt; void bubblesort(T* pArray, const int size, CMP cmp) { for(int idx =0; idx &amp;lt; size; idx&#43;&#43;) { for(int pos = 0; pos &amp;lt;= size - idx;pos&#43;&#43;) { if( cmp(pArray[pos&#43;1], pArray[pos]) ) // &amp;lt; { swap(&amp;amp;pArray[pos], &amp;amp;pArray[pos&#43;1]); } } } }  交换排序中最简单的快速排序。  template&amp;lt;typename T, typename CMP&amp;gt; int partition(T* pArray, int p, int r, CMP cmp) { int i = p - 1; int j = 0; for(j = p; j &amp;lt; r; j&#43;&#43;) { if(cmp(pArray[j], pArray[r])) //pArray[j] &amp;gt;= pArray[r] { i&#43;&#43;; swap(&amp;amp;pArray[i], &amp;amp;pArray[j]); } } swap(&amp;amp;pArray[i &#43; 1], &amp;amp;pArray[r]); return i &#43; 1; 测试代码 void print(int&amp;amp; a) { printf(&amp;#34;%d/t&amp;#34;, a); } int genrandom(int min, int max) { return (min &#43; (int)(((float)rand()/RAND_MAX)*(max - min))); } void random(int&amp;amp; a ) { a = genrandom(-50, 100); } void sort_test() { int A[] = {4, 1, 44, -12, 5, 125, 30}; int len = sizeof(A) / sizeof(int); // traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); insertsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); binaryinsertsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); shellsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); bubblesort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); selectsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); quicksort(A, 0, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;#34;/n&amp;#34;); }   上面的函数有C风格的函数指针与C&#43;&#43;风格函数子（Functor，有时也叫函数对象），函数使用了C&#43;&#43;中模板的一些特性，测试环境为eclipse&#43;cdt&#43;gcc。
</content>
    </entry>
    
</search>