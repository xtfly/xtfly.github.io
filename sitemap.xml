<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
    
     <entry>
        <title>云设计模式</title>
        <url>http://lanlingzi.cn/post/technical/2017/0715_cloud_design_pattern/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>cloud</tag><tag>软件架构</tag>
        </tags>
        <content type="html"> 在云环境下，如何构建出可靠，弹性，安全的应用？有哪些挑战？面对这些挑战如何解决，微软Azure总结一系列的设计模式。本文是翻译Azure架构中心在线资料中的云设计模式，仅个人的笔记，借翻译学习一下，英文好的可以直接阅读原文。
挑战 可用性 可用性是指系统功能可用的时间占整体的比例，通常以正常运行时间比来衡量，它会受到系统错误、基础设施问题、恶意攻击和系统负载的影响。云应用典型为用户提供提供服务级协议（SLA），因此必须设计应用以最大限度地可用性。 数据管理 数据管理是云应用的关键要素，影响着大多数质量属性。由于性能、可伸缩性或可用性等原因，数据通常被存放在不同的位置和跨多个服务器上，这可能会带来一系列的挑战。例如，必须保持数据一致性，并且数据通常需要跨不同的位置同步。
设计与实施 好的设计包括组件设计和部署的一致性和关联性、可简化管理和开发的可维护性，以及允许组件和子系统在其他应用和其他场景中的可重用性等因素。在设计和实施阶段作出的决定，对云托管应用和服务的质量和总成本产生巨大影响。
消息 云应用的分布式属性需要一个消息交互基础设施，它将组件和服务连接起来，最好是以松耦合的方式，以最大限度地提高可伸缩性。异步消息的广泛使用，并提供了许多好处，但也带来了挑战，如消息的时序，消息的回环、幂等性等
管理与监控 云应用运行在远程数据中心中，在那里你不能完全控制基础设施，有时也无法控制操作系统。这会使管理和监控比私有部署环境下更加困难。应用必须暴露出管理员和运维员可以使用管理和监控系统运行信息，以及支持在不断变化的业务需求和定制下，而不需要停止或重新部署应用。
性能与扩展性 性能是指一个系统在给定的时间间隔内执行任何操作的响应指标，而可伸缩性是系统处理负载增加而不影响性能或所用资源容易地增加的能力。云应用通常会遇到不同的工作负载和活动高峰。预测这些，尤其是在多租户场景中，几乎是不可能的。相反，应用应该能够在限定范围内扩展，以满足需求高峰，并在需求减少时规模扩大。可伸缩性不仅涉及计算实例，还涉及其他元素，如数据存储、消息传递基础设施等等。
可靠性 可靠性是一个系统优雅地处理和从失败中恢复的能力。云托管的本质是，应用通常是多租户，使用共享平台服务，争夺资源和带宽，通过互联网进行通信，并在通用硬件上运行，这意味着出现瞬态故障和永久故障的可能性增加。检测故障并快速有效地恢复是保持可靠性的必要条件。
安全 安全性是系统在设计使用之外防止恶意或意外行为的能力，以及防止信息泄露或丢失的能力。云应用在互联网上暴露在可信的私有区域之外，通常向公众开放，并且可能服务于不可信的用户。应用必须设计和部署，以保护它们免受恶意攻击，限制对只有已允许的用户访问，并保护敏感数据。
设计模式    模式 摘要     Ambassador 创建帮助服务，代表消费者服务或应用发送网络请求。   Anti-Corruption Layer 在现代应用和遗留系统之间实现个门面或适配层。   Backends for Frontends 创建隔离的后端服务，提供接口给特定的前端应用使用。   Bulkhead 将应用的元素隔离到池中，以便当一个失败时，其他元素将继续发挥作用。   Cache-Aside 将数据数从据存储中按需加载到缓存中。   Circuit Breaker 当是连接远程服务或资源时，修复错误可能需要花费可变的时间。（注：直译不好理解，指发生错误时像电源断路器一样断开访问远程服务或资源）   CQRS 更新数据的操作与读取数据的操作的接口隔离。   Compensating Transaction 撤消由一系列步骤执行，这些步骤一起达到一个最终一致的操作结果。   Competing Consumers 允许多个并发消费者在同一通道上接收处理消息。   Compute Resource Consolidation 将多个任务或操作合并到单个计算单元中。   Event Sourcing 使用额外的只可追加的存储来记录域中数据所有的操作事件。   External Configuration Store 将配置信息从应用部署包中移到一个集中位置。   Federated Identity 将身份验证委托给外部身份提供者。   Gatekeeper 在客户端与应用或服务之间，采用专用的主机实例作为代理，以保护应用或服务，代理在他们之间验证和审查请求，并传递请求和数据。   Gateway Aggregation 使用网关把多个独立请求合并一个请求。   Gateway Offloading 分担共享与特定服务到网关代理。   Gateway Routing 使用同一端点路由请求到多个服务实例。   Health Endpoint Monitoring 在外部工具可以定期通过暴露的端点检查应用中实现功能是否健康。   Index Table 给频繁查询的数据字段创建索引。   Leader Election 在分布式应用中，一组协作的任务实例执行时，由Leader协同执行。Leader是通过选举一个实例来负责管理其它的实例。   Materialized View 在一个或多个数据存储，当数据不理想数据格式查询时，生成预先设置好视图。   Pipes and Filters 将执行复杂处理的任务分解成一系列可重用的独立元素。   Priority Queue 优先级高的请求发送给服务，较高优先级的请求比那些优先级较低的请求更快地接收和处理。   Queue-Based Load Leveling 使用一个队列作为一个任务和它调用的服务之间的缓冲区，以平滑间歇性的重载.   Retry 当它试图连接到一个服务或网络资源时，使应用能够处理预期的，暂时的失败，并透明地重试。   Scheduler Agent Supervisor 协调跨分布式服务集和其他远程资源的一组操作。   Sharding 将数据存储水平分区或分片。   Sidecar 将应用的组件部署到一个单独的进程或容器中，以提供隔离和封装.   Static Content Hosting 将静态内容部署到基于云的存储服务，该服务可以直接将它们提供给客户端。   Strangler 通过新的应用和服务逐步替换特定的功能块，来逐步迁移遗留系统。   Throttling 控制应用实例、单个租户或整个服务所使用的资源的消耗。   Valet Key 使用令牌或密钥，为客户提供对特定资源或服务的受限直接访问。   </content>
    </entry>
    
     <entry>
        <title>运维模式</title>
        <url>http://lanlingzi.cn/post/technical/2017/0708_ops_pattern/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>运维</tag>
        </tags>
        <content type="html"> 背景 最近一段时间由于工作内容重心变化，从PaaS系统的设计到运维系统的设计。运维系统的设计对我来说，还是一项全新的领域，需要学习的理念与技术很多。全司虽有大量的产品涉及到软件系统，但本质还是一个硬件盒子，运维的对象还是偏硬件。
熟悉电信IT系统的人或许听说过：OSS(Operation Support System)，运营支撑系统，它是运营商IT系统中三大支柱系统之一。其它两大系统是：BSS(Bussiness Support System), MSS(Management Support System)。
OSS是面向资源的后台支撑系统。资源主要包括网络，电信设备，计算系统等。系统的主要功能是包括专业网络管理，综合网络管理，资源管理，业务开通，服务保障等。但公司的产品线众多，产品形态也是千差万别，公司的OSS产品也一直在探索与发展。产品开发部门也是分分合合，一直是想打造一套统一的运营支撑平台。 我们所说的OSS，其实与互联网的业务运维系统主要功能也是相同的：
 对网络，设备，计算系统，业务系统的监控，维护 对监控数据的智能分析，结果用于支持业务运营决策  而我现在工作的范畴也是面向软件业务的运维系统构建，与一些业界（互联网公司）的同行交流，发现运维理念是在面向的业务特征与场景上有着显著的差异。总结起来是业务产品形态决定运维系统的模式, 大概分为两种运维模式：
标准化运维 标准化运维是基于标准化的体系建设，对业务环境、配置、操作、流程等通过制定、发布和实施标准达到统一，以获得最佳秩序和效益。标准化的优势是显而易见的，标准是实现运维自动化地基础，是提高团队效率的重要方式，是梳理运维杂乱问题的重要依据。
标准化运维模式是非常适合于自研业务的运维。自研的业务在行政政策下，标准规范可以统一规划，推广普及。所有的业务在服务器、操作系统、中间件，语言框架统一选型；制定统一的业务开发规范，如安装目录，配置标准，日志标准，发布包标准，CI/CD流程标准等。标准化制定由统一的委员会制定，委员会由各领域的专家组成，规范基于业界或自身一些最佳实践整理。
标准化的另一个目的是可以简化运维平台的建设，让人和系统更有效率地做事。尤其是在一个大型企业，若先不做规范，就做运维系统的建设，到最后极可能会失控，运维系统变得自已不可维护，整体成本倍增。符合标准规范的业务，可以快速接入到运维系统，操作流程化，自动化，从而提升运维效率，减少维护成本的支出。
标准化不只是针对有问题的地方，就去设定规范和标准化，输出相应的规范文档。而是把规范工具化，规范必须沉淀到平台，才能真正做到方便运维，体现规范的价值。
我司在标准化做得非常的好，设计了一个专门的行管组织，制定了相当多的标准规范。但随着时间的推移、人员的更替、业务的发展与技术的换代，标准化也可能变成了教条。标准规范只在一定时间，一定范围内才能最大效益化。另外一个需要注意的问题是，若行管组织只负责规范制定，不对具体的业务运维负责，也会导致规范会越来越脱离实际。
SaaS运维 另一种运维模式是运维能力平台化，把运维能力通过API的方式开放出来。不同的业务运维基于API开发、模板定制、能力编排来开发与定制SaaS运维应用。SaaS运维的基础是运维系统的能力成熟度与开放度。
SaaS运维模式非常适合于异构环境下的业务运维。尤其是业务系统非公司自研，购买于不同的厂商。这是因为他们的资源诉求不同，架构不同，运行形态不同，操作流程不同。在这种场景下，标准化运维很难执行落地，业务购买时已成型，不可能再修改；采购时也不太可能要求供应商遵循你私有的标准。
随着云计算的发展，现在越来越多的传统APM（Application Performance Management）或其它运维产品的公司推出他们的运维SaaS在线云服务，业务系统可以接入到运维系统或使用其提供运维云服务，来完成业务的运维，从来减少运维的基础设施投资。
SaaS运维是一种新的模型，也是后续运维系统的主要发展模式，SaaS将是未来主战场。但SaaS运维系统构建的困难相对于标准化在于：
 无侵入的运维接入 集成与被集成能力 简易定制开发能力 运维数据的安全性 运维生态系统构建  小结 标准化运维与SaaS运维有着不同的适应场景，但他们并不完全冲突，在SaaS运维系统中，也可以引入一些标准规范。目前一些开源社区或基金组织在推动一些项目，如OpenTracing，Prometheus Exporter等，这可能会形成事实标准。在云时代，SaaS云运维刚刚起步，也将是群雄逐鹿，有着不少的机会。
</content>
    </entry>
    
     <entry>
        <title>为什么我写不下去</title>
        <url>http://lanlingzi.cn/post/thoughts/2017/0626_how_to_write/</url>
        <categories>
          <category>感想</category><category>杂记</category>
        </categories>
        <tags>
          <tag>写作</tag>
        </tags>
        <content type="html"> 近一年来，写博客很少。总结起来有如下三点：
 没有时间 没有素材 没有心情  我很佩服那种每天都能写上千字博文或公众号的人，因为坚持写作需要很强的毅力。我没有能够坚持下来，其实最重要还是没有心情，动力不足。那作为一位内心深处又想写点东西的人，如何破？ 没有时间 没有时间，是我们最常用的借口。但有一句名言：
 时间就如海绵里的水，去挤总是有的
 换作搞IT的术语来说，我们工作中的空闲时间就像内存使用产生的碎片。碎片化的时间我们用来做什么呢，刷刷朋友圈，看看新闻。如果没有一套行之有效的碎片整理机制，系统的性能就会越来越下降，工作效率也是如此，还谈何写作。有时我也想像Windows一样有个磁盘碎片整理工具。但这些都是事后整理，最有效地还是如何事先减少碎片的产生。
减少碎片工作重要的做好等级划分，杂事集中在某一时间段处理。其实，重要的工作没有想像的那么多，紧急事情也不会像担心的地么紧急。不要搬石头砸自己的脚，否则格外的痛，而且没有地方埋怨。
工作分解如果不能将碎片化整理成一个更大的块，那么就把工作分成碎片放进去。这样慢是慢了些，但总比浪费的好。写作尤其适合这样的原则，不要强迫自己一次性从第一个字敲到最后一个字，那我们发现，时间过去了，我们没有写下几个字。
写作的碎片分解还是非常简单的可参考：金字塔原理，先设计好文档结构，再完成具体地写作；即先设计好蓝图，再去搭建。这与软件开发中面向对象设计有异曲同工之处。先设计好软件框架，类及关系，对象运行机制等；再去一一实现。先自上而下，大道至简，很多东西是相通，可以相互借鉴。
没有素材 写东西，尤其是写工作相关的总结性文档，不需要有惊天地、泣鬼神的才华。简单明了，直抒胸意即可，但要杜绝啰嗦，逻辑混乱。
有时候，发现写作是素材极缺，不知如何的展开。其实我们将现有的资料完善，系统化，并能够使自己头脑中零散的知识更加有效地使用。把这些写出来，可以理解更加的深刻，系统地把握其中的要素。
每个人或多或少会对自己所工作范围有些小的“创新”，如果能够及时地文档化，系统化地整理，并通过某种方式分享出来。这不仅会增强自己的知名度，也共享给其他人一个不一样的思想，不何尝不是一种双赢的事情。
当然写作也非常讲究技巧，尤其是文章的排版技巧。俗话说，”三分靠长相，七分靠衣着“。文章的版面工作，虽决定不了文档的内涵丰富，但它却有那七分的影响。试想若排版乱七八糟，会影响看文章人的心情，内容再好，可能由看不下去而错过。文章的版面不只是它需要漂亮的图片，格式来装饰。而是至少达到它的结构层清楚，逻辑清晰。更一步来说，若能图表化让表达更为直观明了，一图胜过千言万语。当感觉使用文字描述很麻烦时，不妨考虑使用图表来简化了。
好的文章一定也是艺术化，人的审美观是有一个交集的。越是同一个文化背景下的人们，交集越大。所以如果能将自己个性审美融入到写作中，并体现出来。作品往往就会产生一定的艺术气质，也会让人产生共鸣。所以我们写作时也可以尝试融入自己的喜怒哀乐。
没有心情 没有心情写作，其实很多时间是我们无法静心下来。
我们有时太过于注重在说，而忘记写了。说与写是相互影响的。说，具有及时，直接，感染的优点。但它却稍纵即逝，局部，浅显的缺点；写，就是为了弥补说的缺点而生。写能够让我们完整，系统，深刻，持久地，感情十分丰富地去阐述自己的观点；写能够真正长久地传播经验，知识。
一般来说，我们都会说会写，只是没有掌握方法，也没有去有意识地加强。有些人强于说弱于写，有些人反之，强弱差距间，这就需要我们在平时工作学习中弥补。行动从来都是非常重要的，说与写好比鸟的一对翅膀，只有两者都平衡了，才能更好地飞起来。
写作时需要放下心来，这没有什么好说的。静心你才能专注，专注才能从容。若是烦躁不安，怎么能写出东西来呢。静心需要合适的时间点，合适的外部环境。写作之前，不防先听一首好歌，喝一怀好茶。有时我们为写点东西，拖拖拉拉，硬着头皮，还不如痛痛快快，高高兴兴地完成。
人是需要成就感来填充时间的。这样人才能觉得清力充沛，状态良好。有很多的方式去获取成就感，最容易一种可能是如下方法：保持每天要抽出一点时间做自己最感兴趣的事，让自己每天进点一点点；每一阶段定一个小目标，达成学会庆祝自己。成就感也源自对自己的自信与满足。比如每周完成一篇博文，也是不错的，自我感觉良好。
说了这么多，也是对我为什么写不去一种救赎思考：没有时间，好就计划好时间；没有素材，从工作生活中寻找；没有心情，那就静下心来。
</content>
    </entry>
    
     <entry>
        <title>Install MySQL on MacOS</title>
        <url>http://lanlingzi.cn/post/notes/2017/0603_mac_mysql/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>MySQL</tag><tag>MacOS</tag>
        </tags>
        <content type="html"> 最近在家想写的东西，在MacOS上需要使用到MySQL。在MacOS下，使用brew来安装软件是最便捷。关于brew是什么，可在brew官网查看：brew官网
安装：
➜ ~ brew info mysql mysql: stable 5.7.18 (bottled) Open source relational database management system ...... ➜ ~ brew install mysql  
mysql的安装过程会显示，注，我安装的5.7.18，目录为/usr/local/Cellar/mysql/5.7.18_1：
==&amp;gt; /usr/local/Cellar/mysql/5.7.18_1/bin/mysqld –initialize-insecure –user=xiao –basedir=/usr/local/Cellar/mysql/5.7.18_1 –datadir=/usr/local/var/mysql –t ..... We’ve installed your MySQL database without a root password. To secure it run: mysql_secure_installation  这说明MySQL已安装成功，必需要使用mysql_secure_installation来初始化用户密码：
➜ ~ mysql.server start Starting MySQL SUCCESS! ➜ ~ mysql_secure_installation Securing the MySQL server deployment. Connecting to MySQL using a blank password. ......  按英文提示一步步设置password validation policy与password等。
测试，输入mysql_secure_installation设置过程的密码：
➜ ~ mysql -u root –p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 6 Server version: 5.7.18 Homebrew ......  新增用户xiao，密码为123456，并赋所有权限给他：
mysql&amp;gt;use mysql; mysql&amp;gt;GRANT ALL PRIVILEGES ON *.* TO &#39;xiao&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION; mysql&amp;gt;flush privileges;  如果想设置开机启动MySQL，执行如下命令：
➜ ~ mkdir -p ~/Library/LaunchAgents ➜ ~ cp /usr/local/Cellar/mysql/5.7.18_1/homebrew.mxcl.mysql.plist ~/Library/LaunchAgents/ ➜ ~ launchctl load -w ~/Library/LaunchAgents/homebrew.mxcl.mysql.plist  使用命令行来操作MySQL不方便，推荐使用Navicat MySQL/Preminum软件。软件安装包在网上搜索吧。
参考：
[1] https://dev.mysql.com/doc/refman/5.7/en/mysql-secure-installation.html
</content>
    </entry>
    
     <entry>
        <title>PaaS的发展</title>
        <url>http://lanlingzi.cn/post/technical/2017/0304_paas/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>PaaS</tag>
        </tags>
        <content type="html"> 云计算按提供服务层次，通常划分为三层：
 IaaS ：基础构架即服务。这一层主要是对基础设施进行管理以给用户提供资源使用，如提供计算服务、安全备份、负载管理等。 PaaS ：平台即服务。这一层主要是基于IaaS之上，简化应用的部署、维护等，提供一些通用平台软件能力，如数据挖掘、系统管理、编程模型等。 SaaS ：软件即服务。这一层主要是面向终端客户，提供一站式的解决方案。如提供CRM、HRM、SCM等，是可以直接使用其服务。  个人一直从事PaaS的研发，而我们做的又是面向电信领域的PaaS。与外面的朋又交流发现，大家对PaaS的理解是不一样的，主要还是由于PaaS的本质是要解决的问题是：
 简化开发，打通DevOps，实现业务应用的敏捷与弹性。
 不同的业务领域，要面对是不同的传统应用架构如何通过PaaS平台迁移到云上，这就会导致各自对PaaS的需求或多或少有着不同的差异，理解不一样也是正常的。

PaaS定义 NIST（National Institute Of Standards and Technoloy）曾对PaaS有过经典的定义：
 面向应用的核心平台，封装应用分布式复杂性，实现应用层自动化、高可用。
 从功能定义来看，主要包含三个方面：
 应用托管：可将开发者创建或拥有的应用部署到云基础设施上。其价值是应用对基础设施资源的获取自动化。 应用开发：开发者使用供应商提供的运行环境，编程语言框架，服务以及工具等来构建应用。其价值是应用对中间件服务的获取自动化，软件开发自动化。 应用运维：应用的运维无需管理或控制底下的基础设施（计算、网络、存储、OS等），可以控制已部署的应用，并有可能对应用托管的环境、其配置进行控制。其价值是应用的运维管理（伸缩，配置，升级等）自动化。  所以PaaS是以应用开发为中心，解决如下三个问题：
 应用全生命周期管理：从应用的开发、部署，到运维的全流程生命周期管理。开发者可使用供应商提供的运行环境，编程语言框架，服务与工具等快速构建应用；通过平台将应用部署到云基础设施上，并对应用进行自动伸缩，弹性扩展，灰度发布等；对上线的应用可以实现监控管理，故障分析，自动迁移，自动恢复，为应用提供高用性，高可扩展性。 中间件云服务：提供丰富的预集成服务，如分布式数据库服务，分布式消息队列服务，分布式缓存服务等。把通用的软件能力服务化，使得应用能快速拥有分布式的高用性，高可扩展性。同时中间件服务让多租能力变得可行，在中间件云服务层，不同的租户可参共享或隔离不同的服务资源。 基础资源的高效利用：对底层资源的抽象，可以按用户要求分配的相应用资源部署实例。大规模的应用部署在云基础设施上，PaaS可能通过调度算法，把应用实例调度到不同的资源上运行。通过资源层的隔离，尽可能地共享或平摊资源，以提高资源整体使用率，从而降低基础设施的投入。  PaaS的发展历史 早期公有云，主要是提供高效多语言多框架的开发与运维环境：
 2005年，Rackspace，提供托管PHP与.Net语言的Web应用，不支持多租户，API和自动伸缩。 2007年，Heroku/Force.com，支持Ruby语言，引进数据库，企业工作流服务，主要是支持托管CRM相关的应用。 2008年，GAE, Google发布面向WEB的开发和托管的平台，早期支持python、java语言。  开源PaaS成长期，主要是提供应用快速部署到基础设施上的能力：
 2008年，CloudFoundry，提供支持多语言，多框架的可移植的PaaS平台。2011年被VMWare收获，其后开源。 2010年，OpenShift，Redhat发布OpenShift，支持多种异构I层。受2011的CloudFoundry，也开源。 2010年，Cloudify，Gigaspace开始基于Java构建支持多种异构I层的PaaS，重点在应用部署，并开源。  在2014年之后，PaaS也不在仅仅是互联网的公有云玩法，而是百花齐放。软件开发管理模式正在PaaS技术的驱动下，经历一场新的变革：
 传统软件巨头份份杀人：Oracle，SAP，IBM，HP等发布云战略，构建PaaS平台，极力在其各自的传统领域打造云生态系统。 公有云PaaS呈现三国鼎立：AWS， Azure与GAE的PaaS平台走向成熟，构建方式呈现多层次，应用可以按需组合；并且在提供的服务数量，服务性能不断提升。 PaaS开源项目爆发：早期的CloudFoundry，OpenShift，Cloudify历经多个版本也走向成熟；轻量级的PaaS不断涌现，如Apache Stratos, Deio, Flynn等；面向应用与资源调度的PaaS开源抢占风头，Docker，CoreOS, Mesos, Kubernetes。  可以说，当前的PaaS也不在局限于NIST的经典定义，而是在大规模的云基础设施上，提供更多的高性能的云服务，更高效的资源使用方式。PaaS已经呈现多样形态，在灵活性和易用性上不断地提升。同时多形态并存，但也没有一个形态可以满足所有用户需求。
PaaS的发展趋势 随着新技术的出现，目前PaaS的发展趋势主是容器化，微服务化，分布式化。
 容器化  Docker简化了软件打包，形成了新的软件分发标准；同时解决了应用环境的一致性，加快了应用的部署，DevOps; Docker能更粒度地的资源分割。这些特性使得Docker技术快速应用，其技术以及生态的发展正对PaaS产生革命性的冲击与影响。基于Docker的PaaS平台也是层出不穷，如OpenShift，CloudFoundry，Deis与Flynn等，而公有云AWS， Azure，GCE与IBM等都份份支持Docker容器。
 微服务化  传统的集中式的三层架构，转变到微服务架构。应用由一组无状态，功能分离，可独立部署的小服务集组合而成。而每个服务又具体语言多样性，不同的开发团队可以选择其熟悉与场景适合的语言。服务间是解耦合的，每个服务内部可能快速上线，而不影响其它的服务。某个服务的故障只会影响到自己。微服务化架构下，PaaS平台要支持对微服务架构的应用平滑地演进。
 分布式化  传统PaaS面临着缺少大规模跨DC跨集群的管理能力；资源分配算法比较简单，不支持应用感知的多集群等资源分配需求；资源分配并行技术缺少在大量资源需求时验证，分配速度不理想。但无论是公有云还是私有云大规模地发展，都驱动了大规模集群管理与资源跨Region跨DC跨AZ调度。当前基于容器集群管理编排、资源调度技术还在不断地演进发展。
PaaS构建新目标 应用敏捷性，集中式朝分布式架构演进，构建PaaS时需考虑如下：
 PaaS支持应用渐进式地演进：构建基础通用技术共享平台（如微服务框架，DevOps流水线，通用中间件服务等），逐步迁移改造应用，让应用更好地Cloud Native。 PaaS支持应用的高用性：基于Design for failure理念，构建基础的可靠性工具集，通过软件来实现应用层的高可用性，支持跨DC，AZ等高用性部署；支持跨2地3中心的高可用性路由；支持应用分布式下事务管理，数据的一致性等。  大规模的基础设施建设，需要打通IaaS/PaaS，构建基于应用层的统一资源编排调度：
 全自动化：支持应用自动化部署，伸缩，灰度发布等；开发环境的自助式获取与应用自动化验证。 混合调度：支持基于物理机，虚拟机，以及容器在应用层的不同需求下的混合调度。  开放性才能让PaaS更具有生命力，PaaS需易集成，无锁定，让应用可以快速平滑迁移：
 多IaaS： 公有层场景下，可能由PaaS供应用商自建IaaS。但在私有云场景下，支持多IaaS对接是非常有价值的。 多运行环境： 微服务化，不同的服务可能采用不语言开发，这要求PaaS支持多语言的运行环境。 多服务：无论是平台本身提供的中间件云服务，PaaS还要能支持第三方传统服务的接入以供应用使用。 多工具：目前开源的自动化工具非常多，PaaS平台需要考虑支持可以集成多种工具，拉通现有应用的DevOps。 </content>
    </entry>
    
     <entry>
        <title>Design for Failure</title>
        <url>http://lanlingzi.cn/post/technical/2017/0216_dff/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 背景 故有的思维会影响创新，在传统的软件设计考虑高可靠性，主要方法论是”防“，处处保护，让系统的每一处能长时间运行，不中断地提供服务。事实上电信级高可用性（HA）也只能宣称达到5个9，这意味着一年也就只有5分半钟的中断时间。但每增加一个9却实施成本非常地高，有些是建立在硬件可靠基础之上，并且不少是实验数据或理论上支持。传统的思维认识，在泥沙上建房子不可靠的。但软件架构设计，即完全不一样，在不可靠的基础设施上构建上可靠的系统，那才是真正NB的。
依稀记得云计算刚出来时，大家都是持怀疑态度：性能下降的虚拟化技术、安全不可控的网络、变化复杂的资源管理，在其上如何构建可靠稳定的软件系统？事实上，Netflix完全基于AWS云基础设施，认为都有可能发生任何的故障（Failure），更何况资源也不掌握在自己手上。Netflix基于Design for Failure理念却构建出用户无感知的高可用系统，支撑他的业务飞速发展。事实上，故障无所不在，尤其是在云计算环境中：
 资源层次：电能失效，整个数据中心不可用；部分计算失效，网络不通，存储IO高等 应用层次：资源泄露；软件Bug；系统处理能力不足等 数据层次：数据丢失；数据不一致等  
概念解读 既然故障不可避免，何不让故障尽早的暴露，尽快的恢复。设计时针对故障场景而设计，一切假定在故障失效下如何处理，局部的失效不影响整体的可用性。这就是Design for Failure的核心理念。这个设计理念其实也跟人类社会很像：一个人的细胞代谢，只要有新的细胞补上就行；一个组织中，高度细分工作，几个人的离开，不影响整体的运转。Design for Failure不仅仅是高可用性设计，而是一种新的设计理念，有别于传统，通过单点的可靠性达到整体的高可用性。以Netflix公布的数据来看，每个EC2实例平均生命周期只有36个小时，每个单点不断地重生，才能达到整体的高可用性。其关键实施要点总结如下：
 容错：当系统中出现了各种故障时，系统能够自动隔离故障而不影响系统对外的服务质量。 冗余：提供系统冗余配置，当系统发生故障时，冗余的快速介入并承担已发生故障的工作。  以一个运行在云环境中的应用为例，Design for Failure理念需要按如下步骤来考虑：
 每个应用程序组件必须部署在冗余的云组件/服务上，有很少或没有失败的共同点，即不存在单点故障； 每个应用组件必须对基础设施不作任何假设，它必须能够在不停机的情况下适应基础设施的变化； 每个应用程序组件应该是分区容忍，换句话说，它应该能够生存的网络延迟（或通信损失）的节点上； 借助于自动化工具，必须能编排应用程序，以便响应失败或其他基础设施的变化等等。  案例分析 一个单点的故障，我们可能针对性地很容易解决，这可能是头痛医头的做法。但一个系统软件往往没有那么简单，举例来说，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。 此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。这就是我们常说的雪崩效应。所以我们非常有必要分析系统中的各种依赖关系。不同的层次来Design for Failure，不同的技术组合来解决问题。
以Netflix的系统架构来简单分析一下，看它是如何分层解决问题的：
接入层： AWS ELB 典型的部署架构都是多地区（Region）、多可用区（Zone）的部署。负责四层负载分发，支持跨Region调用，它解决是当一个Region不可用的分发。
Zuul Zuul负责七层分发，提供动态路由，监控，弹性，安全等。Zuul可以通过加载动态过滤机制，从而实现以下各项功能：
 验证与安全保障: 识别面向各类资源的验证要求并拒绝那些与要求不符的请求； 审查与监控: 在边缘位置追踪有意义数据及统计结果，从而为我们带来准确的生产状态结论； 动态路由: 以动态方式根据需要将请求路由至不同后端集群处； 压力测试: 逐渐增加指向集群的负载流量，从而计算性能水平； 负载分配: 为每一种负载类型分配对应容量，并弃用超出限定值的请求； 静态响应处理: 在边缘位置直接建立部分响应，从而避免其流入内部集群； 多区域弹性: 跨越AWS区域进行请求路由，旨在实现ELB使用多样化并保证边缘位置与使用者尽可能接近； 金丝雀测试：金丝雀版本实现精确路由； 故障注入：结合故障注入工具，从前端自动注入故障；  服务层 Eureka Eureka为所有Netflix服务提供服务注册集中管理，当然它也是可以分Zone分Region集群部署的。它与Zookeeper不同是：Zookeeper侧重于CP，而Eureka侧重于AP；服务注册信息支持跨Region的复制。
 Eureka服务端用作服务注册，提供服务实例信息注册与同步； Eureka客户端用用服务发现，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。  Ribbon 由于Eureka是非强一致性，服务实例状态并非是实时性，服务调用可能失败或超时。所以Ribbon作为客户端组，配合Eureka一起使用，作为服务路由均衡的补充。
 Ribbon客户端提供一系列完善的配置选项，比如连接超时、重试、重试算法等， Ribbon内置可插拔、可定制的负载均衡组件，支持多种均衡策略：简单轮询负载均衡；加权响应时间负载均衡；区域感知轮询负载均衡；机负载均衡。  在选择服务器时，该负载均衡器会采取如下步骤：
 负载均衡器会检查、计算所有可用区域的状态。如果某个区域中平均每个服务器的活跃请求已经达到配置的阈值，该区域将从活跃服务器列表中排除。如果多于一个区域已经到达阈值，平均每服务器拥有最多活跃请求的区域将被排除。 最差的区域被排除后，从剩下的区域中，将按照服务器实例数的概率抽样法选择一个区域。 从选定区域中，将会根据给定负载均衡策略规则返回一个服务器。  Hystrix Hystrix提供分布式系统使用，提供延迟和容错功能，隔离远程系统、访问和第三方程序库的访问点，防止级联失败，保证复杂的分布系统在面临不可避免的失败时，仍能有其弹性。
 隔离模式：简单说就是为每个依赖调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队，加速失败判定时间。 熔断模式：目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。  上述两种模式的实施，是服务速错，服务降级的基础。
数据层 EVCache VCache是一个数据缓存服务，专门为Netflix的微服务提供低延迟，高可靠性的缓存解决方案。它是基于memcached的内存存储，专门为云计算优化，适合对强一致性没有必须要求的场合。它不需要处理全局锁，群体读写，事务更新，部分提交和回滚，和其他一些分布式一致性的复杂设计。
 跨区可用：一个地区的的会员切换到另外一个地区，会在新的地区缓存中没有老地区的数据，称为cold cache，缓存会保存着重新计算需要的临时数据，这些数据如果从持久层存储获得将会非常昂贵，所以这种数据写入到本地缓存，并必须复制到所有地区的缓存中，以便服务于各个地区会员使用。 复制延迟：在跨区域复制变慢的情况下，不会影响性能和本地缓存的可靠性，所有复制都是异步的，复制系统能够在不影响本地缓存操作情况下悄悄地短时间中断。不需要一个完美的复制系统，可以接受EVcache一定限度的延迟和不一致，只要能满足应用和会员的需要就行。  其它 Cassandra是一个NoSQL数据库，是购买一家商业公司的服务，主要是用于各种Session的存储，并且支持跨区的同步复制。S3主要用于数据的备份。
总结 Netflix在每层上都考虑了失效，如何处理，但它每一层都没有做到尽善尽美，但不同层次的组合，却做到几乎完美的高可用性。当然Netflix构建高用性的系统还不只是我上面所列出的组件或工具。列出关键的部分是为了表达出Design for Failure的理念是：故障不可避免，可以分层次的设计，通过多个技术方案组合应用，从而达到故障隔离，冗余恢复，实现整体的高可用性。
</content>
    </entry>
    
     <entry>
        <title>35还能做技术吗</title>
        <url>http://lanlingzi.cn/post/thoughts/2017/0208_35_change/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>程序员</tag>
        </tags>
        <content type="html"> 最近我司心声社区到处充斥着在40岁左右惯例的帖子，之前觉得这些觉得离自己很远。不经意发现自己今年也35岁了，惯例这一天迟早会来临，只是早晚而已，按目前现状，再为公司奋斗也不会有太多年了，你想奋斗关键公司不让你啊。最近也陆续听到之前曾经共事的同事，或由于身体原因，被沟通退休或离职；或由于绩效平平，合同到期不再续签；或由于种种原因，被进入战备预备队前途不明。公司主营业务已遇到瓶颈，整个行业暮色深沉，新的领域就开拓不足，公司高层也不断地发文要打粮食，熵减等等。总之：“山雨欲来风满楼”。
35岁应该是一个年富力强的年龄，不应该发出“今年35，还能做技术吗？”这样的话题，其中透露出一丝不自信。话说三十而立，但目前这个年龄段，我是上有老，下有小，身上还背着几百万的房贷，说没有压力不是可能的。作一名软件工程师，在国内来说其职业生涯是相当短的。而我一直从事软件相关的工作，目前虽是做软件架构设计，但还是喜欢写写代码，一直没有找到自己明确的发展方向，一方面有我自身的性格原因，一方面能力的确有些偏科。

我非常能理解公司最近一些HR政策，企业为了保持长期的活力，换血难免。不管这事是否有多么无情，站在企业的角度来说无疑是正确的，毕竟企业不是慈善机构。公司也不可能让一个上了年龄、有家室的人一直从事一线编码工作。公司注重的是流程管理，觉得编码也可以像产业工人一样批量地生产。而年轻人更能干得多，给予得少。即使最近提倡的工程师文化，也是很难真正地做到，越提倡说明越缺失。
先简单说一说我为什么走上软件开发这一条路的经历吧：
90年代还是读初中时，老爸单位就开始使用电脑记账，那时觉得电脑太神奇了。个人虽买不起电脑，而要求老爸买了学习机，当时按着说明书，用basic语言输出满屏幕的各种形状的图型，心中也被巨大的喜悦填满。目前我清楚地记得，我爷爷看到我能在学习机上打出全家的名字，觉得这个是怎么做到的而不可思议。
高考那一年，我一表哥从大学里寄来一本小说《第一次亲密地接触》，讲得就是网络交友，原来交朋友也可能通过互联网，当时觉得这个太好玩了。于是高考填写志愿，我报了某211计算机专业，可惜语文成绩刚及格，总分数不够（在本省就招3个，我排名第6，我爸通过关系才知道的）。还好有个第三志愿保底，并且填写可以调剂，于是我调转到另一所大学，学的是信息管理。妈蛋，到学校才知道，这个信息管理其实与计算机不太相关，虽然也会学些计算机原理，C语言编程等。但这不是主业，主业是信息检索，运筹学，是一个从图书馆管理发展起来杂学科，什么都学，什么都浅。
大学一年级第二学期就买了电脑，一买电脑，就没有心思学习了，第一年还拿奖学金，后面连课不上了。每天大部分时间都在折腾电脑，重装系统，Win系统不知安装了多少次；Linux当时还远没有现在好用，也折腾过蓝点，RedHat。除了折腾就是打游戏，或者泡在网上看各种论坛。计算机理论没有怎么学，但其间还是有些编程的基础，曾获得校编程比赛三等奖。后面也和同学搞搞网站，系网站还是我们整理的，界面虽然丑点，但蛮有满足感。
04年大学毕业后就来了深圳，开始家里就给我安排了一份工作，是做物业管理。但我不是这种菜，没有干一天，就辞职不做了，现在想想年轻就是任性啊。出来就自己开始找工作，找来找去，发现只有做网站的公司要我，于是第一年我就在一家当时在体育界还算小有名气的小公司做一名程序员，负责后台的程序开发，从此就踏上了软件开发这一条道路。后来05年华为大规模地招新四军，经过电话面试，当面做题，也没有怎么答好就稀里糊涂地来了华为，真还得谢谢当时的技面官。后面更没有想到的事，有些同学纷纷转行，中间也有过多次的机会离开，而我却一干就是12年了。
在华为一直干得比较辛苦，结婚生小孩之后，发现再不能跟小伙伴一直挑灯夜战了。之前也不是没有奋斗过：
 去国外出差，可以整夜不睡觉，为了就是调通一个功能，等着明天客户可以验收。而这样的状况是持续的，每天吃不好，睡不着，最后回来发现落下胃病。 可以持续一个多月每天晚上11:30下班，回到公司附近的出租屋倒头就睡，明天又接着干。 可以凌晨不知几点，一个电话把你叫醒，说日志发到你邮箱，尽快定位解决问题。 可以明知道不可能完成的任务，还是坚持答应下来，即使周末过来，也要加班加点把它做完。 &amp;hellip;&amp;hellip;  当过了三十多岁，的确现发现状态不如以前了，说一下感受吧：
 明显感觉体力不行了。以前定位解决问题，搞到凌晨三四点也没有什么睡意，第二天精神也不错。现在如果要搞到凌晨或通宵的话，后面两三天觉得身心疲惫。 亚健康状态，平时锻炼比较少。每年的体检都有不少的问题，坐久了时间就觉得腰，颈椎痛。 记忆力没有以前好了。以前看过的代码，长时间能记住，定位问题总是比其它人快速。看过的资料，吸收没有哪么快了，记得的东西有时突然就想不起来。 明显感觉脑力跟不上了。以前码代码非常地快，一周就写10K；现在写代码总是思前想后，生产率没有那么高，但现在质量可能更好一些。想问题时注意力容易被打断，打断之后再难回神。  当然这些年也积累了非常多的经验：
 尤其是攻关方面，我总是能解决问题，因为之前踩过不少的坑，看过不少的坑，也解决过不少的坑，问题总是本质一样的。写代码会本能地避免，定位总是会举一反三。 知道怎么去做方案设计，分解并指导新人完成一个系统。有些问题能轻车熟路，以前解决类似问题的方案可以拿来复用。 知道系统架构一些设计原则，理论基础，抽象建模，知道如何去权衡一些方案的利弊等。 知识不再局限于编程语言，知道从多角度，多层次来看待一些问题，也在尝试去提炼一些编程之外的东西。  热爱与钻研技术这个没有错，也不会随着年龄大了就不行了。虽然软件界的技术日新月益，编程语言层出不穷，各种框架各领风骚，但解决实现问题的经验与能力是非常重要的。现在你跟一群年轻人去拼体力拼时间，肯定是拼不过了，唯有作出转变。以前可能是“我能力强，效率高，部门的关键人物”，其实那是错的，不可替代性才是最有价值的。“人无远虑，必有近忧”，平时不妨努力提升自己，专注于某一领域，你能想到别人所想不到的，您能解决别人所处理不了的。编程只是一种解决问题的手段，技术也不仅仅只是编程。简单地说对于通用软件领域，当前主要的价值是如何构建分布式的架构体系统，以应对不断变化的商业模式与体量。
当然上面说的还是一条技术路线，更重要的是你想明白技术只是为了产品，为了商业模式服务的。要让自己增值，不再吃码农的青春饭，那就要改变自己的想法，以快速适应未知的变化。积累系统架构经验，积累技术把控能力，积累对商业的理解，积累发现机会的敏感，果敢地作出改变。
</content>
    </entry>
    
     <entry>
        <title>再说说微服务</title>
        <url>http://lanlingzi.cn/post/technical/2017/0207_msa_think/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>微服务</tag>
        </tags>
        <content type="html"> Why 我司从15年开始学习互联网的微服务构架，到今16年的全云化战略，微服务已作为架构体系的重要工作。但微服务看似美好，在IT界应用非常的成熟与成功，但这个本质没有革命性的技术架构，在我司却非常地难以落地。主要原因：传统的CT应用太过厚重，面临着软件交付模式完全不一样，历史包袱改造面临短期看不到收益的成本投入：
 IT界：软件是自运维，借助于微服务构架，DevOps工程化，以及相对扁平的组织结构。软件向微服务转变相对阻力比较小，按康威定律，组织决定架构，微服务构架与扁平化、轻小的、精英化的组织是完全匹配的。在微服务构架实施上可以快速迭代演进，同时形成回路反馈，架构更符合良性的发展。同时像BAT等公司，业务上爆发式的增涨，也会加速微服务构架软变与满足。 我司：软件非自运维，做的是产品卖给运营商，DevOps当前无法直接打通。微服务构架对交付与运维来说，没有直接带来价值，反而会带来更多的问题。运营商是不可能像IT界每日构建灰度升级的。当然运营商自己也在改变，但这个改变是基础设施平台化，上层业务应用会拉入IT厂商，反而像我司这类传统的设备供应商会被旁落。说起来，这是另一个更大沉重的话题，不就再展开了。  
What 微服务架构转变当前遇到的各种问题，不是我们不实施微服务架构的理由。软件全云化，微服务这是趋势。再说说微服务对我们目前软件开发的核心价值吧：
 设计：微服务架构下，设计上可以重用已有微服务，反哺微服务仓库，达到软件功能更好的复用；同时由于微服务具有9大特性，使架构师能更好的守护软件架构。 开发：相比原来组件化架构，每个开发人员负责的代码量减少，更能把事件做精；微服务架构下，一般会有像JDF或HSF的服务框架，使开发难度降低；业务功能的细分，基于服务化接口契约，使并行开发变成可能，工期缩短；细粒度快速验证，单个微服务的更容易稳定。 部署：基于微服务的功能组合，可以按不同的特性交付，特性独立上线，而不原有的通过License开关控制；容量上可以按小颗粒度，自动化地伸缩，系统拥有更好的弹性。 运行：可以小颗粒度，自动化地故障隔离，故障影响范围可控；按服务的滚动升级。  有上面的这些理由，难道我们还不选择微服务架构吗？架构上是OK的，但我司的矩阵性管理，有项目经理，有产品管理，有服务人员，有部门经理，有成本管理等，他们会看到，会认可吗？会有产品上收益来支撑吗？遗憾是目前没有，所以仅仅是研发体系上的隐性收益很难快速地推进。
How 在我司，那如何地渐进式地推进微服务架构，从四个维度架构视图展开：
 逻辑视图：
 存量代码按特性功能进行分析梳理，优先有商业价值的特性功能重构 将老版本进程进行拆分与整合，对于相对稳定的原有组件尽量只服务化，而不微服务化 新增特性直接按照微服务架构设计，并优先考虑重用已有拆分的微服务 服务独立自治，多实例集群负荷均衡，可靠性服务内完成，服务内性能并发，服务使用者性能透明 去中心化治理，无全局控制节点，避免全局故障 服务划分原则：数据私有化，功能实例化，接口标准化，依赖最小化  部署视图：
 独立进程承载服务功能，在部署形态上做到可分可合 服务尽量部署独立数据库，在设计上考虑Schema的隔离 服务内的多进程统一服务控制节点管理 服务可靠性，并发性统一由服务控制节点管理 改造老进程新增服务接口，新老并存，调通后再去除老接口 新服务新进程承载，调通后替换老进程  开发视图：
 按照服务构建开发视图 按照服务构建测试工程 按照服务适配个人构建  能力视图：
 配置能力完善，包括基础架构，研发工具，人员能力 探索适合我司交付模式的微服务的开发模式   总之，微服务架构落地不可能一蹴而蹴，更不可能一场运行就能解决的。
</content>
    </entry>
    
     <entry>
        <title>Go性能优化小结</title>
        <url>http://lanlingzi.cn/post/technical/2017/0203_go_optimize/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 内存优化 小对象合并成结构体一次分配，减少内存分配次数 做过C/C&#43;&#43;的同学可能知道，小对象在堆上频繁地申请释放，会造成内存碎片（有的叫空洞），导致分配大的对象时无法申请到连续的内存空间，一般建议是采用内存池。Go runtime底层也采用内存池，但每个span大小为4k，同时维护一个cache。cache有一个0到n的list数组，list数组的每个单元挂载的是一个链表，链表的每个节点就是一块可用的内存，同一链表中的所有节点内存块都是大小相等的；但是不同链表的内存大小是不等的，也就是说list数组的一个单元存储的是一类固定大小的内存块，不同单元里存储的内存块大小是不等的。这就说明cache缓存的是不同类大小的内存对象，当然想申请的内存大小最接近于哪类缓存内存块时，就分配哪类内存块。当cache不够再向spanalloc中分配。
建议：小对象合并成结构体一次分配，示意如下：
for k, v := range m { k, v := k, v // copy for capturing by the goroutine go func() { // using k &amp;amp; v }() }  替换为：
for k, v := range m { x := struct {k , v string} {k, v} // copy for capturing by the goroutine go func() { // using x.k &amp;amp; x.v }() }  
缓存区内容一次分配足够大小空间，并适当复用 在协议编解码时，需要频繁地操作[]byte，可以使用bytes.Buffer或其它byte缓存区对象。
建议：bytes.Buffert等通过预先分配足够大的内存，避免当Grow时动态申请内存，这样可以减少内存分配次数。同时对于byte缓存区对象考虑适当地复用。
slice和map采make创建时，预估大小指定容量 slice和map与数组不一样，不存在固定空间大小，可以根据增加元素来动态扩容。
slice初始会指定一个数组，当对slice进行append等操作时，当容量不够时，会自动扩容：
 如果新的大小是当前大小2倍以上，则容量增涨为新的大小； 否而循环以下操作：如果当前容量小于1024，按2倍增加；否则每次按当前容量1/4增涨，直到增涨的容量超过或等新大小。  map的扩容比较复杂，每次扩容会增加到上次容量的2倍。它的结构体中有一个buckets和oldbuckets，用于实现增量扩容：
 正常情况下，直接使用buckets，oldbuckets为空； 如果正在扩容，则oldbuckets不为空，buckets是oldbuckets的2倍，  建议：初始化时预估大小指定容量
m := make(map[string]string, 100) s := make([]string, 0, 100) // 注意：对于slice make时，第二个参数是初始大小，第三个参数才是容量  长调用栈避免申请较多的临时对象 goroutine的调用栈默认大小是4K（1.7修改为2K），它采用连续栈机制，当栈空间不够时，Go runtime会不动扩容：
 当栈空间不够时，按2倍增加，原有栈的变量崆直接copy到新的栈空间，变量指针指向新的空间地址； 退栈会释放栈空间的占用，GC时发现栈空间占用不到1/4时，则栈空间减少一半。  比如栈的最终大小2M，则极端情况下，就会有10次的扩栈操作，这会带来性能下降。
建议：
 控制调用栈和函数的复杂度，不要在一个goroutine做完所有逻辑； 如查的确需要长调用栈，而考虑goroutine池化，避免频繁创建goroutine带来栈空间的变化。  避免频繁创建临时对象 Go在GC时会引发stop the world，即整个情况暂停。虽1.7版本已大幅优化GC性能，1.8甚至量坏情况下GC为100us。但暂停时间还是取决于临时对象的个数，临时对象数量越多，暂停时间可能越长，并消耗CPU。
建议：GC优化方式是尽可能地减少临时对象的个数：
 尽量使用局部变量 所多个局部变量合并一个大的结构体或数组，减少扫描对象的次数，一次回尽可能多的内存。  并发优化 高并发的任务处理使用goroutine池 goroutine虽轻量，但对于高并发的轻量任务处理，频繁来创建goroutine来执行，执行效率并不会太高效：
 过多的goroutine创建，会影响go runtime对goroutine调度，以及GC消耗； 高并时若出现调用异常阻塞积压，大量的goroutine短时间积压可能导致程序崩溃。  避免高并发调用同步系统接口 goroutine的实现，是通过同步来模拟异步操作。在如下操作操作不会阻塞go runtime的线程调度：
 网络IO 锁 channel time.sleep 基于底层系统异步调用的Syscall  下面阻塞会创建新的调度线程：
 本地IO调用 基于底层系统同步调用的Syscall CGo方式调用C语言动态库中的调用IO或其它阻塞  网络IO可以基于epoll的异步机制（或kqueue等异步机制），但对于一些系统函数并没有提供异步机制。例如常见的posix api中，对文件的操作就是同步操作。虽有开源的fileepoll来模拟异步文件操作。但Go的Syscall还是依赖底层的操作系统的API。系统API没有异步，Go也做不了异步化处理。
建议：把涉及到同步调用的goroutine，隔离到可控的goroutine中，而不是直接高并的goroutine调用。
高并发时避免共享对象互斥 传统多线程编程时，当并发冲突在4~8线程时，性能可能会出现拐点。Go中的推荐是不要通过共享内存来通讯，Go创建goroutine非常容易，当大量goroutine共享同一互斥对象时，也会在某一数量的goroutine出在拐点。
建议：goroutine尽量独立，无冲突地执行；若goroutine间存在冲突，则可以采分区来控制goroutine的并发个数，减少同一互斥对象冲突并发数。
其它优化 避免使用CGO或者减少CGO调用次数 GO可以调用C库函数，但Go带有垃圾收集器且Go的栈动态增涨，但这些无法与C无缝地对接。Go的环境转入C代码执行前，必须为C创建一个新的调用栈，把栈变量赋值给C调用栈，调用结束现拷贝回来。而这个调用开销也非常大，需要维护Go与C的调用上下文，两者调用栈的映射。相比直接的GO调用栈，单纯的调用栈可能有2个甚至3个数量级以上。
建议：尽量避免使用CGO，无法避免时，要减少跨CGO的调用次数。
减少[]byte与string之间转换，尽量采用[]byte来字符串处理 GO里面的string类型是一个不可变类型，不像c&#43;&#43;中std:string，可以直接char*取值转化，指向同一地址内容；而GO中[]byte与string底层两个不同的结构，他们之间的转换存在实实在在的值对象拷贝，所以尽量减少这种不必要的转化
建议：存在字符串拼接等处理，尽量采用[]byte，例如：
func Prefix(b []byte) []byte { return append([]byte(&amp;quot;hello&amp;quot;, b...)) }  字符串的拼接优先考虑bytes.Buffer 由于string类型是一个不可变类型，但拼接会创建新的string。GO中字符串拼接常见有如下几种方式：
 string &#43; 操作 ：导致多次对象的分配与值拷贝 fmt.Sprintf ：会动态解析参数，效率好不哪去 strings.Join ：内部是[]byte的append bytes.Buffer ：可以预先分配大小，减少对象分配与拷贝  建议：对于高性能要求，优先考虑bytes.Buffer，预先分配大小。非关键路径，视简洁使用。fmt.Sprintf可以简化不同类型转换与拼接。
参考：
1. Go语言内存分配器-FixAlloc
2. https://blog.golang.org/strings
</content>
    </entry>
    
     <entry>
        <title>CloudNative初探</title>
        <url>http://lanlingzi.cn/post/technical/2017/0106_cloudnative/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag><tag>容器</tag><tag>软件架构</tag>
        </tags>
        <content type="html"> 随着日益普及的云计算，越来越多的传统应用迁移到云上。尤其是视频巨头NetFlix从2009年开始，放弃构建自己的数据中心，把所有应用迁移到AWS。NetFlix认为云环境下，everything will be failure。它基于微服务架构，以及Design for failure理论，构建出一系统非常成功的云应用（微服务），支持它的业务飞速发展。NetFlix认为他们比Amazon自己更懂得AWS。同时业界也提出了CloudNative概念，Netflix的应用也认为目前最为成功的CloudNative应用（参考Cloud Native at Netflix）。那什么是CloudNative？
概念 目前对CloudNative并没有明确的定义。15年，Google联合其他20家公司宣布成立了开源组织Cloud Native Computing Foundation（CNCF）。想通过开源的Kubernetes，在云计算领域占据主层地位。当然Kubernetes目前是一个以应用为中心容器编排，调度集群管理系统。它想做的是CloudNative Application的基石。从CNCF组织来看，CloudNative Application应该包含微服务，容器，CI/CD特征。
早在2010年，WSO2的联合他始人Paul Fremantle在业界最早提出CloudNative，认为有如下几个关键特征：  Distributed/Dynamically wired，分布式/动态连接 Elastic，弹性；Scale down as well as up, based on load，基于系统负载的动态伸缩 Granularly metered and billed，粒度合适的计量计费；Pay per user，按使用量计费 Multi-tenant，多租户 Self service，自服务 Incrementally deployed and tested， 增量的部署与测试  CloudNative系统的效果： Better utilization of resources, faster provisioning, better governace。
在2013年，AWS的云战略架构师同时也是NetFlix的云架构师Adrian Cockcroft提出对CloudNative新的定义：基于不可靠的，易失效的基础设施(ephermeral and assumed broken components), 构建高度敏捷（high agile），高可用（highly available）的服务，包括如下几个方面：
 目标：Scalability，伸缩性；Availablility，可用性；Agile，敏捷；Efficiency，效率 原则：Separation of Concerns，关注点分离；Anti-Fragility，反脆弱性；High trust organization，高度信任的组织 特点：Public Cloud，基于公有云； Mirco-services，微服务；De-normalized data，反范式化数据；Chaos Engines，混沌引擎；Continues Deployment，持续部署；DevOps等等  在2015年，Pivotal的产品经理Matt Stine又对CloudNative关键架构特征进行补充：
 Twelve Factor App，十二因子应用 Mirco-services，微服务 Self Service Agile Infrastructure，自服务敏捷的基础设施 API Based Clolaboration， 基于API的协作 Anti-Fragility，反脆弱性  总结 总结起来，要实施CloudNative，包括三个维度：
 软件架构：基于敏捷基础设施，是整个Cloud Native的根基；基于微服务架构，微服务架构是Cloud Native的一个核心要素；基于Design for failure理论，构建高可用的系统；基于容器部署，确保环境一致性，应用快速启动终止，水平扩展。 组织变革：根据康威定律，如果要达到比较理想的云化效果，必须进行组织变革。一个合理的组织架构，将会极大提高云化的推行；推行DevOps文化，倡导开放、合作的组织文化。 软件工程：推行持续集成与持续交付，联合开发、质量、运维各个环节，打通代码，编译，检查，打包，上线，发布各个环节。全自动化，包括自动化部署，升级，灰度，以及运维。  CloudNative背后的软件架构需求：
 按需特性的伸缩 按特性持续演进 应用快速上线 系统的高用性 全面解耦合 系统自服务 支持多租户 异构公有云  参考：
1. http://wso2.com/library/articles/2010/05/blog-post-cloud-native
2. https://www.infoq.com/presentations/migration-cloud-microservices
3. http://www.infoq.com/cn/articles/cloud-native-architectures-matt-stine
4. 一篇文章带你了解Cloud Native
</content>
    </entry>
    
     <entry>
        <title>Go依赖管理机制</title>
        <url>http://lanlingzi.cn/post/technical/2016/1120_go_deps_mgnt/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 无论何种语言，依赖管理都是一个比较复杂的问题。而Go语言中的依赖管理机制目前还是让人比较失望的。在1.6版本之前，官方只有把依赖放在GOPATH中，并没有多版本管理机制；1.6版本（1.5版本是experimental feature）引入vendor机制，是包依赖管理对一次重要尝试。他在Go生态系统中依然是一个热门的争论话题，还没有想到完美的解决方案。
看其它 我们先来看看其它语言怎么解决，例举两种典型的管理方式：
Java 开发态，可以通过maven和gradle工具编辑依赖清单列表/脚本，指定依赖库的位置/版本等信息，这些可以帮助你在合适的时间将项目固化到一个可随时随地重复编译发布的状态。这些工具对我来说已经足够优雅有效。但maven中也有不同依赖库的内部依赖版本冲突等令人心烦的问题。尤其是在大型项目中的依赖传递问题，若团队成员对maven机制没有足够了解下，依赖scope的滥用，会让整个项目工程的依赖树变得特别的巨大而每次编译效率低下。运行态，目前Java也没有很好的依赖管理机制，虽有classloader可以做一定的隔离，但像OSGi那种严格的版本管理，会让使用者陷入多版本相互冲突的泥潭。
Node.js npm是Node.js的首选模块依赖管理工具。npm通过一个当前目录的 package.json 文件来描述模块的依赖，在这个文件里你可以定义你的应用名称( name )、应用描述( description )、关键字( keywords )、版本号( version )等。npm会下载当前项目依赖模块到你项目中的一个叫做node_modules的文件夹内。与maven/gradle不同的是，maven最终会分析依赖树，把相同的软件默认扁平化取最高版本。而npm支持nested dependency tree。nested dependency tree是每个模块依赖自己目录下node_modules中的模块，这样能避免了依赖冲突, 但耗费了更多的空间和时间。由于Javascript是源码发布，所以开发态与运行态的依赖都是基于npm，优先从自己的node_modules搜索依赖的模块。 go get Go对包管理一定有自己的理解。对于包的获取，就是用go get命令从远程代码库(GitHub, Bitbucket, Google Code, Launchpad)拉取。并且它支持根据import package分析来递归拉取。这样做的好处是，直接跳过了包管理中央库的的约束，让代码的拉取直接基于版本控制库，大家的协作管理都是基于这个版本依赖库来互动。细体会下，发现这种设计的好处是去掉冗余，直接复用最基本的代码基础设施。Go这么干很大程度上减轻了开发者对包管理的复杂概念的理解负担，设计的很巧妙。
当然，go get命令，仍然过于简单。对于现实过程中的开发者来说，仍然有其痛苦的地方：
 缺乏明确显示的版本。团队开发不同的项目容易导入不一样的版本，每次都是get最新的代码。尤其像我司对开源软件管理非常严格，开源申请几乎是无法实施。 第三方包没有内容安全审计，获取最新的代码很容易引入代码新的Bug，后续运行时出了Bug需要解决，也无法版本跟踪管理。 依赖的完整性无法校验，基于域名的package名称，域名变化或子路径变化，都会导致无法正常下载依赖。我们在使用过程，发现还是有不少间接依赖包的名称已失效了（不存在，或又fork成新的项目，旧的已不存维护更新）。  而Go官方对于此类问题的建议是把外部依赖的代码复制到你的源码库中管理。把第三方代码引入自己的代码库仍然是一种折中的办法，对于像我司的软件开发流程来说，是不现实的：
 开源扫描会扫描出是相似的代码时，若License不是宽松的，则涉及到法律风险，若是宽松的，开源扫描认证确认工作也很繁琐。 如何升级版本，代码复制过来之后，源始的项目的代码可以变化很大了，无明显的版本校验，借助工具或脚本来升级也会带来工作量很大。 复制的那一份代码已经开始变成私有，第三方代码的Bug只能自己解决，难以贡献代码来修复Bug，或通过推动社区来解决。 普通的程序问题可能不是很大问题，最多就是编译时的依赖。但如果你写的是一个给其他人使用的lib库，引入这个库就会带来麻烦了。你这个库被多人引用，如何管理你这个库的代码依赖呢？  好在开源的力量就是大，Go官方没有想清楚的版本管理问题，社区就会有人来解决，我们已经可以找到许多不错的解决方案，不妨先参考下官方建议。
vendor vendor是1.5引入为体验，1.6中正式发布的依赖管理特性。Go团队在推出vendor前已经在Golang-dev group上做了长时间的调研。最终Russ Cox在Keith Rarick的proposal的基础上做了改良，形成了Go 1.5中的vendor:
 不rewrite gopath go tool来解决 go get兼容 可reproduce building process  并给出了vendor机制的&amp;rdquo;4行&amp;rdquo;诠释：
 If there is a source directory d/vendor, then, when compiling a source file within the subtree rooted at d, import &amp;ldquo;p&amp;rdquo; is interpreted as import &amp;ldquo;d/vendor/p&amp;rdquo; if that exists.
When there are multiple possible resolutions,the most specific (longest) path wins.
The short form must always be used: no import path can contain “/vendor/” explicitly.
Import comments are ignored in vendored packages.
 总结解释起来：
 vendor是一个特殊的目录，在应用的源码目录下，go doc工具会忽略它。 vendor机制支持嵌套vendor，vendor中的第三方包中也可以包含vendor目录。 若不同层次的vendor下存在相同的package，编译查找路径优先搜索当前pakcage下的vendor是否存在，若没有再向parent pacakge下的vendor搜索（x/y/z作为parentpath输入，搜索路径：x/y/z/vendor/path-&amp;gt;x/y/vendor/path-&amp;gt;x/vendor/path-&amp;gt;vendor/path) 在使用时不用理会vendor这个路径的存在，该怎么import包就怎么import，不要出现import &amp;ldquo;d/vendor/p&amp;rdquo;的情况。vendor是由go tool隐式处理的。 不会校验vendor中package的import path是否与canonical import路径是否一致了。  vendor机制看似像node.js的node_modules，支持嵌套vendor，若一个工程中在着两个版本的相的包，可以放在不同的层次的vendor下：
 优点：可能解决不同的版本依赖冲突问题，不同的层次的vendor存放在不同的依赖包。 缺点：由于go的package是以路径组织的，在编译时，不同层次的vendor中相同的包会编译两次，链接两份，程序文件变大，运行期是执行不同的代码逻辑。会导致一些问题，如果在package init中全局初始化，可能重复初化出问题，也可能初化为不同的变量（内存中不同），无法共享获取。像之前我们遇到gprc类似的问题就是不同层次的相同package重复init导致的，见社区反馈。  所以Russ Cox期望大家良好设计工程布局，作为lib的包不携带vendor更佳 ，一个project内的所有vendor都集中在顶层vendor里面。
后续 Go的包依赖问题依旧困扰着开发人员，嵌套vendor可以一定程度解决多版本的依赖冲突问题，但也引入多份编译导致的问题。目前社区也在一直讨论如何更好的解决，将进入下一个改进周期。这次将在Peter Bourgon的主持下正式启动：go packaging proposal process，当前1.8版本特性已冻结，不知这个改进是否会引入到1.9版本中。
参考：
[1] 理解Go 1.5 vendor
[2] Golang的包管理之道
</content>
    </entry>
    
     <entry>
        <title>要学会思维图形化</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/1118_arch_drawing/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 曾经，我幼稚地认为：只有写好代码才能对产品最“大”的贡献。什么需求分析文档，架构设计文档，没有最终的代码落地，那就是一张张的空纸。那些职位高高在上的架构师们，就也是写写胶片，画画图，他们又不懂技术细节，天天开会讨论来，讨论去都是在空谈一切。没有我们这些屌丝写的代码，你让他们去实现，估计几年也搞不出来。我写代码的能力比他们顶上N个人；再看看人家老外，60/70岁了还在码代码。为什么我国到了30岁了，都不去写代码了，都去搞所谓的架构设计了。是他们写代码写不好才去干架构师活吗？
经过这么多年在产品中挖坑、填坑，发现我们的产品是越来越复杂，但使用上也是越来越复杂，问题也是越来越难理清。我们的问题到底是出在什么地方：  数据不可靠，系统常出错 增加新需求困难，场景总是覆盖不全 系统之间集成各种问题难以轻易解决 交付不同局点，代码总是改来改去 每年代码量成倍增加，前辈的代码看不懂、改不动 &amp;hellip;  这其实是光写好代码是不能解决上述问题的。只有你经历过，感受到，才能认识到系统的架构是何其重要。作为曾经一名码农，这几年一直在设计部与架构部工作，总是羡慕那些高级别的架构师：
 他们思考问题角度完全不同，总能高屋建瓴概括总结 他们思考问题比较全面，又能抽象提炼，让人快速抓住要要点 他们们输出的胶片、图画非常简洁，优美，明了，无二义 他们画出来图来指导解决集成问题，往往能一针见血地说明关键之处 &amp;hellip;  为什么他们的图能画得那么好，胶片写得那么牛，而我们似乎绞尽脑汁也难画出一张满意的图，难写出几张像样的胶片，是什么原因？是画得太少，写得太少，经验不足，方法不对，无灵感，还是天赋？
看到采铜老师的文章才悄然大悟：原来，不仅是因为架构师需要丰富的实践经验、敏锐的分析能力，以及系统性的建模能力，更主要的是因为：
 日常我们通过文字/讲故事是线性叙述，是人和时间的结合；而画图，是人与空间结合，理有助于思维拓展
 推荐阅读：
[1] 思维运筹学导论（原理篇）
[2] 思维运筹学导论（实践篇 · 图形化 · 上）
[3] 思维运筹学导论（实践篇 · 图形化 · 下）
</content>
    </entry>
    
     <entry>
        <title>Archlinux on WSL</title>
        <url>http://lanlingzi.cn/post/notes/2016/1030_archlinux_wsl/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>WSL</tag>
        </tags>
        <content type="html"> 最近国庆某东活动，搞了一台HP的笔记本，系统是Win10。经过不断地折腾，在Win10上启用了Windows Subsystem for Linux（简称WSL），并在WSL上安装了Archlinux。加入Insider Preview会员计划，可以最快地获取Win10的最新内部版本，以便及时获取WSL的功能更新。 WSL Windows Subsystem for Linux是一个为在Windows 10上能够原生运行Linux 二进制可执行文件（ELF 格式）的兼容层。 WSL提供了一个微软开发的Linux兼容内核接口（不包含Linux代码）。它包含用户模式和内核模式组件，主要是由如下组成：
 用户模式会话管理器服务，处理Linux实例的生命周期； Pico（可编程输入输出）提供驱动程序（lxss.sys，lxcore.sys），通过转换的Linux系统调用模拟Linux内核； 承载未经修改的用户模式Linux的Pico进程，例如/bin/bash。  在用户模式Linux程序和Windows内核组件之间，通过将未修改Linux程序放入Pico进程，我们让Linux系统调用被引导至Windows内核。lxss.sys和lxcore.sys驱动转换Linux系统调用进入NT API并模拟Linux内核。
Bash on Ubuntu on Windows就是WSL的具体应用。它是由微软与Canonical公司合作开发，目标是使纯正的 Ubuntu 14.04镜像能下载和解压到用户的本地计算机，并且镜像内的工具和实用工具能在此子系统上原生运行。在最近的14959更新中，Ubuntu已是默认为16.04。
Bash on Ubuntu on Windows 作为一名ArchLinux忠实爱好者，自然想在WSL上运行ArchLinux。参考了一些网上的资料，我已把Win10升级到14955，首先还是先得安装Bash on Ubuntu on Windows：
 开启开发人员模式：设置-更新与恢复-针对开发人员-开发人员模式 开启WSL子系统：控制面板-程序和功能-启用或关闭 Windows 功能-适用于 Linux 的 Windows 子系统（beta） 安装Bash on Ubuntu on Windows: 命令提示符（cmd）-输入bash-按提示完成安装  由于需要下载Ubuntu需要从应用商店下载，在天朝的网络，可能会比较慢，甚至会连接不上，我就折腾好久。并且它居然没有断点续传，好几次下载到70%多，就断开了，真让人受不了。
由于后续把Ubuntu替换成Archlinux，需要使用到Archlinux的roofs。squashfs-tools工具是用于解压sfs文件的，所以先把Ubuntu的更新源替换成国内的，比如mirrors.163.com/ubuntu或mirrors.aliyun.com/ubuntu。
$ sudo apt-get update $ sudo apt-get install squashfs-tools  Archlinux on WSL 首先从http://mirrors.aliyun.com/archlinux/iso/latest/下载最新的ArchISO。
从ArchISO中提取出/arch/x86_64/airoot.sfs文件放在Bash on Ubuntu on Windows 能读取的目录下。WSL系统会把Windows的磁盘挂载到/mnt目录下，如D盘则是/mnt/d。
在Ubuntu中把airoot.sfs解压，建议在当前Ubuntu的用户Home目录下执行：
$ sudo unsquashfs airoot.sfs  然后把Bash窗口关掉，通过Windows的文件资源管理器进行到C:\Users\&amp;lt;用户名&amp;gt;\AppData\Local\Lxss文件夹。由于AppData与Lxss都是隐藏目录，可以在地址栏上直接输入路径就可以直接进入，否则需要在文件夹选项 中把“隐藏受保护的操作系统文件”选项取消才能看到。
其中的rootfs文件夹就是Linux中的/，先把原有的rootfs修改其它名称备份，还把之前airoot.sfs解压的squashfs-root直接剪切到Lxss，重命名为rootfs。注意，squashfs-root不能在Windows下拷贝到Lxss\rootfs，由于在WSL与Windows对文件读写操作还是有区别，Windows下拷贝可能存在丢失文件。
先在命令提示符（cmd）用lxrun /setdefaultuser root 把默认的用户换成root。再输入bash进入Linux。
这个我们就把Ubuntu替换成Archlinux。我们就可以像使用Archlinux一样来在WSL中使用Archlinux。比如创建新的用户，设置locale，替换Archlinux的更新源。不过由于我最早是在14396版本中使用WSL，还是在使用过程遇到了几个问题：
 无法chroot，解决办法：  升级到14936或以后的Insider Preview版本。
 Archlinux无法更新或安装新的软件，由于keyringVerifying失败，解决办法:  # pacman-key --init # pacman-key --populate   locale-gen失败(找不到UTF-8的charmaps文件)，解决办法：  # cd /usr/share/i18n/charmaps # tar zxvf UTF-8.gz # locale-gen   编译Go语言程序失败（估计是系统调用没有实现，没有proc），解决办法：  升级到14959或以后的Insider Preview版本。
WSL终端 windows下命令提示符（cmd），输入bash可以直接进入WSL，但它的使用体验无法跟Linux中的终端相比。好在网上已有同学先贡献了终端模拟器，都是基于mintty，总算能找回一些在纯Linux中使用终端的感觉。若使用下msys2的同学应该对它比较熟悉。
 https://github.com/mintty/wsltty https://github.com/goreliu/wsl-terminal  参考：
[1] https://blog.yoitsu.moe/arch-linux/wsl_with_arch_linux.html
[2] http://tieba.baidu.com/p/4834742871
[3] https://linux.cn/article-7857-1.html
[4] https://linux.cn/article-7209-1.html
</content>
    </entry>
    
     <entry>
        <title>团队管理</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/1027_team_mgnt/</url>
        <categories>
          <category>笔记</category><category>感想</category>
        </categories>
        <tags>
          <tag>团队</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 最近由于Go语言项目，又带一个小团队。以前作为团队的Leader，总是遇到各种问题，尤其是如何管理好人很困惑。HW的组织相对是比较宽松的，内部号称是矩阵式，感觉一个团队的凝聚力个人还是来源于Leader的个人技术感召力。好吧，这个只是凭感觉的管理，这是远远不够的。
作为一个技术团队的小Leader，整体来讲，它面临”业务“，”人“，”事“这三个方面的工作展开。这些是来源公司内牛人们的一些总结，我把他们纪录下来，是为了我更好地开展工作。 业务 虽是一个技术团队，所交付是面向客户交付的软件。两个方面是需要思考的：
 价值贡献 满意度  我们常说”质量是我们最后尊严，业务价值是我们存在之本“，道理简洁朗朗上口，但也是最难做好的，做好又是一白遮百丑。
 面向业务：核心竞争力，价值识别与规划 面向业务&amp;amp;解决方案：领域级，变革项目级规划、运作 满意度管理：面向业务（客户，用户）；面向解决方案；面向部门；面向合作伙伴 Top产品，问题的攻关  人 人的运用，对于Leader来说，是一项非常具有挑战的事，这需要Leader有很高的EQ与IQ。总结起来选用育留四个字：
 选
 亲自招聘，选择合适的人 已有员工中骨干识别 非关键外包合作  用
 角色与岗位排兵布阵 合作外包  育
 能力引入：公司内部交流：经验总结交流分享；部门内外专家交流；业界交流：参加相关技术峰会；高级顾问培训交流 能力培养：提升人员技能；组织能力建设 全程关注：事前辅导，事中监控，事后总结  留
 绩效辅导 即时激励 组织氛围：员工座谈，组织集体活动，员工关怀（问题员工识别管理，异常事件处理） 岗位流动   事 以前作为一个团队的小Leader，感觉一天都在忙，但不知在忙些什么。管事恨不得像孙猴子能分身出来，但健身乏术，如何正确合理地授权也是考验Lader的水平。
 TopN问题与任务跟踪管理 KPI管理：现状问题分析；改进计划（包括措施）；改进监控；达成评估 风险管理 技术持续改进：新技术引入；优秀实践； 质量持续改进：质量文化；质量监控，问题日清日结；质量回溯；质量改进 流程运作持续改进 知识管理 跨部门协同 </content>
    </entry>
    
     <entry>
        <title>软件变革下设计原则</title>
        <url>http://lanlingzi.cn/post/technical/2016/0910_soft_design/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件设计</tag><tag>设计原则</tag>
        </tags>
        <content type="html"> 传统大型软件系统 ，多以功能需求驱动设计与开发。在体系结构上是一个单体应用，变更修改往往是牵一而发动全身；在系统生态上是一个封闭系统，系统集成是大量定制开发。单体封闭的系统在交付中面临着越来越多的挑战，提升系统的竞争力首先是在软件架构上先行。软件系统发展也需像硬件一样不断地更新换代，软件架构设计需要输入新的思维。只有在思想上彻底地变革，才能摆脱原有的束缚与局限性。
体验为王 软件原本是一种信息技术发展不断地服务于各行各业，软件在实现上又是偏向技术性。如何让普通用户能够较好地使用软件，而不需要这方面的专业背景，需要思考软件减少数字与体验之间鸿沟。互联网思维一直讲求如何让用户感知到你对他的价值，而且把这个价值争取做到极致，超出用户的预期，这个就叫体验。只有用户产生体验之后，才能形成口碑。简而言之，体验的思想，就是从用户的感受出发，把它做到极致。 正如我们所见到的，iPhone的成功原因之一，就是注重用户的体验获得巨大的成功。今天，人们于弹指间操控丰富业务。无数应用，以碎片化的形式填满用户时间，连接起永远在线的数字生活。一个显见的事实是，“体验”正被尊奉为至高无上的法则，用户已重掌驱动行业发展的威权。
曾经一位领导说我们的软件系统发展应该先是“能用”，再是“好用”，最后是“易用”。这其实也是软件系统从功能为主朝用户至上，体验为王方向发展。套用阿里一句词：“让天下没有难用的软件”。
那如何能做到“体验为王”的软件设计呢？
作名一名架构师，首先要始终以用户和角色为中心，要从原有的我能为你提供什么功能，转变成用户最需要什么为出发点。首先要把自己当成用户，如果连自己都不去使用自己设计的系统，又如何把系统设计好呢。
有人说，软件架构设计不是UI/UE设计，架构设计是功能逻辑设计，是技术实现设计，是物理部署设计；而用户体验只是UI/UE都需要考虑的。UI设计，确切地说，用户使用界面上设计首先要考虑用户体验。但体验不仅仅是界面上的交互操作的易用性，心理感受等。试想，如果你浏览一个网页或使用一个App，虽UI设计非常符合用户的使用习惯，但响应速度却非常地慢。这也不会是好的体验。速度上需要零等待，存储上需要大容量，并发上需要高吞量。这些都需要在软件系统架构上着重设计。
软件架构设计要以需求的场景化、实例化驱动设计。无法场景化的需求往往是伪需求。真正的需求是满足目标用户在特定场景下的目标。作为架构设计师，要弄清其中两个关键因素：1）目标用户；2）特定场景下的目标。
平台为本 平台化分为技术支撑型平台和应用实现型平台。技术支撑型平台的用户为软件开发人员，提供者负责平台的维护和升级，用户负责基于平台的上层实现。这类平台包括软件中间件、开发工具、应用服务器等。应用实现型平台的用户为终端用户，提供者不但负责平台的维护和升级，还要负责实现基于平台的上层应用。
平台化首先需要在架构设计上考虑系统的开放性，通常的做法是系统功能服务化，API化。采用标准的通信协议，让系统易于被集成。系统具备更好的应用开发和维护的工具和接口，实施时可以迅速根据用户的特点进行部署和二次开发，用户可以最大限度地使用贴近自身特点来重新定义软件功能。
像Saleforce等SaaS平台一样，平台化使运行于上层的应用软件在某种程度上做到与技术无关，而是面向具体业务，提供更为领域化的DSL。平台化提供各种易于组装的套件，可定制修改的业务模板。这样才能面向合作伙伴，构建平台之上的工具链，生态社区等。
软件系统在研发和使用过程中需求变更不可避免。平台化的软件也在架构设计上，需地支持系统的平滑演进与对外接口兼容。这也需要在设计上考虑平台与上层业务之间的边界划分。上层的业务是最为变更频繁的，一是业务领域特性一般的变更不要侵入到平台。其二、平台的发展也不能影响上层业务的运行。当系统面对市场需要时，要评估这些需求是否需要在平台增加或改动哪些功能，平台软件是要随着客户需求而发展演进的。只有不断切合上层业务发展诉求的平台才具有更久的生命力。
内生敏捷 业务逻辑复杂多变，如何保证程序逻辑的代码稳定是架构师需要解决的问题，良好的模块划分和扩展性强的接口设计都是解决这个问题的利器。微服务化，大系统小做。系统分解的目标并不仅仅是搞出一堆很小的服务，这不是目标；真正的目标是解决系统在业务急剧增长时遇到的问题。
模块化，微服务化的让某一个功能足够内聚，足够小，代码容易理解、开发效率提高。服务之间可以独立部署，微服务架构让持续集成（CI），持续部署（CD）成为可能，基于数据化地构建软件生产流水线成为可能。各个服务之间可以在流水线上按功特性灵活组装。
软件的本质是要面对各种业务需求的变化，这需要系统高度地抽象化，以不变来应对万变。使用一切可以减少编码的技术，例如元数据驱动。软件系统设计已经发展到使用运行时引擎从元数据（即关于应用程序本身的数据）生成应用程序组件的阶段。在一个定义良好的元数据驱动的体系结构中，已编译的运行时引擎（内核）、应用数据、描述一个应用程序的基础功能的元数据，以及与每个租户的数据和定制相关的元数据之间有一个明确的分离。这些明显的边界使人们有可能独立更新系统内核，修改的核心应用程序，或定制租户的具体组成部分，虚拟意义上来说，几乎不会影响其他人。
数据驱动 数据驱动是系统内生的数据感知，基于系统运行数据进行系统的预测与资源优化。数据驱动的终极目标是希望利用数据能够直接在生产环境带来改变，提供价值。
数据驱动自动化干预，需要不断优化的分析算法，利用数据基础在特定领域完成基于算法的自动调整。算法线上部署除了对平台和算法本身的支持之外，还需要考虑：
 数据的及时性：实时数据和历史数据的组合，在特定周期下替换历史数据。 异常数据的容忍：线上算法的输入无法做到离线的清洗水平，需要更健壮的数据预处理模块。 算法的迭代：需要可靠的离线迭代平台来纠正线上算法运行过程中的误差和偏离。采集线上的数据到离线平台，通过离线平台调整参数和适应性。支持从离线平台推送新的算法。  一个系统的开放性，也体现在数据的开放性。系统架构上需考虑可被高层的系统，更深度的分析。不同维度与不同层次的分析，才能让数据变得更有价值。
原生云化 原生云化指“Cloud Native”，它是多种不同思想的一个集合，这些思想帮助软件系统转移到云平台。这些思想包括DevOps、持续交付、微服务、敏捷基础设施、康威定律等。“Cloud Native”没有标准的官方定义，但包括如下几个特征：
 可移植：应用层与物理层隔离。应用从开发环境迁移到物理环境无需改变环境配置。 自动化：通过持续集成和自我修复系统将IT基础设施的开发和部署进行自动化。 效率提升：通过引入全新方式来降低运维成本，让系统管理员可以有更多时间去改进系统，而不是把时间都用在维护系统上。 意识改变：DevOps的兴起以及运维和开发人员越来越多的共同协作发布服务，包括微服务和传统服务，让用户意识到服务发布的速度和敏捷性，已经和稳定性一样重要。  原生云化的系统也是具有12因子。原生云化首先考虑是的分布式一切。分布式架构可以以水平扩展，通过横向扩充节点，如一个节点扩充到多个节点，每个节点运行独立实例，节点与节点之间通过网络互连，随着节点扩充系统处理能力能够随之提升，单节点失效时，整个集群仍然可以对外提供服务。遵循12因子原则的应用程序，具有一致的架构接口。为了使创建的分布式应用马上就可以部署在云中，这些接口的构建采用一种无状态、面向进程的设计模式。
多租户也是云计算的基本属性之一，原生云化的系统也必定是多租户架构的系统。利用多租户带来资源上高度共享模式，提高资源资源利用率，降低单位资源成本。但是共享资源越多，会带来租户的隔离性难度越大，成本越高。在按隔离程序不同层次，可分为物理多租架构与逻辑多租架构，物理多租架构技术如采用虚拟化技术，Docker容器，以及应用容器技术来隔离租户资源。逻辑多租架构技术如应用程序进程间隔离，数据切割隔离。
原生云化的系统也是最大程度自动化。健壮自动化几乎能处理传统IT中需要手工处理的所有事情：当应用实例增减时更新路由器和负载均衡组件，部署应用所需的供应和联网服务，分配新的基础设施，设置监控和灾后恢复服务，日志聚合，当基础设施失效时重新部署应用。这些高级自动化实践，能把你从应对零日危险的痛苦中拯救出来：自动化采用滚动更新的方式，为每一个节点打上安全补丁，同时又保证服务一直在线。
</content>
    </entry>
    
     <entry>
        <title>Go map key类型分析</title>
        <url>http://lanlingzi.cn/post/technical/2016/0904_go_map/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 团队成员中大多是原来做Java，深受Java的影响，对于使用map问得最多的：map的key如何计算它的HashCode。下面试图通过讲解一些类型知识来解答。
map的key类型 map中的key可以是任何的类型，只要它的值能比较是否相等，Go的语言规范已精确定义，Key的类型可以是：
 布尔值 数字 字符串 指针 通道 接口类型 结构体 只包含上述类型的数组。  但不能是：
 slice map function   Key类型只要能支持==和!=操作符，即可以做为Key，当两个值==时，则认为是同一个Key。
比较相等 我们先看一下样例代码：
package main import &amp;quot;fmt&amp;quot; type _key struct { } type point struct { x int y int } type pair struct { x int y int } type Sumer interface { Sum() int } type Suber interface { Sub() int } func (p *pair) Sum() int { return p.x &#43; p.y } func (p *point) Sum() int { return p.x &#43; p.y } func (p pair) Sub() int { return p.x - p.y } func (p point) Sub() int { return p.x - p.y } func main() { fmt.Println(&amp;quot;_key{} == _key{}: &amp;quot;, _key{} == _key{}) // output: true fmt.Println(&amp;quot;point{} == point{}: &amp;quot;, point{x: 1, y: 2} == point{x: 1, y: 2}) // output: true fmt.Println(&amp;quot;&amp;amp;point{} == &amp;amp;point{}: &amp;quot;, &amp;amp;point{x: 1, y: 2} == &amp;amp;point{x: 1, y: 2}) // output: false fmt.Println(&amp;quot;[2]point{} == [2]point{}: &amp;quot;, [2]point{point{x: 1, y: 2}, point{x: 2, y: 3}} == [2]point{point{x: 1, y: 2}, point{x: 2, y: 3}}) //output: true var a Sumer = &amp;amp;pair{x: 1, y: 2} var a1 Sumer = &amp;amp;pair{x: 1, y: 2} var b Sumer = &amp;amp;point{x: 1, y: 2} fmt.Println(&amp;quot;Sumer.byptr == Sumer.byptr: &amp;quot;, a == b) // output: false fmt.Println(&amp;quot;Sumer.sametype == Sumer.sametype: &amp;quot;, a == a1) // output: false var c Suber = pair{x: 1, y: 2} var d Suber = point{x: 1, y: 2} var d1 point = point{x: 1, y: 2} fmt.Println(&amp;quot;Suber.byvalue == Suber.byvalue: &amp;quot;, c == d) // output: false fmt.Println(&amp;quot;Suber.byvalue == point.byvalue: &amp;quot;, d == d1) // output: true ci1 := make(chan int, 1) ci2 := ci1 ci3 := make(chan int, 1) fmt.Println(&amp;quot;chan int == chan int: &amp;quot;, ci1 == ci2) // output: true fmt.Println(&amp;quot;chan int == chan int: &amp;quot;, ci1 == ci3) // output: false }  上面的例子让我们较直观地了解结构体，数组，指针，chan在什么场景下是相等。我们再来看Go语言规范中是怎么说的：
 Pointer values are comparable. Two pointer values are equal if they point to the same variable or if both have value nil. Pointers to distinct zero-size variables may or may not be equal.当指针指向同一变量，或同为nil时指针相等，但指针指向不同的零值时可能不相等。 Channel values are comparable. Two channel values are equal if they were created by the same call to make or if both have value nil.Channel当指向同一个make创建的或同为nil时才相等 Interface values are comparable. Two interface values are equal if they have identical dynamic types and equal dynamic values or if both have value nil.从上面的例子我们可以看出，当接口有相同的动态类型并且有相同的动态值，或者值为都为nil时相等。要注意的是：参考理解Go Interface A value x of non-interface type X and a value t of interface type T are comparable when values of type X are comparable and X implements T. They are equal if t&amp;rsquo;s dynamic type is identical to X and t&amp;rsquo;s dynamic value is equal to x.如果一个是非接口类型X的变量x，也实现了接口T，与另一个接口T的变量t，只t的动态类型也是类型X，并且他们的动态值相同，则他们相等。 Struct values are comparable if all their fields are comparable. Two struct values are equal if their corresponding non-blank fields are equal.结构体当所有字段的值相同，并且没有 相应的非空白字段时，则他们相等， Array values are comparable if values of the array element type are comparable. Two array values are equal if their corresponding elements are equal.两个数组只要他们包括的元素，每个元素的值相同，则他们相等。  注意：Go语言里是无法重载操作符的，struct是递归操作每个成员变量，struct也可以称为map的key，但如果struct的成员变量里有不能进行==操作的，例如slice，那么就不能作为map的key。
类型判断 判断两个变量是否相等，首先是要判断变量的动态类型是否相同，在runtime中，_type结构是描述最为基础的类型（runtime/type.go），而map, slice, array等内置的复杂类型也都有对应的类型描述（如maptype，slicetype，arraytype）。
type _type struct { size uintptr ptrdata uintptr hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg gcdata *byte str nameOff ptrToThis typeOff } ... type chantype struct { typ _type elem *_type dir uintptr } ... type slicetype struct { typ _type elem *_type } ...  其中对于类型的值是否相等，需要使用到成员alg *typeAlg(runtime/alg.go)，它则持有此类型值的hash与equal的算法，它也是一个结构体:
type typeAlg struct { // function for hashing objects of this type // (ptr to object, seed) -&amp;gt; hash hash func(unsafe.Pointer, uintptr) uintptr // function for comparing objects of this type // (ptr to object A, ptr to object B) -&amp;gt; ==? equal func(unsafe.Pointer, unsafe.Pointer) bool }  runtime/alg.go中提供了各种基础的hash func与 equal func，例如：
func strhash(a unsafe.Pointer, h uintptr) uintptr { x := (*stringStruct)(a) return memhash(x.str, h, uintptr(x.len)) } func strequal(p, q unsafe.Pointer) bool { return *(*string)(p) == *(*string)(q) }  有了这些基础的hash func与 equal func，再复杂的结构体也可以按字段递归计算hash与相等比较了。那我们再来看一下，当访问map[key]时，其实现对应在runtime/hashmap.go中的mapaccess1函数:
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) // 1 m := uintptr(1)&amp;lt;&amp;lt;h.B - 1 b := (*bmap)(add(h.buckets, (hash&amp;amp;m)*uintptr(t.bucketsize))) // 2 ... top := uint8(hash &amp;gt;&amp;gt; (sys.PtrSize*8 - 8)) if top &amp;lt; minTopHash { top &#43;= minTopHash } for { for i := uintptr(0); i &amp;lt; bucketCnt; i&#43;&#43; { ... k := add(unsafe.Pointer(b), dataOffset&#43;i*uintptr(t.keysize)) if alg.equal(key, k) { // 3 v := add(unsafe.Pointer(b), dataOffset&#43;bucketCnt*uintptr(t.keysize)&#43;i*uintptr(t.valuesize)) ... return v } } ... } }  mapaccess1的代码还是比较多的，简化逻辑如下（参考注释上序列）：
 调用key类型的hash方法，计算出key的hash值 根据hash值找到对应的桶bucket 在桶中找到key值相等的map的value。判断相等需调用key类型的equal方法  到现在我们也就有了初步了解，map中的key访问时同时需要使用该类型的hash func与 equal func，只要key值相等，当结构体即使不是同一对象，也可从map中获取相同的值，例如：
m := make(map[interface{}]interface{}) m[_key{}] = &amp;quot;value&amp;quot; if v, ok := m[_key{}];ok { fmt.Println(&amp;quot;%v&amp;quot;, v) // output: value }  参考：
[1] https://blog.golang.org/go-maps-in-action
[2] https://golang.org/ref/spec#Comparison_operators
</content>
    </entry>
    
     <entry>
        <title>Go VIM开发环境</title>
        <url>http://lanlingzi.cn/post/technical/2016/0903_vim/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>vim</tag>
        </tags>
        <content type="html"> 背景 个人最近一直使用VSCode&#43;Go插件来开发Go代码，虽然也觉得VSCode是目前最好用的Go的开发工具，但还是对VIM有点不可割舍，对我来说原因有三：
 VIM可以在控制台使用，适合远程登陆到Linux进行代码调试修改 配合Tmux使用，开启多个Pane各司其职，不同Pane之间快速切换 有Tagbar，团队内代码串讲，能先看出每个文件的大纲，代码跳转也非常方便  截图 第一张是自己截的，后两张是使用各插件官方的：
插件 我配置VIM主要用于Go语言开发，所以对VIM的配置是主要是集中于代码编写，Go语言的代码提示，格式化等。使用了如下主要插件:
Plugin &#39;honza/vim-snippets&#39; &amp;quot;快速插入代码片段snippets Plugin &#39;scrooloose/nerdtree&#39; &amp;quot;文件浏览，文件树目录 Plugin &#39;scrooloose/nerdcommenter&#39; &amp;quot;快速加减注释 Plugin &#39;scrooloose/syntastic&#39; &amp;quot;代码错误检测，其它应该也类似 Plugin &#39;Xuyuanp/nerdtree-git-plugin&#39; &amp;quot;Git插件 Plugin &#39;majutsushi/tagbar&#39; &amp;quot;标签列表 Plugin &#39;kien/ctrlp.vim&#39; &amp;quot;文件搜索,杀手级,重新定义了编辑器打开文件的方式 Plugin &#39;vim-scripts/TaskList.vim&#39; &amp;quot;快速跳转到TODO列表 Plugin &#39;vim-scripts/SuperTab&#39; &amp;quot;Tab代码提示 Plugin &#39;fannheyward/rainbow_parentheses.vim&#39; &amp;quot;括号匹配高亮 Plugin &#39;tpope/vim-surround&#39; &amp;quot;快速加环绕符 Plugin &#39;tpope/vim-repeat&#39; &amp;quot;配合使用增强版命令重复 Plugin &#39;tpope/vim-sensible&#39; &amp;quot;基本的Vim设置 Plugin &#39;mhinz/vim-startify&#39; &amp;quot;更改开始界面的插件 Plugin &#39;fatih/vim-go&#39; &amp;quot;GO语言 Plugin &#39;bling/vim-airline&#39; &amp;quot;状态栏 Plugin &#39;junegunn/vim-easy-align&#39; &amp;quot;方便的按分隔符对齐,比如=号 Plugin &#39;ConradIrwin/vim-bracketed-paste&#39; &amp;quot;插入模式下粘贴内容，不会有任何变形 :set paste Plugin &#39;fholgado/minibufexpl.vim&#39; &amp;quot;多文件切换，也可使用鼠标双击相应文件名进行切换 Plugin &#39;SirVer/ultisnips&#39; &amp;quot;宏定义补全 Plugin &#39;Yggdroot/indentLine&#39; &amp;quot;缩进虚线 Plugin &#39;Shougo/neocomplete.vim&#39; &amp;quot;自动补全 Plugin &#39;Shougo/unite.vim&#39; &amp;quot;文件或Buffer列表 Plugin &#39;Lokaltog/vim-easymotion&#39; &amp;quot;快速移动,杀手锏，跳转到光标后任意位置 Plugin &#39;Raimondi/delimitMate&#39; &amp;quot;自动括号补全   vim-go：已把Go的开发工具大包大揽了，非常省事。可以通过运行:GoInstallBinaries来自行安装 neocomplete.vim：非常轻量的基于缓存的代码补全，vim-go中已集成gocode来做代码联想，并能与neocomplete配合使用。 unite.vim：又一个神器，使用类似于SublimeText与VSCode的Go to xxx(快捷键:CMD&#43;P/Ctrl&#43;Shift&#43;P)功能，能快速列出最使用打开文件，当前目录下文件，Buffer列表等。 tagbar：标签列表，需要ctags，而Go的各元素能正常展示，则需要依赖于gotags，vim-go中已集成。  分享 个人的VIM的配置，已放入在Github上，若有需要的朋友尽管拿去使用，有问题欢迎反馈。
GitHub地址：https://github.com/xtfly/xvim
</content>
    </entry>
    
     <entry>
        <title>入园家长沟通会</title>
        <url>http://lanlingzi.cn/post/stories/2016/0829_kid_garden/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>育儿</tag><tag>家庭</tag>
        </tags>
        <content type="html"> 时间真是过得太快，转眼儿子要上幼儿园了。昨天是第一次参加儿子的入园家长沟通会。
上幼儿园的意义 上幼儿园是小孩步入社会第一步，是融入世界的起点。脱离原生家庭才能独立成长，幼儿园有孩子同龄的伙伴，可以让孩子收获不同的体验；幼儿园也有专业的老师，可以让孩子快乐自由的探索自己，认识朋友，体验世界。
我平时的工作都比较忙，基本都是早七晚九，白天小孩要么是跟他奶奶，要么是跟他外婆。还好他妈妈是小学老师，晚上能投入一些时间与他相处。大家居住环境比较封闭，邻里来往不多, 小孩基本都是呆在家里的时间居多。他对家的依赖比较多。虽他平时也会经常去他妈妈工作的小学玩，但还是在大家的完全监控下。养孩子的最终目的是为了看着他们独立，幼儿园是教孩子独立的第一步，也是教家长放手的第一步。 幼儿园与家长的关系 现在的媒体会经常报道一些幼儿园的老师是怎么不负责的，同时家长也不太可能放心让孩子在外面受丁点的苦。在幼儿园只要有些风吹草动，就会造成冲突。作为家长，先要信任，再及时沟通。
诚然，当今的社会的幼儿园也是一个趋利机构，在知识学习上急功近利，拔苗助长。我个人是不太在乎小孩在幼儿园是否能学到多少知识，而是关心他过得快不快乐。非常反感把小学生的学习任务强加到幼儿园孩子身上的做法，孩子的天性就是玩，在玩的过程得到性格、情感、心智的成长才重要。
爸爸妈妈永远是孩子最重要的人，哪怕这个世界真的有一所完美的幼儿园，也永远不要把所有责任都扔给幼儿园。毕竟，对爸爸妈妈来说，自己的孩子独一无二，对孩子来说，自己的爸爸妈妈也独一无二。
孩子上幼儿园并不是不需要再管孩子，而是更需要花更多的时间去侧面了解孩子，关心孩子，教育孩子。幼儿园是一个小社会，不同的小朋友来自不同的家庭。不同的家庭，有不同的价值观，不同的思维，不同的生活习惯。这些都会影响孩子的性格成长，生活习性。所以也需要家长投入更多的精力来关注孩子的成长。
家长如何做 小孩上幼儿园，小孩突然完全脱离了自己的控制，这尤其是对家长的一种考验。孩子的成长也需要家长一起成长，那家长如何做呢？总结起来，有五要，有五不要：
 五要：
 走路回家 保持平静 分享快乐 主动沟通 积极配合  五不要：
 甜水等待 刨根问底 迁就放纵 零食补偿 偏信偏听   </content>
    </entry>
    
     <entry>
        <title>Hexo NexT主题移植</title>
        <url>http://lanlingzi.cn/post/technical/2016/0828_hugo_next_theme/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>hugo</tag><tag>theme</tag>
        </tags>
        <content type="html"> 概述 我应该是一个喜欢折腾的技术党。从采用Hugo建静态blog以来，算上今天移植的这个，一共使用了三个主题：
第一个是修改自Hueman，它是一个Wordpress主题。第二个是修改自pacman，它是一个Hexo的主题。
这二个主题都是coderzh最早移植的，我只是在其上修改些布局，增加点功能，换个图片什么。这个过程让我弄清楚了Hugo中模板制作方法。
第三个则是从零开始，移植Github上人气最高的Hexo主题：NexT。正如你现在看到的，NexT是一款简洁又富有动感的主题，当前天我第一眼看到它时，就喜欢上它的风格。于是乎趁着周日，就开始NexT主题移植之旅。 功能  支持分类、标签索引 支持归档列表索引 支持分页栏 支持RSS 支持文章大纲（TOC） 支持分享，采用多说的分享 支持统计分析（目前支持百度统计，与REVOLEERMAPS） 支持评论系统（多说） 支持菜单定制 支持社区链接定制 支持外部链接定制 全配置化  分享 这个NexT主题是使用Hugo的模板语法，从零开始，经过差不多一天的时间折腾才完工。目前也应用到了我现在的这个Blog上，看起来还行:)。若有需要的朋友尽管拿去使用，有问题欢迎反馈。
GitHub地址：https://github.com/xtfly/hugo-theme-next
由于Hugo的模版引擎和Hexo有区别，部分Hexo的样式或功能暂时无法实现，它还没有像Hexo NexT那样能高度地配置定制。并且它也仅仅在自己的Blog简单测试过，可能并不一定完全适合您的定制，您可以根据需求调整。
注意 由于Hugo的.Summary只有70个字符，对于中文文章来说，实在是太短了，你可以在文档中任一地方增加HUGOMORE42来分割。
</content>
    </entry>
    
     <entry>
        <title>Go测试</title>
        <url>http://lanlingzi.cn/post/technical/2016/0824_go_testing/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go语言内置了测试框架，编写单元测试非常方便。
命名约定  测试代码位于以_test.go结尾的源文件中，一般与源码在同一个package中。
位于同一个package中的主要原因是：测试可以访问package中不可导出的变量，方法等元素。
 测试源码可以修改package名，带上_test结尾
修改的package名称，不需要再单独新建立目录，也与源码在一个目录下。参考标准库的bytes中的测试代码，方便使用被测试的元素，可以采用.来import测试的package：
package bytes_test import ( . &amp;quot;bytes&amp;quot; &amp;quot;io&amp;quot; ... )  
 以Test开头的功能测试函数
 以Benchmark开头的性能测试函数
 以Example开头的样例代码
func ExampleHello() { hl := hello() fmt.Println(hl) // Output: hello. }  示例函数无需接收参数，但需要使用注释的Output:标记说明示例函数的输出值，未指定Output:标记或输出值为空的示例函数不会被执行。go doc工具会解析示例函数的函数体作为对应包/函数/类型/类型方法的用法。
示例函数需要归属于某个包/函数/类型/类型的方法，具体命名规则如下：
func Example() { ... } // 包的示例函数 func ExampleF() { ... } // 函数F的示例函数 func ExampleT() { ... } // 类型T的示例函数 func ExampleT_M() { ... } // 类型T的M方法的示例函数 // 多示例函数 需要跟下划线加小写字母开头的后缀 func Example_suffix() { ... } func ExampleF_suffix() { ... } func ExampleT_suffix() { ... } func ExampleT_M_suffix() { ... }   测试类型 功能测试 功能测试函数以*testing.T类型为单一参数t，testing.T类型用来管理测试状态和格式化测试日志。测试日志在测试执行过程中积累，完成后输出到标准错误输出。
常用方法:
 测试预期不符，使用t.Error()或t.Errorf()记录日志并标记测试失败
func TestToTitle(t *testing.T) { for _, tt := range ToTitleTests { if s := string(ToTitle([]byte(tt.in))); s != tt.out { t.Errorf(&amp;quot;ToTitle(%q) = %q, want %q&amp;quot;, tt.in, s, tt.out) } } }  测试预期不符，使用t.Fatal()和t.Fatalf()跳出该测试函数
func TestUnreadByte(t *testing.T) { b := new(Buffer) b.WriteString(&amp;quot;abcdefghijklmnopqrstuvwxyz&amp;quot;) _, err := b.ReadBytes(&#39;m&#39;) if err != nil { t.Fatalf(&amp;quot;ReadBytes: %v&amp;quot;, err) } ... }  记录日志， 使用t.Log()和t.Logf()
func TestFowler(t *testing.T) { files, err := filepath.Glob(&amp;quot;testdata/*.dat&amp;quot;) if err != nil { t.Fatal(err) } for _, file := range files { t.Log(file) testFowler(t, file) } }  跳过某条测试用例，使用t.Skip()和t.Skipf()
func TestZip64(t *testing.T) { if testing.Short() { t.Skip(&amp;quot;slow test; skipping&amp;quot;) } const size = 1 &amp;lt;&amp;lt; 32 // before the &amp;quot;END\n&amp;quot; part buf := testZip64(t, size) testZip64DirectoryRecordLength(buf, t) }  并发执行测试用例，使用t.Parallel()标记
func TestStackGrowth(t *testing.T) { t.Parallel() var wg sync.WaitGroup // in a normal goroutine wg.Add(1) go func() { defer wg.Done() growStack() }() wg.Wait() ... }   性能测试 性能测试函数以接收*testing.B类型为单一参数b，性能测试函数中需要循环b.N次调用被测函数。testing.B类型用来管理测试时间和迭代运行次数，也支持和testing.T相同的方式管理测试状态和格式化测试日志，不一样的是testing.B的日志总是会输出。
 启用内存使用分析，使用t.ReportAllocs()
func BenchmarkWriterFlush(b *testing.B) { b.ReportAllocs() bw := NewWriter(ioutil.Discard) str := strings.Repeat(&amp;quot;x&amp;quot;, 50) for i := 0; i &amp;lt; b.N; i&#43;&#43; { bw.WriteString(str) bw.Flush() } }  停止/重置/启动时间计值，使用b.StopTimer()、b.ResetTimer()、b.StartTimer()
func BenchmarkScanInts(b *testing.B) { b.ResetTimer() ints := makeInts(intCount) var r RecursiveInt for i := b.N - 1; i &amp;gt;= 0; i-- { buf := bytes.NewBuffer(ints) b.StartTimer() scanInts(&amp;amp;r, buf) b.StopTimer() } }  记录在一个操作中处理的字节数，使用b.SetBytes()
func BenchmarkFields(b *testing.B) { b.SetBytes(int64(len(fieldsInput))) for i := 0; i &amp;lt; b.N; i&#43;&#43; { Fields(fieldsInput) } }  并发执行被测对象，使用b.RunParallel()和*testing.PB类型的Next()
func BenchmarkValueRead(b *testing.B) { var v Value v.Store(new(int)) b.RunParallel(func(pb *testing.PB) { for pb.Next() { x := v.Load().(*int) if *x != 0 { b.Fatalf(&amp;quot;wrong value: got %v, want 0&amp;quot;, *x) } } }) }   测试执行  在某一包下执行测试: go test 执行指定的包测试: go test $pkg_in_gopath 执行某一目录下以及子目录下所有测试: go test $pkg_in_gopath/... 执行包下某一些用例: go test -run=xxx，-run参数支持使用正则表达式来匹配要执行的功能测试函数名 执行包下性能测试: go test -bench=. 查看性能测试时的内存情况: go test -bench=. -benchmem 查看每个函数的执行结果: go test -v 查看覆盖率: go test -cover 输出覆盖率到文件: 增加参数-coverprofile，并使用go tool cover来查看，用法请参考go tool cover -help  测试工具 IO测试 testing/iotest包中实现了常用的出错的Reader和Writer:
 触发数据错误dataErrReader，通过DataErrReader()函数创建 读取一半内容的halfReader，通过HalfReader()函数创建 读取一个byte的oneByteReader，通过OneByteReader()函数创建 触发超时错误的timeoutReader，通过TimeoutReader()函数创建 写入指定位数内容后停止的truncateWriter，通过TruncateWriter()函数创建 读取时记录日志的readLogger，通过NewReadLogger()函数创建 写入时记录日志的writeLogger，通过NewWriteLogger()函数创建  HTTP测试 net/http/httptest包提供了HTTP相关代码的测试工具
 httptest.Server用来构建临时的Server，测试发送与接收HTTP请求 httptest.ResponseRecorder用来记录应答  黑盒测试 testing/quick包实现了帮助黑盒测试
 Check函数，测试的只返回bool值的黑盒函数f，Check会为f的每个参数设置任意值并多次调用
func TestOddMultipleOfThree(t *testing.T) { f := func(x int) bool { y := OddMultipleOfThree(x) return y%2 == 1 &amp;amp;&amp;amp; y%3 == 0 } if err := quick.Check(f, nil); err != nil { t.Error(err) } }  CheckEqual函数，比较给定的两个黑盒函数是否相等
func CheckEqual(f, g interface{}, config *Config) (err error)   测试框架 stretchr/testify是个人觉得目前最好的测试框架，相比标准库中testing包支持如下特性：
 Easy assertions Mocking HTTP response trapping Testing suite interfaces and functions  参考：
[1] https://golang.org/pkg/testing
[2] https://golang.org/pkg/testing/iotest
[3] https://golang.org/pkg/testing/quick
[4] https://golang.org/pkg/net/http/httptest
[5] https://github.com/stretchr/testify
</content>
    </entry>
    
     <entry>
        <title>Goroutine Local Storage</title>
        <url>http://lanlingzi.cn/post/technical/2016/0813_go_gls/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 背景 最近在设计调用链与日志跟踪的API，发现相比于Java与C&#43;&#43;，Go语言中没有原生的线程（协程）上下文，也不支持TLS（Thread Local Storage），更没有暴露API获取Goroutine的Id（后面简称GoId）。这导致无法像Java一样，把一些信息放在TLS上，用于来简化上层应用的API使用：不需要在调用栈的函数中通过传递参数来传递调用链与日志跟踪的一些上下文信息。
在Java与C&#43;&#43;中，TLS是一种机制，指存储在线程环境内的一个结构，用来存放该线程内独享的数据。进程内的线程不能访问不属于自己的TLS，这就保证了TLS内的数据在线程内是全局共享的，而对于线程外却是不可见的。
在Java中，JDK库提供Thread.CurrentThread()来获取当前线程对象，提供ThreadLocal来存储与获取线程局部变量。由于Java能通过Thread.CurrentThread()获取当前线程，其实现的思路就很简单了，在ThreadLocal类中有一个Map，用于存储每一个线程的变量。 ThreadLocal的API提供了如下的4个方法：
public T get() protected T initialValue() public void remove() public void set(T value)   T get():返回此线程局部变量的当前线程副本中的值，如果这是线程第一次调用该方法，则创建并初始化此副本。 protected T initialValue(): 返回此线程局部变量的当前线程的初始值。最多在每次访问线程来获得每个线程局部变量时调用此方法一次，即线程第一次使用get()方法访问变量的时候。如果线程先于get方法调用set(T)方法，则不会在线程中再调用initialValue方法。 void remove(): 移除此线程局部变量的值。这可能有助于减少线程局部变量的存储需求。如果再次访问此线程局部变量，那么在默认情况下它将拥有其 initialValue。 void set(T value)将此线程局部变量的当前线程副本中的值设置为指定值。许多应用程序不需要这项功能，它们只依赖于initialValue()方法来设置线程局部变量的值。  在Go语言中，而Google提供的解决方法是采用golang.org/x/net/context包来传递GoRoutine的上下文。对Go的Context的深入了解可参考我之前的分析：理解Go Context机制。Context也是能存储Goroutine一些数据达到共享，但它提供的接口是WithValue函数来创建一个新的Context对象。
func WithValue(parent Context, key interface{}, val interface{}) Context { return &amp;amp;valueCtx{parent, key, val} } type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } return c.Context.Value(key) }  从上面代码中可以看出，Context设置一次Value，就会产生一个Context对象，获取Value是先找当前Context存储的值，若没有再向父一级查找。获取Value可以说是多Goroutine访问安全，因为它的接口设计上，是只一个Goroutine一次设置Key/Value，其它多Goroutine只能读取Key的Value。
为什么无获取GoId接口  This, among other reasons, to prevent programmers for simulating thread local storage using the goroutine id as a key.
 官方说，就为了避免采用Goroutine Id当成Thread Local Storage的Key。
 Please don’t use goroutine local storage. It’s highly discouraged. In fact, IIRC, we used to expose Goid, but it is hidden since we don’t want people to do this.
 用户经常使用GoId来实现goroutine local storage，而Go语言不希望用户使用goroutine local storage。
 when goroutine goes away, its goroutine local storage won’t be GCed. (you can get goid for the current goroutine, but you can’t get a list of all running goroutines)
 不建议使用goroutine local storage的原因是由于不容易GC，虽然能获当前的GoId，但不能获取其它正在运行的Goroutine。
 what if handler spawns goroutine itself? the new goroutine suddenly loses access to your goroutine local storage. You can guarantee that your own code won’t spawn other goroutines, but in general you can’t make sure the standard library or any 3rd party code won’t do that.
 另一个重要的原因是由于产生一个Goroutine非常地容易（而线程通用会采用线程池），新产生的Goroutine会失去访问goroutine local storage。需要上层应用保证不会产生新的Goroutine，但我们很难确保标准库或第三库不会这样做。
 thread local storage is invented to help reuse bad/legacy code that assumes global state, Go doesn’t have legacy code like that, and you really should design your code so that state is passed explicitly and not as global (e.g. resort to goroutine local storage)
 TLS的应用是帮助重用现有那些不好（遗留）的采用全局状态的代码。而Go语言建议是重新设计代码，采用显示地传递状态而不是采用全局状态（例如采用goroutine local storage）。
其它手段获取GoId 虽然Go语言有意识地隐藏GoId，但目前还是有手段来获取GoId：
 修改源代码暴露GoId，但Go语言可能随时修改源码，导致不兼容
在标准库的runtime/proc.go（Go 1.6.3）中的newextram函数，会产生个GoId：
mp.lockedg = gp gp.lockedm = mp gp.goid = int64(atomic.Xadd64(&amp;amp;sched.goidgen, 1))  通过runtime.Stack来分析Stack输出信息获取GoId。
在标准库的runtime/mprof.go（Go 1.6.3）中，runtime.Stack会获取gp对象(包含GoId)并输出整个Stack信息：
func Stack(buf []byte, all bool) int { if all { stopTheWorld(&amp;quot;stack trace&amp;quot;) } n := 0 if len(buf) &amp;gt; 0 { gp := getg() sp := getcallersp(unsafe.Pointer(&amp;amp;buf)) pc := getcallerpc(unsafe.Pointer(&amp;amp;buf)) systemstack(func() { g0 := getg() g0.m.traceback = 1 g0.writebuf = buf[0:0:len(buf)] goroutineheader(gp) traceback(pc, sp, 0, gp) if all { tracebackothers(gp) } g0.m.traceback = 0 n = len(g0.writebuf) g0.writebuf = nil }) } if all { startTheWorld() } return n }  从文件名就可以看出，runtime/mprof.go是用于做Profile分析，获取Stack肯定性能不会太好。从上面的代码来看，若第二个参数指定为true，还会STW，业务系统无论如何都无法接受。若Go语言修改了Stack的输出，分析Stack信息也会导致无法正常获取GoId。
 通用runtime.Callers来给调用Stack来打标签
代码参考：https://github.com/jtolds/gls/blob/master/stack_tags_main.go#L43
 通过内联c或者内联汇编
go版本1.5，x86_64arc下汇编，估计也不通用
// func GoID() int64 TEXT s3lib GoID(SB),NOSPLIT,$0-8 MOVQ TLS, CX MOVQ 0(CX)(TLS*1), AX MOVQ AX, ret&#43;0(FP) RET   开源goroutine local storage实现 只要有机制获取GoId，就可以像Java一样来采用全局的map实现goroutine local storage，在Github上搜索一下，发现有两个：
 tylerb/gls
GoId是通过runtime.Stack来分析Stack输出信息获取GoId。
 jtolds/gls
GoId是通用runtime.Callers来给调用Stack来打标签
  第二个有人在2013年测试过性能，数据如下：
 BenchmarkGetValue 500000 2953 ns/op
BenchmarkSetValues 500000 4050 ns/op
 上面的测试结果看似还不错，但goroutine local storage实现无外乎是map&#43;RWMutex，存在性能瓶颈：
 Goroutine不像Thread，它的个数可以上十万并发，当这么多的Goroutine同时竞争同一把锁时，性能会急剧恶化。 GoId是通过分析调用Stack的信息来获取，也是一个高成本的调用，一个字：慢。  不管怎么样，没有官方的GLS，的确不是很方便，第三方实现又存在性能与不兼容风险。连jtolds/gls作者也贴出其它人的评价：
 &amp;ldquo;Wow, that&amp;rsquo;s horrifying.&amp;rdquo;
&amp;ldquo;This is the most terrible thing I have seen in a very long time.&amp;rdquo;
&amp;ldquo;Where is it getting a context from? Is this serializing all the requests? What the heck is the client being bound to? What are these tags? Why does he need callers? Oh god no. No no no.&amp;rdquo;
 小结 Go语言官方认为TLS来存储全局状态是不好的设计，而是要显示地传递状态。Google给的解决方法是golang.org/x/net/context。
参考：
[1] golang-nuts
[2] go-nuts-re-goroutine-local-storage-implementation
[3] jtolds/gls
[4] tylerb/gls
[5] 在golang中如何优雅地获取goroutineID？
</content>
    </entry>
    
     <entry>
        <title>理解Go Interface</title>
        <url>http://lanlingzi.cn/post/technical/2016/0803_go_interface/</url>
        <categories>
          <category>技术</category><category>笔记</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 概述 Go语言中的接口很特别，而且提供了难以置信的一系列灵活性和抽象性。接口是一个自定义类型，它是一组方法的集合，要有方法为接口类型就被认为是该接口。从定义上来看，接口有两个特点:
 接口本质是一种自定义类型，因此不要将Go语言中的接口简单理解为C&#43;&#43;/Java中的接口，后者仅用于声明方法签名。 接口是一种特殊的自定义类型，其中没有数据成员，只有方法（也可以为空）。  接口是完全抽象的，因此不能将其实例化。然而，可以创建一个其类型为接口的变量，它可以被赋值为任何满足该接口类型的实际类型的值。接口的重要特性是：
 只要某个类型实现了接口所有的方法，那么我们就说该类型实现了此接口。该类型的值可以赋给该接口的值。 作为1的推论，任何类型的值都可以赋值给空接口interface{}。  接口的特性是Go语言支持鸭子类型的基础，即“如果它走起来像鸭子，叫起来像鸭子（实现了接口要的方法），它就是一只鸭子（可以被赋值给接口的值）”。凭借接口机制和鸭子类型，Go语言提供了一种有利于类、继承、模板之外的更加灵活强大的选择。只要类型T的公开方法完全满足接口I的要求，就可以把类型T的对象用在需要接口I的地方。这种做法的学名叫做&amp;rdquo;Structural Typing&amp;ldquo;。 方法 Go语言中同时有函数和方法。一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。所有给定类型的方法属于该类型的方法集。
type User struct { Name string Email string } func (u User) Notify() error // User 类型的值可以调用接受者是值的方法 damon := User{&amp;quot;AriesDevil&amp;quot;, &amp;quot;ariesdevil@xxoo.com&amp;quot;} damon.Notify() // User 类型的指针同样可以调用接受者是值的方法 alimon := &amp;amp;User{&amp;quot;A-limon&amp;quot;, &amp;quot;alimon@ooxx.com&amp;quot;} alimon.Notify()  User的结构体类型，定义了一个该类型的方法叫做Notify，该方法的接受者是一个User类型的值。要调用Notify方法我们需要一个 User类型的值或者指针。Go调用和解引用指针使得调用可以被执行。注意，当接受者不是一个指针时，该方法操作对应接受者的值的副本(意思就是即使你使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作，而不是指针操作。
我们可以修改Notify方法，让它的接受者使用指针类型：
func (u *User) Notify() error  再来一次之前的调用(注意：当接受者是指针时，即使用值类型调用那么函数内部也是对指针的操作。
总结：
 一个结构体的方法的接收者可能是类型值或指针 如果接收者是值，无论调用者是类型值还是类型指针，修改都是值的副本 如果接收者是指针，则调用者修改的是指针指向的值本身。  接口实现 type Notifier interface { Notify() error } func SendNotification(notify Notifier) error { return notify.Notify() } unc (u *User) Notify() error { log.Printf(&amp;quot;User: Sending User Email To %s&amp;lt;%s&amp;gt;\n&amp;quot;, u.Name, u.Email) return nil } func main() { user := User{ Name: &amp;quot;AriesDevil&amp;quot;, Email: &amp;quot;ariesdevil@xxoo.com&amp;quot;, } SendNotification(user) } // Output: cannot use user (type User) as type Notifier in function argument: User does not implement Notifier (Notify method has pointer receiver)  上述代码是编译不过的，见Output，编译错误关键信息Notify method has pointer receiver。 编译器不考虑我们的值是实现该接口的类型，接口的调用规则是建立在这些方法的接受者和接口如何被调用的基础上。下面的是语言规范里定义的规则，这些规则用来说明是否我们一个类型的值或者指针实现了该接口：
 类型 *T 的可调用方法集包含接受者为 *T 或 T 的所有方法集 类型 T 的可调用方法集包含接受者为 T 的所有方法 类型 T 的可调用方法集不包含接受者为 *T 的方法  也就是说：
 接收者是指针 *T 时，接口的实例必须是指针 接收者是值 T 时，接口的实例可以是指针也可以是值  空接口与nil 空接口(interface{})不包含任何的method，正因为如此，所有的类型都实现了interface{}。interface{}对于描述起不到任何的作用(因为它不包含任何的method），但是interface{}在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。它有点类似于C语言的void*类型。
Go语言中的nil在概念上和其它语言的null、None、nil、NULL一样，都指代零值或空值。nil是预先说明的标识符，也即通常意义上的关键字。nil只能赋值给指针、channel、func、interface、map或slice类型的变量。如果未遵循这个规则，则会引发panic。
在底层，interface作为两个成员来实现，一个类型(type)和一个值(data)。参考官方文档翻译Go中error类型的nil值和nil。
import ( &amp;quot;fmt&amp;quot; &amp;quot;reflect&amp;quot; ) func main() { var val interface{} = int64(58) fmt.Println(reflect.TypeOf(val)) val = 50 fmt.Println(reflect.TypeOf(val)) }  type用于存储变量的动态类型，data用于存储变量的具体数据。在上面的例子中，第一条打印语句输出的是：int64。这是因为已经显示的将类型为int64的数据58赋值给了interface类型的变量val，所以val的底层结构应该是：(int64, 58)。我们暂且用这种二元组的方式来描述，二元组的第一个成员为type，第二个成员为data。第二条打印语句输出的是：int。这是因为字面量的整数在golang中默认的类型是int，所以这个时候val的底层结构就变成了：(int, 50)。
func main() { var val interface{} = nil if val == nil { fmt.Println(&amp;quot;val is nil&amp;quot;) } else { fmt.Println(&amp;quot;val is not nil&amp;quot;) } }  变量val是interface类型，它的底层结构必然是(type, data)。由于nil是untyped(无类型)，而又将nil赋值给了变量val，所以val实际上存储的是(nil, nil)。因此很容易就知道val和nil的相等比较是为true的。
进一步验证：
func main() { var val interface{} = (*interface{})(nil) if val == nil { fmt.Println(&amp;quot;val is nil&amp;quot;) } else { fmt.Println(&amp;quot;val is not nil&amp;quot;) } }  (*interface{})(nil)是将nil转成interface类型的指针，其实得到的结果仅仅是空接口类型指针并且它指向无效的地址。也就是空接口类型指针而不是空指针，这两者的区别蛮大的。
对于(*int)(nil)、(*byte)(nil)等等来说是一样的。上面的代码定义了接口指针类型变量val，它指向无效的地址(0x0)，因此val持有无效的数据。但它是有类型的(*interface{})。所以val的底层结构应该是：(*interface{}, nil)。
有时候您会看到(*interface{})(nil)的应用，比如var ptrIface = (*interface{})(nil)，如果您接下来将ptrIface指向其它类型的指针，将通不过编译。或者您这样赋值：*ptrIface = 123，那样的话编译是通过了，但在运行时还是会panic的，这是因为ptrIface指向的是无效的内存地址。其实声明类似ptrIface这样的变量，是因为使用者只是关心指针的类型，而忽略它存储的值是什么。
小结: 无论该指针的值是什么：(*interface{}, nil)，这样的接口值总是非nil的，即使在该指针的内部为nil。
接口变量存储的类型 接口的变量里面可以存储任意类型的数值(该类型实现了某interface)。那么我们怎么反向知道这个变量里面实际保存了的是哪个类型的对象呢？目前常用的有两种方法：
 comma-ok断言
value, ok = element.(T)，这里value就是变量的值，ok是一个bool类型，element是interface变量，T是断言的类型。如果element里面确实存储了T类型的数值，那么ok返回true，否则返回false。
 switch测试
switch value := element.(type) { case int: fmt.Printf(&amp;quot;list[%d] is an int and its value is %d\n&amp;quot;, index, value) case string: fmt.Printf(&amp;quot;list[%d] is a string and its value is %s\n&amp;quot;, index, value) ...  element.(type)语法不能在switch外的任何逻辑里面使用，如果你要在switch外面判断一个类型就使用comma-ok。
  接口与反射 反射是程序运行时检查其所拥有的结构，尤其是类型的一种能力。Go语言也提供对反射的支持。
在前面的interface{}与nil的底层实现已提到，在reflect包中有两个类型需要了解：Type和Value。这两个类型使得可以访问接口变量的内容，还有两个简单的函数，reflect.TypeOf和reflect.ValueOf，从接口值中分别获取reflect.Type 和reflect.Value。
如同物理中的反射，在Go语言中的反射也存在它自己的镜像。从reflect.Value可以使用Interface方法还原接口值:
var x float64 = 3.4 v := reflect.ValueOf(x) // Interface 以 interface{} 返回 v 的值。 // func (v Value) Interface() interface{} // y 将为类型 float64 y := v.Interface().(float64) fmt.Println(y)  声明：本文是收集网上一些关于Go语言中接口(interface)的说明，是一篇学习笔记，文中多处引用，参考文章列表在最后，可直接访问了解详情。
参考：
[1] Go 语言中的方法，接口和嵌入类型
[2] 详解interface和nil
[3] Go语言interface详解
</content>
    </entry>
    
     <entry>
        <title>理解Go Context机制</title>
        <url>http://lanlingzi.cn/post/technical/2016/0802_go_context/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 什么是Context 最近在公司分析gRPC源码，proto文件生成的代码，接口函数第一个参数统一是ctx context.Context接口，公司不少同事都不了解这样设计的出发点是什么，其实我也不了解其背后的原理。今天趁着妮妲台风妹子正面登陆深圳，全市停工、停课、停业，在家休息找了一些资料研究把玩一把。
Context通常被译作上下文，它是一个比较抽象的概念。在公司技术讨论时也经常会提到上下文。一般理解为程序单元的一个运行状态、现场、快照，而翻译中上下又很好地诠释了其本质，上下上下则是存在上下层的传递，上会把内容传递给下。在Go语言中，程序单元也就指的是Goroutine。
每个Goroutine在执行之前，都要先知道程序当前的执行状态，通常将这些执行状态封装在一个Context变量中，传递给要执行的Goroutine中。上下文则几乎已经成为传递与请求同生存周期变量的标准方法。在网络编程下，当接收到一个网络请求Request，处理Request时，我们可能需要开启不同的Goroutine来获取数据与逻辑处理，即一个请求Request，会在多个Goroutine中处理。而这些Goroutine可能需要共享Request的一些信息；同时当Request被取消或者超时的时候，所有从这个Request创建的所有Goroutine也应该被结束。 context包 Go的设计者早考虑多个Goroutine共享数据，以及多Goroutine管理机制。Context介绍请参考Go Concurrency Patterns: Context，golang.org/x/net/context包就是这种机制的实现。
context包不仅实现了在程序单元之间共享状态变量的方法，同时能通过简单的方法，使我们在被调用程序单元的外部，通过设置ctx变量值，将过期或撤销这些信号传递给被调用的程序单元。在网络编程中，若存在A调用B的API, B再调用C的API，若A调用B取消，那也要取消B调用C，通过在A,B,C的API调用之间传递Context，以及判断其状态，就能解决此问题，这是为什么gRPC的接口中带上ctx context.Context参数的原因之一。
Go1.7(当前是RC2版本)已将原来的golang.org/x/net/context包挪入了标准库中，放在$GOROOT/src/context下面。标准库中net、net/http、os/exec都用到了context。同时为了考虑兼容，在原golang.org/x/net/context包下存在两个文件，go17.go是调用标准库的context包，而pre_go17.go则是之前的默认实现，其介绍请参考go程序包源码解读。
context包的核心就是Context接口，其定义如下：
type Context interface { Deadline() (deadline time.Time, ok bool) Done() &amp;lt;-chan struct{} Err() error Value(key interface{}) interface{} }   Deadline会返回一个超时时间，Goroutine获得了超时时间后，例如可以对某些io操作设定超时时间。
 Done方法返回一个信道（channel），当Context被撤销或过期时，该信道是关闭的，即它是一个表示Context是否已关闭的信号。
 当Done信道关闭后，Err方法表明Context被撤的原因。
 Value可以让Goroutine共享一些数据，当然获得数据是协程安全的。但使用这些数据的时候要注意同步，比如返回了一个map，而这个map的读写则要加锁。
  Context接口没有提供方法来设置其值和过期时间，也没有提供方法直接将其自身撤销。也就是说，Context不能改变和撤销其自身。那么该怎么通过Context传递改变后的状态呢？
context使用 无论是Goroutine，他们的创建和调用关系总是像层层调用进行的，就像人的辈分一样，而更靠顶部的Goroutine应有办法主动关闭其下属的Goroutine的执行（不然程序可能就失控了）。为了实现这种关系，Context结构也应该像一棵树，叶子节点须总是由根节点衍生出来的。
要创建Context树，第一步就是要得到根节点，context.Background函数的返回值就是根节点：
func Background() Context  该函数返回空的Context，该Context一般由接收请求的第一个Goroutine创建，是与进入请求对应的Context根节点，它不能被取消、没有值、也没有过期时间。它常常作为处理Request的顶层context存在。
有了根节点，又该怎么创建其它的子节点，孙节点呢？context包为我们提供了多个函数来创建他们：
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) func WithValue(parent Context, key interface{}, val interface{}) Context  函数都接收一个Context类型的参数parent，并返回一个Context类型的值，这样就层层创建出不同的节点。子节点是从复制父节点得到的，并且根据接收参数设定子节点的一些状态值，接着就可以将子节点传递给下层的Goroutine了。
再回到之前的问题：该怎么通过Context传递改变后的状态呢？使用Context的Goroutine无法取消某个操作，其实这也是符合常理的，因为这些Goroutine是被某个父Goroutine创建的，而理应只有父Goroutine可以取消操作。在父Goroutine中可以通过WithCancel方法获得一个cancel方法，从而获得cancel的权利。
第一个WithCancel函数，它是将父节点复制到子节点，并且还返回一个额外的CancelFunc函数类型变量，该函数类型的定义为：
type CancelFunc func()  调用CancelFunc对象将撤销对应的Context对象，这就是主动撤销Context的方法。在父节点的Context所对应的环境中，通过WithCancel函数不仅可创建子节点的Context，同时也获得了该节点Context的控制权，一旦执行该函数，则该节点Context就结束了，则子节点需要类似如下代码来判断是否已结束，并退出该Goroutine：
select { case &amp;lt;-cxt.Done(): // do some clean... }  WithDeadline函数的作用也差不多，它返回的Context类型值同样是parent的副本，但其过期时间由deadline和parent的过期时间共同决定。当parent的过期时间早于传入的deadline时间时，返回的过期时间应与parent相同。父节点过期时，其所有的子孙节点必须同时关闭；反之，返回的父节点的过期时间则为deadline。
WithTimeout函数与WithDeadline类似，只不过它传入的是从现在开始Context剩余的生命时长。他们都同样也都返回了所创建的子Context的控制权，一个CancelFunc类型的函数变量。
当顶层的Request请求函数结束后，我们就可以cancel掉某个context，从而层层Goroutine根据判断cxt.Done()来结束。
WithValue函数，它返回parent的一个副本，调用该副本的Value(key)方法将得到val。这样我们不光将根节点原有的值保留了，还在子孙节点中加入了新的值，注意若存在Key相同，则会被覆盖。
小结 context包通过构建树型关系的Context，来达到上一层Goroutine能对传递给下一层Goroutine的控制。对于处理一个Request请求操作，需要采用context来层层控制Goroutine，以及传递一些变量来共享。
 Context对象的生存周期一般仅为一个请求的处理周期。即针对一个请求创建一个Context变量（它为Context树结构的根）；在请求处理结束后，撤销此ctx变量，释放资源。
 每次创建一个Goroutine，要么将原有的Context传递给Goroutine，要么创建一个子Context并传递给Goroutine。
 Context能灵活地存储不同类型、不同数目的值，并且使多个Goroutine安全地读写其中的值。
 当通过父Context对象创建子Context对象时，可同时获得子Context的一个撤销函数，这样父Context对象的创建环境就获得了对子Context将要被传递到的Goroutine的撤销权。
 在子Context被传递到的goroutine中，应该对该子Context的Done信道（channel）进行监控，一旦该信道被关闭（即上层运行环境撤销了本goroutine的执行），应主动终止对当前请求信息的处理，释放资源并返回。
  使用原则 Programs that use Contexts should follow these rules to keep interfaces consistent across packages and enable static analysis tools to check context propagation:
使用Context的程序包需要遵循如下的原则来满足接口的一致性以及便于静态分析。
 Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. The Context should be the first parameter, typically named ctx；不要把Context存在一个结构体当中，显式地传入函数。Context变量需要作为第一个参数使用，一般命名为ctx；
 Do not pass a nil Context, even if a function permits it. Pass context.TODO if you are unsure about which Context to use；即使方法允许，也不要传入一个nil的Context，如果你不确定你要用什么Context的时候传一个context.TODO；
 Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions；使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数；
 The same Context may be passed to functions running in different goroutines; Contexts are safe for simultaneous use by multiple goroutines；同样的Context可以用来传递到不同的goroutine中，Context在多个goroutine中是安全的；
  参考：
[1] https://blog.golang.org/context
[2] http://blog.golang.org/pipelines
[3] http://studygolang.com/articles/5131
[4] http://blog.csdn.net/sryan/article/details/51969129
[5] https://peter.bourgon.org/blog/2016/07/11/context.html
[6] http://www.tuicool.com/articles/vaieAbQ
</content>
    </entry>
    
     <entry>
        <title>为什么是Go</title>
        <url>http://lanlingzi.cn/post/technical/2016/0723_why_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>cloud</tag>
        </tags>
        <content type="html"> HW的执行力就是强，推广Go也是雷力风行，几乎目前是全员皆Go。作为一名其中的参与者，也知目前Go若大规模应用还是有很多的不成熟，风险也非常大。那为什么我司还是选择Go？也来谈谈我个人对为什么选择Go的认识，仅是个人拙见，不代表我司官方的观点。
背景 Go语言主创人员之是C语言与Linux的发明人，所以Go的语法在C的基础之上取众家之精华：
 主要继承了C(func, struct，指针) 包管理吸取自Java（package, import） 多态吸取自Python与Ruby(duck type) 并发吸取自Limbo(CSP模型)。   同时是一种多范式的编程语言，集众多编程范式之所长，并以自己独到的方式将它们融合在一起：
 面向过程（if，switch，for&amp;hellip;) 面向对象（部分支持）：封装（struct），继承（匿名组合），多态（隐式Interface，即duck type） 函数式（部分支持）：闭包，函数作为参数（入参，返回值）  Go语言打的组合拳:
 简单易用 vs Python 机器码性能 vs C/C&#43;&#43; 跨平台/标准库 vs Java 并发模型（goroutine/channel）vs Erlang 异步网络 vs Scala/Node.js 动态反射 vs Java 垃圾回收 vs Java  Go语言可能不是每一条都是No.1，但却是目前同时具备上述全部7点特性唯一语言，看似平衡中庸的组合拳往往威力强大。
而我司主要开发语言是C/C&#43;&#43;，Java，Python，可以说是若应用Go语言具有广泛的群众基础，同时Go语言兼具他们各自的一些优点，在不同的场景下，能一定的范围内可以代替他们。并且我司的程序员大多较底级，Go语言的简洁与工程化能可能大大提升产品研发效率与降低维护成本。
云计算 我司原是一个设备制造厂商，而不是一个软件开发厂商。但是云计算已正快速改变原有的生态，当软件定义一切，尤其是云计算的全面渗透，计算资源统一X86化。即使传统的网络设备也将网络功能虚拟化（NFV）。NFV化是趋势，若拒绝将是失去未来；只有及时拥抱，才能不被抛弃。
虚拟化/容器化显著的特点：
 不再依赖于专用硬件，跨平台跨硬件混合部署：
如传统的网卡直通，CPU绑定，内核零拷贝将在云计算下无法再发挥优势。而Go语言相比于C/C&#43;&#43;天生跨平台，引入内置Runtime，通过它来隔离与不同的系统调用。这让程序迁移到不同的OS或CPU架构成本非常低，程序只需要重新在目标平台上编译而已。
 物理资源更细粒度的分割，提高整体资源利用率：
Go语言相比于Java，在CPU、内存与磁盘大小占用方面相对比较低。尤其当前Docker等容器技术的兴起，细粒度的资源隔离。Go语言相比于Java动则上G的内存占用情况下，在资源上可能通过细粒度逻辑分割而达到充分灵活共享；而Go语言内置并发机制，并且Goroutine调度机制在设计上就充分考虑利用多核，让编写多核并发的程序变得更加的容易。
 快速上线开发与部署，缩短上线周期：
Go语言设计的一个主要目的是降代程序员的心智负担，设计哲学是大道至简，所以一开始就在可读性、模块化、编译速度、适合大型团队（工程优化）和语法简洁上下足了功夫。Go语言相比于Java与C/C&#43;&#43;，开发更简洁；内置丰富的标准库也能有效降低代码量。Go程序默认也是编译只是单个文件，减少了部署态的第三方依赖，这让应用上线部署非常容易。
 快速伸缩，故障隔离与自愈：
Go语言相比于Java与Python，不需额外的运行环境，编译为一个独立的执行文件；相对于C/C&#43;&#43;没有依赖动态库版本不一致的问题；Go语言程序相对于Java启动速度快，很适合于快速伸缩。而独立进程相比于Java中类Tomcat容器内多WebApp部署方式有更好的故障隔离；Go语言虽有异常（Panic），但可预知的错误建议采用error处理，引入了内置的error类型以及defer关键字来处理异常安全，这让程序员更容易写健壮的代码。
  在云计算环境下，只要是适合的场景产品（Go目前还不适合要求低时延，高实时的场景），如在面向管理控制、网络并发等领域，采用Go语言开发，用来代替部分C/C&#43;&#43;开发的系统应用；Java开发的网络或后端服务应用；Python开发的管理控制应用；可能极大提升产品的整体竞争力。
微服务 现在的应用程序规模越来越庞大，逻辑处理也是越来越复杂。在我司的电信领域，一个产品的研发也是动则几百号人的团队一起开发；系统上处理的数据规模，与接入的用户请求数也是几何级增加，在吞吐量、稳定性都会面临着极大的挑战；当前的业务尤其是面向移动终端用户的业务，需求变化快，业务不断推出与消亡，传统的单体架构根本无法适合频繁的变更，系统的可扩展性、定制性尤显得重要。当功能繁杂，结构混乱，以及人员变化等因素影响下，要解决这些问题，不得不在交付中不断地制定策略，演进架构：
随着云计算应用经验的不断积累，以及相关的工具链不断成熟，也伴随着微服务架构的出现。它通过将功能分解成多个独立的服务，以实现对解决方案或者复杂系统的解耦。微服务的诞生并非偶然:
 领域驱动设计指导我们如何分析并模型化复杂的业务； 敏捷方法论帮助我们消除浪费，快速反馈；持续交付促使我们构建更快、更可靠、更频繁的软件部署和交付能力； 虚拟化和基础设施自动化( Infrastructure As Code)则帮助我们简化环境的创建、安装； DevOps文化的流行以及特性团队的出现，使得小团队更加全功能化。这些都是推动微服务诞生的重要因素。  微服务通常有如下几个特征,也是与Go语言特征不谋而合：
 小：专注于做一件事情
小即是极多，这与Go语言遵循设计原则。保持简单性的方法就是：每种特性仅提供一种方法，减少重复、冗余，只提供一种方法做事情，把事情做到极致，这就是Go语言的原则。而微服务通常讲是两个Pizza能吃饱的团队来共用维护一个服务的代码。与”单一职责原则”类似，每个服务只做一件事情，并且把它做好。Go语言在语法特性简洁处理，编写相同的功能，相比于其它语言代码量很少。同时它提供高质量的标准库，让程序员减少对第三方框架选择与熟悉难题，让程序员更多的精力放在业务本身的逻辑上。
 独：运行在独立的进程中
当初接触Go语言时，发现它既然支持与C的调用，一直不太理解它为何不支持动态库（1.5版本部分支持）。但事实上，Go语言认为如果一项特性不带来显著的有益，那就不提供。其实动态库的版本当编译与运行时不一致导致程序崩溃一直是C/C&#43;&#43;开发的噩梦。Go编译单一执行文件，能一定程度缓和这个问题。另外Go一直追求生成代码优化，执行文件最小化。这也方便程序部署在Docker容器中，运行在一个独立的操作系统进程，拥有更好的故障隔离。
 轻：轻量级的通信机制
服务和服务之间通过轻量级的机制实现彼此间的通信。所谓轻量级通信机制，通常指基于语言无关、平台无关的这类协议，例如XML、JSON。Go语言的主要发力点之一就是网络编程，标准库内置了HTTP协议框架，同时也提供了对JSON、XML的序列化与序列化支持，结合它的Goroutine并发机制，开发一个Rest服务只须很少的代码。
 松：部署态与运行态松耦合
Go语言是一个强类型静态语言，可以把代码编译为本地机器指令。它的RUNTIME是会在编译时一起链接到执行文件中，这也就意味着我们不需要像JAVA那样装一个JVM。而且编译出的执行文件本身不依赖于其他动态库，完全可以做到轻松的发布。Go语言基于Channel来通讯，也会带来一定程序代码结构上的松耦合。
  当产品架构朝微服务架构演进时，Go语言语言特征与微服务不谋而合，采用Go语言在一定程度上会助力微服务架构实施与落地。单体应用拆分成众多微服务时，服务之间从传统的插件机制来获得扩展性，转化成分布式多进程通讯来扩展。Go语言在网络并发上的优势，使得微服务开发变得更为简单，性能上更有优势。
参考：
[1] 基于微服务架构，改造企业核心系统之实践
[2] Go在谷歌：以软件工程为目的的语言设计
[3] Why Go is not Good
[4] 说说Golang的使用心得
[5] go语言设计哲学
[6] 少即是极多 - Go 语言设计理念
</content>
    </entry>
    
     <entry>
        <title>Go语言不足</title>
        <url>http://lanlingzi.cn/post/technical/2016/0718_go_insufficient/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> 最近公司是在疯狂地推广Go语言，我也是推广小组成员。Go语言的确很多的优点，这里并不想表扬Go语言，而是说说它的不足。
生态不成熟 一个语言的流行，都有其背后的推动者。Go语言是由Google公司创建与推动。最近我司的高层也亲自拜访了Go语言的主创人员。Google称目前已有100&#43;的App从Java转向Go。Google内部主要有三大语言（C&#43;&#43;、Java、Python），之前对Go语言的公司内部的政治意义大于它的实际使用。近两年来，语言的战略地位凸显，不断地在推动Go语言的应用。
目前主要使用Go语言的公司是一些创业公司或互联网公司。而这些公司采用Go语言非技术的因素主要有：
 公司软件资产积累少，不存在切换其它语言成本，使用Go语言可以轻装上阵； 互联网公司的技术人员流动大，Go语言面向开发简化，招人容易，上手快；   采用Go语言的技术因素主要有：
 Go语言在语言级通过Goroutine与网络IO的Netpoller的封装，能大在简化高并发的网络应用开发，而互联网的应用都以HTTP、网络通讯应用为主； Go语言标准库丰富，能满足互联网应用的常用应用场景：不需要太多的业务逻辑，偏网络接入；  Go当前很多的第三方开源框架，库都是最近一到两年内才诞生的，并且后面没有相应的大公司支撑，个人或小团体的维护的项目居多。这些框架，库的成熟需要时间来锤炼与稳定。
动态扩展机制不成熟 对于编译型静态语言，需要有一种机制来支持动态扩展。C/C&#43;&#43;是通过动态库来扩展，Java是支持Class动态加载，或基于JVM平台的其它脚本语言互通。Go语言长期没有支持动态库，Go语言的创始人曾明确表态：
 动态库的存在是一个系统的设计Bug
 但是在Go1.5版本又加入了动态库支持，对动态库支持采用一定的妥协，这也说明它确有它的应用场景。但目前只支持：Linux/AMD64，ARM平台（cgo·golang/go Wiki,WindowsDLLs·golang/go Wiki）。同时支持也是有限制：
 Go语言代码，可以生成动态库给C代码调用，也可能给Go代码调用，但他们使用也有区别，参考：Go1.5生成动态库 不支持运行时在代码中动态加载库  目前可行的解决方案：
 生成C语言动态库：通过动态加载生成C语言动态库，实现动态扩展，一个进程中，运行了多个“Go世界”（Go的Runtime）
 这需要GCC编译器，所以严格来说并不支持Win下的纯DLL动态库（cywin之类的gcc没有验证过）  嵌入脚本语言，实现功能逻辑的动态扩展。
 目前开源项目已有纯Go实现的Lua VM，也有通过CGo绑定C的Lua。也有开源项目通过Cgo绑定支持Python,Ruby等； 自创脚本脚本，或DSL脚本，采用Go来实现脚本解释。但如果对性能要高要求，需要支持对脚本的JIT，这是相当有难度，目前也未见有解决方案。  实现基于通信机制的插件模式
 类似于VScode的语言服务插件机制，参考：通用语言协议 这本质是进程间的通讯，并不传统意义上的插件扩展机制。   不支持泛型 泛型是目前高级语言最常见的语言基础，Java1.5采用擦除法的泛型（并不像C&#43;&#43;一样的Template技术）也解放了不少生产力，能大大减少相似的代码。而Go语言官方团队相对是“民主集中制”，很难听取社区的意见，认为这个总是不紧急，并且他们也没有找到满意的实现方式（C&#43;&#43;/Java实现方式都不让他们满意：C&#43;&#43;是编译期间展示，生成不同的代码，对编译速度与生成文件大小都有影响；而Java是擦除法，只是语法糖，生成Bytecode变成Object对象，并没有本质变化）。
从目前来看，Go语言在1.0规范发布之后，语法特性几乎没有什么变化，围绕是性能优化与跨平台支持。至少在Go2.0之前，极可能不会引入这个语言特性。
目前可行的解决方案
 interface{}
 类似于C的void*，Java的Object，但这会增加代码的可读性差与安全危险，又与Go的简单哲学不相符  Go generate
 参考：Golang generate 草案  Go泛型编程库：gen
 gen 项目目的是为 Go 语言带来了类似泛型的函数，灵感来自 C# 的 LinQ 和 JavaScript 的 Array methods 以及 underscore 库。操作包括过滤、分组、排序等等。   Goroutine性能陷阱 Goroutine简化了并发编程，但它并不能消除并发问题（资源竞争，原子性操作），只是把线程的调度预置到了它的Runtime中，让上层应用代码变得很少。它的坑也主要体现在它的调度不可控制上。
下面阻塞不会创建新的调度线程：
 网络IO阻塞 Channel阻塞 Sleep，同步锁阻塞 基于底层系统异步调用的Syscall  下面阻塞会创建新的调度线程：
 磁盘IO阻塞 CGo方式调用C语言动态库中的调用IO或其它阻塞  这些情况下会导致线程数量爆涨，从而导致系统性能下降，而Goroutine通过go func就能产生一个Goroutine，犯错的成本低，容易被滥用。这需要开发人员熟悉Goroutine内部机制，并小心地避开这些坑。期待Go官方将来能重点解决这些问题。
参考：
[1] goroutine背后的系统知识
[2] golang的goroutine是如何实现的
[3] goroutine与调度器
</content>
    </entry>
    
     <entry>
        <title>Go语言在线书籍收集</title>
        <url>http://lanlingzi.cn/post/technical/2016/0717_go_book/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Effective Go 在线阅读：
 http://www.hellogcc.org/effective_go.html  Go语言圣经 Go语言圣经，《The Go Programming Language》 中文版本  项目主页：http://github.com/golang-china/gopl-zh 项目主页：http://bitbucket.org/golang-china/gopl-zh 原版官网：http://gopl.io   在线阅读：
 http://gopl-zh.b0.upaiyun.com/ http://docs.ruanjiadeng.com/gopl-zh/ http://shifei.me/gopl-zh/ http://2goo.info/media/html/gopl-zh-gh-pages/ http://docs.plhwin.com/gopl-zh/  Go Web 编程 Go Web 编程，《Build Web Application with Golang》国内首个讲解Go Web编程的在线书籍。 在线阅读：
 English 中文  雨痕学习笔记 在线下载：
 https://github.com/qyuhen/book  The way to Go 《The Way to Go》中文译本，中文正式名《Go入门指南》
在线阅读：
 https://github.com/Unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md  Network Programming with Go 在线阅读：
 https://jannewmarch.gitbooks.io/network-programming-with-go-golang-/content/index.html </content>
    </entry>
    
     <entry>
        <title>Pandoc&#43;Mardown生成Web Slide</title>
        <url>http://lanlingzi.cn/post/notes/2016/0716_pandoc_md_ppt/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Markdown</tag><tag>Slide</tag>
        </tags>
        <content type="html"> 背景 在我司PPT被称为胶片。一层层的汇报都是胶片承载，胶片也是做得非常漂亮。像我所在领域，架构师主要产出也是胶片，俨然无胶片就无架构。一方面个人非常羡慕胶片写得好（内容与外观）的人，另一方面觉得像使用MS的PowerPoint几乎要把一半的精力放在外观而不是内容上。甚至感觉到为了一个格式、一个颜色，调整都需要老半天时间。大家的胶片都做得漂亮，而你不可能也就只草草准备，尤其是给领导的胶片，人在江湖，身不由已。但做一名技术人员，内心还是比较抵触形式大于内容的胶片。昨天，一名同事给我展示了一个由Markdown生成Slide，给人感觉是耳目一新。
Markdown是一种内容与形式的分享的轻量级标记语言，受到越来越多的人喜欢，只要只简单的文本编辑器，都能书写文本内容。那有什么工具能快速方便地生成Slide呢。Markdown本身是为了方便输出到HTML格式。而HTML&#43;CSS&#43;JS是一个开放的，可扩展的技术。自然Markdown也可以通过工具生成像PPT一样可以上下翻页的HTML Slide，同样借助CSS与JS的结合，Slide一样可以做得像PPT一样格式漂亮，动作酷炫。 Pandoc Pandoc 则是一款非常优秀的开源文本格式转化神器。Markdown转换为HTML Slide也自然不在话下。Pandoc是由Haskell开发，Pandoc作者John MacFarlane一位来自美国加州大学伯克利分校的哲学教授。Haskell是一种函数式编程语言。而文本格式转换，看似简单，其实非常麻烦。Haskell干这脏活、累活的最恰当选择，Pandoc也的确成功了，并已成功在短期内构建一个完整的生态链。
安装 个人PC使用的Macbook，所以安装比较简单：
$ brew install pandoc  检验 $ pandoc --version pandoc 1.17.1 Compiled with texmath 0.8.6.3, highlighting-kate 0.6.2. Syntax highlighting is supported for the following languages: abc, actionscript, ada, agda, apache, asn1, asp, awk, bash, bibtex, boo, c, changelog, clojure, cmake, coffee, coldfusion, commonlisp, cpp, cs, css, curry, d, diff, djangotemplate, dockerfile, dot, doxygen, doxygenlua, dtd, eiffel, elixir, email, erlang, fasm, fortran, fsharp, gcc, glsl, gnuassembler, go, hamlet, haskell, haxe, html, idris, ini, isocpp, java, javadoc, javascript, json, jsp, julia, kotlin, latex, lex, lilypond, literatecurry, literatehaskell, llvm, lua, m4, makefile, mandoc, markdown, mathematica, matlab, maxima, mediawiki, metafont, mips, modelines, modula2, modula3, monobasic, nasm, noweb, objectivec, objectivecpp, ocaml, octave, opencl, pascal, perl, php, pike, postscript, prolog, pure, python, r, relaxng, relaxngcompact, rest, rhtml, roff, ruby, rust, scala, scheme, sci, sed, sgml, sql, sqlmysql, sqlpostgresql, tcl, tcsh, texinfo, verilog, vhdl, xml, xorg, xslt, xul, yacc, yaml, zsh ......  可见，Pandoc支持多种语言的高亮显示，程序员不愁写PPT了。
样例 % Markdown &#43; Pandoc % lanlingzi % 2016-07-16 ## Web-based slideshow - is a slide show which can be played (viewed or presented) using a web browser - is typically generated to or authored in HTML, JavaScript and CSS code (files) - are generated from presentation software - offer templates allowing the slide show to be easily edited and changed. ## Features - Keyboard navigation - Slide transitions and animations - Auto-play/timed transitions - Displays a table of contents - Nested slides - Separate slide notes for the speaker - Full screen support, with automatic text and images resizing to fit full screen - .....  Pandoc对分级标题、列表、插入图片等标准的Markdown语法均被支持，和平常用Markdown记笔记写博客无异。在文本开头需要包含三行以%打头的元信息：标题、作者和日期。
默认情况下每个二级标题是一张独立的幻灯片，所以，注意把每个二级标题下的内容控制在适当的长度。列表的显示效果可以人为设定，例如在幻灯片演示的时候逐条渐入。也可以直接在文本中嵌入HTML，用于显示Markdown等标记语言不支持的表格，或控制字体大小，以及进行其他更加复杂的排版。当然，如果用到的HTML标签过多，这不是Markdown这些轻量级标记语言的错，也许是做幻灯片的方式出了问题。因为演示本身要传达的是内容，复杂的排版没有任何意义。
命令 $ pandoc -s -i -t slidy demo.md -o demo.html  其中-t slidy是生成Slide采用样式框架，目前Pandoc包含了对五种HTML Slide框架的支持:
 DZSlides Slidy S5 Slideous revealjs  其中-i表示渐进显示，即控制列表的显示效果（逐条渐入）。
后记 采用Pandoc把Markdown转化为Slide也不是万能的。受限于Markdown的标签表达能力，其中的表格、复杂公式、多国语言、上下标、交叉引用、图表对齐较多的场合，它并不适合。使用Pandoc，只是喜欢Slide的样式，不用去辛辛苦苦的做PPT， 也有PPT的展示效果，何乐而不为呢？
</content>
    </entry>
    
     <entry>
        <title>Goroutine陷阱</title>
        <url>http://lanlingzi.cn/post/technical/2016/0703_goroutine/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag>
        </tags>
        <content type="html"> Go在语言层面通过Goroutine与channel来支持并发编程，使并发编程看似变得异常简单，但通过最近一段时间的编码，越来越觉得简单的东西，很容易会被滥用。Java的标准库也让多线程编程变得简单，但想当初在公司定位Java的问题，发现很多的同学由于没有深入了解Java Thread的机制，Thread直接New从不管理复用，那Goroutine肯定也要面临这类的问题。
Goroutine泄漏问题 Rob Pike在2012年的Google I/O大会上所做的“Go Concurrency Patterns”的演讲上，说道过几种基础的并发模式。从一组目标中获取第一个结果就是其中之一。 func First(query string, replicas ...Search) Result { c := make(chan Result) searchReplica := func(i int) { c &amp;lt;- replicas[i](query) } for i := range replicas { go searchReplica(i) } return &amp;lt;-c }  在First()函数中的结果channel是没缓存的。这意味着只有第一个goroutine返回。其他的goroutine会困在尝试发送结果的过程中，如果你有不止一个的重复时，每个调用将会泄露资源。为了避免泄露，你需要确保所有的goroutine退出。一个不错的方法是使用一个有足够保存所有缓存结果的channel。
func First(query string, replicas ...Search) Result { c := make(chan Result,len(replicas)) searchReplica := func(i int) { c &amp;lt;- replicas[i](query) } for i := range replicas { go searchReplica(i) } return &amp;lt;-c }  另一个不错的解决方法是使用一个有default情况的select语句和一个保存一个缓存结果的channel。default情况保证了即使当结果channel无法收到消息的情况下，goroutine也不会堵塞。
func First(query string, replicas ...Search) Result { c := make(chan Result,1) searchReplica := func(i int) { select { case c &amp;lt;- replicas[i](query): default: } } for i := range replicas { go searchReplica(i) } return &amp;lt;-c }  你也可以使用特殊的取消channel来终止workers。
func First(query string, replicas ...Search) Result { c := make(chan Result) done := make(chan struct{}) defer close(done) searchReplica := func(i int) { select { case c &amp;lt;- replicas[i](query): case &amp;lt;- done: } } for i := range replicas { go searchReplica(i) } return &amp;lt;-c }  为何在演讲中会包含这些bug？Rob Pike仅仅是不想把演示复杂化。这么做是合理的，但对于Go新手而言，可能会直接使用类似代码，而不去思考它可能有问题。
Goroutine Race问题 Go语言支持函数中定义函数，看下一个例子：
func saveRequest(request *Request) { …. go func() { request.Users = []{1,2,3} … db.Save(request) } }  很多情况下，由于程序员对goroutine了解不够深入，又由于goroutine使用很容易。为了性能，很容易把一个同步函数变成异步函数，但这违背了go”不要通过共享内存来通信，相反应该通过通信来共享内存“的原则。即上述的例子中起了一个goroutine，并修改了request指针指向的对象。即使对request只读，也可能不是安全，因为你无法保证request指针不在其它goroutine中修改。
在本质上讲，goroutine的使用会增加了函数的危险系数，尤其是函数参数传递指针时。任何一个对象的操作，如果没有加上锁，当项目比较庞大时，可能不知道这个对象是不是会引起多个goroutine竞争。
什么是goroutine race（竞争）问题？官网的文章 Introducing the Go Race Detect给出的例子如下：
package main import( &amp;quot;time&amp;quot; &amp;quot;fmt&amp;quot; &amp;quot;math/rand&amp;quot; ) func main() { start := time.Now() var t *time.Timer t = time.AfterFunc(randomDuration(), func() { fmt.Println(time.Now().Sub(start)) t.Reset(randomDuration()) }) time.Sleep(5 * time.Second) } func randomDuration() time.Duration { return time.Duration(rand.Int63n(1e9)) }  这个例子看起来没任何问题，但是实际上，time.AfterFunc是会另外启动一个goroutine来进行计时和执行func()。由于func中有对t(Timer)进行操作(t.Reset)，而主goroutine也有对t进行操作(t=time.After)。 这个时候，其实有可能会造成两个goroutine对同一个变量进行竞争的情况。
那什么才是goroutine的使用正确姿势，怎么理解“通过通信来共享内存”来避免Race问题？先看一个例子：
type SimpleAccount struct{ balance int } func NewSimpleAccount(balance int) *SimpleAccount { return &amp;amp;SimpleAccount{balance: balance} } func (acc *SimpleAccount) Deposit(amount uint) { acc.setBalance(acc.balance &#43; int(amount)) } func (acc *SimpleAccount) Withdraw(amount uint) { if acc.balance &amp;gt;= int(amount) { acc.setBalance(acc.balance - int(amount)) } else { panic(&amp;quot;杰克穷死&amp;quot;) } } func (acc *SimpleAccount) Balance() int { return acc.balance } func (acc *SimpleAccount) setBalance(balance int) { acc.balance = balance } type ConcurrentAccount struct { account *SimpleAccount deposits chan uint withdrawals chan uint balances chan chan int } func NewConcurrentAccount(amount int) *ConcurrentAccount{ acc := &amp;amp;ConcurrentAccount{ account : &amp;amp;SimpleAccount{balance: amount}, deposits: make(chan uint), withdrawals: make(chan uint), balances: make(chan chan int), } acc.listen() return acc } func (acc *ConcurrentAccount) Balance() int { ch := make(chan int) acc.balances &amp;lt;- ch return &amp;lt;-ch } func (acc *ConcurrentAccount) Deposit(amount uint) { acc.deposits &amp;lt;- amount } func (acc *ConcurrentAccount) Withdraw(amount uint) { acc.withdrawals &amp;lt;- amount } func (acc *ConcurrentAccount) listen() { go func() { for { select { case amnt := &amp;lt;-acc.deposits: acc.account.Deposit(amnt) case amnt := &amp;lt;-acc.withdrawals: acc.account.Withdraw(amnt) case ch := &amp;lt;-acc.balances: ch &amp;lt;- acc.account.Balance() } } }() }  上面的例子，SimpleAccount所有方法，当多goroutine操作是不安全的，而通过ConcurrentAccount封装，所有处理都统一通过channel通信到listen开启的goroutine，即只有一个goroutine能操作SimpleAccount中成员变量，那也就不会发现Goroutine Race问题。
</content>
    </entry>
    
     <entry>
        <title>Go/Java/C&#43;&#43;杂谈</title>
        <url>http://lanlingzi.cn/post/technical/2016/0702_go_cpp_java/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>cpp</tag><tag>java</tag>
        </tags>
        <content type="html"> 最近公司层面在摧广Go语言，我作为平台DU的首席编程，参加其中一些讨论。虽有5年&#43;的C&#43;&#43;开发经验，也有5年&#43;的Java开发经验，Go差不多也有2年时间。但个人仍觉得语言不是解决业务问题的银弹，换种语言也不可能就能提升开发效率。从语言层面来说，各种语言都有它们的优缺点，有不同的使用场景；而一个语言是否能大规模应用，往往是它的整个生态。个人虽比较喜欢Go，但从目前刚兴起的生态来看，也不敢在产品中大面积推广它。下面就从各语言概要来说说他们。
Go 首先要肯定的，Go语言在并发方面，goroutine与channel机制提供了语言层面的轻量组的并发机制，使得并发编程变得较为简单；在性能方面，由于它直接编译为机器码，提供了据说超过Java的运行性能（1.6版本在计算方面部分已超过Java）；在内存资源点用方面，相对Java或其它带有虚拟机的语言来说，具备明显的优势；在语法方面，继承了C的简洁，严谨的编码要求，以及吸收像Python动态语言特性，在对象构建，序列化提供简洁的表态方式，而这些代码可能占据10%~20%的代码量，尤其对于处理数据，配置，协议映射场景下，相比C/C&#43;&#43;在此方面笨拙，这就是动态语言为何让人着迷的地方。 这也是为什么Go语言一发布时就如此受人瞩目的关键原因，尤其是对于动态语言来说，这提供了动态语言所不具有的并发与性能优势。Go主创人员设计语言的目的是解决原来C/C&#43;&#43;大工程编译慢，维护困难的问题，作为其另外一个可选的角色。Pike 12年“大道至简”演讲稿中对此目标充满沮丧，引用其中一名话：
 Although we expected c&#43;&#43; programmers to see Go as an alternative, instead most Go programmers come from languages like Python and Ruby. Very few come from C&#43;&#43;.
 C&#43;&#43;的价值精髓在于：语言提供更加广泛的抽象，优雅和灵活的特性，而这些表达能力是硬件零成本的。而Go思考的方向显示不是零成本，至少不是零CPU成本，Go的主张更多考虑的是最小化程序员的工作量。
一个是硬件零成本的极致追求，一个是最小程序员的工作量，谁都替换不了谁最最价值的部分。Go无法同时符合两个目标，选择了动态语法与GC，就注定了选择开发效率，会为开发效率牺牲硬件效率，所以它走向另外一个方向，也就是目前Java所擅长的应用方向，尤其是目前的网络与WEB应用方面，这就需要有良好的标准库和生态系统支持。在标准方面，Go已提供了处理tcp/http/json/crypto/image等方面的标准库，它对网络的核心协议HTTP高并发支持，已经开发在抢Java的地盘了。
Go目前在分布系统，WEB应用，云计算云平台开始显示出优势，但是我们也必须看到它的不足，Go在创业公司与互联网企业应用越来眼越多，但在企业级还是未看到成功的案例。最重要的原因可能是其语言重要特性与工业工具还远未成熟，还有不少的断层或临时解决方案。但Go这两年来，在开源界发展速度，生态也会越来越成熟。在Go编译与Runtime也是在多个版本不断地优化与调整。Go于12年发布第一个版本，截止目前的1.7 beta版本发布，差不多是一年两个大版本，对于语言级，每年的版本发布可能会让大企业选择它犹豫再三，不敢应在极核心业务领域，担心它的不稳定带来商用风险不可控。
 Go已证明在动态语言需要性能，是作为Python与Ruby的理想候选者。在生产方面，其语言特性与生态系统还远没有像Python与Java成熟，目前阶段也是只在某些场景下的可选角色，从长期来看，在Google的战略支持下，肯定越来越蚕食Python与Java等带有GO与动态性的语言地盘。但在C/C&#43;&#43;擅长的领域，尤其是要求实时性，CPU密集计算的领域，短期Go还无法渗入。
 Java Java的成功，10年前靠Unix系统的SUN/IBM/Oracle的强国支撑让它在企业应用领域和WEB应用方面站稳了脚跟；而随后的10年，前半段是靠x86&#43;Linux带来的革命继续保持份额，后半段依托于Android的成功让其在步履蹒跚停止脚步后再一次登顶。二十多年，Java积累了最大的生态系统，可以说它是无说不包，已是一艘航空母舰，足已证明它的地址与成功。但是在其语言、库、框架与生态的复杂度，对技术的人员来说，Java已不太简单，已构成巨大的障碍。比如在Go擅长的并发，语言层面有synchronized机制，标准库的lock与notify，再到后来的concurrent库。基于JVM，Java又可以与其它语言具有良好的互操作性，如并发方面的Scala，可以选择Actor或Akka。
Java的世界轮子太多，你需要重复造轮子，也是Java成功的关键之一，历史沉淀下来让Java选择太多，也显著增加成本。深入后Java的学习成功可以比C&#43;&#43;更高，技术人员需要非常精心地组织框架与设计，否则各种复用的结果就是堆砌出一个异常臃肿的程序，其运行时对资源的消耗有时候会让你感到恐惧，而这是太多的基于Java所开发的平台被广泛诟病的重要原因之一。复用是一把双刃剑，是要量体裁衣还是一锅端，拿捏的尺度对于开发人员要求无疑是高昂的。
 Java已是无所不包，近十年基本都是排名最好的语言，积累最强大的生态。但其众多的框架，库复杂度也远不是让一个普通程序员能轻易掌握的，拿捏不好也将是一场灾难。
 C/C&#43;&#43; C/C&#43;&#43;在嵌入式和系统编程方面，依然占据差牢固地位，但是在并发、网络和应用编程等方面，一直处于讳莫如深的黑暗时代，语言本身未提供任何支持，而太单薄的标准库也毫无此方面的野心，C/C&#43;&#43;的标准库的规模恐怕始终无法比拟Java/Go，因为C/C&#43;&#43;不受任何一家大型商业公司控制，而是完全片处于“放养“状态。标准库需要得到大型商业公司持续的投资，这就是为什么C&#43;&#43;98标准库在13年后才获得一次大的更新。C/C&#43;&#43;需要封装各种硬件平台的系统API，而linux&#43;x86大面积击败Unix之前，众多的Unix系统更加剧了跨平台编程的难度。2000年左右出现跨平台的ACE库，还有Win平台上MFC库，都是糟糕难用，所以也没有大规模地成功，反而成了当时程序员的救命草，显然，这些技术已被历史所丢弃。而同时期Java原生提供了多线程，网络的标准库，以及基于JVM技术的跨平台支持，把Java推向了主流语言。
对于C/C&#43;&#43;程序员，有一个振奋人心的大事件，C&#43;&#43;11发布，相比C&#43;&#43;98，无论在语言和标准库上，都是一个极大飞跃。C&#43;&#43;之父说它是一门新语言，这不为过，同时如此多的顶尖C&#43;&#43;高手对boost库的贡献，它也是事实上的标准库，在网络、并发编程和一些基本应用方面，已经提供了性能优秀的库，极大地降低了此方面的开发难度。传统的C&#43;&#43;程序员，须尽快过渡到C&#43;&#43;11上，这需要编译环境的更新，而编译环境更新又会带来内存检测和性能分析方面最强力的工具。C/C&#43;&#43;曾经最广泛的内存越界与泄露总是，在GCC5.2版本与Intel最新CPU面前，内存飞踩可参被抓在第一现场，同时Intel提供的vtune性能分析工具，足也解决绝大多数的问题。
 传统C&#43;&#43;程序员，须尽快拥抱C&#43;&#43;11，新的标准库，Boost库，这会极大提高开发与维护效率。
</content>
    </entry>
    
     <entry>
        <title>第八届中国云计算大会简纪</title>
        <url>http://lanlingzi.cn/post/technical/2016/0519_cie_cloud/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag>
        </tags>
        <content type="html"> 第一次参加由电子协会举办的云计算大会，这届是在北京国家会议中心举行，据说这一届参加的人数有1.4W人。主题为“技术融合 应用创新”。云计算走到今天，已不在是什么新概念，在中国已大规格地使用起来。作为一名技术从业者，有幸参加，虽可能得不到干货，但可听一听，看一看，启发思路。
云计算是产业变革的推进器 第一场是来自工业和信息化部副部长怀（进鹏）部长致辞，领导果然是领导，带病撑着拐杖登台。整个过程是滔滔不绝地精彩分享，作一名学术官员，能脱稿是我发挥，说明他这个领域的真正专家。核心观点：
 云计算是解决方案，助推产业变革。给我们日常生活变化，也给我们产业带来新结构调整 云计算与大数据互为孪生兄弟，助推企业、行业和信息化解决方案起到了特别的支撑作用 云计算提供低成本便捷的IT资源，提供数字均衡发展，降低数字鸿沟，大幅度降低创业门槛   云计算的产业快速发展，带动硬件基础设施的发展，也带动了软件产业的发展，也带动了应用领域不同行业的发展,也迎来了新发展中的问题:
 技术方面的问题：面向工业互联网仍然有大量未知问题，在大数据分析和处理能力仍然需要发展；可靠性、安全性、系统能力方面不断加强；核心技术面对新的挑战需要不断地进行优化和完成。 标准方面的问题：通过推动标准，推动各类云计算系统互联互通，共享创造为更多应用有效服务的应用内容。 产业变革的总是：建立有效的人才培养和产业发展的环境，来推动产业有序、健康和快速的增长以推动产业结构的调整，同时建立有效的安全环境和有效的机制，以保障信息的安全、个人隐私安全和云数据交换交流当中所提供的安全保护机制。  点评：传统产业正面临云计算的冲击，谁先拥抱云计算，对产业信息化调整，谁就有可能先抢占新的机会。工业云、智能制造、工业互联网和工业大数据将推动产业发展和技术进步。
云计算挑战与机遇并存 第二场是IFIP主席Mike Hinchey致辞，英文不好，不太听懂。第三场是工信部信息化和软件服务业司司长谢少峰的演讲，全程都是念稿子，整个过程比较枯燥。开始是介绍我国云计算产业发展的现状，一堆的数字，没有太仔细听。后面是谈一下当前云计算发展面临的挑战：
 公有云的安全性和可靠性和可迁移性，行业对公有云的顾虑，政务、金融采购公有云服务的还面临着政策、标准等障碍。（PS：个人觉得不是什么问题，云计算也有细分市场，公有云，私有云，混合云都会发展） 产业规模小，技术产品服务仍需提高。（PS：这的确是一个总是，目前国内的云计算针对行业来说，没有形成成熟的解决方案，这也说明这一块的发展空间很大） 标准体系和认证测评体系不完备。（PS：中国的流氓公司太多，个人隐私数据保护法律法规有待健全啊）  云计算产业发展的未来趋势展望：
 中国制造2025年和互联网&#43;战略的不断推进，行业迫切需要通过云计算系统助推行业转型升级发展。（PS：行业转型会有阵痛） 开源技术推动云计算的发展。开源将是事实上的标准。（PS：对于我们这种屌丝程序员来说，参与开源也是提升自己的职业空间） 混合云将成为云服务业态的重要方向，私有云和公有云之间需要高效对接和无缝的切换。（PS：云集成将又是一片蓝海） 大数据的整合。云计算与大数据的深度融合，才能发挥更大的作用。（PS：马云早就说过已进入DT时代）  云计算这十年 这个分享个人觉得非常精彩，内容比较多。云计算已经成为我们互联网创新的一个主要的基础设施。计算理论和技术方法随着网络化、泛载网络智能化，形成新模式和新思维方式。面向未来我们基于物三元社会在整个信息社会推动之下的融合也需要我们云计算提供基本的技术和基础设施的支撑。云资源管理全面走向软件定义，我们可以对规模化的资源进行高效的管理，这是软件定义技术基于虚拟化和管理编程综合的体现，我们涉及到软件定义计算，软件定义网络，软件定义的存储。
过去云涌十年分成三个阶段：
 概念探索期：争论云到底是什么，主要的是一些专业实践 技术落地期：技术落地基本上形成共识开始呈现对云计算的大众化。 应用繁荣期：各个领域各个行业都会大量基于云计算搭建它的服务。  未来云计算发展趋势以及展望，三化一提升：
 应用领域化
在领域化基本里面能不能对这种各种的应用，我们提供面向领域的按需开发，面向特定的领域需求提供支持云涌开发运行的API解决方案及其他一体化的解决方案，支撑更多的应用，是云未来发展在应用繁荣面临非常重要的挑战。
云感知的软件服务正在成为一种新形态，我们可以看到软件服务提出已经很久了，在软件服务的早期，以前系统是紧偶合一体化的，SOA出现出现双偶合分布式应用，基于云所提供的服务或者微服务进行构建，感知云环境各种资源的变化，充分利用提供的各种API。
 资源泛载化
客户端软件资源、硬件资源、能耗资源，和服务端软件资源、硬件资源、能耗资源可以在两端合理分布，数据两端分布成熟，以及两端独特资源的共享，这样云端不仅是我们现在移动互联网支撑智能手机端，甚至包含物联网所承担的各种各样的联网设备，这样态势之下我们可以看到未来面临一定的挑战。存在万物互联的阶段，各种端上的设备能不能在云平台形成统一管理模式，这是云端面临的挑战。
 系统平台化
正在走向云操作系统的概念。操作系统是什么？向下管理资源，向上提供服务。单机操作系统基本构成，管理资源、管理作业、我们现在云管理系统主要管理云的资源，上面支撑各种操作系统运行，未来云操作系统除了管理云资源之外，还要管理云上面各种各样的作业，把操作系统的理念在整个云环境中间进行一次复制。
云操作系统可能面临这么一系列的挑战，一个是复杂多样的应用需求、传统应用可能怎么实现无缝的云化，支持基于互联网多终端的交互，云内海量资源的管理。
 服务质量的提升
服务质量的提升，用三个字概括，更高、更快、更强壮。高意味着支持高吞吐，需要聚合大规模资源提供海量处理能力实现高吞吐并发访问。快响应就是提供高吞吐的同时能够盘活降低请求的响应机制，能够降低我们所有请求的机制，也就是形成一种新的提升用户的体验，提升他的服务质量。更强壮体现在可靠可用，像云计算和规模复杂度的快速增长，要求更为全面质量保证，数据中心规模不断增长大规模部署成为事实，高吞吐的云计算环境大家看到增加的故障越来越多，故障损失很大。
  点评：三化一提升还是很有高度地概括性的。
云网将为运营商带来新的融合和创新 国内互联网的企业做云计算从08年就开始了，而运营商开始进入到云计算领域在2012年末到2013年开始，是后来者。十年前左右开始的趋势是，网络和内容服务商开始崛起，这让运营商与做SP的赚了不少钱。但互联网的发展，尤其是移动互联网的发展，但运营商变成了管道，OTT长尾业务都被其它赚走了运营商就开始坐不住了。
从分享的内容来看，中国电信的云计算来停留建设数据中心的阶段，做自己定位为云服务商，也就是提供基础设施供应商，帮助客户完成互联网&#43;。其中谈到行业系统云计算化面临两点挑战，我个人非常赞同：
 行业应用的IT系统的迁移，迁到云上面有非常大的工作量，甚至迁移的工作量比我们新建一套还要大。 需要一个服务型的工具，不能两套人马两套班子维护这么一个东西。还有一个层面是安全，安全变得异常作用。  应用和数据的特征，变得多样化。不同的应用当都移的云上去的时候，要求也不一致，服务无法提供标准化。未来面临都做混合云，混合云对于网络或者一体化部署的要求远远会超过原来我们单做一个私有云或者说我们仅仅是去面临一个相较而言可靠性、安全性没有那么高的公有云服务不同。业务的迁移服务变成了本身云服务其中的一个内容。理想的云服务商应该具备什么特征，五个方面：
 网络基础设施 产品研发 运营安全 营销和服务 定制和实施  当前运营商提供云服务的长板：
 在网络的基础设施，尤其是咱们的基于客户贴身营销和服务方面，运营安全方面有优势 原有的运营商的基础网络之上，继续把这个网络变得更强健。如通过CDN让业务流量都发生在它的身边，提升服务。又如去做基于冷数据、温数据以及热数据，根据目前的地理敏感的要求重新设计我们目前的资源部署。  运营商提供云服务的短板：
 在研发、和定制实施方面有短版。 除云资源的安全，数据的安全之外，以及网络安全方面。 可定制的服务，重新定制化服务自己作为的定制化一朵云。  点评：主要观点，运营商来讲依然应合作双融的驱动继产业链之力满足客户端到端的优势，产业合作方面应该做更多的一些事情。基础能力的合作伙伴，最终给客户提供一个针对性、整体性的服务。
</content>
    </entry>
    
     <entry>
        <title>Golang Web开发</title>
        <url>http://lanlingzi.cn/post/technical/2016/0515_go_web/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>go</tag><tag>web</tag>
        </tags>
        <content type="html"> 标准库[net/http] 采用Golang来开发Web应用或Rest接口的应用还是比较容易的。golang标准库就提供对Http协议的封装，主要涉及到net/http包，它包括了HTTP相关的各种函数、类型、变量等标识符。标准库的net/http是支持HTTP1.1协议，而目前Go1.6也支持HTTP2.0，包放在golang.org/x/net/http2,后续可能会移到标准库。
net/http库中主要涉及到如下几个类型与接口：
Request结构体 封装了HTTP的请求消息，其结构如下，可以很方便的地取出Method，Header与Body。  type Request struct { Method string URL *url.URL Proto string ProtoMajor int ProtoMinor int Header Header Body io.ReadCloser ContentLength int64 TransferEncoding []string Close bool Host string Form url.Values PostForm url.Values MultipartForm *multipart.Form Trailer Header RemoteAddr string RequestURI string TLS *tls.ConnectionState Cancel &amp;lt;-chan struct{} }  Response结构体 封装HTTP的响应消息，其结构如下，Response会关联Request。
 type Response struct { Status string StatusCode int Proto string ProtoMajor int ProtoMinor int Header Header Body io.ReadCloser ContentLength int64 TransferEncoding []string Close bool Trailer Header Request *Request TLS *tls.ConnectionState }  Handler接口 用于构建Response。应用开发就编写各种实现该Handler接口的类型，并在该类型的ServeHTTP方法中编写服务器响应逻辑。
 type Handler interface { ServeHTTP(ResponseWriter, *Request) }  ResponseWriter接口 即应用通过各种Handler操作ResponseWriter接口来构建Response。ResponseWriter实现了io.Writer接口，可以写入响应的Body，WriteHeader方法用于向HTTP响应信息写入状态码，但必须先于Writer方法调用。若不调用WriteHeader，使用Write方法会自动写入状态码http.StatusOK。
 type ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(int) }  ListenAndServe函数 启动HTTP服务，需要构建Server对象，并调用该Server的ListenAndServe方法，Server是HTTP服务的主控器。期结构定义如下，应用可以设置HTTP监听的地址，配置TLS，以及一些其它参数配置。
type Server struct { Addr string // TCP address to listen on, &amp;quot;:http&amp;quot; if empty Handler Handler // handler to invoke, http.DefaultServeMux if nil ReadTimeout time.Duration // maximum duration before timing out read of the request WriteTimeout time.Duration // maximum duration before timing out write of the response MaxHeaderBytes int // maximum size of request headers, DefaultMaxHeaderBytes if 0 TLSConfig *tls.Config // optional TLS config, used by ListenAndServeTLS TLSNextProto map[string]func(*Server, *tls.Conn, Handler) ConnState func(net.Conn, ConnState) ErrorLog *log.Logger disableKeepAlives int32 // accessed atomically. nextProtoOnce sync.Once // guards initialization of TLSNextProto in Serve nextProtoErr error }  Server需要关注如下几个方法，从方法名就可能知道它的用途。
func (srv *Server) ListenAndServe() error func (srv *Server) Serve(l net.Listener) error  ServeMux结构体 用于HTTP路由配置，其结构体定义如下：
type ServeMux struct { mu sync.RWMutex m map[string]muxEntry hosts bool // whether any patterns contain hostnames }  ServeMux有如下几个方法，用于配置HTTP与URL的映射关系。其实ServeMux也是实现ServeHTTP接口，其ServeHTTP方法完成了ServeMux的主要功能，即根据HTTP请求找出最佳匹配的Handler并执行之，它本身就是一个多Handler封装器，是各个Handler执行的总入口。
func (mux *ServeMux) Handle(pattern string, handler Handler) func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request)  ServeMux的路由功能是非常简单的，其只支持路径匹配，且匹配能力不强，也不支持对Method的匹配。net/http包已经为我们定义了一个可导出的ServeMux类型的变量DefaultServeMux。net/http包也提供了注册Handler的方法，它其实也是操作DefaultServeMux：
 调用http.Handle或http.HandleFunc实际上就是在调用DefaultServeMux对应的方法。 若ListenAndServe的第二个参数为nil，它也默认使用DefaultServeMux.  第三方库[fasthttp] 说到Golang的http，也不是只有标准库一家，Github也有人开源了fasthttp，并号称比net/http包快10倍，上面介绍的echo，底层同时支持net/http与fasthttp，其性能测试对比如下： 但是由于fasthttp的API与net/http完全不同，这使得无法重用目前基于net/http开发的路由，Handler等工具，这也让人在选择它时不得不面临考虑的问题。
工具或框架 由于Golang提供了标准库net/http，使得开发Go的Web框架变得很简单，在Github上可以搜索到各种不同层次的框架。
路由工具  gorilla/mux julienschmidt/httprouter  Handler工具  gorilla/handlers codegangsta/negroni  轻量框架  echo，底层支持绑定fasthttp，号称10倍快于其它框架。 goji，借鉴了Sinatra了思想。 martini，提供了丰富的中间件。 goin，借鉴了Martini，号称比它更快。 macaron，其思路来自martini，个人感觉API比martini方便很多。  全功能框架  web.go，其思路来自web.py。 beego，其思路来自Tornado, Sinatra与Flask框架。 revel，其思路完全来自Java的Play Framework。 </content>
    </entry>
    
     <entry>
        <title>Oracle Cloud Day见闻简纪</title>
        <url>http://lanlingzi.cn/post/technical/2016/0414_oracle_cloud_day/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Oracle</tag><tag>Cloud</tag>
        </tags>
        <content type="html"> 今天有幸参加Oracle举办的cloud day。Oracle从开始对云计算不敏感，到后来的大力投入，并购与产品整合，目前Oracle在云计算领域已涵盖IaaS，PaaS，SaaS。Oracle正借助于云计算，把帮助企业把传统的应用产品搬迁到云计算上。Oracle应用产品发发展战略三个核心阶段：
 无极限的应用产品支持：对所有目前使用Oracle OP部署方式的应用产品客户提供持续支持。 下一代“云”应用产品的开发以及战略并购：基于统一标准的PaaS平台，并购整合并开发下一代的，最优的基于云的产品。 切实可行的”云”之路：为客户提供各种服务和商务方案使客户以最小的投资风险采用Oracle云服务。  从上也可以看出Oracle在云计算野心，它虽相对起步晚，但它由于在传统IT领域的优势，通过整合基础设施，平台与中间件，以及社交资源，是在云计算领域内少数几个能针对企业各种业务提供一套完整的解决方案，涵盖如下领域：  客户关系管理：销售管理（Sales），市场管理（Marketing），服务管理（Service），电子商务（Commerce），社交媒体（Social） 供应链管理：产品创意与研发，供应认证与寻源，采购管理，物流管理，销售管理，计划管理，生产管理 财务及人力资源：财务管理，差旅报销，财务报告与分析，见血预算管理，项目管理，人力资源管理  Oracle的云应用具有如下特点：
 完整：一个云平台支持所有业务动作 一流：基于Oracle在企业领域的最佳实践 现代：数据驱动的业务执行与管理； 个性：个性化的“云”应用体验，提供SaaS（来ERP，HCM）来定制用户体验，提供PaaS来丰富与创建新的应用 集成：提供iPaas与集成能力来连接与协作已有资产 安全：大使级的安全性和兼容，支持传统的多租户的安全数据隔离，以及SaaS的便利  今天的cloud day也是从上述几个方面的展开的，我感兴趣的是他们的PaaS平台。确切地说，Oracle的PaaS是一个较泛的统称，今天主要介始的包括如下：
 应用开发云：提供代码配置库（git/svn）集成，支持直接从github同步代码，基于Maven等代码构建能力，有限地支持DevOps。 应用部署云：提供企业级的Java云服务，它是基于Weblogic的Java应用，每个WebLogic部署在一个虚拟机内。也提供支持其它JEE的应用环境，如scala, groovy, jypthon, jruby, 它们基于Docker容器部署。也支持对Node应用的部署。 数据库云：提供Oracle 11g与12c的数据库服务。 集成云：集成平台即服务(iPassS)，其中包括了Oracle集成云服务(ICS)、Oracle SOA云服务以及Oracle Cloud中的Oracle SOA套件与Oracle API Manager Cloud Service。 内容和协作云平台：个人感觉是就支持审批流程管理的文档管理云平台，像云盘一个共享文档，基于流程编排来文档审批。 移动云：提供统一的App开发MAF，针对多种平台，只需编写一个应用，可以运行在iOS、Android，支持本地或混合开发。  一天下来，感觉Oracle的垂直整合能力太强了，即使在PaaS领域，你也要什么，它就能给你什么。相比与我司的企业BG，在企业云整合能力与之相差太远了，不知要追赶多少年。可见预见，未来在云计算领域，公有云的领导者是AWS，私有云的领导者或许就是Oracle。IBM呢？Pure System与BlueMix在Oracle面前，感觉有点小打小闹了。
</content>
    </entry>
    
     <entry>
        <title>制作Archlinux Docker基础Image</title>
        <url>http://lanlingzi.cn/post/notes/2016/0410_archlinux_docker_images/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>Docker</tag>
        </tags>
        <content type="html"> 想在Mac本上使用Docker来运行Archlinux，家里安装的是长城宽带，无奈从docker hub下载Archlinux基础Image网速无法忍受。在国内的alauda.cn镜像中心搜索到有Archlinux基础Image，可能由于在Docker使用Archlinux国内人比较少，估计alauda.cn的CDN也没有缓存Archlinux基础Image，下载同样也是龟速，下载多次超时就放弃了。
正好个人还有一台老的笔记本安装了Archlinux，那何不自己做一个基础Image。说真的，还没有从零开始做过基础Image。在Docker hub搜索时发现有一个已有的脚本mkimage-arch.sh，于是把它做了些改造，制作过程记录一下：  源修改为国内的阿里Archlinux镜像源，这个速度快，超赞。 默认安装openssh软件，可以通过ssh来连接Container。 增加一个入口脚本run.sh，在此脚本主配置sshd，并启动sshd。  这个过程看似简单，不过还是遇到一些坑，毕竟Archlinux最小系统与自己已安装的Archlinux在使用sshd上有些区别，不得不反复修改脚本，Build Image与Run Container来验证：
 先是采用systemd来启动sshd，在run.sh使用systemctl enable sshd是OK的，但systemctl start sshd却无法启动报找不到文件。 是systemd的配置问题，也没有再去深究，放弃systemd，于是又直接使用/usr/bin/sshd -D来启动sshd，发现还启动失败报没有sshkey。 再使用ssh-keygen来生成系统的ssh_host_*_key。 终于sshd可以正常启动了，但使用ssh -p &amp;lt;port&amp;gt; root@&amp;lt;host&amp;gt;来连接Container，发现报无权限。 于是又得修改/etc/ssh/sshd_config，让root可以ssh登陆。  修改之后的脚本已提交到个人github上，可以在这里下载，使用方式如下：
 前提Archlinux中也安装了docker引擎
# pacman -S docker # systemctl enable docker # systemctl start docker  以root用户执行mkimage.sh脚本
# ./mkimage.sh  制作完成之后，使用docker images查看，生成一个名为archlinux的images
# docker images REPOSITORY TAG IMAGE ID CREATED SIZE archlinux latest dc54036acaa4 About an hour ago 337.2 MB  使用如下命令生成一个container，容器名为arch1
# docker run -d --name -arch1 -p 2222:22 archlinux /run.sh  使用ssh登陆验证，ssh -p &amp;lt;port&amp;gt; root@127.0.0.1，默认密码是123456。
 也可以使用命令docker exec -it arch1 bash来执行bash进入container操作。
 </content>
    </entry>
    
     <entry>
        <title>软件架构一些感想</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/0319_arch_diathesis/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag>
        </tags>
        <content type="html"> 软件架构 软件系统架构不只是软件本身架构，它是一个全系统、全网络的架构，从层次上由低到高分为：
 程序架构 系统架构 产品架构 生态、商业模式的架构  任何一个架构师，都是需要重点解决某方面的尖锐问题，同时避免在不合适的场景下，一种技术、一类框架或一种架构模式被滥用。架构就需要对整体框定好范围与约束。
架构设计不可能面面俱到，要解决或是发挥关键路径上的资源合理有效的最大价值。一个好的架构，不会随着时间或业务的变换，而需要进行大的破坏性的变化。 架构演进 从互联网公司的角度来看，他们认为架构都是在实际应用过程中的生长，一开始就设计和实施面面俱到的架构是不符合互联网快速交付的方式的，不要过度设计，谁也不知道业务上线后业务量将会是一个什么量。
架构的演进过程基本是围绕着性能，可靠性，扩展性，安全性，容灾展开。而对于可靠性，他们认为故障是不可能避免的，失败可能是常态，核心是如何地减少故障对用户或系统产生的影响范围。要提供有损服务，在故障的情况下，保证核心服务，可能放弃一些其它的服务。
相对于电信业务，互联网公司的业务更侧重于用户体验，极致的响应速度与简单易用的体验是第一个设计原则。而电信业务传统是更侧重于可靠性，甚至零无损。
架构师素质 架构师要能充分理解用户需要，充分协调和利用资源，满足需求； 具备基本的方法论，敏锐的观察力，善于对事物的抽象，提炼，简化。同时由于架构涉及到范围广，需要能快速学习新知识，善于学习关键点，不能由于过多限于细节而影响精力分配。
架构师很多时间是技术决策，需要能勇于应对变化，积极改变，敢于挑战。能够将方案落地，从解决系统的具体问题出发，能解决别人看不清的问题，也同时需要具有战略眼光，看得更远。
架构是上层建筑，影响深远，所以架构师需要善于识别和消除高风险，要广泛地吸收不同的意见，头脑风暴，风险识别、评估。对于风险进行排序，对于高风险点进行原型验证，切不可纯理论的架构，做成空中楼阁。
</content>
    </entry>
    
     <entry>
        <title>Grub引导Win10</title>
        <url>http://lanlingzi.cn/post/notes/2016/0313_grub_win10/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Archlinux</tag><tag>Win10</tag><tag>grub2</tag>
        </tags>
        <content type="html"> 个人有两台笔记本电脑，一台Sony安装Win10，平时给岳父上上网，自己使用比较少；另一台是MBA，自己在捣腾点代码，写点东西。今天心血来潮，想体验一个KDE的plasma 5，于是又来折腾Sony安装双系统。由于在使用MBA之前，也在Sony上安装过Archlinux，不过后来安装Win10，又把Archlinux删除了。这次的双系统，Linux还是选择Archlinux。
安装Archlinux按照Wiki一路下来很顺利，最后安装plasma，使用了一下，感觉也不够如此，可能是使用Mac OSX时间长了的原因。后面发现想回到Win10，发现Grub默认没有生成Win10的引导菜单。 我的Sony本本比较老，并不支持UEFI，所以系统选择安装Grub来引导。
# grub-install --target=i386-pc --recheck /dev/sda # grub-mkconfig -o /boot/grub/grub.cfg  采用grub-mkconfig生成的grub.cfg并没有引导Win10的菜单，解决方法如下。为了实现多系统启动，需要安装os-prober。进入到/etc/grub.d/目录下，发现存在30_os-prober文件，说明os-prober是安装的（pacman -S grub会自动安装）。
我的Windows分区是/dev/sda1。首先，找到Windows系统分区的UUID(bootmgr存放其上)。
# mount /dev/sda1 /mnt # grub-probe --target=fs_uuid /mnt/bootmgr 70B235F6749E84AE # grub-probe --target=hints_string /mnt/bootmgr --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1  接着，将下面的代码添加到/boot/grub/grub.cfg中，注意替换其中的fs_uuid，即70B235F6749E84AE。保存grub.cfg文件，重启系统，在gurb菜单就可以看到Windows 10 (loader) (on /dev/sda1)项了。选择，成功进入win10。
### BEGIN /etc/grub.d/30_os-prober ### menuentry &#39;Windows 10 (loader) (on /dev/sda1)&#39; --class windows --class os $menuentry_id_option &#39;osprober-chain-70B235F6749E84AE&#39; { insmod part_msdos insmod ntfs set root=&#39;hd0,msdos1&#39; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 70B235F6749E84AE else search --no-floppy --fs-uuid --set=root 70B235F6749E84AE fi parttool ${root} hidden- drivemap -s (hd0) ${root} chainloader &#43;1 } set timeout_style=menu if [ &amp;quot;${timeout}&amp;quot; = 0 ]; then set timeout=10 fi ### END /etc/grub.d/30_os-prober ###  注：后经验证，grub-mkconfig无法扫描到win10，是由于少安装了os-prober。
# pacman -S os-prober  参考：GRUB_(简体中文)
</content>
    </entry>
    
     <entry>
        <title>软件设计原则</title>
        <url>http://lanlingzi.cn/post/technical/2016/0306_arch_principle/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件设计</tag><tag>软件架构</tag><tag>设计原则</tag>
        </tags>
        <content type="html"> 软件也像人一样，具有生命力，从出生到死亡，会经历多种变化。软件架构设计也不是一蹴而就的，是不断地演进发展。但为了能较好的发展，在软件设计时需要考虑一些原则。
清晰原则：使用简洁接口，简单部件组合  编程的本质就是要控制复杂度，后期维护会占用大部分的时间。 降低整体复杂度，用清晰的接口把若干简单模块组合成一个复杂的系统。 对外隐藏细节，“不要与陌生人说话”。 多数问题局限天一个局部，不要影响到全局。  小结：本质是分而治之，复杂问题简单化，抽象框架，有序组全。 清晰原则：清晰胜于机巧  代码直白易懂，代码是给人看的，不是给机器看的。 维护代码的人，其中也你包括你自己，善待代码，就是善待自己。 不要了一点性能提升而引入复杂的算法，不要为了炫耀技能而编写晦涩难懂的代码。 复杂晦涩的代码是Bugs的温床，高昂的维护成本将抵消可怜的性能提升。  小结：代码简洁晚懂，谨慎引入复杂度。
简洁原则：设计简洁，降低复杂  复杂问题简单化是一个设计者的能力体现，避免不必要的使用问题复杂化的因素。 在市场导向下，在不良的架构上很容易堆砌花哨无用的新特性，导致软件趋于复杂。 在进度压力下，不会做出各种折中的个性与不和谐的新特性开发。  小结：过滤排序需求，追求稳定简洁。
组合原则：组合，接拼，编排  把复杂问题分解为一条程序处理链条。 程序之间可以通信，前者的输出是后者输入。 通信方式尽量采用简单协议，并且与语言无关。 组合程序之间无内部状态依赖，互相独立，处理链上下游不做假设，可替换。  小结：面向微服务的设计。
透明原则：设计与实现分离可见  设计简单，包括流程、数据结构、接口，在代码级别容易理解。 支行时刻可通过输出信息或者接口查询运行状态，可控制程序是否正确运行。 执行调试链、健康状态可跟踪、可分析。  小结：简单设计，简明实现，状态监控。
吝啬原则：除非别无它法，不要编写庞大的程序  程序庞大包括两个方面：程序体积大与程序复杂而维护困难。 模块和函数尺寸都有一个上限，比如单模板代码10K，单函数100L。 导致程序庞大的因素：先天设计不良，后天维护增加新特性。  小结：合理设计，考虑扩展性，对庞大保护警惕。
吝啬原则：有的放矢，按需分配资源  若可能，当一个事情发生时候再分配资源，而不是预先分配，初始化时静态分配最小资源，随着业务动态增加资源分配。 异步消息环境下，消息通信带来上下文切换，代价高昂。 必要时对消息数据合并，打包发送，减少对网络资源的消耗。 业务处理与消息发送分离，数据组织独立，统一打包发送。 控制并发实例的数据，分批处理，防止下游过载各实例之间的恶性竞争通信资源。  小结：按需分配资源，珍惜消息通信机会。控制并发，避免消息突发。
健壮原则：健壮源于透明与简洁  软件在超过设计者设想的意外场景下也能够运行良好。 Bugs是一种异常，复杂性和特殊处理都是Bugs的温床。 逻辑透明，接口简单有助于减少Bugs，即使出现Bugs也容易排除。 软件设计时要考虑异常输入，边界条件，和过载场景。 软件模块之间要处理流程上考虑能务匹配，流控，过载保护。  小结：简单透明，处理能力匹配；考虑异常场景，提升健壮性；匹配上下游处理能力，闭环控制为主，开环控制为辅。
表示原则：把知识叠入数据，简化统一处理逻辑  数据抽象建模，使用数据之间的关联关系来体现业务逻辑，或者领域知识，使得业务处理逻辑代码简单一致稳定。 可通过修改数据模型可以支持新业务，逻辑处理代码不用修改。  小结：领域模型驱动设计，数据数据提练来描述业务本质。
缄默原则：只输出有用的信息  保持沉默，良好的行为是默默地工作，决不唠唠叨叨，碍手碍脚，程序也是如此。 输出大量无用的信息会耗费资源，淹没重要信息，干扰维护人员定位问题。  小结：沉默是金，惜时亦如金。输出的信息是必要的，有用的，不重复的。
补救原则：异常时候，干净退出，输出详细信息  当程序出现异常时，输出必要信息，使用简单方法结束。 宽容地接受，严格地发送，提升程序的容错能力。 程序要么正确执行，要么响亮倒塌。  小结：看待这个问题一分为二，选择异常恢复方法要保证对用户的业务逻辑影响最小为基本原则。因此并不是说所有的异常都是进程退出重启，有时可以告警，事件通知，让管理员来处理，给出明确的修复方案说明。
经济原则：宁花机器一分钟，不花程序员一秒  对于一个问题，选择算法的时候宁愿选择一个简单，但可能是效率低一些的算法，也不要选择一个性能好但复杂度很高的算法。 硬件的进步来弥补性能的下降，换来的是程序简单可靠，维护成本低。  小结：辩证地看问题，选择简单，把复杂留给机器，解放程序员。
生成原则：避免手工Hack，让程序去生成代码  人最不适合干大量重复细致的工作，或多或少都会出错，因此导致Bugs。 与此相反，计算机最适合干规则明确，重复枯燥的工作，而且不会出错。 对于一个规则明确的工作，一种可行的办法就是编写一个我程序，根据输入规则生成代码，让生成的代码去解决问题。  小结：分析规则，能按照规则生成代码，可检查发现问题。
优化原则：雕琢前先有原型，跑之前先学会走  90%的功能能够实现，比100%功能永远不能实现要好得多。 先求可行，再求正确，最后求快。 原型可能有效地解决关键技术，保证系统是可以实现的。 让客户看到可以执行的原型，对需求的理解更为准确，防止做无用功。 过早优化是万恶之源，过早地优化会破坏程序结构，代码与数据结构杂乱无章；过早优化不清晰系统瓶颈，局部优化破坏整体优化。  小结：性能是设计出来，不是优化来出来。
多样原则：拒绝封闭和唯一  系统开放，只有开放，才能进步，才能得到最为广泛的验证。 开放，可扩展，用户可定制，符合实际需求和获到高可靠性。  小结：系统开发，留给用户定制空间，毕竟需求具体多样性，我们不能穷尽，最终只有用户才能准确理解自己的需求。
同源原则：避免重复，数据同源  重复的代码不仅仅是浪费，也是Bugs的滋生之地。 出现大段代码重复，说明开发者缺少对代码控制与抽象提炼能务，优秀的工程轻易不会在进度压力下让步。 数据重复危害更大，一则浪费存储空间，二则容易出现不一致。 在性能允许的情况下，尽量共享数据或者按需订阅，避免全量订阅。 如果上述条件不具备，那么采用数据同源技术和一致性校验来保证数据的一致性。  小结：拒绝重复，必须重复的时候考虑通过工具同源和一致性校验。
扩展原则：设计时着眼未来，未来总比想象来得快  对于一个一次性的程序来讲，架构和设计只会带来成本上升，复杂度提高，与性能的下降。 当开发一个支持多种产品的软件平台，其生命周期可能是十年以上。用户的需求是不断地变化，硬件环境也是不断地变化。 只有适应变化，不能拒绝变化，可扩展性是软件非功能属性中，在大部分情况下排在可靠性，高性能之前  小结：不对外界进行假设，这些假设在时间面前都是脆弱的。
扩展原则：给雪球寻找一个核心  雪球都有一个内核，尽管可能是一粒不起眼的小石头。 常说软件要内聚，内聚需要核心。 微内核，插件化机制。框架即核心，框架之上定制好插件，构建系统。 从问题知识域发现稳定部分进行抽象提升，成为系统的框架。  小结：从框架的角度来看系统，框架之间的有机组合构建系统，系统的演化就是在框架稳定情况下增加替换相关的插件。
扩展原则：扩展就是少修改  软件可扩展性是有前提和应用场景的，不存在可以随意扩展的软件。 增加新功能做到不修改既有软件，代码无需修改，通过修改数据模型或者重新配置获得新特性。 修改集中在新增加的软件之上，也就是说在增加新特性时，对老代码封闭，对新代码新特性开放。  小结：系统开闭原则，修改对系统稳定不构成影响。
</content>
    </entry>
    
     <entry>
        <title>使用tmux</title>
        <url>http://lanlingzi.cn/post/notes/2016/0221_mac_tmux/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>Shell</tag>
        </tags>
        <content type="html"> 什么是tmux tmux是一个支持多会话独立运行的优秀的终端复用软件。它类似GNU Screen，自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再“浪费”多余的终端来连接这台远程主机。
tmux的使用场景 Mac自带的Iterm2很好用啊。既支持多标签，也支持窗体内部Panel的分割，为什么还要用tmux？
 与VIM配合使用，打造出更高效、更优雅的终端工具。尤其是在当前大屏幕显示器下，多标签和分割窗体，无缝跳转。既可使用vim来写代码，也可使用tmux来查询代码编译与支行结果。 提供了一个窗体组随时存储和恢复的功能。调试程序，开了一堆窗口。出去吃了个饭，发现SSH超时了，如果使用tmux就attach就能找回原来打开的那些窗口。   tmux的基本概念 tmux的主要元素分为三层：
 Session会话： 一组窗口的集合，通常用来概括同一个任务。session可以有自己的名字便于任务之间的切换。 Window 窗口： 单个可见窗口。Windows有自己的编号，也可以认为和ITerm2中的Tab类似。 Pane 窗格： 被划分成小块的窗口，类似于Vim中 C-w &#43;v 后的效果。  安装 在Mac环境下，先安装Brew，使用Brew安装tmux命令如下：
brew install tmux  使用 安装完成之后，在终端中直接敲入tmux就可启动一个 tmux 的会话。退出会话敲入 exit 即可退出当前会话Pane。可以使用 tmux detach 命令断开已有的会话。也可以使用快捷键 Ctrl-b d 断开会话
tmux 默认使用 Ctrl-b 作为激活快捷键的开关,开关开启后就可以通过快捷键迅速调用大量的功能。快捷键参考如下：
基础  ? 获取帮助信息  Session管理  s 列出所有会话 $ 重命名当前的会话 d 断开当前的会话  window管理  c 创建一个新窗口 , 重命名当前窗口 w 列出所有窗口 % 水平分割窗口 &amp;rdquo; 竖直分割窗口 n 选择下一个窗口 p 选择上一个窗口 0~9 选择0~9对应的窗口  pane管理  % 创建一个水平窗格 &amp;rdquo; 创建一个竖直窗格 h 将光标移入左侧的窗格* j 将光标移入下方的窗格* l 将光标移入右侧的窗格* k 将光标移入上方的窗格* q 显示窗格的编号 o 在窗格间切换 } 与下一个窗格交换位置 { 与上一个窗格交换位置 ! 在新窗口中显示当前窗格 x 关闭当前窗格&amp;gt; 要使用带“*”的快捷键需要提前配置  其他  t 在当前窗格显示时间  配置 像VIM一样，可以定制你的tmux。tmux默认会先从 /etc/tmux.conf 加载系统级的配置项，然后从 ~/.tmux.conf 加载用户级的配置项。也可以启动tmux时使用参数 -f 指定一个配置文件。配置包含如下几个配置项：
 自定义各种快捷键 自定义屏幕下方的状态条  如配置激活快捷键：
set -g prefix ^k unbind ^b  默认的tmux风格比较朴素甚至有些丑陋。如果希望做一些美化和个性化配置的话，建议使用gpakosz 的tmux配置。它的本质是一个tmux配置文件，实现了以下功能：
 基于powerline的美化 显示笔记本电池电量 和Mac互通的剪切板 和vim更相近的快捷键  </content>
    </entry>
    
     <entry>
        <title>软件架构设计</title>
        <url>http://lanlingzi.cn/post/notes/2016/0215_about_soft_arch/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>软件架构</tag>
        </tags>
        <content type="html"> 什么是软件架构设计 依稀记得公司的软件架构培训材料中说到软件架构=组件&#43;交互。最近读温昱的《软件架构设计》才知道这只是其中一大阵营的观点。而软件架构在定义上分为“组成派”和“决策派”两大阵营。“组成派”认为软件架构是将系统描述成计算组件及组件之间的交互；而“决策派”认为软件架构包含了一系列的决策。事实上，从我司实际操作来看，两种观点并不是互斥的，而是相辅相成。两种观点只是站在不同的角度来看待软件架构。架构师在分割组件模块时，选择备选方案时，也是会不得不去作出各种决策，架构没有最完美的，只有在特定场景需求下最合适的。 “组成派”的两个明显的特点：
 关注架构实践的客体——软件，以软件本身作为描述对象。 分析了软件的组成，说明软件不是一个‘原子’意义上的整体，而是有不同的部分经过特定的接口进行连接组成的一个整体，这对软件开发来说很重要。  “决策派”的两个明显的特点：
 关注软件架构中的实体——人，以人的决策为描述对象。 归纳了软件架构决策的类型，指出架构决策不仅包括关于软件系统的组织、元素、子系统和架构风格等几类决策，还包括关于众多非功能性需求的决策。  按照“组成派”的观点，软件架构关注的是软件整体的分割和交互，之所以分割，是因为不同的部分在逻辑或物理上相对独立，通过“分而治之”的原则进行分割可以更好的理解整个系统，把握用户的需求，但是虽然整个软件可以分割成多个模块或子系统，但是模块和子系统之间的通信和交互也是很重要的。按照这种观点，架构师的主要任务是将软件分割成不同的模块，并定义模块之间的接口。
按照“决策派”的观点，软件是一个在很多限制下产生的产品，这些限制包括用户和技术两方面，用户方面包括功能需求、性能需求、硬件需求等，技术方面包括技术选择、可扩展性、可重用性、可维护性等。按照这中观点，架构师的主要任务就是作出上述个各种限制作出选择或决策，是一系列的有层次的决策。
软件架构设计的质量属性 按照“决策派”的观点，软件架构并不仅仅关注软件本身的结构和行为，还注重其他特性：使用、功能性、性能、弹性、重用、可理解、经济以及技术的限制和权衡等。
软件架构设计中需要考虑软件的质量属性，也是上述所说需要权衡与决策的。质量属性可归类为三类：
 软件系统本身的质量属性：可用性，可维护性，高性能，安全性，可测试性，易用性。 软件系统的商用属性：上市时间，成本与收益，目标市场，生命周期，系统生态。 架构本身的质量属性：概念完整性，正确性，可理解性，可构建性。  如何描述质量属性需求呢？一般采用质量属性场景作为一种规范。 质量属性场景是一种面向特定的质量属性的需求。它由六部分组成：
 刺激源：这是某个生成该刺激的实体（人、计算机系统或者任何其他刺激器）。 刺激：该刺激是当刺激到达系统时需要考虑的条件。 环境：该刺激在某些条件内发生。当刺激发生时，系统可能处于过载，或者运行，也可能是其他情况。 制品：某个制品被刺激。这可能是整个系统，也可能是系统的一部分。 响应：该响应是在刺激到达后所采取的行动。 响应度量：当响应发生时，应当能够以某种方式对其进行度量，以对需求进行测试。  软件架构设计的原则  全面解耦合原则：对业务进行抽象建模，业务数据与业务逻辑解耦，软件件与硬件解耦，平台与产品解耦，系统各部件之间解耦。 服务化、组件化原则：以服务，数据为中心，构建服务化，组件化的架构，具备灵活，按需组合的能力。 隔离与自治原则：通过接口隐藏服务、组件的实现细节，服务与组件之间只能基于接口交互，接口契约化、标准化。跨版本兼容；服务、组件可独立发展，独立发布，独立升级。服务自治，可视，可管，可控，可测，可维，故障自愈。 弹性伸缩原则：构建全分布式云化架构，或借鉴云化架构思想，每个服务具备横向扩展能务，支持按需使用、自动弹性伸缩，可动态替换，灵活部署，支持高性能、高吞吐量、高并发，高可用业务场景。 安全可靠原则：构建最小的权限、纵深防御、最小公共化、权限分享、不轻信、开放设计、完全仲裁、失效安全、保护薄弱环节、安全机制经济性、用户接受度以及加强隐私保护的安全体系，确保系统、网络、数据的机密性，完整性、可用性、可追溯。业务系统零故障为导向，按需构建分层分级的可靠性，通过故障的预测、预防、快速恢复，避免故障的发生。 高效开发原则：创建支持迭代、增量、持续交付的架构，支持部件可独立开发，自动化编译构建、测试、集成验证，并易于高效修改与持续优化；支持开发组织小型化、扁平化，支持小团队独立高效并行开发。 持续演进原则：架构并非一蹴而就，需要有效地管理架构需求，持续构建和发展架构，适应业务需求变化，适时引入业界最佳实践，及时重构，确保架构生命力和竞争力。   参考材料：
* 温昱的《软件架构设计》
* 软件体系结构的质量属性
* 华为产品架构设计原则
</content>
    </entry>
    
     <entry>
        <title>软件开发知行合一</title>
        <url>http://lanlingzi.cn/post/thoughts/2016/0131_unity_knowledge_action/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 最近在走读团队的代码，有时实在是看不下去。不是因为他们的代码编写有很多Bugs，而是没有设计实现太复杂了。当面对众多的需求需要快速实现，没有几个人会去思考代码怎么写结构才更合理，而是在不断去搬砖垒需求。当我去咨询他们为什么要这样实现时，每个人能只能说出一，不知其二。即使自己写的代码，也不知道当初为什么这么实现。
同时，我们团队中不乏有各种兴趣小组。例如学习新的技术框架，交流设计模型，讨论重构技巧、性能优化经验。而实际在操作层面上，代码却正如前面所讲，有时真的不堪入目。由于这近在看王阳明传，突然想到我们没有知行合一啊。 知 ：一方面是我们对技能掌握，如程序语言知识，设计模式，框架类库等；另一面是我们对需求理解，如场景梳理，用例分析，关键指标等。 行 ：能根据掌握的知识技能，以及对需求的认识应用于项目中，能过代码转化为实际客户所需的产品。
结合按王阳明的学说，做为一名合理的软件工程师，则需要格物致知，知行合一，良知和致良知。
 格物致知 ：
 格需求。对需求不断地格，才能知道客户真正需要什么。因为客户的提出需求时，往往是感性的，非技术化的描述，也可能是模糊不清晰的。那就需要我们不断去交流与探讨，才能明白客户的痛点，进而知行合一，指导你编码，做出满足客户真正需要的东西。 格技术。软件开发会涉及到很多的知识，尤其是大型的项目。我们面对操作系统，各种框架程序，以及各种软件工程方法。我们需要不断地格，去深入探本究源，明白什么场景下，使用什么技术是最优的。  知行合一 ：
 知而为行。知行合一很好理解了，简单的就是“知”和“行”统一。理论与实践想结合，一切的实践行动又必须有理论支撑。所想即所写，所写即所需。你能编写出来的代码才是真正知道的需求，你真正知道的需求你就一定能编写出来代码。 行而促知。我们不断地学习与交流，本身没有什么问题。其实如果没有实践的切身体验，是难以有较深的认知的。往往是学完也说不出一个所以然。知行合一，学习必须时刻结合实践行动，这样才能真正的掌握并不断的进步。  良知和致良知 ：
 良知。良知是人内心深处的心声。软件开发的良知是程序员做事的标准。显然，不断地只按需求去垒代码不是标准，能跑起来的代码也不是标准。软件开发的标准可能很多，不同的人有不同的看法。但一个团队一定要代码编写标准化，开发流程标准化。没有规矩成不了方园，标准化才能提高我们的效率。 致良知。找到标准（良知），然后去做到知行合一（致良知）。如果程序的良知是优秀的代码，那致良知就是我们不断地为实现优秀的代码去努力。优秀的代码涵盖代码的可读性，可理解性，同时还需要兼顾代码的可扩展性，可维护性。不要对自己编写的代码放任不理，识别代码的坏味道，编程的过程实际是一个不断重构改进的过程。古人说“三日省吾身”，编程也需要不断地反思。  </content>
    </entry>
    
     <entry>
        <title>重构已死</title>
        <url>http://lanlingzi.cn/post/technical/2016/0123_refactor_death/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件重构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 上周在食堂吃饭，遇到同事聊起最近的系统重构，她说这一批的新员工不如13年的一批，就一个看似简单的问题也是折腾很久，重构的周期越拉越长。我作为这次的重构的特性SE，可以说也是硬着头皮上。我是越来越反感重构，尤其是涉及到多个模块的重构。在新年的聚餐上，我说我给你挖了坑，你来填坑，让我感到非常惭愧的，即又不得做这些事。
在现阶段项目交付变得越来越难，一方面我们面对众多的需求，做还是不做并不是你能轻易决定的；而另一方面我们又想从架构上解决可以快速满足需求。但本质的是这几个月内，人的技能与意识没有根本性的变化。在大家没有主人翁的精神下，说来说去也是为了需求在垒代码。即使你想从代码结构上重新设计，让系统更松的耦合性，更好的扩展性。受于项目进度冲击，以及代码实现者的被动，最终也会变得让你不想回头多看一眼。 编程如果仅仅越考虑短期实现项目需求目的肯定是不好的，但想通过强制的管理手段，或重构手段来想延长它的生命周期也并一定能行得通。当同一份代码是多人开发与维护，并在领导眼中的谁有时间谁就上的话。本意可能是想通过多人的备份，或共同完成以期缩短工期。其实这种做法无疑更是加重了代码朝腐化之路上走的趋势。
重构有很多的手法或方法理论，其核心都会有提到不改变软件的外部行为，是对软件内部结构进行修改与调整。这实际上是非常难以做到的，我们是如何去评估不改变软件的外部行为，充分的测试能保证吗？显然就我们目前的测试能力来看，这简单是非常美好的梦想。尤其是具有一些年头的代码，或者又是人员变化较频繁的代码，看上去并不清爽的代码，至少还能正常的工作，一旦重构不知会丢失多少其中通过各种手段修改出来的小功能点。
今天的软件交付，可能说由于整体的需求是具有多变性，给软件开发带来不确认性。不确定就会产生怀疑和恐惧，我们经常会说，软件架构是要架构未来，不是解决当下问题。当不确定性还不算太多的时候，我们还在架构层面上来推演，整个软件系统的大致方向可以被预测，然后在此基础上不断地演化。而当不确定性实在太多的时候，对软件的要求就变成了可丢弃。换句话说，你开发的所有软件，从一开始，你就应该做好很快被丢弃的准备。
 采用开源：尤其是Github让开源的推广与使用变得越来越简单，开源软件在商用软件领域成为了越来越主流。即使你开发的是非常重要的商用软件也不需要自己从头开始，自己实现并一定比开源实现的好。
 平台框架：平台软件的目的是让通用的能力重用与沉淀。业务领域更倾向于采用面向领域的DSL描述简化开发，代码量要求是越来越少。目前各种基础框架越来越成熟，基于基础构架上构建，可以在最短时间内以最少代码量做出一个符合要求的软件。并且业务层不需要过多的设计，因为大部分设计已经蕴含在框架内。
 职责单一：可以把系统拆多功能单一的服务，符合单一职责原则，做且仅做一件事。这样代码量就不会太多，也不需要频繁地添加新的功能，变化少就不不会导致不稳定，所以这样代码烂也烂不到哪里去。另一方面功能单一，在其上的工作团队成员也会很少，四五个人能搞定的代码，它的也不会因为多人的经手变得不可维护。
  在面对需要快速迭代交付的项目下，软件开发变得越来越轻量化下。尤其是在微服务架构下，软件开发其实可以不需要重构，该烂的就让它烂掉。对于单个微服务或单个小的模块内的代码重构意义也变得越来越小。如果这个微服务真的到了无法满足需求情况下，那没有必要对它进行重构，重写一个就行了。所以在这样的情况下“重构已死”，其实又是系统中另外一种“重生”，就像人的身体一样，做换只手的手术可能影响非常地大，如果只是细胞不断地死去，新的又产生替换，你是感觉不到有什么影响。
</content>
    </entry>
    
     <entry>
        <title>Taipei-Torrent源码分析</title>
        <url>http://lanlingzi.cn/post/technical/2016/0117_torrent_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Torrent</tag><tag>Go</tag><tag>P2P</tag>
        </tags>
        <content type="html"> 提到P2P，总会少不了BitTorrent。BitTorrent是一种P2P协议。BitTorrent协议是由程序员Bram Cohen在2001年四月份设计的，最终版本在2008年确定。
BitTorrent协议简介 一个BitTorrent的文件在网络传输过程，由以下几个部分组成：
 WEB服务器 文件元信息(metainfo) BitTorrent Tracker 原始资源发布者 目的端用户浏览器 目的端用户下载者   其中原始资源发布者与目的端下载者都称为Peer，而Tracker主要用于获取不同的Peer信息信息，BitTorrent把要下载文件虚拟分成大小相等的块，并把每块的索引信息与Hash验证码等元数据信息写到一个.torrent文件中，即种子文件。种子文件采用B编码格式，它本质是一个文本。Peer与Tacker或DHT节点通讯也采用B编码格式。根据获取Peer信息的途径不同，又分为两种。
 有的Tracker结构  	[WebServer] | | torrent file | [ Peer ] ---Get Peers --- [TrackerServer] \ \ Download&amp;amp;Upload(TCP) \ \ [ OtherPeer ]   Trackerless的DHT结构  	[WebServer] | | torrent file | [ Peer ] ---Get Peers --- [DHT Nodes] \ \ Download&amp;amp;Upload(TCP) \ \ [ OtherPeer ]  Trackerless的DHT结构解决了Trakcer中心故障的问题，是一个更去中化的结构。DHT结构中，每个peer都可能是一个tracker。DHT是基于Kademila协议的，并且在UDP协议基础上实现。
每个节点都有一个全局唯一的标识符，称为节点ID。距离度量用来比较两个节点或者节点与infohash之间的远近程度。节点必须维护一个含有少量其他节点联系信息的路由表。ID越靠近自身ID时，路由表越详细。节点知道很多离它很近的节点，只知道少量离它很远地节点。
在Kademlia中，距离度量采用异或计算，结果解释成一个无符号整数。 distance (A,B)=(A ~| B)，值越小，距离越近。每个节点维护一个路由表，由它所知道的好节点组成。路由表中的节点被用作在DHT中发送请求的起点。当其他节点查询时，就返回路由表中的节点。
开源实现 C&#43;&#43;语言 实现BitTorrent协议最有名要算两个C&#43;&#43;的实现：
 rakshase 版本：他来源于Mozilla NSS的项目，LICENSE是GPL，使用它的客户端亦rtorrent等，基于Posix接口开发，可以在兼容Posix系统中编译使用，也支持HDT。这个项目已有12年了，目前还在发展，可以是非常的稳定与成熟，据说是速度之王。 rasterbar(arvidn/libtorrent)版本，GitHub上有两个地址，另一个是libtorrent/libtorrent。前者是还是发展，后者已停止开发了。rasterbar版本是基于boost asio编写的，跨平台不存问题。默认有Python与Ruby的绑定接口。并且具有良好扩展性，例如有uTP，DHT安全扩展  Go语言 由于个人爱好的原因，一真想找是否有Go语言实现版本，于是在GitHub上寻寻觅觅，也找到两个不错的实现：
 Taipei Torrent：它一个较轻量的，基于命令行接口的Torrent客户端，主要功能有支持多Torrent文件，Magnet链接，DHT，UPnP/NAT-PMP打洞，也提供简单的tracker服务。 anacrolix/torrent: 它实现了BitTorrent协议相关功能包，以及提供较丰富的命令行工具集。支持加密协议，DHT，PEX，uTP以及多种扩展。从代码结构来说，anacrolix/torrent比Taipei Torrent更容易做二次开发。  Taipei Torrent 首先它的名字比较有意思，项目开始于作者在台北的旅游，所以取名为Taipei Torrent。它的代码量比较不多，像Bencode，DHT，NAT-PMP，网络工具包都采用第三方库。
代码结构 Taipei-Torrent git:(master) tree ├── main.go ├── queryTracker.bash ├── resolveBindIP.go ├── resolveBindIP_test.go ├── test.bash ├── testData │ ├── a.torrent │ └── testFile ├── testdht.bash ├── testswarm.bash ├── testtracker.bash ├── torrent │ ├── accumulator.go │ ├── accumulator_test.go │ ├── bitset.go │ ├── cache.go │ ├── cache_test.go ....... │ ├── upnp.go │ ├── uri.go │ └── uri_test.go └── tracker ├── tracker.go └── tracker_test.go  源码分析 花了一个下午走读它的代码，代码简洁易懂，主要功能都在torrent目录下。每个Peer对一个torrent文件会产生一个会话，在我的笔记本记，使用Docker搭建了6个节点，发布下载77M的go的安装包，是秒级速度。如下所示：
2016/01/17 12:13:13 Starting. 2016/01/17 12:13:13 Listening for peers on port: 7777 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Tracker: [], Comment: , InfoHash: 556871e1ada306c2da5033e8fe0d4f077edbe6f7, Encoding: , Private: 0 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Computed missing pieces (0.35 seconds) 2016/01/17 12:13:13 [ go1.5.3.linux-amd64.tar.gz ] Good pieces: 0 Bad pieces: 1223 Bytes left: 80147269 2016/01/17 12:13:13 Created torrent session for go1.5.3.linux-amd64.tar.gz 2016/01/17 12:13:13 Starting torrent session for go1.5.3.linux-amd64.tar.gz 2016/01/17 12:13:14 [ go1.5.3.linux-amd64.tar.gz ] Peers: 0 downloaded: 0 (0.00 B/s) uploaded: 0 ratio: 0.000000 pieces: 0/1223  作为Peer Client，主要代码逻辑在torrent\torrentLoop.go的RunTorrents方法中，它充分利用了Go的channel机制。实现步骤如下：
 根据命令参数，开启Peer连接端口（TCP）。若不指定端口，则采用随机端口。目前是绑定在所的IP上，如果是内网，可以做NAT转换。 根据MaxActive参数，开启Session（对象为TorrentSession）数，如果同时下载torrent多余MaxActive则排队处理 如果设置参数useDHT，或torrent文件中没有Tracker服务，则会开启DHT，而DHT是采用UDP，端口与第1步的相同。 如果设置useLPD（Use Local Peer Discovery），则又会通过组播在同一个网段内相互发现，组播地址为239.192.152.143:6771。 当完成上述初始化之后，在mainLoop主要根据事件来处理：  如果是Session创建成功，则异步执行TorrentSession.DoTorrent方法开始启动下载 如果是有Session下载结束，则从排队中取出未处理的torrent文件加入到Session处理。 如果是收到退出信号，则等下载结束退出。 如果是收到其它Peer的连接请求，根据Infohash来判断是否存在相应的Session，如果存在，则提供给其它的Peer下载数据。 如果是收到DHT Peer的请求结果，则处理其它的Peer地址，根据地址从其它Peer下载数据。 如果是收到其它Peer的组播请求，则处理其它的Peer地址，根据地址从其它Peer下载数据。   另一个核心代码逻辑是在torrent\torren.go的DoTorrent方法中，实现步骤如下：
 如果设置了内存缓存或硬盘缓存数，则根据torrent文件中元信息（块个数，整个大小）初始化缓存。 开启几个定时器，每隔1秒心跳检查，每隔60秒连接KeepAlive，如果采用Tracker服务，每隔20秒与Tracker服务列表请求，直到有Tracker服务有咱应。 如果是DHT，则从DHT Peer获取其它的Peer地址。 处理各种Channel的消息。  还一个重要的torrent\torren.go的DoMessage方法，它用于是产生协议的消息，与一个peer建立TCP连接后，首先向peer发送握手消息，peer收到握手消息后回应一个握手消息。握手消息是一个长度固定为68字节的消息。消息的格式如下：
[pstrlen][pstr][reserved][info_hash][peer_id]     参 数 含 义     pstrlen pstr的长度，该值固定为19   pstr BitTorrent协议的关键字，即“BitTorrent protocol”   reserved 占8字节，用于扩展BT协议，一般这8字节都设置为0。有些BT软件对BT协议进行了某些扩展，因此可能看到有些peer发来的握手消息这8个字节不全为0，不过不必理会，这不会影响正常的通信   info_hash 与发往Tracker的GET请求中的info_hash为同一个值，长度固定为20字节    对于除握手消息之外的其他所有消息，其一般的格式为：
[length prefix][message ID][payload]  length prefix（长度前缀）占4个字节，指明message ID和payload的长度和。message ID（消息编号）占一字节，是一个10进制的整数，指明消息的编号。payload（负载），长度未定，是消息的内容。
 keep_alive消息：[len=0000]
keep_alive消息的长度固定，为4字节，它没有消息编号和负载。如果一段时间内客户端与peer没有交换任何消息，则与这个peer的连接将被关闭。keep_alive消息用于维持这个连接，通常如果2分钟内没有向peer发送任何消息，则发送一个keep_alive消息。
 choke消息：[len=0001][id=0]
choke消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。
 unchoke消息：[len=0001][id=1]
unchoke消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。客户端每隔一定的时间，通常为10秒，计算一次各个peer的下载速度，如果某peer被解除阻塞，则发送unchoke消息。如果某个peer原先是解除阻塞的，而此次被阻塞，则发送choke消息。
 interested消息：[len=0001][id=2]
interested消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。当客户端收到某peer的have消息时，如果发现peer拥有了客户端没有的piece，则发送interested消息告知该peer，客户端对它感兴趣。
 not interested消息：[len=0001][id=3]
not interested消息的长度固定，为5字节，消息长度占4个字节，消息编号占1个字节，没有负载。当客户端下载了某个piece，如果发现客户端拥有了这个piece后，某个peer拥有的所有piece，客户端都拥有，则发送not interested消息给该peer。
 have消息：[len=0005][id=4][piece index]
have消息的长度固定，为9字节，消息长度占4个字节，消息编号占1个字节，负载为4个字节。负载为一个整数，指明下标为index的piece，peer已经拥有。每当客户端下载了一个piece，即将该piece的下标作为have消息的负载构造have消息，并把该消息发送给所有与客户端建立连接的peer。
 bitfield消息：[len=0001&#43;X][id=5][bitfield]
bitfield消息的长度不固定，其中X是bitfield(即位图)的长度。当客户端与peer交换握手消息之后，就交换位图。位图中，每个piece占一位，若该位的值为1，则表明已经拥有该piece；为0则表明该piece尚未下载。具体而言，假定某共享文件共拥有801个piece，则位图为101个字节，位图的第一个字节的最高位指明第一个piece是否拥有，位图的第一个字节的第二高位指明第二个piece是否拥有，依此类推。对于第801个piece，需要单独一个字节，该字节的最高位指明第801个piece是否已被下载，其余的7位放弃不予使用。
 request消息：[len=0013][id=6][index][begin][length]
request消息的长度固定，为17个字节，index是piece的索引，begin是piece内的偏移，length是请求peer发送的数据的长度。当客户端收到某个peer发来的unchoke消息后，即构造request消息，向该peer发送数据请求。前面提到，peer之间交换数据是以slice（长度为16KB的块）为单位的，因此request消息中length的值一般为16K。对于一个256KB的piece，客户端分16次下载，每次下载一个16K的slice。
 piece消息：[len=0009&#43;X][id=7][index][begin][block]
piece消息是另外一个长度不固定的消息，长度前缀中的9是id、index、begin的长度总和，index和begin固定为4字节，X为block的长度，一般为16K。因此对于piece消息，长度前缀加上id通常为00 00 40 09 07。当客户端收到某个peer的request消息后，如果判定当前未将该peer阻塞，且peer请求的slice，客户端已经下载，则发送piece消息将文件数据上传给该peer。
 cancel消息：[len=0013][id[=8][index][begin][length]
cancel消息的长度固定，为17个字节，len、index、begin、length都占4字节。它与request消息对应，作用刚好相反，用于取消对某个slice的数据请求。如果客户端发现，某个piece中的slice，客户端已经下载，而客户端又向其他peer发送了对该slice的请求，则向该peer发送cancel消息，以取消对该slice的请求。事实上，如果算法设计合理，基本不用发送cancel消息，只在某些特殊的情况下才需要发送cancel消息。
 port消息：[len=0003][id=9][listen-port] * port消息的长度固定，为7字节，其中listen-port占两个字节。该消息只在支持DHT的客户端中才会使用，用于指明DHT监听的端口号，一般不必理会，收到该消息时，直接丢弃即可。 &amp;gt; 注：Taipei Torrent未实现此消息
 extension消息：[len=0009&#43;X][id=20][payload]
extension消息消息的长度不固定，消息Id为20， Taipei Torrent来来与其它的Peer交换torrent文件的元数据信息（每块Pieces的信息），同样采用B编码格式。
 </content>
    </entry>
    
     <entry>
        <title>软件分发加速</title>
        <url>http://lanlingzi.cn/post/technical/2016/0116_speed_sw_distribute/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Cloud</tag><tag>Multicast</tag><tag>P2P</tag>
        </tags>
        <content type="html"> 背景 在云环境下，服务器（物理机）或虚拟机越来越多，存在同一个应用软件需要大规模地部署场景。传统的方式下是搭建一个软件仓库，由物理机或虚拟机节点直接从软件仓库下载。如果采用sftp或http协议，则只能做到从一个中心软件仓库分发软件包给其它的节点，若给上百台的节点同时分发同一软件包，则存在受带宽、负载限制等因素，导致分发的速度就会比较慢。 常用技术 组播 传统的IP通信有如下三种方式：
 单播（Unicast）：源主机与目的主机之间点对点的通信。 广播（Broadcast）：源主机与同一网段中所有其它主机之间一点对多点的通信。 组播（Multicast）：源主机与一组目的主机之间一点对多点的通信。与广播不同的是组播组中的所有接收者都可收到同样的数据拷贝，并且只有组播组内的主机可以接收该数据，而其它主机则不能收到。  组播技术有效地解决了单点发送、多点接收的问题。所以组播非常适合运用在云环境下的软件分发场景，单点到多点的高效数据传送，能够大量节约网络带宽、降低网络负载。
一般情况下，在二层网络中，交换机会默认开启组播，但会对组播带宽进行抑制，防止网络风暴造成的影响。在实现应用中可以在交换机上设置合适的组播带宽。如果组播需要跨二层网络，需要在路由器上开启组播路由协议。
组播组内的所有主机共享同一个地址，这种地址称为组播地址。组播地址是范围在224.0.0.0~239.255.255.255之间的IP地址。此范围内的所有地址的前4个二进制为都是“1110“。组播地址也被称为D类IP地址，与其它的A类、B类和C类地址相区别。组播组是开放的，主机可以在任何时候进入或离开组。 IANA(Internet Assigned Numbers Authority)组织负责分发永久组播地址。
由于组播地址是开放的，在实现组播服务，需要在上层设计加入组播的认证机制，如采用IP白名单，或在自定义上层协议，会话协商时进做登录认证。
组播是采有UDP，与单播UDP不同，前者必须考虑TTL(Time to live)值，它用IP数据包的头部的一个字节表示。 TTL通过限制IP包被丢弃前通过的路由器数目，来决定IP包的生存时间。IP包每通过一个路由器，TTL就减一，当TTL变为0，这个包就被丢弃。 TTL的一个作用是防止配置有误的路由器把包在路由器之间无限的来回传递，还有一个作用是限制组播的地理范围。
由于UDP不可靠，会存在丢包的情况，在设计组播服务需要考虑对传包个数与内容的校验，以及重传机制，或者在最坏的情况，采用TCP的补偿传输。通常的做法是在另开TCP连接来控制组播的传输质量，而UDP是负责数据流。
Java在1.7中，已支持MulticastSocket API。API比较低层，需要结合NIO一起使用，另外JGroup与Netty也对组播有更高层的封装。
P2P P2P(Peer to Peer)端到端传输模型，与传统的C/S（Client-Server）模型相对应的。P2P与C/S都是单播。但C/S是集中由Server端来分发中转，所以当多个节点从Server下载软件时，对Server的流量与性能影响最大。而在P2P网络中，每个节点都是对等的。网络中的每个节点既能充当网络服务的请求者，又对其它节点的请求作出响应，提供资源和服务。
P2P组网按是否有中心索引节点来分有三种：
 集中式P2P：存在中心服务器，保存所有节点信息与资源信息，其它节点通过它找到需要连接的节点与资源。 无结构化P2P：节点同时作为客户端和服务器端，无中心服务器，无中心路由器。 结构化P2P： 将网络中所有资源整理成一张巨大的表，表内包含资源的关键字与存入节点地址，这张表裸眼分割分别存储到网络中每个节点中。结构化组网常见有三种：  DHT结构 树形结构 网状结构   在实现P2P技术中，需要考虑如下几点：
 可控性：由于P2P流量特征具有上下行流量对称的特性，这使得直接面向用户的接入网络需要相应提高所能承载上行流量的能力。 安全性：P2P相对随机的端口号，难以实话实行有效地监测和管理，加大了日常维护的难度。 效率性：对等的节点需要尽快地得到所需要文件块，需要有机制查找出节点已有文件块信息。 可靠性：不能存在文件块永久丢失的情况，必须存在源节点是可靠的。  所以，在私有云环境下的软件分发，需要同时考虑安全与可靠性。一般是采用集中式P2P，存在中心服务器，只不过这个中心服务器可以是集群的。每个节点与中心服务器建立控制连接，什么节点下载什么软件，从哪些节点来下载软件，由中心服务器根据不同节点的负载来做出决策。利用近播原则、分域调度的思想来尽可能控制P2P流程对网络节点的影响。
实施建议 在我们的实际测试中，一个400M软件包，100个节点的分发场景下，组播速度大约是P2P的5倍右右。但组播只能在一个二层网络中，如果跨二层网络需要在路由器上开启组播功能。而一般出于安全等多因素考虑，路由器会禁掉。P2P在安全与可靠性更难以控制，以及会对网络节点的产生影响，甚到会影响节点的业务正常的性能。所以优先是选择组播，如果存在跨二层网络，可以部署多套软件仓库。P2P可以运用在组播不能使用，以及节点并发初始部署软件时，而节点上已运行业务时，则需要从P2P网络退出，不能长期做来提供服务的节点。
</content>
    </entry>
    
     <entry>
        <title>如何看待Docker</title>
        <url>http://lanlingzi.cn/post/technical/2016/0107_docker/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag>
        </tags>
        <content type="html"> 从国内来看，从14年的发迹，到15年的红火。基于Docker的国内创业公司不停的涌现，Docker的概念不断地炒作。软件界似乎人人在谈论Dcoker，给我的感觉就像中国大妈跳广场舞一样，歌声大，动作乱，到底有没有用，难说。毕竟Docker只是一项技术，技术是否能成功应用，给你的产品带来价值才是最重要的。下面是个人一些对Docke的看法与见解，可能有不对之处，望交流赐教： 标准化是基础 从对Linux的贡献角度来说，Docker并没有什么技术创新。但为什么它会得到如此众多的追捧，主要他得益它制定了标准。尤其是我所在电信行业感受最深，真是得标准得天下：
 容器镜像：软件的交付件标准化，使得软件在云环境中的构建，发布，运行，迁移，复制等软件分发变得更加容易。 容器引擎：容器操作方式标准化，提供标准的Rest API，使得对容器的创建，删除，启停等生命周期管理更简单。  简单就是生产力 我们再来看Docker的诞生，它是来源于Docker公司前身dotCloud的实践，出发点是为了解决如何帮助开发人员实现软件的快速打包，部署。其实也就是目前大家都在说的CICD，通过统一的格式来提升打包，测试，部署的效率。所以大家看到Docker宣传的“Build，Ship，Run”，也就说它最大的特点，简化了开发到部署操作，极大地提高的软件开发验证效率。
会带来什么价值 除前面的提高软件的开发验证效率，它还能给出我们带来什么价值？首先，Docker屏蔽了软件运行环境差异，这个怎么理解呢？因为它的镜像具有便携性，一致性的特点。这极大地简化了软件在部署过程由于环境的差异带来的不确认性。其次Docker本身就是一种OS容器技术。而OS容器是基于操作系统内核的虚拟化，是一种轻量的虚拟化。相比于Hypervisor的虚拟化技术，它没有指令转化这一层，只是共享主机内核，划出不同的Namesapce。在计算能力上它是没有什么性能损耗的。容器可以运行在物理机或虚拟机之上，不依赖于虚拟化软件。所以它的价值主要体现在两大方面：
降成本（相比Hypervisor）  基于Hypervisor虚拟化的应用性能下降比较高，尤其是IO密集型，同等性能指标需要消耗更多的资源。
 采Hypervisor虚拟化技术，License费用支出高，虚拟化管理软件也有成本支出。 Hypervisor虚拟化对资源划分粒度比较大，而容器可以更细粒度你分割资源，可以提整体资源利用率。 虚拟机镜像大（以G为单位），启动慢（分钟级）；而容器镜像相对小（以M为单位），启动快（秒级），应用可以快速伸缩，降低维护成本 容器能快速创建与销毁，可以应用在一些短任务的业务（如大数据分析），长短任务的业务混合部署，错峰填谷来提升资源利用率。  加速创新  改变软件的交付模式：CICD变得更加容易，可以使软件快速开发、上线、验证。软件开发迭代周期缩短，试错风险小，加速业务的创新能力。 改变软件的架构模式：容器即完整执行环境，可以使用软件“微”服务化，服务之间能够快速组合和重构，提升业务的创新能力。  网络与存储 相对于传统的虚拟化来说，包括三个方面，计算虚拟化，网络虚拟化，存储虚拟化。映射到容器技术上来说，计算能力就是Docker引擎，而网络则是容器网络管理，存储则是容器卷管理。Docker在容器管理上是相对比较成熟的，但在网络方面目前还是相对比较弱，Docker现有的网络模型主要是通过使用Network namespace、Linux Bridge、Iptables、veth pair等技术实现的。Docker提供了四种网络模式：
 host模式： 容器和宿主机共享Network namespace。没有网络隔离，多容器需要规划端口，适合不需要动态调度的静态部署使用Docker。 bridge模式： Bridge模式是Docker的默认模式，即NAT方式，容器网卡从docker0网桥所在的IP网段中选取一个未使用的IP，容器端口映射到主机上。性能下降15~20%，对网络性能与时延敏感的应用不适合。 container模式： 容器和另外一个容器共享Network namespace。kubernetes中的pod就是多个容器共享一个Network namespace。这些方式有它特定的应用场景。 none模式：容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。这些方式适合通过Libnetwokr方式扩展。  目前Docker释放出Libnetwork，旨在将Docker的网络功能从Docker核心代码中分离出去，形成一个单独的库。 Libnetwork通过插件的形式为Docker提供网络功能。用户可以根据自己的需求实现自己的Driver来提供不同的网络功能。 Libnetwork引入了容器网络模型（CNM）:
 Network Sandbox：容器中一个网络配置的隔离环境 Endpoint：在某个网络上进行网络通讯的接口，Endpoint可以加入一个network，同时，多个Endpoint也可以在一个网络沙盒中共存。 Network：一个唯一的、可识别的endpoint组，组内endpoint可以相互通讯。  Libnetwork从Docker1.7开始，目前整体来说，还是属于起步阶段。由于网络是一个绕不开的话题，网络方案热度很高，目前各个企业在使用Docker时也是有各自的解决方案，他们各所有长，没有包打天下的方案。Docker 1.9发布，已把libnetwork合入，号称已Production Ready，实际还是底层调用OVS或Vxlan。OVS与Vxlan在性能上都存在损耗。
容器卷的管理相对网络来说，热度比较低。Docker之前可以通过Monut主机的目录来解决数据持久存储的问题，由于容器的特点是便携，本地数据肯定存在数据迁移的问题。Docker 1.9重新设计的一套完整存储卷管理系统，也像网络一样，支持能过插件形式来为Docker提供卷功能，实现自己的Driver来提供不同的卷管理功能。卷管理这一块走在前面是Flocker，其它没有看到较成熟的产品。
Docker开放网络与卷管理扩展能力，可能是出于建立生态考虑。毕竟即使开源，如果系统的开放性不够，就会导致商业可能为黑寡妇，最终伤害也是自己的利益。
使用方式 正如前面所说的，容器涉及到计算，存储，网络。而目前网络与存储相对不是很成熟，也是影响着大家使用Docker的方式，目前主要有几种形态：
 IaaS &#43; Docker：在虚拟机或物理机上是使用容器，容器是对资源进一步的分割与隔离。目前是主流，应用较成熟。 轻量虚拟机 &#43; Docker：主要是虚拟化技术厂商为准，借助虚拟化在存储，网络，安全的能力。像Vmware的Photon，创建虚拟机时同时拉起容器。其它代表有Intel的ClearLinux，国内的Hyper.sh。目前还实验阶段。  目前大家还是把Docker当工具使用，因为整个工具链还不太成熟。容器编排与调度领域目前有K8S与Mesos/Marathon，Docker自家也有compose与swarm，但明显Google在这一领域更有发言权（Borg的成熟应用），也主导了CNCF。将来Google领导的K8S可能是容器编排的事实标准。
而传统的虚拟化厂商明显感到来自Docker的挑战，所以也顺适而为，摧出轻量虚拟化&#43;Docker结合技术，来继续巩固已有的虚拟化市场，这真是一个有意义的现象。
标准之争 CoreOS不满于Docker在容器技术一家独食，发起了AppC的容器规范，并实现该规范RTK与其竞争。其后在15年6月大家握手言和，成立了OCI（Open Container Initiative）组织。RunC就是Docker贡献出来的，按照该开放容器格式标准（OCF, Open Container Format）制定的一种具体实现。而Docker公司也很不情愿地把LibContainer以RunC方式贡献出来。从使用量来看，目前RKT使用很少，Docker是事实标准。值得一提的是，我司也在标准这块发挥着重要作用，并发布了OCT，一个基于开放容器规范的测试框架。
</content>
    </entry>
    
     <entry>
        <title>7秒时光</title>
        <url>http://lanlingzi.cn/post/stories/2016/0103_7s_time/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>休闲</tag>
        </tags>
        <content type="html"> 三天的元旦时间很快就过去，前两天是窝在家搞我这个网站。今天怎么也得出去走走，于是老婆约上她的几位好友，说去莲塘边的罗湖5号绿道感受一下大自然。天公有点不作美，一直下着毛毛细雨，但是我们还是意识坚定，风雨无阻。当我们一行7人踏上路程，蓦然发现朦胧细雨下的水库与5号绿道，别有一番诗情画意，望着不远的仙湖与梧桐山，他们就像一幅幅山水水墨画，恨不得把她们都收入到相机中。 一路上我们有说有笑，完全忘记了天气的不适。虽已是深冬，但深圳的冬天却还是花开的春天般。我们一行中有一位博学的动植物学老师，一路上的花花草草，她都能讲解得恰当时机，本是由于下雨无趣的路程，给增添了不少的知识与乐趣。不知不觉我们就到达了我们的目的地，梧桐山下的大望艺术小镇。正值中午，一路的能量消耗，也需要新的补充，她提议去她在杭州开会认识一位朋友的小店，说她家做的东西非常好吃。作为吃货的我们，自然是欣然答应。
在大望艺术小镇内，七拐八拐才找到她，她仿如世外桃园，不与商业争艳。这不是一家普通的店，而是一家颇具文艺气息的休闲别院。店有一个非常诗意的名字：七秒时光。当我们推开门，经过一段门廊，映入我们眼帘是一座极具风情的别院：树，小溪，茶亭，书，钟表，留声机。一切充满了文艺，轻松的气息。而正门墙上的一段文字也深深地吸引了我：
 这也是我的天涯。进，看不见幸福，退，看不见你。止于此。春便还是春，夏便还是夏。爱止于此，心也止于此，风止于秋水，我止于你。
 店名的也是别具深意，在这个繁华的世界，你我学会放下烦恼，只要拥有你，便能止于此：
 传说鱼的记忆只有七秒 七秒一过，它们就会忘记所发生的事情,每一刻都是崭新的，一点也不会疲惫，这样快乐总有理由&amp;hellip;
 是的，我们的痛苦，大多是来自我们虚无空洞的追求。愿做一条七秒鱼，安顿身心，把每一刻活出崭新。这或许是2016年元旦最大的收获。
推荐阅读：我是一条只有七秒记忆的鱼
</content>
    </entry>
    
     <entry>
        <title>新年新目标</title>
        <url>http://lanlingzi.cn/post/stories/2016/0101_new_year/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 韶华易逝，往昔不再。时间已翻到2016年，在15年的12月份，忽然做了一个决定，注册了lanlingzi.cn这个域名，开始鼓励自己写写东西。原由是在15年的下半年，工作上做一个重大的调整，暮然发现自已写东西有时真让人费解。这个域名上已有的文章，是我之前在CSDN上一些记忆，以及自已电脑上留下的文档。虽然在公司也会写写技术博文，但那些更倾向于技术的细节与程序语言，对问题的思考与见解少了一些。
在16年的计划目标是每个月一到两篇，争取多写些有思想，有见解的干货。经过这几天的梳理，才有了这个网站。发现写东西是一个比较费时费脑力的事儿，甚至比写起代码来还难。苦于自己的文思，文笔，写完之后，有时连自己都看不下去，一堆的错别字，语句不通顺。有时，脑子中是飞快地转，好似有千言万语，下笔时却不知从何写起。 不管怎么样，我已经开始写了，我也开始享受写作的过程，整理文字，就是整理自己的思绪。可以把零星的，模糊的想法，通过这个网络串起来，记录下来。我不求有人会去欣赏，孤芳自赏也是一种自娱。也许，每每自己回头阅读自己的文字，也是阅读自己的回忆。有会也许会觉得自己一些想法，见解，观点是那么的幼稚、怪诞，可笑。这或许也是自我的一种成长历程吧。
16年不再年轻，而技术却是日新月异，既然今年放弃了带团队，专走技术这一线，那就坚持吧。16年加油，技术不会随着年轮越走越窄，无论是编写代码，还是做设计方案，只要能沉下心来，专心专意去付出，就会又有收获。
15年在思想上虽有一些波折，但整体还是圆满，要感谢的人太多太多。感谢家人的理解与支持，感谢领导与同事的器重，感谢大家的宽容与谅解。那些往事，那些经历，一路上有你们的支持，才能有我每年的成长。学会感恩，让自己的内心更加的平静，更加的强大。
16年加油，让生活更美好！
</content>
    </entry>
    
     <entry>
        <title>虚拟与现实</title>
        <url>http://lanlingzi.cn/post/stories/2015/1231_debian_ian_die/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>Debian</tag>
        </tags>
        <content type="html"> 万万没想到，在即将迎来2016年时，微信，科技新闻中都在传“Debian创始人Ian Murdock离奇死亡，曾发推表示要自杀”。作为一个对Debian系Linux的忠实爱好者，有种莫名的感伤，对大神的离去表示衷心的哀悼。 30日Debian社区正式发表了悼念声明如下：
 我们怀着沉重地心情哀悼刚刚离我们而去的 Ian Murdock，开源软件的坚定支持者，父亲，儿子，和 Debian 中的 &amp;ldquo;ian&amp;rdquo;。
Ian 从 1993 年8 月开始启动 Debian 项目，并在同一年的稍晚时间正式发布了它的第一个版本，Debian 还会一直坚定不移地继续努力，成为流行世界、亿万人受惠的通用操作系统，不管是嵌入式设备还是太空站，都能看到它的身影。
Ian 一直非常关注在创建一个发行版和开源社区文化的过程中做正取的事情，不管是技术上，还是道德上。每一次准备好的系统发布，都包含着对自由软件和自由精神立场的坚定支持。
Ian 对开源的忠诚奉献一直引导着他的工作，不管是在 Debian 还是在后来的年月里，一直伴随他朝着最好的未来。Ian 的梦想一直都在发扬和纪旭，Debian 社区仍然非常活跃，成千上万的开发者们用数不清的工作时间带给世界一个安全可靠的操作系统。
这段特殊时期，Debian 社区的精神会一直陪伴着 Ian 的家庭，会陪伴一起共度难关。
他的家庭同时也请求大家在这个艰难的时刻留给他们一些隐私空间，我们对此非常尊重，同时也号召大家尊重 Ian 家人的愿望，来自 Debian 社区和开源社区的关心他的人们的慰问，可以发送到这个专属邮箱，Debian 社区会保存这份善意，并存档。
 Debian的诞生本来就是一件很浪费的事，理想主义，追求纯粹，不包含非自由软件，充满激情，同也是非常的沉稳。Debian也是目前Linux发行版本中，最为彻底，最为忠实，践行开源精神的版本。它曾经是一个符号，一面旗帜。
Debian的名称也据说来源一个美丽的爱情故事（Deb来自于前女友Debra，Ian来自他自己的名字），Ian长期担任Linux基金会的首席技术官，他的成就在自由软件，开源社区是一个了不起的传说。
逝者已往，愿Ian安息，这位把自己的浪漫书写在了Debian和OpenSource的传奇人物，一路走好，我们会永远记住您！
他能在软件开源这个虚拟世界中，一呼百应呼风唤雨，但在现实世界也是一个普通人。作为一名程序员，或许不经意的创作，能改变世界科技的发展。开源摧动了技术的发展，使得知识更容易获取，使得技术更容易创新。但他们却可能不是这个过程中最大的获利者。在虚拟的技术世界中，我们敬奉他们为大神，而在现实世界中，很少有人能获得像政要，企业家的社会地位，甚至不如某国一名歌坛明星。即使面对一名小警察，或许只能通过自杀来表达诉求或无奈。
</content>
    </entry>
    
     <entry>
        <title>参加ArchSummit北京站感受</title>
        <url>http://lanlingzi.cn/post/technical/2015/1227_bj_archsummit/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>北京</tag>
        </tags>
        <content type="html"> 参加ArchSummit北京站已有一周时间，一直没有时间来梳理一下。整体来说，这次的北京之行，不是很满意，可能是这类会议听多的原因，感觉ArchSummit的质量是越来越差了，没有什么新鲜感，觉得不值那6K的价格。
组织不足 12月份的北京已是非常的干冷，可能由于我在南方呆久了，一到北京是极其地不适应，在北京三天多的时间，嘴唇开裂，到现在还没有完全好干净。离开北京的那一天，正好又感受了一下北京正宗的霾，帝都的人们活得真不容易啊。 为什么说ArchSummit组织不足呢？InfoQ也算是组织过多次大型会议的公司，但这一次比我之前参加InfoQ组织的任何会议都差，更无法与阿里组织的云栖会议相比。一个是以组织会议赚钱，一个是以个会议来打造生态。这次的ArchSummit是在北京国际个会议中心举行，每个分会场我都差不多的参加过，明显感觉组织不足:
 每个分会场演讲时，大门紧闭，空间质量非常的差，又没有充足的通风设备，感觉非常的窒息。 工作人员能力不行，第一天下午，有几个分会议室由于投影没有准备好，拖时半个多小时，也不见中途主持人来了说一声，最后连声道歉都没有。 几个分会场的投影效果差，灰蒙蒙的看不清楚。 连个矿泉水瓶上都是广告，并且不是每个位置都摆放好水，而是需要自己去指定位置去拿。有的分会场甚于连矿泉水都没有见到，准备的份数太少，6K的价格连个水都喝不到。 就餐地方太小（又是自助餐），效率低下，大量的人员挤在走廊上，我是差不多等了30多分钟才能进餐厅吃饭。大量的人员挤在一起存在安全风险。  两天的ArchSummit大会日程比较紧凑，再加上大多数时候有六个专题在并行，因此每个人能够真正去听的课程不会太多。我们也是只能选择地去听，但是每个演讲介绍不足，有些演讲名字高大上，听了之后，感觉有点上当，部分讲师存在水分，这里就不直说了。
不过，参加ArchSummit大会，还是听到一些业内公司的技术分享，尤其是互联网企业，在应用新技术方面还是比较超前的。相对我们电信行业来说，我们遇到的问题有些是相似的，甚至部分问题的解决办法也与我们曾经想过的一些方案类似，只是他们早已经落地并且做到极致了。有很多东西对我们值得参考，可以说从开源使用、技术形态，运作方式，远远走在我们的前面了。
PaaS平台 目前稍具规模的互联网公司，都会自建数据中心。而互联网的业务又有如下特点：
 业务需要快速上线，唯快不破 业务形态众多，迭代周期快 数据处理量大，海量请求和高并发的挑战  支撑业务的发布，上线，运维，都需要对业务应用的全生命周期管理，各个公司都有一套平台，他们或多或少都能称得上内部的PaaS平台。而PaaS平台核心：
分布式框架 首先是《蚂蚁金服金融级PaaS平台构建之道》分享，阿里在国内技术一直算是走到前列。这次带来的演讲，蚂蚁金服的分布式服务注册中心（DSR），与阿里其它系的Dubbo，HSF都差不多。他们的目标都要解决应用服务化后，服务注册发现问题，可以说是未来PaaS平台中，服务注册发现将成来PaaS的核心中的核心。
后一场听了《主流容器SDN技术与微服务架构实践》，来自七牛的分享。虽然演讲的内容是容器的SDN技术（算不上大范围的SDN），也同时点到微服务架构。虽然他们所讲的容器方案都说是自研的，但整体上感觉与K8S的设计是相似，甚至像Pod之类的概念来也是借鉴来的。在容器环境下的同时也要解决分布式的服务发现问题，他们采用是DNS机制。服务路由上支持L4与L7的负载均衡，对业务无侵入。基于安全组的服务Discovery，虽然没听太明白，感觉跟K8S的Proxy机制是差不多的。
中间件服务 在《蚂蚁金服金融级PaaS平台构建之道》中初步介绍了分布式消息(DMS)、分布式数据源（DDS），分布式事务（DTS）的一些使用场景与技术特点。在云环境下，中间件服务必不可少，让业务应用只关注自己的业务逻辑。中间件服务要面对的是一个复杂、不断变化的计算环境。抽象出业务的公共能力服务化。使用中间件服务，可以简化业务应用在一些通用技术的成本，如数据一致性，安全控制，高性能，可靠性等。而中间件技术正在呈现出业务化、服务化、一体化的趋势发展。高可用性，自管理性，业务适应性是当前中间件服务面临的挑战。
弹性扩展 在云计算中，引入虚拟化技术，采用弹性伸缩是老生常谈了，一键式按需弹性，基于性能采集的自动弹性。听了《微众银行基于自主可控技术的分布式架构实践》，给我对弹性带了新的思考。互联网&#43;的应用是：海量用户，海量交易，海量数据。这要求对系统在架构设计上充分考虑容量的扩展性，性能的扩展性。
微众的架构特点是分布式松耦合架构&#43;一主两从节点强制同步的架构。在分布式松耦合架构是按客户群来水平分割，一个节点上涵盖多个客户业务。分布式多节点是分散风险，如果有节点受损，也是部分客户有影响。而每个节点上又采用一主两从节点强制同步，来提高整个系统的冗余。整个系统以客户为单元可控分布，将客户量、交易频繁度与系统负载之间的关系解耦。随着客户量增加或客户交易频繁度的增加,系统负载也会随着增加：
 横向扩展(Scale Out)解决用户量增加 纵向扩展(Scale Up)解决交易频繁度增加  并且严格要求，横向扩展只能解决用户量问题，不能通过纵向扩展来解决用户量问题，反之亦然。
容灾备份 云计算环境下，容灾备份也是需要重点考虑的，容灾设计强调的是系统对外界环境影响具备快速响应能力，尤其是当发生灾难性事件并对IDC节点产生影响时，能够具备节点级别的快速恢复能力，保障系统的持续可用。像微众介绍IDC2.0中提到的：
 数据库三中心集群化部署 三数据副本强同步 应用多中心多活部署 应用多中心多实例多活部署  蚂蚁金服金服提到的：
 两地三中心 异地多活  支付宝有一个专题《支付宝的高可用与容灾架构演进》，我觉得有意思的是其中的单元化与容灾。单元化应该是微服务化中一种具体运用吧。什么是支付宝的单元化：
 核心业务,核心剥离：数据按照UserID拆分,多机房部署,调用封闭,部分数据,不共享 非核心业务,长尾独立：不能按照UID拆分，核心不依赖长尾  单元化的实现思路：
 水平拆：交易、支付、账务等,每个单元只有部分数据 上层单元化改造：从DB层往上延伸水平拆分概念,包括应用层到入口层  在容灾同步上，是基于单元化的多中心同步，这已打破我们对原有容灾备份的认识，基于单元化的容灾同步，可以细粒度的控制，解决数据一致性和时效性问题：
 基于DB同步的数据复制：延时非敏感业务的异地复制方案;部分业务数据,可忍受3s时效性延迟(比如大部分的配置 数据) 基于消息系统的数据复制：对于延时非常敏感的业务,更低延时的实现方案;上层基于应用进行复制,减少延时。底层 DB主备同步同时进行  高效运维 开发团队快节奏的版本迭代，以及服务的快速上线的要求，驱动着PaaS平台要提供出更为高效的运维服务。高效运维的思路是建立以 应用服务 为核心的管理标准体系。把运维能力服务化(API)，使运维的能力无处不在。高效运维，综合几个公司的介绍主要需要如下几个系统设计：
 发布系统：负责应用服务的上线，应用服务的资源管理，扩容，权限管理，支持Beta发布，灰度升级。 监控系统：通用&#43;自定义监控配置,运维&#43;开发可以时刻关注自己的服务状态和质量。 全链路系统：复杂的分布式系统，一次点击，几十次的RPC调，需要全链路跟踪，出了问题,如何快 速定位到故障点。 限流与降级：限流,Web层,防止被流量打垮；降级,App层(服务化),保障核心应用 容量评估：基于全链路的压测手段、数据分布的模拟方法、关键场景调用量预估 蓝绿发布：即多站点的灰度。具体操作流程：切流（将待发布机房流量切走）-&amp;gt; 机房发布（待发布机房全应用并行发布）-&amp;gt; 引流验证 （逐步按规则引流至100%）-&amp;gt; 流量交换（将全部流程切换到已发布机房）-&amp;gt; 机房发布（另一个机房全应用并行发布）-&amp;gt; 分流还流（分流规则还原，两机房各50%）  服务化 今年IT界是对服务化异常的火爆，系统的稳定和流畅依赖好的应用架构，服务化治理如何规划和落地，是众多厂商系统的痛点。
首先是来自1号店订单系统对SOA化的分享，SOA是一种架构模式,是设计原则,不是技术规范。狭义的SOA：Service化， 标准化、模块化、组件化。广义的SOA：模式、原则、思想。
 Service化：1）分层结构，基础Service不含业务逻辑,只封装基本的数据操作。业务(聚合)Service封装业务逻辑甚至是全部的业务逻辑。2）Service层次调用，上层可以调用下层、下层不可调用上层、同层间可互相调用，调用链长度不超过3级、不循环调用。
 服务粒度划分：1）迷你裙定律。2）细粒度的服务(fine-grained)提供相对较小的功 能单元,或交换少量的数据。细粒度的服务使服务更容易被组装。3）粗粒度的服务(coarse-grained)则是在一个抽象 的接口中封装了独立的业务/技术能力,减少服务请求交互的次数。粗粒度的服务适合更广泛的需求。
  再次是来自Twitter的服务化思路分享：
 单体：牵一发而动全身 分拆：把单体分成多个模块 服务化：把模块按功能服务化 平台化：模块功能中部分服务化为通用服务，通用服务提供一般化服务，平台化  Docker 在不断寻求性能更好、速度更快、成本更低的云计算核心技术中，容器技术是目前最吸引人注意的技术之一。尽管除去效率、速度和成本等方面的优势以外，容器技术还存在一些安全上需要斟酌的问题，但是其实际表现仍然得到了肯定。还是借用其中的分享内容来说明一下Docker。
在遇到Docker之前：
 混乱的环境：Java, Golang, Ruby 混乱的配置：Upstart, authorized_keys, dependency, 各种脚本 混乱的监控：ErrorReporter, Message 混乱的资源：计算资源与预估不匹配  导致的结果是：
 环境不匹配导致,测试跟生产不一致 配置混乱导致事故频发 监控不统一导致运维难上加难 资源效率低导致成本很高却达不到相应目标  而Docker具有如下特点：
 构建快：应用&#43;运行环境 = 镜像 启动快：容器相比于虚机,更轻量级 迁移快：应用以容器的方式标准化交付,标 准化运行  去年Docker主要是在吵作概念，而今年很多的互联网厂商已在使用Docker，本次Docker中都分享各自针对Docker的一些定制化修改及踩过的各种坑，所遇到的困难和走过的弯路。
当然这些坑不是阻当我们不使用Docker的理由，Dockerk只是一个系统架构优化的承载体。来自Coding.net的分享最后总结的比较好，Docker会对软件，流程带入变革与影响，是否采用Docker，系统都需要关注如下三个方面，只是Docker让你不得不关注他们：
 软件架构的升级：微服务、无状态、数据执行分离 研发体系、环境管理理念的升级：容器化、代码化、自动化 资源管理理念的升级：Pet vs Cattle，多留点富余量，迁移能力比压榨能力更重要 </content>
    </entry>
    
     <entry>
        <title>我为什么喜欢GoLang</title>
        <url>http://lanlingzi.cn/post/technical/2015/1113_why_love_go/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Go</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 从8月份到现在，一直在公司尝试用Go写点东西。虽然我们几乎是清一色的Java开发，但我还是愿意在同事之间推广Go，有时间还是学学Go吧。
认识Go 我大概是一个不太执着的语言控，什么语言喜欢玩玩，在大约在12年时，就开始自学Go，但仅仅是看看语法，写写Helloword之类的小程序而已。在13年底，我被抽去分析Cloud Foundry的架构与实现机制。当时的CF是V2版本，其中的GoRouter，HM9000已采用Go重写，另外消息总线NATS也有Go语言版本。而我又重点分析了NATS，HM，以及部分GoRouter的Go源码。发现居然Go能写出如此简练的代码。性能验证时，又发现Go版本的NATS比Ruby版本的强得不是一点点，我们在单板上测试出有50万&#43;的QPS。14年做融合架构，又把我们原有的消息中间件RabbitMQ换成了NATS。当时的出发点主是能与CF通过NATS融合拉通，另外是看重它的高性能。而RabbitMQ是erlang写的，部门熟悉erlang人几乎没有，维护成本高。当然到现在来看，NATS太简单了，并不是个消息队列，很多的特性都没有。 14年的Docker以席卷全球之势火了一把。在15年，我又投入到平台集成Docker的分析，于是又开始了Go语言之旅，重点研究了Docker Distribution的代码，以及由其它部门开发的Index等相关部件的代码（都是基于Go）。自己也是顺便练练手，如把系统中Java的通用加解密库（是基于AES与HamcSHA256之上的封装库），转换Go实现。经测试发现原来在Java对于HamcSHA256迭代6W&#43;次数时需要差不多一分钟，而Go只需要几秒。由于系统需要对接Docker的API，涉及到Http Hijack，于是又得去分析Docker源码中这一块是怎么实现的，把它的实现转换成Java（虽有开源的Java Client API，但不能满足我们的要求）。所以差不多就是干些Java转Go，Go转Java的体力活。整个版本开发中也协助定位一些Docker相关的问题，需要走读Docker代码。整体来说，我写的Go代码不是太多。
曾经的痛苦 C&#43;&#43; 十多年的编码经验,一半是做C/C&#43;&#43;开发，一半是Java。目前还记忆犹新的是，在08年写的一个消息缓存中间件，大量使用了共享内存、内存分片技术、大文件操作，以及缓存淘汰算法（主要与业务特性相关）。原本只是一个消息缓存&#43;持久化，但后来做着做着已不再是一个纯粹的缓存，参杂着业务复杂的逻辑，最终也导致代码质量不可控。一出问题就是踩地址（用于大消息缓存，原本设计是小消息），CoreDump文件分析困难。现在来看，其实如果只是做纯粹的缓存与持久化，Redis也能满足当时的需求，可惜那时开源没有现在这么火，更没有听说有Redis，连Memchached都没有听过。后来在09年与10年，又负责过另一个产品的版本稳定与性能提升。在那段日子里，我与另一个兄弟不知解决多少个CoreDump问题，现在还记得一个踩栈地址的问题整整花了我一周时间，通过猜测CoreDump中的地址信息加上反复走读代码才找到问题的原因。为了压榨单板的性能，在做优化时真是极其语言的偏门用法，尤其是在老的代码上为了发挥并发多线程的能力，代码写得真是惨不忍睹（那时也接触过erlang，发现erlang进程模型是多美好）。目前我司还有很多产品为了提高性能与降低时延，甚至是在内核做了一些修改，如零拷贝技术。这些性能上极致的代码也只能是少数人能看得懂。10年还做一件非常痛苦的工作，就是把跑到Linux上代码移植到Window，主要用于做开发验证仿真工具。即使采用MGWin，也是苦不堪言，其中的困难是谁做谁知道。
Java 10年底开始做云计算，又开始做Java开发（之前也开发过Java，主要是JNI）。使用C开发时，没有什么开源框架可选，但Java的框架是一大堆，J2EE，OSGI，Spring&amp;hellip;无论是哪种，框架都是又臭又硬，太厚重了。大量使用第三方的开源Jar管理也是非常困难。即使我们采用Maven来做工程管理，也是相当的复杂，尤其是对一个大型系统，全编译构建时间都可以与原有C/C&#43;&#43;有得一拼（我之前经历过的C/C&#43;&#43;写的系统，全编译要花差不多一天时间，拿现的DevOps理念是不可想象的），也尝试使用过Maven的并行编译，但由于部分的Mavne插件不支持也放弃了，只能换成多台机器分布式编译。Java运行环境到14年我们才换成JDK8，之前一直采用JDK6，写多了就觉得Java的语法是硬伤，太不灵活，尤其是一堆的Getter与Setter（采用lombok简化），什么都得先定个interface，总之代码看起不是清爽简洁。Java的打包发布更是一个噩梦，虽有Maven管理，但对于一个大型系统，差不多一百号人的开发团队，系统整体打包是差不多2G的压缩包。我们是花了不少时间去清理不同版本的第三方Jar包（公司要求同一产品依赖的版本要归一），每次做版本升级，换一个Jar的版本会牵出一堆的Jar依赖要升级，也是苦不堪言，其中的痛苦是谁做谁知道。经过不断地努力，目前整个团队使用第三方Jar登记还有100&#43;，整体打包差不多1G的压缩包，对于严格的电信行业说，任何第三方Jar包要做内部开源扫描认证，这是一项浩大的工程。在06年做Java时，为了性能比拼，JVM的性能参数调优也是一个非常要有技术的活，吞吐量与时延两者不能兼顾。
再来说Go 缘由 我为什么喜欢Go，最重要的原因是我目前从事云计算领域的研发。总结之前说了这么多的痛苦，对于C/C&#43;&#43;:
 开发效率低，定位问题复杂，对开发者技术要求高 C/C&#43;&#43;偏底层，对系统依赖度高，系统迁移困难 开源框架少，系统API只向后兼容，维护成本高  那Java呢：
 框架臃肿庞杂，反而简单问题复杂化 规范繁多，实现框架也多，选择太多，产品容易被框架绑定 语法啰嗦，全OOP化不灵活  技术特征 当然，无论是C/C&#43;&#43;还是Java，如果项目决策需要，我还是会继续使用他们。他们的成功有他们成功的原因，纯粹的语言比较都有各自的优缺点。我在这也不是为了说喜欢Go而去有意贬低他们，只是列一下个人觉得遇到痛苦。为什么我喜欢Go，主要原因还是它在云计算相关产品的发力，像Google的K8S，Docker，CoreOS，CloudFoundry等等都大规模地使用Go。在学习与使用Go的过程中，被他的设计理念所折服，它是一个面向工程而简化的语言。从语言学上来说，他可能不是最好的语言，但对于大多数的系统，一般都需要兼顾开发效率，运行性能，维护成本。而Go似乎在这几个方面能做到很好平衡。
 开发效率  语法简单，学习曲线低 代码简洁，格式统一 静态类型，编译期检查 内置GC，Runtime期识别 标准库丰富，网络库简单易用  运行性能  编译为机器码，不依赖其它库 语言层面并发模型，可充分利用多核 内嵌C支持，可直接利用C的资产 启动快，执行效率高，内存占用低 标准库质量高，针对性优化  维护成本  没有什么语法糖，高级特性少，格式统一，阅读方便 自带工具链完善，如代码格式化，代码检查，性能分析等工具 默认编译为单个执行文件，部署简单，超赞 标准库跨平台支持，迁移成本非常低   不足 当然Go在工程方面也不是很完美，就目前个人使用经验来看：
 缺少Go工程的依赖库版本管理，尤其是使用第三方开源不好控制（注：1.5引入 go vendor） 错误机制采用返回值，真是满眼的if来判断错误，代码相似度高 接口与实现未分离，对于商用产品，想只提供接口定义来保护知识产权操作不方便 Goroutine调度切换不能由程序控制，需由上层有严谨的设计，维护困难，容易修改出问题  如果你也是在云计算领域，或会从事服务端的应用开发，如中间件，分布式，网络通讯的系统开发，有时间不妨学习学习Go，他简单易学，多掌握一语言，多一门求生技能。
</content>
    </entry>
    
     <entry>
        <title>Mesos与K8S的区别</title>
        <url>http://lanlingzi.cn/post/technical/2015/1020_k8s_mesos/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag><tag>k8s</tag><tag>mesos</tag>
        </tags>
        <content type="html"> 最近经常有同事问道，mesos与k8s有什么不同？平时对k8s要研究多一些，对mesos仅限于一些网上的了解。前一段时间去参加阿里云栖大会，正好也有一场是由于Mosos及Mesosphere公司的人来现身说“法”，听了之后对mesos算了解更深一点吧。 Mesos Mesos是倾向于是IaaS层上的 资源管理器。Mesos不要求计算计算是物理服务器还是虚拟机，只要是Linux操作系统计算资源就可以，Mesos可以理解成一个分布式的Kernel。所以讲师强调DCOS一个OS(阿里云栖讲师的分享)，而不是一个调度器。Mesos只分配集群计算资源，不负责任务调度。基于Mesos之上可以运行不同的分布式平台，如Spark，Storm，Hadoop，Marathon，Chronos等。
Mesos中的核心是DFS，即资源管理策略 Dominant Resource Fairness。Mesos能够保证集群内的所有用户有平等的机会使用集群内的资源，这些资源包括 CPU，内存，磁盘等等。Mesos只做一件事，就是分布式集群资源分配，不管任务调度。Mesos只要你给出CPU、Memory参数就能分配资源，用于你的计算。
Mesos 是一个双层调度器。 在第一层中，Mesos 将一定的资源提供（以容器的形式）给对应的框架或应用程序。在第二层中 ，应用程序将收到的资源进一步分配给内部的任务。但是资源分配器智能化程度不同，mesos是基于resource offer的调度机制，包含非常少的调度语义，他只是简单的将资源推给各个应用程序，由应用程序选择是否接受资源，而mesos本身并不知道各个应用程序资源需求。
Mesos是Apache的开源项目，起源于UC Berkeley的一个研究项目。而背后的商业运作公司是Mesosphere，主要产品是基于Mesos构建的DCOS(datacenter operation system)。Mesos的商用程度很高，在国外的Airbnb, Apple, Uber, Twitter在使用，其中Apple的语音助手 siri是基于DCOS部署，有6000&#43;节点。而国内有携程，爱奇艺在使用。
Mesos与Docker 没有Dokcer之前，物理机，虚拟机都可以作为Mesos的集群节点，引入Docker之后，对资源的管理与分配粒度更细，更能提高对资源的利用率。但Mesos只负责资源的分配，对Docker的调度需要上层的调度器，而马拉松Marathon框架就是解决这个问题。当前Mesos &#43; Marathon 基本上是现在最成熟的分布式运行框架。
K8S 与Mesos最大的不同就是，Kubernetes(K8S)一开始设计是 面向应用的，而Mesos是 面向资源的 。Kubernetes是应用的集群管理工具。它是构建Docker技术（也可支持其它的容器技术，如Rocket）之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。
Kubernetes重新实现了Google在构建集群应用时积累的经验。这些概念包括如下内容：
 Pods：一种将容器组织在一起的方法 Replication Controllers：一种控制容器生命周期的方法（Replication Controller确保任何时候Kubernetes集群中有指定数量的pod副本(replicas)在运行） Labels：一种可以找到和查询容器的方法 Services：一个用于实现某一特定功能的容器组  K8S和Borg系出同门，基本是Borg的开源改进版本，吸收了包括Omega在内的容器管理器的经验和教训，label, annotaion等功能的加入让容器分类检索信息标记管理更加便捷。目的就是将Borg最精华的部分提取出来，使现在的开发者能够更简单、直接地应用。K8S是在Google内部积累发展10年的容器及集群管理专家经验基础上开源实现，有其自身的独特优势来构建容器应用部署、可伸缩可扩展，多平台兼容的容器集群管理体系。可以说，K8S的出现，也是为容器而生。
使用K8S你就能够简单并快速的启动、移植并扩展集群。在这种情况下，集群就像是类似虚拟机一样灵活的资源，它是一个逻辑运算单元。打开它，使用它，调整它的大小，然后关闭它。
Mesos与K8S Mesos与K8S都起源于Borg，Mesos和K8S的愿景差不多，但是它们在不同的生命周期中各有不同的优势。Mesos 虽更多的是侧重在资源管理上。而Mesos&#43;Marathon与K8S存在竞争关系，他们在容器调度编排上有些交叉，后续如何发展，还需要看社区的走向。目前K8S是可以运行在Mesos上。
如何选型  Mesos更适合做跨DC的资源管理，对于大数据领域，大量存在短任务，可以采用Mesos&#43;上层调度器来解决大数据的资源池化调度问题。 K8S更适合当应用的集群管理，它解决大规模应用部署的问题，而它的集群的热升级，动态伸缩，负载均衡，服务发现等特性可以让你的应用的更可靠。 </content>
    </entry>
    
     <entry>
        <title>成都映象记</title>
        <url>http://lanlingzi.cn/post/stories/2015/0926_chengdu/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>成都</tag>
        </tags>
        <content type="html"> 风味十足的四川话，风姿卓然的川妹子，麻辣干香的风味菜，是我是对成都的初步映象。有“天府之国”、“蜀中苏杭”美誉的成都蓉城，在小说与故事中都有耳闻，向往已久。在上高中时，就想报考虑成都的高校，无奈分数不够高，被调济到北方。这次作为招聘技术面试官出差来了一趟成都，了却了一桩十几年前的心愿。
作为面试官，我们必须西装革履，多年的散慢习惯，反而不太适当。我们下榻的酒店，环境与生活还算不错，但是地理位置有点偏，即使晚上空闲下来，也难以感受到成都的气息。招聘其实是个苦差事，连续二天集中的面试时间，已让我有些疲倦。第三天中午面试完最后几个之后，下午忽然空闲下来。秘书说下午面试预约已结束，我们几个来自深圳的同事可以去成都逛逛。 背上背包，一路朝南，寻找成都的古迹。步行街、杜甫草堂、武侯祠，锦里古街，古香古色，即使仿古，也别有风味。在锦里，见到是当地老头老太，倒上一怀茶，四个人摆起麻将旧，忘记的游人带给这个城市的喧嚣。深深的巷子里，不管是一条宽的还是一条窄的，人们总是贪恋的过着闲趣的生活。而我也妄想在某个旧的巷子里头，旧的墙砖缝里，寻找历史的一点蛛丝马迹。
人最大的享受之一就是吃喝。来到成都，自然少不了品尝一下当地的小吃美食。“棒棒鸡”、“怪味兔”、“张飞牛肉”，总是映入到你的眼帘，从一品天下，到锦里古街，还是秘书安排的晚宴，我觉得我想吃的东西太多，但发现只要吃上一种，就有种会上瘾的感觉。即使我带回给儿子的牛皮糖，他也是爱吃得不了。
成都的生活的确是安逸的，哪怕是现在。它始终是一个生活的好地方。也始终是令人憧憬或向往的。回到深圳，望着车流川息，感觉是从一个世界到另一个世界，快节奏的生活，超熬贵的房价，让我们无法去轻触着这个城市的生活轨迹。
</content>
    </entry>
    
     <entry>
        <title>参加CNUTCon全球容器大会感受</title>
        <url>http://lanlingzi.cn/post/technical/2015/0902_bj_cnutcon/</url>
        <categories>
          <category>技术</category><category>感想</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>容器</tag><tag>北京</tag>
        </tags>
        <content type="html"> 由于最近一直在从事Docker相关的工作，所以有机会参与这次的CNUTCon全球容器大会。名字比较“高格”，虽有少量的外国人分享，大部分还是中国的互联网企业在宣传，忽悠。除去这些，整体来说这次大会还是非常不错的，门票也不算太贵，目前看来应该还是值的。我司还是这次大会的钻石赞助商，也说明我们在容器这一块的发力程度。
整体感受 Docker是这这两年成长最快的技术，受到资本市场的热捧。Docker技术以势不可挡地席卷全球。参考这次大会，整体感受是：
 Docker已不再是概念，已进入互联网企业的实际生产环境中 Docker的创业公司多，有远见的想在这次的浪潮中分享红利 大公司借Docker东风，亦想在云计算领域中拿下更多话语权 容器技术处于战国群雄，完整的生态还比较混乱技术栈不成熟   看国外 这次的CNUTCon，居然没有请求正牌的Docker公司，而是请到他的死对头CoreOS，其次还有RedHat，Google，以及Rancher。
第一天的首场分享是来自RedHat副总裁，印度英语原来在公司就听到不少的印度同事，虽说听不太清楚，却有一股莫名的亲切感。由于是副总裁人物，讲的东西也是太High了，主要是分享OpenShift为什么要使用Docker，以及对Docker的认识。可以说在技术上空洞无物，对我来说“然并卵”。过程中的演示貌似险出了岔子。总之，他是来宣传OpenShift。
其次是来自CoreOS产品负责人分享，不过也没有什么干货，可能他对国内Docker技术应用程度还不太了解，还停留在宣传概念阶段。主要讲了两组项目：一个是Chubby&#43;Borg，之后是etcd&#43;k8s。并分别对比了Chubby以及etcd，最后是基于etcd的使用演示，Demo放到了Git上。只能说这个Demo是对etcd相当的入门级。总之，他是来宣传etcd。
可以说，第一天的两场分享，其实跟Docker，或容器技术关联不是很大，看来InfoQ请错人了。
第二天的来自国外的分享，有Google的华人美女工程师分享了“Kubernetes和Borg的设计哲学”。这一场还是不错的，虽也是比较High Level的介绍，不过让我这种屌丝有机会了解一下Google十多年前就开始的容器管理理论，感觉是真是简单实用：
 declarative &amp;gt; imperative Control loops Simple &amp;gt; Complex Modularity Legacy compatible Network-centric No grouping Cattle &amp;gt; Pets Open &amp;gt; Closed  再次是来自Rancher Labs的秦总分享的“Rancher Labs 企业级私有容器服务平台解决方案分析”，并且他还跟我一起在现场的另外一个同事是之前的同事。干货比较多，演讲者虽说不懂技术，但Rancher给我带来是思维，尤其是后面介绍的“RancherOS”，在会场没有听太明白什么是“Dockerized OS”，后面查询一些资料，发现它除了内核之后，PID1就是Docker，其它的系统服务都Dockerized，并且在发行包的大小做到了极致，只有20M。能把Linux的系统服务通过Docker容器来管理，不得不说这这一项不错的创意，如果能实现应用在生产中，这不知又会对Linux产生什么样的深远影响。
小结 由于只有四场，OpenShift与CoreOS是来做广告，我也曾经想在OpenShift免费空间上搭建Go的Web环境，发现真TMD的难用，OpenShift又想借Docker打个翻身仗，PaaS本身的体验不解决，Docker也“然并卵“。而CoreOS在容器中扮演着是一个搅局者，对防止Docker一家独大是益的，但它的RKT差不多落后Docker一年半，但是ETCD还是不错的。
Google是老牌的容器使用者，他在这一这方面的经验可能是最具有发言权的。他也乘着Docker之势，迅速摧出K8S。并极力去构建Container Orchestration，ContainerInfrastructure，ContainerManagement的生态。虽说K8S目前还是很成熟，但在未来在容器界K8S必定举足轻重，甚于可能是Container Orchestration的事实领导者。
看国内 在国内，自然少不了BAT，以及后之秀京东。商业的成功驱动他们在技术上必定走在前列。第一天下午几场都使来自大厂的分享。
首位是京东云平台的分享，京东最初的希望是通过一个平台，将物理机，虚拟机，容器，三种资源统一管理，随后的演化中，容器逐渐成为了一等公民。一种是容器直接在VM上，一种是让VM看起来像容器。开始是采用“胖容器”的模式，这一思路与我们的不谋而合，首先是要把容器使用起来，不管它是容器还是虚拟机；再次是业务的纯容器化。如何把容器中融合到已有系统中是目前大家遇到的最大挑战。
其次是来自大众点评的分享，同样对容器的使用，也是使得容器看起来像虚拟机。重点介绍了在网络方面的经验，如通过新创建的br0网桥与eth连接，使得docker 容器可以有自己独立的IP。最后也分享在使用容器过程中一些坑。
再次是阿里百川的TAE Docker全架构分享，干货是相当的多，信息量是相当的大的。Docker只是TAE中非常小的一部分，目前还是把Docker当做工具来用，重要介绍不是为了Docker而Docker，Docker并不等于容器。在实践的过程中，Docker的优势，基于Docker的全架构的PaaS平台，才兼具IaaS的灵活性和PaaS的易运维性。其实也说明Docker技术拉低了云平台的技术门槛，像原有的IaaS只有大投入才能玩得起，而Docker让你使用云资源变得更轻捷。
再次是也来自腾讯的在游戏上，Docker实践：现状、经验及展望。其中有意义是在网络上的改造，目前Docker在网络上是很弱的。像点评一样，不得不面对网络打通的问题。一般来说，游戏业务的生命周期长短不一，这需要弹性的资源管理和交付。相比于虚拟机，容器更加轻量，效率更高，资源的交付和销毁更快。可能说像Docker的应用可对针对游戏业务提升资源的利用率，降低运营成本，也是Docker的魅力之一。
第二天是来自百度的分享，感觉百度对于容器的实践比较牛逼，在docker没出来之前，他们就学Google都着眼于容器技术了。对于大企业来说，在资源调度上面对的困难是如何错峰填谷，如何将服务与机器解耦、预算调度，资源精细分配，统一池化，如何解决混合部署带来问题。而基于容器技术构建的Matrix平台，直接是在cgroup （划出一个资源框）namespace（内部的话只需要部分）的基础上定制操作。再通过agent来把这些所谓的“容器”启动起来，架构上有统一的container操作接口。其次是百度对于容器的安全性也有了很多实践，其实所说的安全性就是让容器上的代码不会跳到主机上去，让host上的代码不会逃逸出去。分享的内容很多，整体来说，百度应该是在国内互联网企业研究容器技术比较深的，而不仅仅是Docker的简单使用。
小结 大公司的docker实践更有发言权，实际上他们对于docker的实践才是真正切合实际的，在实践过程中也是对于原有业务的相关性迁就比较多，不是为了容器而容器。各个公司解决方案，定制的过程，玩法，基本上是各有各的招。如遇到的网络的改进，渐进式的使用，某种程度上把docker当成虚拟机的来用。究其原因，还是因为业务解耦，平台自由，容器化的过程并没有那么简单。
看编排调度 这次会议上有几个都在分享K8S，Swarn的技术。由于一直关注K8S，我只是选择都听了一下。谈到K8S，大家都要说说mesos swarm，对比一番。后也听了我司的线超博对Swarn分享。整体来说，像K8s这种，还是理念较新的技术，大公司没有看到一个在采用，一是它出来太新了，二是在性能及稳定上存在问题。只有新创业的一些公司，赶上打着这些的旗号。一些散户玩玩还行，但对一企业级的业务，如何彻底地服务化，如何灵活地容器调度，原有业务如何契合，明显还有很长的路要走。而swarm更是不适合在生产环境中使用，并且docker公司想一家独食的原因，又要在编排上分一怀羹，目前大家都不看好它。另外swarm在设计上缺乏集群管理的视角，也难以在生产环境中发挥调度的优势。个人认为K8S在编排调度上会完胜Swarn。
</content>
    </entry>
    
     <entry>
        <title>配置与定制</title>
        <url>http://lanlingzi.cn/post/technical/2015/0813_cfg_vs_cus/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 作为一个软件人员，我们会经常遇到各种各样的需求，有时为了避免定制，通常的做法是提供更多的配置选项，以通过配置出满足不同的特定需求。
原因是而当你开发定制代码来修改或扩展一个功能需求时，有可能会导致软件不能正常的工作，必须通过严格的测试与验证。在重大的版本升级情况下，定制是苛刻的和耗时的。甚至会面临无法修复的功能可能会被重构，从零开始。因此，一些做法是通过采越来越多地选择配置，来解决由于开发定制代码引入的问题与软件带来的成本。
因此配置与定制之间的区别是：
 配置：使用现有的数据来配置系统以满足您的业务需求 定制：将定制或使系统适应业务需求，涉及到定制开发流程。   作为一名开发或设计人员，重要的是要了解不同的配置和定制的区别，差异的关键是复杂度。配置使用的软件具有固有的灵活性，如添加字段，更改字段名称，修改下拉列表，或添加按钮。配置是使用强大的内置功能集。而定制是包括代码更改以创建出不可通过配置解决的功能。定制可能是昂贵的，并且可能会使软件的升级复杂化，因为由于代码变更可能不会很容易迁移到新版本。像“修改”或“扩展”往往意味着不同的东西，存在不确认的风险。
要避免定制，提供的一些配置工具并不总是一个较简单的选择。但这些配置选项如何配合业务运行时，也会让运维人员无所事从，太多的配置选项最终变成谁也不敢去使用，因为无法去评估配置带来的运行期的影响。一种方式是提供向导驱动的配置，但同样面临没有在初始部署时掌握他们的细节和晦涩深奥的设置。
</content>
    </entry>
    
     <entry>
        <title>微服务与SOA</title>
        <url>http://lanlingzi.cn/post/technical/2015/0516_microservice_soa/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件开发</tag><tag>微服务</tag>
        </tags>
        <content type="html"> 我司学习一个新的技术，往往是搞得轰轰烈烈，比如数字化转型，向互联网技术学习。其中一个非常重要的方向就是学习互联网的服务化体系架构。国内的阿里，京东，腾讯在服务化，确切地说是微服务应用取得非常大的成功。而国外的Netflix的微服务架构更是成为我们必定的样板教材。你做设计，谈方案，不说说微服务都不好意思。如果你不说这样，说明你思维落后陈旧了。任何一项技术都有一段疯狂期，虽这近一次在搞架构重构，领导遇到你，总是关心地问到：“服务化进展怎么样了”。甚至还得跟一些不太懂的领导解释什么是微服务。
10年前差不到了SOA也像今天的微服务一样火爆。那微服务与SOA的关系或区别是什么？是不是SOA的旧洒换新瓶？软件界的大牛 Martinfowler的《微服务》更是像一部微服务的圣经，无奈是E文，大家都有各自的理解。在我司更是大家对这个各抒己见，谁都可以说上几句服务化的原则是什么，微服务成了领导专家们口里的口头禅。如果我们的系统不是微服务化，都怀疑我们系统的先进性。想当初，大家也都谈SOA，也极力推广SOA。似乎到了今天，微服务与SOA两者是势不相容。SOA是传统的IT架构，而微服务是当今互联网架构，微服务似乎比SOA更“逼格”。甚至这样的争论成了不同兄弟的心头痛。 那先来看看Martinfowler怎么说的：
 微服务风格也与SOA所提倡的一些优势非常相似。尽管如此，问题在于SOA意味的太多不同的东西了，因此通常时候我们谈的所谓“SOA”时，它与我们谈论的风格不一致，因为它通常是指在整体风格应用中的ESB。
 从试图使用ESB隐藏复杂性，到集中治理模式抑制变更，这种面向服务的风格是复杂的，没有ESB什么都不是。互联网的发展，利用简单的协议方法，让它从这些经验传达的出来。可能说对SOA集中式标准中的一种反模式，而SOA需要用一个服务来管理你的所有的服务，你就知道这很麻烦。
 SOA的这种常见行为让微服务的提倡者拒绝打上SOA的标签，尽管有人认为微服务是从SOA中发展而来的，或许面向服务是对的。无论如何，事实上SOA表达这么多的含义，它给一个团队清醒的认识到这种构架风格就已经值的了。
 至少Martinfowler在面向服务体系中，微服务是从SOA发展出来的，只是大家受到SOA的伤害而不太愿意打上SOA的标签。他们本质与出发点是相同的。微服务是细粒度的SOA，你不用去关心“庞大的”ESB，也不用去熟悉大堆的WS-*术语。当服务变得微小（micro）时，服务可能是由规模恰当的团队（12个人）制定的，也可能是单个人制定的。
我们没有办法对微服务进行准确的定义，怎么去划分服务，什么算是微服务？两个比萨能吃饱的团队（12个人）也说得太抽象了，在面对具体的实践来说，到底怎么才是SOA中微小服务，我们又如何去分析与设计？以为团队中的成员能力来划分，学是以业务功能集来划分，再去组织团队？这些问题都是我们在实践中面对的挑战。
微服务架构中的“微”体现了其核心要素，即服务的微型化，就是每个服务微小到只需专注做好一件事。 这件事紧密围绕业务领域，形成高度内聚的自治性。
微服务架构强调“微”，与之前有些采用了SOA服务化架构思想的系统搞出很多胖服务来说，一点也不微，这依然带来耦合。 这一点只能依赖系统架构师的服务化建模能力了，但微服务架构强调每个服务一个进程， 使用进程为边界来隔离代码库至少让同一应用系统不同层次的开发人员享有自己完全自治的领地，每个微服务都有一个掌控者。
《Building Microservices》一书对实施微服务架构有系统性的描述和很多业界案例的简单引用描述，这里不展开讲实施细节，那样就太长了。简单总结下实施的要点：
 自动化文化与环境：自动构建、自动测试、自动部署。 围绕业务能力建模服务，松耦合、高内聚、暴露接口而隐藏实现细节。 服务协作模型：中心化（乐队模型：中心指挥）和去中心化（舞蹈模型：群舞自组织），各自场景不同。 服务交互方式：RPC/REST/WS 技术很多但考虑统一。 服务部署：独立性、失败隔离性、可监控性。 服务流控：降级、限流 服务恢复：多考虑故障发生如何快速恢复而非如何避免发生故障。 服务发布：灰度。 服务部署：一服务一主机模型，需要虚拟化(Hypervisor)、容器化(LXC, Docker)等技术支持，实现硬件资源隔离。 服务配置：中心化配置服务支持 康威定律：任何设计系统的组织，最终产生的设计等同于组织之内、之间的沟通结构。系统架构的设计符合组织沟通结构取得的收益最大。 伯斯塔尔法则：服务健壮性原则 —— 发送时要保守，接收时要开放。   注：部分参考 《微服务架构实践感悟》
</content>
    </entry>
    
     <entry>
        <title>架构重构</title>
        <url>http://lanlingzi.cn/post/technical/2015/0430_arch_refactor/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件架构</tag><tag>软件重构</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 最近一直在做系统架构上重构工作，理论不能不学习啊，只有在思想上把自己武装起来，才能减少我们工作上的错误。之前参加过或亲自操刀过多次的代码局部或模块重构，但这一次架构重构是范围波及最广，收获颇多。
什么是重构  重构是指在不修改代码外在行为的前提下，对代码做出的修改，以改进程序的内部结构，提高其可理解性，降低其修改成本。
 这是来自马大神的《重构》一书对重构释义。重构可以改进软件设计；使软件更容易理解；使软件更容易维护；帮助找到软件Bugs；帮助提高编程效率。重构按对系统修改的粒度层次可以分为如下：
 局部代码重构，操作与实施比较容易，《重构》一书中介绍了大量经典的方法。 模块级代码重构，可能涉及到模块之间的接口重构，操作与实施难度相对适中。 架构重构，是对整个系统架构层次的重构，牵系相当的广，操作与实施难度比较高。   重构风险 无论何种层次的重构，都必须要有一个可靠的测试环境，即自动化测试环境。因为频繁的代码修改可能会引入更多的缺陷，只有执行自动化测试并回归所有用例，才能保证及时发现这些缺陷，最大限度地降低重构的风险。
 局部的不良代码，可以通过小范围的重构来优化。但是对于架构上重构，因为重构影响范围过大，在实践中仍然存在绪多的困难。 架构上大的重构，至少几十人的投入，更需要半年到一年的开发周期。在老软件不能停止维护的前提下，这对开发人力将产生巨大冲击。 新架构虽然先进，但历史经验表明，新软件的成熟与稳定需要时间。在沉重的交付压力下，风险需要做很多的预防控制。  为什么要重构 给老大说明重构的意义往往很难，尤其不是技术出身的管理者，即使是，也需要面临交付上的考虑。从技术上讲，为什么要重构：
 不论如何先进的软件架构也不可能预见到几年甚至十几年后的需求，并预先设计 随着新功能的不断增加，以及新成员的加入，软件架构必然逐渐腐化 虽然强力的架构看护制度可以延缓架构腐化的速度，但不可能看护到实现细节 重构则提供了软件持续优化的机会，从而使软件更容易适应新的需求，同时及时地改进不合理的部分  重构与重写 对于一次重构来说区别不大，只是力度不同，重构侧得局部优化，也会重用现有的资产，重构的极端就是重写。他们的主要区别是重构强调的是持续的，随时的优化，而重写强调的是一次性的天翻地覆的改造。那我们如何判断是要重构还是重写？
 重构是持续的，并不是等到极端恶心才开始优化，所以坚持持续的重构可以代价更小的达到优化的目的 若已经极端恶化的模块，重写也是一种解决方式，但要注意避免失控，须在设计、测试、管理、人员能力等多方面要做好准备  何时重构 何时重构，因项目因人员能力而异：
 不同粒度层次的重构，重构的时机选择应该是不同的 不同粒度层次的重构，实施的节奏也必然不同的 关键技术需要提前原型验证，风险评估 对于模块级，架构级重构，通常在添加新功能或特性之前充分考虑，留出部分空档期来重构 制定重构计划，步步为营，切忌全面开花，导致风险不可控  同时在重构时，需要平衡重构与交付：
 为了交付而不重构，是恶性循环，最终交付的压力会越来越大，质量会越来越差 对于模块级，架构级重构，应该是有计划地落入到迭代版本中 可以采用冬虫夏草的方式重构，逐步重构或替换，随时（至少每个迭代）可以保证系统的完整性 注意控制每次迭代重构的范围，要分析并划分合理的重构边界  重构人员 重构最终落实还是人员能力，对于参与的人员能力要求：
 知道重构的意义，重构需要有个人强烈的意愿，才能有所突破 对现有的组件流程与实现非常地清楚 针对性强，能够熟练地运用各种重构方法 能够察觉出实现的问题，能提出改进（重构）建议（方案） 经验是基础，对构架本身的体系有较为深厚的理解和应用经验 不同层级的重构，需要不同的参与，不同阶段投入  重构中有哪些角色，他们职责是什么
 SA/SE（系统架构师，系统设计师）：负责按照架构正确地设计与分解需求，能清楚系统中的痛点，以及各组件的主要问题 SE/MDE（系统设计师，模块设计师）：负责某个组件整体看护，设计组件内疗实现机制，系统约束等 SWE（软件工程师）：在软件架构的基础上，负责具体的功能实现。 TE（测试工作师）：补充用例，执行自动化测试，及时发现系统中的缺陷，并与SWE结队处理问题。  总之，重构要务实，务实就是尊重现实，基于现实情况分析与实施，不断地推进演化。架构重构不仅需要充分的设计，切实有效的重构操作方法也非常地重要。架构重构，抛开代码搞理论上的重构不行；充分利用代码，但又不能掉进“代码泥潭”。无论怎么重构，一定要构建夯实的测试防火墙，快速反馈重构中的问题。
</content>
    </entry>
    
     <entry>
        <title>OSGi的缘起缘灭</title>
        <url>http://lanlingzi.cn/post/technical/2015/0422_remove_osgi/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>OSGi</tag><tag>软件开发</tag>
        </tags>
        <content type="html"> 什么是OSGi 维基百科：
 OSGi（Open Service Gateway Initiative）有双重含义。一方面它指OSGi Alliance组织；另一方面指该组织制定的一个基于Java语言的服务（业务）规范——OSGi服务平台（Service Platform）。
 我们所说的OGSi，通常讲的是Java语言实现的OSGi，但也是有其它语言实现过OSGi，由于没有Killer应用，几乎是无人知晓。
2003年Eclipse选择OSGi作为其插件的底层运行时架构。Equinox project对该理念进行了实验，2004年6月在Eclipse3 R3中发布。Eclipse的成功让人认识到OSGi的优秀与魅力，也把OSGi带到众多的程序员面前。 缘起 正好10年底开始转型做云计算，当时选型的开发语言是Java，这没有错，看看目前Java在云计算中应用程度，说明我们是选对了。同时我们也选型开发框架。我当时受到Eclipse的基于OSGi的插件机制成功影响，是极力推荐使用OSGi的。当然最终决策采用OSGi的不是我，但我的确在其中起了摧动作用。当时采用它的主要原因我想有如下：
 模块化，模块之间基于服务接口通讯。 插件化，Bunlde可以动态加载。 组件化，面向服务的组件，组件由多个服务组成。 生命周期管理，相比普通Jar包，我们可以更细粒度的管理 &amp;hellip;  我们使用OSGi，采用两种框架，一个是Apache的Felix，使用它主要是看重它很小，用于开发主机代理，在其上开发各种采集插件。一个是Spring的Spring DM，即后面的Eclipse Virgo。使用它主要是看重它集成了Spring，用于开发后端服务，采用Spring DM来简化OSGi的服务发布与引用，以及能较好地使用Spring的其它能力。
可以说从11年到14年，我都是在基于OSGi做开发，从早期喜爱到最后的放弃，个中的滋味真不知怎么说。期间我在整个团队做了不少关于OSGi的推广，写过些文档介绍，规范要求，定位过稀奇的问题，最后大家都觉得我是这一方面的专家，只有搞不定的问题就来找我，我才逐渐意识到OSGi的理念虽好，但要真的把它使用得很好，真是不简单啊。
OSGi虽解决了本地的服务访问的问题，但云系统是一个分布式的系统，所以在后面又折腾过DOSGi，使用是的CXF实现的DOSGi，这个更难使用。先只有少数一两个服务在尝试使用它，期间遇到的问题更多，最后也不得不在13年初就放弃了。我不得不搞出另一个RPC的框架出来。
缘灭 在去年的时候就开始讨论是否去OSGi，连最早鼓吹使用OSGi的阿里，也花了很大精力去OSGi，不过他们的动作早在12年就开始了，Spring也在12年摒弃OSGi，把Spring DM捐献给Eclipse。我们更是受项目进度与人力不足限制，去OSGi也只是停留在讨论中，有点“不破不修”的意思，OSGi凑合着使用。
15年软件界最火爆的两个词可能是：微服务，Docker。去年平台定位发生变化，从偏IaaS转型偏应用的PaaS，原有的架构存在些问题；而今年的微服务概念也直接点然了系统架构重构的火把，而我又是这次架构重构实施落地的组长。这真是有点戏剧性啊！“出来混迟早要还的”，当初我是团队中使用OSGi的带头人，今天又是团队中OSGi的埋葬人。老大们要求我们把架构重构，目标是系统解耦合，轻量化，利于团队分工。自然去掉OSGi，朝分布式微服务化演进在设计考虑的范围中。的确，微服务化与OSGi也不冲突，为什么要去OSGi呢：
 OSGi的门槛太高，学好用好它对程序员要求高，而团队新人比例高 很多第三方组件不是Bundle，需要Bundle化，增加维护成本 使用到其它部门的中间件也宣称不支持OSGi，越来越处于孤立 多版本管理问题，在同一套环境中，相同的第三方Jar存在多个版本，版本无法归一，增加维护成本 基于OSGi的服务接口测试难度高，LLT测试时依赖于OSGi环境，测试成本高 OSGi的服务接口只是本地接口，而云计算中恰恰需要分布式服务调用框架 ClassLoder问题，导致很多的开发兄弟考虑不足出问题，经常是运行期抛ClassNotFound Virgo， Felix其实也很重，多个组件部署在同一套环境中，隔离性差，不适合微服务理念 Bundle的动态替换就是伪命题，从来没有用过 用于做插件机制，动态加载的ClassLoder问题 JRE在Virgo环境下会出现死锁，需要升级JRE到8才能解决，还不知会有其它问题，社区支持不足 大环境下，OSGi已成明日黄华，不再是宠儿 &amp;hellip;  从上面可以看出，OSGi的面向接口编程，服务化，模块化理念在单体应用来说虽不错，在面对分布式的应用时，它带的益处远比它的本身的机制带的问题更多。所以OSGi留得越久，越是技术债务，早去掉早解脱啊。
</content>
    </entry>
    
     <entry>
        <title>软件开发中缺陷管理</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0901_soft_dev_dt_trace/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 在我司，我发现大家很擅长把一个东西到极致，但极致可能是过犹不及了，例如测试并不是发现越来越多的Bug就越好，如果把很多的时间消耗到一些不重要的点，反而不可取，软件只要你去测试，怎能发现一些Bug，如要面对这些就非常纠结。作一名开发，说这话肯定会被一批的测试人员拍砖死了。在此表达一下不同的观点，不一定正确，请轻拍。
在我司的各种度量工具很牛X，缺陷跟踪分析每个迭代阶段就会做，形成一些报告。对于软件质量来说，统计所有过去的Bugs是没有多大用的，相对来说，一些更实际的工作可能更重要，在Douglas Hubbard的《How to Measure Anything: Finding the Value of Intangibles in Business》(如何衡量任何事：寻找商业无形资产的价值)中，把这种现象解释成衡量倒置(Measurement Inversion)：衡量一个东西的经济价值与它通常所受到的关注度多少成反比。 一种较有说服力的观点是缺陷跟踪方便人们发现缺陷的趋势，对流程的改变很有一些效果，如提前做些缺陷预防。对于管理者来说，他们需要缺陷跟踪报告可能了解软件的质量状况。但可能实际却不是这样的，单单根据DI值来判断软件质量，这跟由湿度来判断天气是否好坏一样不太靠谱。
质量是什么，尤其是软件的质量是什么？是看软件的缺陷率吗？比如我现在比较喜欢荣耀手机，我会关注荣耀手机DTS中的单有多少吗？在消费者的眼中，质量就是对他有价值的东西。如果客户是快乐的，存在一些漏洞也是问题不大的。如果客户抱怨，跟有多少Bugs是无关的。
前几年在摧广敏捷时，提到做刚刚好的系统，也提到了零缺陷：符合已确定之要求，一次做对。第一次把正确的事情做正确，包含了三个层次：正确的事、正确地做事和第一次做正确，三个因素缺一不可：
 正确的事：辨认出客户的真正需求，从而制定出相应的战略。 正确地做事：软件开发中所必需的全部活动都符合客户和市场的客观要求。 第一次做正确：防止不符合要求的成本产生，从而降低质量成本，提高效率。  什么是软件的缺陷，在软件程序中存在任何一种破坏正常运行能力的问题，都可能叫作缺陷，Bugs。但生产软件的最终目的是为了满足客户需求，如果以客户需求作为判断软件质量的标准，软件的缺陷可以包括如下几个因素：
 软件未达到客户需求的功能与性能要求； 软件出现客户需求不能容忍的错误； 软件的使用未能符合客户的习惯或工作环境。  软件测试其实并不只是要发现问题，如果我们进行非常变态的测试，的的确确能发现很多的问题，但是有可能此类问题根本不可能出现，或是在软件生命周期内也永远不会出现，没有这么复杂的使用场景。在做异常测试，虽然一定要以发现缺陷的心态挖掘测试，但也不应该是一种无所欲为的测试。还好，公司已积累了不少的故障模式库供参考分析。但是像可服务性，可维护性，易用性应该做到什么样的程度却在实际项目操作中很难把握。任何缺陷的修改都是有成本的，一旦控制不好，可能把有限的精力都浪费在不重要的点了，这也是开篇所说的过犹不及。
测试人员认为某种情况是缺陷，但开发人员认为又不是，而现实就是所争议的情形在需求中也没有明确地描述。公说公有理，婆说婆有理，说不清，道不明的。开发与测试的争执由此开始，矛盾也由此产生，不和谐的气氛由此理下种子。出的原因可能有多种：
 需求澄清不清，需求描述太过于简单，离最终的客户又远。 对于原始需求没有进行评审，整理，并书面化归档。其实需求文档也要测试验证的。 开发与测试存在理解上的偏差； 需求本身的定义存在二义性。  面对这种问题，无论开发与测试人员需要知道：
 要知道任何的争论解决不了问题，争论不要存在个人感情色彩(其实这个很难做到)； 出现问题，首先从自身找问题，有时往往是因为我们的简单思维导致。 人非圣贤，有错就改，并不失面子。讨论对事不对人。  可能在很多的部门，把缺陷做为开发或测试的绩效指标，这种简单而粗暴管理，直接的结果就是让开发和测试从此不和谐，彼此斗角。要相信办法总是比问题多，每一个问题都有至少一个解决的办法，愿开发与测试都能朝同一个目标，把软件做到刚刚好，事成人爽。
</content>
    </entry>
    
     <entry>
        <title>软件开发与中医理论</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0804_soft_dev_tcm_theory/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag>
        </tags>
        <content type="html"> 最近一段时间，看了些的版本迭代开发数据。有CI中QDI，FindBugs，重复率，复杂圈度；也有迭代的Story实现率，IR分解率，DI值;也有测试用例，覆盖率，执行时长，入门用例比等。反正各种度量数据多得是，从各个方面来反馈项目的质量。俗话说：有人的地方就有江湖。有江湖的地方就有纷争。有度量数据就有晒马排名，有排名的地方就有政治任务。我们的流程辅助度量工具多了，但这些真能带动我们的质量上去了吗？
小儿已一岁多，现在回顾他做的一些体检。前三个月每月一次体检，一岁之前每3个月一次，一岁之后是每6个月一次。体检的项目有称体重、量身高、量头围、量胸围、验视力、测听力、检查动作发育、口腔检查、评价智能发育、验血、骨骼检查、心肺与心率检查、大便和血红蛋白。体检医生一上来就是开各个体检单，采用是西医的方式，看指标数据，再评测，体检应该是医院最好的生财路之一。个人也明白，正如我妈说的，我小时候哪有什么体检，也不是好好的吗？现在带小孩去体检，也是图个安心，提早预防。 那说这些跟软件开发有什么关系？西医是基于实验科学，从实验走向临床，再到应用，它关注对外界变化的认知，比如发现了细菌，就有了抗生素；发现了病毒，就有了疫苗；发明了人工心脏，就可以做植入心脏。西医的研究对象是外界。强调对症下药，看的是病。而中医以阴阳五行为基础，将人体看到气，形，神的统一。聚焦于人本身，就是人的经络，阴阳，五行等。通过中药、针灸、推拿、按摩、食疗、拔罐等多种手段来达到人体的阴阳调和而康复。强调调和平衡，看的是人。西医通过相同的病因数据，药物使用可能复制到不同的人。而中医需要通过医生的非常经验，开出不同的药方。所以年纪越老的中医越是历害。
现在的软件工程，也似乎像西医一样，试图通过固化流程，工程手段，指标数据来统一所有项目的开发。典型的是CMM，它关注项目本身，往往忽略了项目中的人。一个C版本三个月，我们个人并没有在这短短的三个月里边发生什么实质性的变化。一个本来连计划变更都要审批，还要被QA严格审计的受控团队，有时又变成一个居然可以什么都自己估算，和中途临时领取需求任务的自组织的团队，不可不谓一个相当疯狂的举动。最后项目管控就看是各种指标数据，个中变化指标能看到什么呢？即使各种指标细化，能真实的反应项目的实情吗，这要大大地打个问号了。也有人会说，数据好的项目并不一定好，但数据差的项目一定是不好。好吧，我认这一条。
外界的敏捷开发，应该是强调项目中人的本身吧，快速适合各种变化。管理以人为本，时刻进行相应的调整，尽可能地发挥个体的能力。一个被各种指标数据盯着的团队能放下这些，快速适合变化，快速响应客户的需求吗？软件的开发过程也不可能固定不变，因人而异，因项目而异，一两种软件工程学能搞定所有的项目吗？
</content>
    </entry>
    
     <entry>
        <title>做一名好的开发人员</title>
        <url>http://lanlingzi.cn/post/thoughts/2014/0729_better_developer/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 我在上一次的新员工交流会议上，问新员工对全栈工程师了解不，我们的目标是成为一名全栈工作师，而不是做一名只会写代码的码工。最近遇到一些不开心的事，可能是在华为呆久了，发现到底都要会学扯皮。而我性情不太喜欢做一些自认为这些是无意义的事情。虽然有前辈告诉我，扯皮可能的效果会让你少加班几个月。说着说着，有点偏了，扯皮其实是沟通成本。项目越大，沟通成本越高。带个项目的人都会意识到，项目中的人力是1&#43;1&amp;lt;2的，人越多效率越低。因为沟通是需要成本的，不同技术的人各说各话，前端和后端是一定会掐架的。每个人都会为自己的利益而战，毫不为已的人是不存在的。
减少沟通成本，我们需要全栈工程师，因为各种技术都懂，胸有成竹，自己就全做了。即使是在团队协作中，与不同技术人员的沟通也会容易得多。懂你的，你懂的，相互理解，也就少了很多的时间在扯。 那什么是全栈工程师：通俗地讲，掌握多种技能，并能利用多种技能独立完成产品的人。打外比方，全栈工程师就是一个能独立盖一幢10层小洋楼的人，而普通工程师，则是可以和一群人盖一幢摩天大楼的人。较搞地讲，全栈工程师=**丝战斗机=系统&#43;网络&#43;研发&#43;DBA&#43;架构&#43;安全=没女朋友/没男朋友，拿一份工资做三份事情，公司的奋斗者，其它人眼中的牛人，傻X。有人说了，你再牛X，你懂五种技术，你能干五个人的活吗？全栈工程师并不是说一个人能干几个人的活，而是要从多个方面来看这个问题。
我们遇到了什么问题？产品在报怨平台；开发在报怨SE没有搞清需求，规格写得不清不楚，不了解系统实现；测试在报怨开发，问题太多，Story写不好，自测试不充分；开发在报怨测试，不了解系统，机械提单，单的质量低，场景不符合业务。听多报怨，人也会变成急躁不安。心平气和，放下争端，谁都想开心上班，开心下班。报怨也是解决不了问题，反而是有摧卸责任之嫌。
那在华为，全栈工程师能解决上面的问题吗？不能！首先，在华为，细化的分工很难培养出全栈工程师，那你还提全栈工程师有什么用。一名的好的开发者，能缓和一些项目中的扯皮矛盾。好的开发者，即使不是全栈，也要融会贯通多种技术。我从来不认为一个只专精一种技术的人有可能成为好的开发者。从广度和深度的组合看，我认为好的开发者大概有两种类型：1)手术刀;2)代码专家(来自《人月神话》)。手术刀是业务驱动的，最需要全栈的人；他们的核心价值在于：懂业务，技术全面，都能拿的起来，而且能选择最合适的技术。代码专家是技术驱动的，即使不够全栈也可以用，但是技能树点的越多当然有好处。
如果你现在是一名开发，那我如何做。而在技术选择上以“关注商业目标”和“关注用户体验”为原则。脱离商业目标的技术都不会得到长期的认可，脱离用户体验的产品终究被淘汰掉。在华为，你做一名开发，首先要主动关注前期需求分析。发现问题，洞察需求，才能设计出实现方案，最终的实现也不太大的偏离。我一直比较反感我们想需求，觉得应该是这样的。或者做些用户根本不会使用的需求。但现在组织结构决定了我们不能向客户靠近太多。那我们能做的就是多与SE讨论，规格是一种载体，把问题讨论清楚，澄清准确是关键。开发也要意识到需求分析，设计不仅仅是SE的事。不懂设计的开发也不是一名合格的开发。
吃自己的狗食。真正的工程师是能真正明白软件开发不单单只是编码，还更要明白整个软件工程。只明白或是只喜欢编码的，那只是码农，不能称之为工程师。程序员要干几乎有的事，从需求分析，设计，编码，集成，测试，部署，从头到尾。如果你不能切身体会到自己干的烂事，自己的痛苦，你就不会有想要去改进的动机。没有痛苦，就不会真正地去思考，没有真正的思考，就没有真正的进步。
学会测试与体验。只有了解了测试的难度，你才明白怎么写出可测试的软件，怎么去做测试的自动化和测试系统。只有自己去使用自己的系统，你才明白用户的反馈，用户的想法，和用户的需求。开发如果都不知道怎么做测试，那还能期望测试能帮助你测试？开发人员本来就要测试自己写的软件，如果开发人员不懂测试，或是对测试不专业，那么这就不是一个专业的开发人员。开发人员了解整个软件的设计和开发过程，开发人员是最清楚应该怎么测试的，这包括单元测试，功能测试，性能测试，回归测试等。开发人员知道怎么测试是最有效的。开发人员的技术能力知道怎么才能更好的做测试。
切忌摇摆不定。我们学习技能和知识，不是为了成为某个领域的专家；而是完成自己目标所需要的。今天学C，明天学Java；今天搞Cloudify，明天搞CF。主张“先精后广，一专多长”的流程来学习，不要左右摇摆，先做一件事件再说。你所学，所使用的是要切合当前业务目标的。当然也要清楚地认清任何技术只是服务于市场的，在市场发生变化，如果程序员不能顺应发生变化，就有被淘汰的风险。人的角色也是不断变化的。8/2定律在哪都适用，全掌握20%常用技能的人，但这20%的技能会有80%的几率被用到，剩下那80%不常用的，让我们Google吧。另外具体经验也是相当的重要，任何的项目，你可以思考一下我学到什么经验。更重要的是思维方式和学习能力。项目中总会遇到各种问题，问题摆在那里你就需要去解决，而无论这要求你去钻研什么。这就是我所说的学习能力。
我不生产博文，只是互联网的搬运工。以上观点与内容来源于互联网，感谢伟大的互联网。
</content>
    </entry>
    
     <entry>
        <title>Git SSH设置</title>
        <url>http://lanlingzi.cn/post/notes/2014/0322_github/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>git</tag>
        </tags>
        <content type="html">  Git HTTPS 和 SSH 的区别：
 前者可以随意克隆github上的项目，而不管是谁的；而后者则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。
 https url 在push的时候是需要验证用户名和密码的；而 SSH 在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。
  首先检查是否已经有 SSH key 运行 git Bash 客户端，输入如下代码：
$ cd ~/.ssh $ ls  这两个命令就是检查是否已经存在 id_rsa.pub 或 id_dsa.pub 文件，如果文件已经存在，那么你可以跳过步骤2，直接进入步骤3。
创建一个 SSH key $ ssh-keygen -t rsa -C &amp;quot;your_email@example.com&amp;quot;  参数含义：
-t 指定密钥类型，默认是 rsa ，可以省略。
-C 设置注释文字，比如邮箱。
-f 指定密钥文件存储文件名。
以上代码省略了 -f 参数，因此，运行上面那条命令后会让你输入一个文件名，用于保存刚才生成的 SSH key 代码，如：
Generating public/private rsa key pair. # Enter file in which to save the key (/c/Users/xiao/.ssh/id_rsa): [Press enter]  当然，你也可以不输入文件名，使用默认文件名（推荐），那么就会生成 id_rsa 和 id_rsa.pub 两个秘钥文件。
接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），
当然，你也可以不输入密码，直接按回车。那么push的时候就不需要输入密码，直接提交到github上了，如：
Enter passphrase (empty for no passphrase): # Enter same passphrase again:  接下来，就会显示如下代码提示，如：
Your identification has been saved in /c/Users/xiao/.ssh/id_rsa. # Your public key has been saved in /c/Users/xiao/.ssh/id_rsa.pub. # The key fingerprint is: # 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com  当你看到上面这段代码的收，那就说明，你的 SSH key 已经创建成功，你只需要添加到github的SSH key上就可以了。
添加你的 SSH key 到 github上面去  首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制。
 登录你的github账号，从又上角的设置（ Account Settings ）进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。
 点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。当然，上面的 Title 所对应的输入框你也可以输入一个该 SSH key 显示在 github 上的一个别名。默认的会使用你的邮件名称。
  测试一下该SSH key 在git Bash 中输入以下代码
$ ssh -T git@github.com  当你输入以上代码时，会有一段警告代码，如：
The authenticity of host &#39;github.com (207.97.227.239)&#39; can&#39;t be established. # RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. # Are you sure you want to continue connecting (yes/no)?  这是正常的，你输入 yes 回车既可。如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码，如：
Enter passphrase for key &#39;/c/Users/xiao/.ssh/id_rsa&#39;:  当然如果你密码输错了，会再要求你输入，知道对了为止。
注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。
密码正确后你会看到下面这段话，如：
Hi username! You&#39;ve successfully authenticated, but GitHub does not # provide shell access.  如果用户名是正确的,你已经成功设置SSH密钥。如果你看到 “access denied” ，者表示拒绝访问，那么你就需要使用 https 去访问，而不是 SSH 。2
设置全局git账号  git config --global user.email &amp;quot;your_email@example.com&amp;quot; git config --global user.name &amp;quot;your name&amp;quot;  参考文档：https://help.github.com/articles/generating-ssh-keys
</content>
    </entry>
    
     <entry>
        <title>优秀程序员</title>
        <url>http://lanlingzi.cn/post/thoughts/2013/1113_good_programmer/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>程序员</tag>
        </tags>
        <content type="html"> 关于什么是一名合格的程序员，优秀的程序员，这些讨论从来没有停止过，标准各不相同。有人说优秀程序员追求简洁的代码，优秀的框架结构，新的技术技能。我们不是在讨论什么是业界大牛，我心中的一名优秀程序具备如下几个素质：
 简洁高效
优秀的程序员会使用整洁，易于理解的方式解决实际的问题，任何不必要的复杂代码均不会出现，简单比复杂更具有价值。能通过简洁的方式把复杂的问题解决掉。  开放心态
不要盲目自信，自负，在IT这个领域，新知识层出不穷，你永远不可能全部掌握，在某些领域，你一定会是低人一等。教条、狭隘与不切实际的表现往往让你变得越来越自负，也会越来越陷入一个很小的框框内。
 切合实际
软件开发，不是理念的教堂，也不是技能的校场。忽略实际情况，再精妙的代码解决不了问题，也只是一纸空文。优秀程序能打破常规，找到问题的本质，快速地，简洁地解决问题。
 质量保证
态度明确，能一直以我交付的代码一定要是高质量的目标。对代码负责，会不停地优化与重构自己的代码。对代码充分的测试与验证，极少的Bugs。只会写代码，不会测试的程序员不是优秀的程序员。
 积累分享
平时注重通过研究新的技术，新的软件工程方法，来为以前无法解决的一些软件问题提供更优的方法。能对软件开发中的实践进行总续与升华，将自己所掌握的东西转成显式的知识，并能通知多种方式进行分享。知识的传承的重要性远远大于代码本身。
 热爱编程
不要做只会编码的码农，热爱生活，才能享受编程带来的快乐。热爱编码，热爱自已的职业。如果对编码没有热情，只是一种谋生手段，那最终在编程这一条路也不会走得太深。
 沟通反馈
在软件开发领域，尤其是大的系统开发，不可能是单打独斗。学会在团队中沟通，与同事协作一起完成任务。同时也要识别不合理的需求，懂得拒绝别人，学会Say No。在项目中，要明确自己的计划，明确自己的职责。要学习与同事，项目经理及时反馈。
 </content>
    </entry>
    
     <entry>
        <title>HW八年总结</title>
        <url>http://lanlingzi.cn/post/thoughts/2013/0909_hw_8years/</url>
        <categories>
          <category>感想</category>
        </categories>
        <tags>
          <tag>软件开发</tag><tag>总结</tag>
        </tags>
        <content type="html"> 白驹过隙，进入公司已是八年，一路学习一路收获。往后回首，一些经历回想起来还历历在目：经历过一线比拼的激情，经历过产品上线的喜悦，经历过多个项目的变换，经历过持续熬夜的艰辛；写过不少的代码，带过一些徒弟，负责过团队开发，一直在公司从事基层的研发工作。一路走下来，也得到部门领导，公司同事的帮助、指导与鼓励，能让我一直坚持下去，过程中我也得到一些很高的认可，感触多，收获多。在此我先感谢大家！
团队成功才能成就个人 还记得进入公司做的第一个项目，就是上海电信的XXX规范比拼项目，在上海一呆就是3个月之久。之后从09年开始到现在，我应该遇到一个不错的机遇，时逢部门的产品在欧洲开花结果，并且我非常有幸地参加了其中的多个项目，TLF比拼、VDF比拼、SFR比拼、O2的交付，DT比拼，有去一线出差现场操作，也有在家持续熬夜支撑。后又参与平台非常重要的新项目C3的构建，见证它从无到有，到多个局点的交付，目前C3在VDF交付。所以说是 只有团队的成功，才能有个人的成就 。我作为一个普普通通的软件工程师，有机会参加了这么多的高端比拼与交付，也可能实属我人生中为数不多，以后可能值得会拿出来说一下的事儿。当然参与这些项目对我自身也是一项非常大的挑战，尤其是在比拼项目中亦时候不知熬了多少个夜晚，甚至彻夜难眠，也不知当面对客户苛刻的验证时的紧张感，心跳加速多少次。但始终相信我是在做一件有意义的事情这就是对的，虽然过程肯是辛苦的，结果可能不理想的。有时甚至还害怕而抵触过，抱怨过。但只要一旦接受了也就始终没有放弃过，把分给我的工作尽自己最大的努力做好做实，做到问心无愧 。 做适合自己做的事 人贵有自知之明，熟悉自己的性格缺陷，搞明白自己擅长什么，这其实也非常地难做到，尤其是在面对一些机会时做决策。当初大学毕业时，家人就安排我在深圳益田村做物业管理，最后也没有做下去，原因是不适合。像我这种人，我不喜欢指挥人去干活。如果去做市场肯定打不开局面，不太会说动别人。如果去搞财经也肯定搞不好，看到一大堆的数据比较头疼。如果去搞前台设计也肯定搞不好，从小就没有什么艺术细胞。最后发现搞搞后台技术可能凑合着，也符合我个人的性格，能安静地做事。所以即使来到公司这么多年了，还是对技术情有独钟。事实上，很多岗位不一定要最优秀的，但必须是要最合适的。 每个人都有优缺点，金无足赤，人无完人，在合适的岗位上做自己擅长的事 。
居安思危，适应变化 信息爆炸的时代，外部形势与内部因素都无时无刻都在变化，对个人来说，时刻可能都面临挑战。从在公司的几年来看，我个人的工作内容也一直在变化着，人传统的智能网到源于互联网的云云计算，从窄带智能网到宽窄带融合，从话音控制到消息内容，从单体大型服务到分布式集群应用，从C&#43;&#43;语言到Java语言。真是变化太快，每次转变，都需要去适应它。面对变化，自己需要时常有点危机感，不断地去学习。比如说去年带头做E2E一键部署时，需要了解的东西很多：要做界面，没有使用过Java Swing；虚拟化部署，没有使用过Power Shell，都需要快速学习，所有事情搞定。可以说每个人都有业务短板，你不可能是一个天才，这种对无法胜用的危机感导致不敢放松自己。缓解危机感往往需要的是应对实际困难的技能或技巧。时常有了危机感，才会促我去主动学习，主动思考，主动改变。我不是一个力求完美的人，但在工作中往往会尽最大的努力与热情来了解各种专业技能，把手头上的事情做对做好。
兴趣，好奇心 记不得是哪个名人说过兴趣是最好的老师，我觉得应该是最好的向导。如果你对某件事感兴趣，它会牵引你去主动学习、行动与思考。 我一直对各种新技术比较好奇，以前下班之后回到家经常去逛一些技术网站与论坛。好奇心是一个研发人员的基本素质，据说做学问成功的第一要素既不是天赋，也不是勤奋与激情，也不是靠你努力就一定出得来的，而可能是好奇的灵光。好奇心驱使我去了解一些技术细节，技术动向，如之前对C&#43;&#43;比较执迷，经常请教同事一些较偏的用法，下班回家喜欢写点代码验证一下想法。又如当时GAE刚出来，我就利用周末开发GAE应用玩玩，后被墙掉访问不方便才没有继续玩了；又如之前开心网种菜火爆时，马上抓包分析写偷菜外挂；我也可能是一个刷机控，从09年开始的M8刷成Android，之后的iPod, iPad, iPhone, SAMSUMG手机没有少被我折腾过，刷成不同版本的定制系统。平时这些技术多猎奇可能看似对工作起不了直接帮助，但它们能扩展的视野，丰富我的知识，强化我的动手能力。若在工作中遇到类似问题时，可能举一反三，找到解决问题办法。关注技术但不要陷入技术，本质是用技术来提升认知问题，分析问题，解决问题的思想高度。
耐得住寂寞 来深圳有不少的高中，大学同学，以及亲朋好友。大家大学毕业都差不多十年了，在坚持做技术是越来越少，尤其是从事软件开发的。以前大学同学每年的聚会，问的最多的问题是你还在HW啊？还在写代码？现在已经不问了。的确，在国内做软件开发的大环境相对不是很好，尤其是上了三十岁的人还从事一线编码工作，会觉得你是没有上进心的人。在外部，我好几个同学转行了，有些创业，做得还不错。在公司内部，也见到越来越多的同事，习惯于风风火火到处开会。这是很危险的，会使我们的杂乱信息越来越多，功底越来越浅。佛家中有一项坐功是讲你你定力修为，HW的研发人员也需要一种定力，任何一件事情的极致需要持续的积累才能达到。我想我还一直在从事基层的研发，一方面源于我的兴趣爱好，另一方面也符合我的性格。从另一方面来说，要能持续把一个简单的事情做好做对，也需要面对各种诱惑而得住寂寞的能力，心无杂念去做事。
知识管理，思考总结 如今是信息爆炸的时代，各种各样杂乱无章的信息迎面扑来。如何将众多的信息提炼，转化为知识对于提升个人能力尤显相当地重要，有时不得不感慨：山中方一日，世上已千年。人与人之间的竞争，从某种意义上讲，可能也是个人运用知识快慢，正确与事的竞争力。大凡成功的人士，都少不了对知识的合理管理。
对于太多数人来说获取过程也是收集过程，记录的知识可能是一些零碎的片段，即使分类也是杂乱的、没有关联的，不利于管理，更难形成体系。时间长了，如果没有好的工具搜索出来，也是前功尽弃。在实际工作中，我们更多是遇到类似的问题，才去搜索，搜索之后就是Ctrl&#43;C与Ctrl&#43;V，多半会被遗忘掉。所以在获取知识以后是积累，积累以后是实用，实用以后是分析，分析以后是总结。这样才能把知识转成一种能力。总结最好的方式是写出来，与人交流，写与说的过程一方面可以督促自己完善想法，加深认识，说不定还会擦出创新的火花。 所以我就一直尝试去写一些东西，虽然文笔很烂，坚持下去也会收获不少，今天一看，在公司的Hi3MS平台已写一百多篇的技术博文了。
回头再看，浓缩一下：“持续学习，实践行动，思考总结”，这几个可能概括出我这几年的经历吧。想起姜育恒的《再回首》歌词来做结尾吧：不管明天要面对多少伤疼和迷惑，曾经在幽幽暗暗反反复复中追问，才知道平平淡淡从从容容是最真，再回首恍然如梦，再回首我心依旧，只有那无尽的长路伴着我。
</content>
    </entry>
    
     <entry>
        <title>Java线程使用建议</title>
        <url>http://lanlingzi.cn/post/technical/2013/0424_java_thread_suggest/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> 最近Review团队内一些的代码，发现不少使用线程池，但使用的比较乱，针对问题建议如下：
 线程不能调用Thread.stop来停止它，我见过有新员工就这么干过哦，而是需要设置一个标识位，在run方法中判断此标识位退出循环。用interrupt也是可以考虑的，但线程的run方法中要捕获InterruptException。
 所有线程需要设置Name，主要是方便线程dump出来之后定位问题。这可是编程军规，我们很多的兄弟没有遵守。  大多直接是使用Exectors.newXXX直接new线程池，没有设置队列的大小，默认是整型的最大值，一旦有线程处理阻塞，队列上涨，内存不可控制啊。
 最好不要使用newCachedThreadPool，曾经有个模块这么干，在工作线程处理慢时，线程线会不断上涨没能及时回收。这个模块出现异常，线程dump之出来发现有2000多个由它产生的线程，内存超高。
 所有线程都要受管理，不允许直接new Thread就直接start就不管了。同样所有从Exectors.newXXX创建的线程池，当bundle去激活时，一定要shutdown。
 线程个数设置多少合适？不是越多越好，多了竞争资源反而效率低。建议配置的线程数=可用的CPU数/(1-阻塞系数)。阻塞系统在0到1之间，所谓阻塞系数就是发生的IO操作，如读文件，读socket流，读写数据库等占程序时间的比率。这个数值每个系统肯定不一样，可通过分析工具或java.lang.managementAPI来确定这个值，也可以做个估计，然后测试逐步往最佳值靠拢。如果线程不是瓶颈所在，那么大概估一个值就好了。
 不要在多线程中共享数据，最佳的实践是无锁编程。所谓有锁编程，就是当你需要共享数据的时候，你需要有序的去访问，所有改变共享数据的操作都必须表现出原子的语义，在无锁编程中，并不是说所有操作都是原子的，只有一个很有限的操作集是原子的。采用wait-free 和lock-free 的算法，基于FIFO 的队列和LIFO的栈，或者更复杂的优化级队列、 hash表及红黑树的lock-free 算法以达到无锁编程。
 定时器中Runnable一定要catch所有异常，否则会由于异常导致定时不再执行。
 如果你在多个线程之间共享数据了，且采用锁了。那一定要防止出现死锁，什么是死锁：线程A加锁锁a，等待线程B已加锁的锁b释放，而线程B却也要锁a才很能释放锁b，就会发生死锁。平台基于monitor会定时检查死锁，一旦存在死锁，平台会自动重启。
 不要在构造函数中启动线程，这个会引起什么问题呢？如果有个类B继承了类A，依据java类初始化的顺序，A的构造函数一定会在B的构造函数调用前被调用，那么thread线程也将在B被完全初始化之前启动，当thread运行时使用到了类A中的某些变量，那么就可能使用的不是你预期中的值，因为在B的构造函数中你可能赋给这些变量新的值。也就是说此时将有两个线程（构造线程与新启线程）在使用这些变量，而这些变量却没有同步。
 你确认你的业务真的需要使用线程池吗？并发异步处理才需要，单线程无阻塞也是效率很高的。多线程在多CPU多核下才有它的真正价值。我们去分析优化时系统时，首先要考虑是减少阻塞，而不是一上来先加几个线程呗。
 </content>
    </entry>
    
     <entry>
        <title>[WebApp沙箱]SecurityManager运用</title>
        <url>http://lanlingzi.cn/post/technical/2011/0212_java_sandbox_sm/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> 在JRE类白名单能控制类的使用权限（请点击），但控制不了一些资源的访问权限。如默认情况下可访问机器下的任意资源，如读取、删除一些文件，网络操作，创建进程与线程等。必须对Web容器下的WebApp进行资源权限访问控制。
Security Manager Java从JDK 1.0开始就实现一套安全架构，主要用于Applet。在这种体系下Java Code的执行环境被严格划分为两部分，本地代码可以访问计算机的所有资源，而远端代码（Remote Code，主要是Applet）只能支行在严格限制的沙箱里面。安全管理器（SecurityManager）作为一个子系统来决定哪些资源允许沙箱中程序访问。这是一种运行期的安全检查。 SecurityManager是一个API级别的，可自定义的安全策略管理器，它深入到Java API中，在各处都可以见到它的身影。默认情况下，Java应用程序是不设置SecurityManager实例的（意味着不会起到安全检查），这个实例需要我们在程序启动时通过System.setSecurityManager来设置。一般情况下，检查权限是通过SecurityManager.checkPermission(Permission perm)来完成的。外部程序通过创建Permission实例，传递给前面的check方法。Permission是一个抽象类，需要继承它实现不同的权限验证，比如FilePermission，代表对某个文件的读写权限。new FilePermission(&amp;quot;test.txt&amp;quot;, &amp;quot;read&amp;quot;)；将这个实例传给SecurityManager，检查是否要读test.txt这个文件。
但SecurityManager也是一个全局管理类，一旦设置，则同容器中所有代码将会受到影响。但我们需要仅仅是对WebApp运行期的资源安全访问控制检查。
检查Permission时机 所以在设计方案时必须考虑对WebApp进行的资源授权只针对WebApp，不能影响Web容器其它代码运行。由于检查权限是通过SecurityManager.checkPermission(Permission perm)来完成的，如果在checkPermission实现很复杂的逻辑会对性能造成影响。所以需要分二个层次来设计Security Manager的设置：
 当Web容器启动时不设置任何的SecurityManager WebApp支行时采用新的SecurityManager类，在部署它时指定新SecurityManager类与Policy,在自定义的Filter中init方法中实现  重载java.security.SecurityManager(假定子类名定为CustomSecurityManager)。它主要是重载如下几个方法：
 checkPermission(Permission perm) checkPermission(Permission perm, Object context) checkAccess(ThreadGroup g) checkAccess(Threa t)  在两个checkPermission方法中主要是判断不是不WebApp的工作线程，如果是再做授权检查，使用自定义的Permissions。否则不做任何的处理.
在两个checkAccess方法中，对Thread权限如创建做一些检查特殊处理,如检查 RuntimePermission(&amp;quot;modifyThread&amp;quot;)与RuntimePermission(&amp;quot;modifyThreadGroup&amp;quot;)。
如果判断WebApp执行线程？由于不允许WebApp创建新的线程，那一个WebApp的一次http请求在Servlet的service方法实现的逻辑肯定只会在一个线程调用栈中。在Servlet的service方法入口前设置当前线程名到系统环境量Value为true，在service方法出口后设置当前线程名到系统环境量Value为false，为了能把上面的Permission只限制在WebApp中使用。需要在CustomSecurityManager.checkPermission根据当前线程名在系统环境量Value是否为true来判断是否需要做Permission检查。
如何在Servlet的service方法入口设置环境变量？Servlet规范中的Filter机制可以使得Web请求在交给Web Servlet处理前进行对请求的预先处理，以及Web Servlet处理完成之后响应后处理。也就是说在相同的URL请求下，容器会优先由Filter处理，再给Web Servlet处理，利用这个特性完成对当前线程名在系统环境变量中的设置。
同样，在Filter的init方法也就可以对CustomSecurityManager注册到系统全局的SecurityManager中。
自定义Permission 配置WebApp安全策略的Permission，可以基于Policy文件配置，以不同的CodeBase来区分不同的权限。由于配置Policy文件时，并不知道WebApp war包解压的具体目录。以Jetty为例，默认会把War解压在java.io.tmpdir目录下，那对WebApp的CodeBase可设置为java.io.tmpdir，否则根据部署实际目录来调整。
另外，需要对容器的其它jar文件的代码权限授权。由于类动态加载的原因，WebApp ClassLoder会委托它的双亲加载。如果不设置，也会在WebApp的工作线程中，会导致在Servlet运行时报一些权限禁止，如SecurityPermission。通过不同的CodeBase来进行不同的授权，除WebApp的Class之外，假定可以考虑是AllPermission。
那如果WebApp的工作线程调用系统平台提供一些API，而平台API要求可以读写文件，开启特定的端口等，这也与WebApp在同一个线程调用栈中，同样也没有权限，那就又何处理？需要两步来完成对平台API的权限授权：
 平台的API Jar包不能放在WebApps目录下，应用与WebApp的War属于不现的保护域（ProtectionDomain） 在平台的API的入口需要加上对AccessController.doPrivileged设置，这样是在调用doPrivileged的方法相关联的保护域拥有执行被请求的操作的权限，AccessController将立即返回，不再在栈的下层继续检查操作权限（也就是说它的代码主休是享受“privileged”特权），它单独负责对它的可使用的资源的访问请求，而不管这个请求是由什么代码所引发的。 </content>
    </entry>
    
     <entry>
        <title>[WebApp沙箱]JRE类白名单运用</title>
        <url>http://lanlingzi.cn/post/technical/2011/0311_java_sandbox_cl/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>Java</tag>
        </tags>
        <content type="html"> ClassLoader JVM类加载器层次结构：
 Bootstrap ClassLoader | Extension ClassLoader | System ClassLoader  JVM一启动，会先做一些初始化的动作。一旦初始化动作完成之后，就会产生第一个类加载器，即所谓的Bootstrap Loader, Bootstrap Loader是由C&#43;&#43;写成，这个BootstrapLoader所做的初始化中，除了做一些基本的初始化动作之外，最重要的就是加载定义在sun.misc命名空间下的Launcher.java之中的ExtClassLoader(因为是innerclass，所以编译之后会变成Launcher$ExtCjassLoader.class)，并设定其Parent为null,代表其父加载器为BootstrapLoader。然后再加载定义于sun.misc命名空间下的Launcher.java之中的AppClassLoader(因为是InnerClass，所以编译之后会变成Launcher$AppClassLoader.class)，并设定其Parent为之前产生的ExtClassLoader实例。AppClassLoader这一层我们也称之为SystemLoader。AppClassLoader会加载CLASSPATH目录下定义的Class。 每一个自定义ClassLoader都必须继承ClassLoader这个抽象娄，而每个ClassLoader都会有一个Parent的ClassLoader，我们可以看一下ClassLoader这个抽象类中有一个getParent()方法，这个方法用来返回当前ClassLoader的Parent。这个Parent不是指的被继承的类，而是在实例化该ClassLoader时指定的上层ClassLoader。
ClassLoader有两种载入类方式：
 pre-loading：预先载入，载入基础类。 load-on-demand：按需求载入，动态载入。  当JVM载入Java类的时候，需要经过三个步骤，装载、连接、初始化。装载就是找到相应的Class文件，读入JVM。连接分三步：
 验证Java类是否符合规格 准备，就是为类变量分配内存同时设置默认初始值 解释，而这步就是可选的，解释就是根据类中的符号引用查找相应的实体，再把符号引用替换成一个直接引用的过程。  每个ClassLoader加载Java类的过程如下：
 检测此Java类是否载入过（即在Cache中是否有此Java类，包括所有Parent的ClassLoader已载入的Java类），如果有到第8步，如果没有到第2步 如果Parent ClassLoader不存在(没有Parent，那Parent一定是Bootstrap Loader)，到第4步 请求Parent ClassLoader载入，如果成功到第8步，不成功到第5步 请求JVM从Bootstrap Loacler中载入，如果成功到第8步 寻找Class文件（从与此classloader相关的类路径中寻找）,如果找不到则到第7步 从文件中载入Class，到第8步 否则找不到，抛出 ClassNotFoundException 返回Class类  这个过程就是双亲委托模式，一是可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次；二是出于考虑到安全因素，避免覆盖基础类。例如无法随时使用自定义的String动态替代java核心api中定义String类型。其中第5、6步我们可以通过覆盏ClassLoader的findClass方法来实现自己的载入策略。
Thread Context ClassLoader Java 2中引入了线程上下文(Thread Context)类ClassLoader的概念，每一个线程有一个ContextClassLoader。这个Context ClassLoader是通过方法Thread.setContextClassLoader()设置的，如果当前线程在创建后没有调用这个方法设置Context ClassLoader，则当前线程从他的父线程继承Context ClassLoader。此Context ClassLoader默认的是System ClassLoader。
利用这个特性，我们可以“打破”ClassLoader委托机制，父ClassLoader可以获得当前线程的Context ClassLoader，而这个Context ClassLoader可以是它的子ClassLoader或者其他其他的ClassLoader，那么父ClassLoader就可以从其获得所需的Class，这就打破了只能向父ClassLoader请求的限制。
这个机制可以满足当我们的classpath是在运行时才确定，并由定制的ClassLoader加载的时候，由System Loader(即在JVM classpath中)加载的Class可以通过Context ClassLoader获得定制的ClassLoader并加载入特定的ClassLoader（通常是抽象类和接口，定制的ClassLoader中实现），例如web应用中的Servlet就是用这种机制加载的。
Class Instance 一个java类只有要实例化时，才会被ClassLoader动态载入，未使用并不会载入。而动态载类又分为两种方式：
 Implicit隐式，即利用实例化才载入的特性来动态载入类，如new-个类的对象。 Explicit显式方式，又分为两种使用java.lang.Class的forName()方法与使用java.lang.ClassLoader的loadClass()方法。  当java类加载时，有一个Class类（JRE中基础类）与每个其它的Java类相关，每个被ClassLoader加载的class文件，最终都会以Class类的实例被程序引用，我们可以把Class类当作是普通类的一个模板。JVM根据这个模板生成对应的实例，最终被程序所使用。某个类的所有实例内部都有一个栏位记录着该类对应的Class的实例位置。java类对应的Class实例可以当作是类在内存中的代理者，所以当要获得类的信息（如有哪些类变量，有哪些方法）时，都可以让类对应的Class实例代劳。java的Reflection机制就大量的使用这种方法来实现。每个java类都是由某个ClassLoader(ClassLoader的实例)来载入的，因此Class类别的实例中都会有栏位记录他的ClassLoader的实例。
WebApp Class WhiteList 对于WebApp，不管是Web容器采用Jetty还是Tomcat。他们都针对每个WebApp Context自定义ClassLoader。为了能达到白名单检查的功能，我们可能在这个自定义ClassLoader的实现对类进行检查(如不在白名单内的类load时报ClassNotFoundException)。
 一种方案是重载ClassLoader.loadClass方法，不允许load此类，也不会在Cache中存在。但这种方案会带来很大的性能问题。每次运行时实例化一个Java类，在Cache中肯定不会存在此java类的Class类。那又会去调用loadClass尝试加载此java类，那又会再一次去检查一下白名单列表，而且白名单列表会很多，遍历会损耗性能。另外，WebApp自己创建的ClassLoader，没有办法重载loadClass方法。
 另一个方案是在WebApp Context的ClassLoader.defineClass方法中修改从Class文件中读取的WebApp中每个类的字节码。使用ASM工具来解释与修改字节码，如果发现此Class的方法中在调用有不在白名单内中的类，则插入抛出NoClassDefFoundError代码。这种方案可以只在第一次加载WebApp类时，判断了它依赖的类是否有不在白名单内中。这种相对前一种方案可以提高性能。同样，WebApp自己创建的ClassLoader，没有办法重载defineClass方法。
  对于ClassLoader.defineClass方法的实现：
 一种方案重载Web容器的WebApp Context自定义ClassLoader.defineClass方法，这要求Web容器支持插件方式替换已有WebApp Context ClassLoader。
 另一种方案是采用JVM的Instrumentation功能。在JVM级别，以插件的方法动态AOP切入JVM或JRE类中已有的实现。正好Instrumentation提供一种机制切入到每个ClassLoader.defineClass方法之前。应用只需要实现接口java.lang.instrument.ClassFileTransformer。在transform方法实现对类字符码的转换。此方法的原型为
 byte[] transform(ClassLoader loader, String className, Class&amp;lt;?&amp;gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegaIClassFormatException  转换器ClassFileTransformer利用Instrumentation.addTransformer注册之后，在定义每个新类和重定义每个类时都将调用该转换器。对新的类定义的请求通过ClassLoader.defineClass进行。对类重定义的请求通过Instrumentation.redefineClasses方法进行。转换器是在验证或应用class文件字节之前的处理请求过程中进行调用的。
如果实现的方法确定不需要进行字节码转换，则将返回null。否则它将刨建一个新的byte[]数组。将输入classfileBuffer连同所有需要的转换复制到其中，并返回新数组。
  采用第二种方案是不个不错的选择，即使用Instrurnentation功能。在transform方法扫描类的字节码，检查类的方法中是否有非白名单中的类。如果有，则插入抛出NoClassDefFounclError代码。
实现简介  定义-个类实现premain接口，做为Instrumentationa机制的入口。并在MANIFEST.MF文件中指定Premain-Class为此类．premain接口如下，顾名思义，它是在main方法之前调用：
public static void premain(String agentArgs, Instrumentation inst);
 实现ClaSsFileTransformer接口。并在premain方法中调用Instrumentation.addTransfanner注册此接口。
 当每个ClassLoader加载字节码时，会回调ClaaaFileTransfonner.transform方法，它实现主要逻辑：
 判断是加载类的ClassLoader是否Web容器中WebAppCantext ClasaLoader。对于WebAppContext ClassLoader可以通过类名在判断。对于webApp创建的新ClassLoader。需扫描字节码，获取类的类型继承列表是否属于ClassLoader，并记录下来。
 如果加载类的ClasaLoade不是应用的ClasSLoader，直接口返回null
 如果是，使用ASM工具对字节码进行分析与重写:
 第一遍扫描类的所有方法字节码，如果Visit到类的类型在不在白名单列表中，则在原有方法中直接插入抛NoClassDefFoundErro代码。满足如下条件：
 调用黑名单列表类的方法 调用黑名单列表类的属性  新的代码类似如下：
//插入抛NoClassDefFoundError代码，调用一个类的静态方法 //原代码  WebApp可能创建的自己实现的ClassLoader。第二遍扫描类的所有方法字节码，判断Visit到类的类型是否URLclassLoader，SecureClassLoader，ClassLoader其中的一个，或者是否继承自他们。则插入记录这些ClassLoader名的代码。自己实现的ClassLoader满足如下条件：
 任何一个新创建的ClassLoader，肯定会在它的调用父类的构造方法，那在此方法中它的字节码肯定会调用URLClassLoader，SecureCldaaLoader，ClassLonder其中一个构造方法；
 另外还可能使用URLClassLoader.newinstance(…）来创建新的classloader；
  上述两种方法新创建的ClassLoader，它的双亲ClassLoader可能不是WebAppContext的Classloader(构造方法或newinatance没有指定参数parent，那parent默认为System ClaaSLoader)，修改字节码时需要修改为调用有参数parent的方法，并且把parent指向WebApp Context的ClasSloader。
 WebApp也可能使用反射机制来访问类。第三遍扫描类的所有方法字节码，判断所Visit到类的类型与Viait到方法，满足如下条件：
 类型为java/lang/reflect/Method，调用方法为invoke 类型为java/lang/reflect/Field，调用方法为getXXXX/setXXXX等方法 类型为java/lang/reflect/Constructor，调用方法为newinstance; 类型为java/lang/Class，调用方法为newlnstance.  当满足上面条件时，修改原有这些方法调用，则在原有方法中插入检查反射的target对象的类型是否不在白名单列表中。新的代码类似如下
void setBoolean (Field f, Object a, final boolean value) { ／／插入检查obj是否有访问权限（配合Securtiy访问控制） ／／插入检查obj是否在黑名单列表中 ／／再加上原有的f.setBoolean(obj，value)； }    </content>
    </entry>
    
     <entry>
        <title>远离罪恶</title>
        <url>http://lanlingzi.cn/post/stories/2011/0122_believe_god/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>宗教</tag>
        </tags>
        <content type="html"> 今天在回家的车上，遇到一个上帝的信徒，在宣传上帝的故事，对着一个高中生大讲特讲信上帝不是一种迷信。举了很多的例子，比如人们熟知的爱因斯坦，牛顿等是上帝的忠实信徒，一边搞学问一边翻圣经，学问做不去了，就去问圣经。也讲宇宙是什么，是上帝创造了宇宙万物，人类就是大海中一粒沙一样存在整个宇宙之中，人类是渺小的。无论人类科技多么的发展，也不能在其它星球上创造生物。最后在快下车的时候，给每人发一张卡片，劝说人们多去教堂感受一下。身体只是一个灵魂的载体，每个灵魂需要远离罪恶，前往永远与罪恶无关的福乐美地。 她所说的前大部分都是废话，最一后说灵魂远离罪恶才是基督的精髓。无论上帝是否存在其实都不重要，或许在人类达到不到地方，就是上帝存在的地方。这个上帝不是一个神，还是人类敬畏的未知领域。在这个物欲横流的糟糕社会，在一堆诱惑的面前，人们的灵魂又有几个能真正地远离罪恶，教堂成了人们忏悔的地方，宗教是一种精神的寄托。有时人有种寄托其实也很幸福的。
</content>
    </entry>
    
     <entry>
        <title>德国出差记</title>
        <url>http://lanlingzi.cn/post/stories/2010/1020_german_travel/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>旅游</tag>
        </tags>
        <content type="html"> 到达德国的Frankfurt法兰克福大约是19号早晨的６点半左右。这边的天还没有亮，取得托运行李，再过完签证检查之后已是７点左右，天还是没有亮。这次还好，去年过境德国，被安检人员问了一堆的问题。这次可能我事先跟海关检查人员打了声招呼“Morning”，他居然什么都没有问，直接盖上大章就说“Pass”。出了Airport，外面非常的冷清，11月的德国已经开始很冷，有点冬的味道。
我要去的目的地是一个叫Darmstadt达姆斯塔特的小城。在Airport的外面bus stations逛了一圈，终天在Terminal 2 E8找到Darmstadt的air line。等了大约２分钟的时光，Bus准时到来，我向司机打了声招呼，示意让我上车。在车上他说了一堆的德语，可惜我一句也没有听明白，我只能用生硬的英语说“I want to go to Darmstadt, how much is the ticket?”或许大家都能听明白Darmstadt。于是他在电子售票机上打了一张票给我，电子屏上显示7.3欧。 我开始以为Darmstadt离Frankfurt比较近，一路坐车走高速过去，发现还是坐了25分钟左右。诺大的Bus上，只有三个人，除了我之外，还是两个本地人吧。我坐在第一排，看着司机很惬意地开着车，经常活动一下上身，偶尔也摇晃一下脑袋。到了Darmstadt，司机好像对我说了些什么，我只听见到Darmstadt，于是我就下了车。外面还是没有放亮，不过街道上开始有人在等公交车上班了。事先同事告诉我公司在Darmstadt火车站附近。还好，下了Bus之后，前面就是Hanptbahnhof，看到DB标识的火车站。
按着同事事先给我的Google地图，穿到火车站左拐一条街，下了电梯，出门之后再也找不到北了，按Google地图，公司办事处就应该在火车站200m附近，可惜我逛了一圈根本没有看到HW的标识，无奈又回到火车站，又开始用生硬的英语问了一个清洁工叔叔，可能也没有完全听懂我说什么，telephone应该在拉丁语系中都发声差不多，加之我的手势。他完全知道我要找公用电话。我是对德语一点不懂，他所说的我一句也没有听清楚。顺着他所指的方向，终天找到了T-Service的公用电话。在一处德语显示的公用电话屏上，我尝试了几次，终于打通同事的电话，涮涮地2.7欧贡献给了电话。
与同事约好见面的地点，再等了约5分钟左右，终于见到我的同事，我的心也开始悬下来了。
今天到德国的初映像就是冷，到达同事住的宿舍里，不得不把秋衣秋裤换上。洗漱一把之后，一点睡意没有，可能是在飞机上差不多朦胧睡了10个小时左右。Darmstadt是一个宁静的小城，一切显得得比较安详。我站在宿舍向外看，绝对见不到任何超过10层的建筑，路面宽阔干净整洁。
公司的办公地点其实离火车站的确很近，走2分钟就到了。据说附近都是一些高科技企业。Darmstadt也是一教育与高新企业云集的小城。公司在这的办公室一共租用两层，大约有近100间的办公室。我们这个项目四波人马分散在各个办公室里，这里没有人认为你是新来的，会怎么怎么样。
我去得比较早，开始公司没有什么人，到9点半之后，才陆续有人来上班。前台是一个来自湖南的MM，正在与我们项目组内一同事fall in love中。她也是这边唯一的女性。这边的工作员工本地德国人也不很多，大部分来自国内，大都也不是常住，随项目而移动。到达公司之后，住宿都没有安排就投入了工作，第一天基本是开了一整天的Test Case Guide的评审会议，一直搞到晚上8点多。
在这边工作，最大的不便是吃饭问题。公司没有食堂，附近也没有快餐站，连麦当劳也没有。同事们都是回宿舍自己做东西吃。我们项目组一波人基本上定在一起做东西吃。吃的问题基本上也算解决了，虽然基本上每餐都是煮些面条吃。
下午从前台MM处领到我住宿钥匙，我们项目组的同事都分散住在不同的地方。而我住的地方更远。住宿已不在Darmstadt，叫一个Griesheim的小城（小镇？）上的Gerh.-Hauptmainn街上，坐有轨电车大约要5分钟左右。晚上9点离开公司，开始我与另一个同事去寻找我的宿舍。
德国的交通系统是非常发达的，公共交通有火车，有轨电车（像火车有多个车箱），Bus，大城市还有地铁，但你见不到Taxi，这边的Taxi是预约的。这些公共交通是相当地准时，站排上写着什么时候到站，就是什么时候。如果不准时，肯定会发现大撞车，因为bus与有轨电车很多的路段都在同一条线上。任何的公共交通是无人售票的，基于人的基本诚信。票的类型单次票，单天票，周票，月票。除单次票之外，其它都是不限次数。并且不限路线与车次，同一张票即可坐有轨电车，也可以坐Bus。像我买的月票，活动范围可以在Darmstadt与Griesheim两个区域，价格比较贵，是47.40欧。
我的宿舍从Darmstadt到Griesheim，一共有5站，最后一站刚好是进Griesheim的第一站。下了有轨电车，东拐西拐地走到宿舍还有15分钟左右。幸亏有同事带路，一个人还是真难找到这个地方。这个宿舍是公司长期租的，它不是hotel(酒店)，更不可能是house（住宅），是apartment（公寓），在德语中叫appartementhaus。这个apartment一共有三层，占地面积很大，应该有几百间房间。附近的环境也很不错，整个Griesheim都是住宅区。除了apartment之外，都是一栋栋的house，相当国内的别墅，家家屋前屋后有车库或花园。这才是人理想居住的环境啊。这些house一般都是两层或三层，富裕的人家可能大一些，穷人可能小一些。没钱的流浪汉才住Darmstadt的街上。在Griesheim是见不流浪汉。
我的入住房间是一室一厅，带独立的厨房与卫生间，这个房间相比其它的apartment算是比较大了。一室中两张床，床是相当的小，可能就一米M宽。如果来了胖子，滚下床的机率应该很大。房间的设施是很全，你住在这里绝对的舒服，有暖气，有热水，有冰箱，有厨具，有网络，有电视。地面是不错的地毯，看来欧洲人喜欢在家铺这个。虽然有两个床铺，但只有一个人入住。
</content>
    </entry>
    
     <entry>
        <title>印度同事记</title>
        <url>http://lanlingzi.cn/post/stories/2010/0716_indian_counterparts/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>印度</tag>
        </tags>
        <content type="html"> 项目组由四地员工组成：深圳，南京，印度，土耳其。印度研究所设在班加罗尔（Bangalore），由于这次项目的重要性，把一堆的印度同事也拉到了深圳集中办公，也把部分的土耳其同事拉到了深圳。
今天有两个印度同事说要回家结婚了，准备回印度，于是他们昨天发了一封mail说要我join us for dinner。盛情难却，于是我说I&#39;m glad to go，我就参加了他们的一次聚会。 在去之前，我在想印度同事们来中国，他们能请什么客。出乎我的意料之外，他们一行10多人把我带到一家火锅店，莫非他们想尝尝中国的火锅？印度人大多是猪肉、牛肉，羊肉都不能吃，想吃火锅也难吧。他们拿着菜单，看图点菜，有点搞笑，点几盘的金银馒头，二盘的大盘鸡，也点了三种鱼（水煮鱼，炸鱼，清蒸鱼），我开始还以为他们很能吃鱼，发现上菜之后，根本不合他们的胃口。我感觉像领了群刚从难民营回来的人，在一家火锅店教着他们拿筷子，吃着馒头，啃着大盘鸡，场面真是极其搞笑。更有几个比较逗的印度同事，不停地在学中国话，用生硬的汉语叫喊着“服务员，纸巾，王老吉”，搞得我与其它两个中方员工脸色极其难堪。总得来说，印度同事还是很好相处的，来自社会底层，乐观而又安于现状。
印度同事给我们的印象还是比较正面的。中文员工自然是深受华为文化的影响，做事情是任劳任怨的。印度人大都比较温顺，有点喜欢跟你讨价还价，但只要确认的事情，是会按时按量完成，哪里他们私下加班加点完成。记得有一天周未，印度同事集体去东部华侨城玩，由于遇到紧急问题需要处理，被我们电话叫回。虽带些不高兴，回来公司还是跟我们一起奋斗到凌晨解决欧洲现场问题。
相比之下，项目组的土耳其人却完全不是一样了，一个字来形容：“懒”。TNND的，拿的薪水比我们多很多，却什么都不会做，也什么都不会愿意做，一点积极性与主动性都没有。老大给三个土耳其人让我带，真是把我折磨死了。一是交流是困难，二是安排他们的工作是能拖则拖，又说他们不得。从与他们打交道，或有所思：一个能任劳任怨的民族才有可能伫立于世界民族之林，土耳其永远不可能，印度还有可能吧。
</content>
    </entry>
    
     <entry>
        <title>团队文化</title>
        <url>http://lanlingzi.cn/post/notes/2010/0111_team_culture/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>团队</tag>
        </tags>
        <content type="html"> 今天晚上在部门的公告牌上看到一个另部门的项目做的总结，觉得后面几句话不错：
 树立团队荣誉感：
如何树立团队荣誉感，没有什么好方法，我的理解就是带领团队不断地打胜仗，克服一个个困难，另外就是获得应该有的荣誉，这样你的团队才能有荣誉感。
 角色认知，系统化思考：
你是代表部门在做这项工作，需要也可以站得更高角度来系统化，有计划地操作这项工作，你也可以行使你应有的权力。  面对不增值的事：
其实在工作中我们总会遇到不少此类的重复又不增值的事情，从个人来讲，可能得不到技能上的提升。但对组织，对团队是非常有益的，需要你无条件地服从，不要去报怨。很多时候，这种忍耐，坚持会帮助你脱颖而出。
 面对困难的事：
如果你所带的团队在最困难的时候，一个团队已经差到谷底了，这时不论住哪个方向走都是往上走。团队的困难时期正是我们做出变革的最佳时机。所以对团队来讲，困难和挫折是福，把一个团队从弱势带到强势的时候，这过程所积累的经验，以及团队的战斗力是无可比拟的。
 积极主动，追求卓越：
有些事情不是组织强制就能做好的，如果没有组织约定我们就不做事了吗，需要我们积极思考推动，价值思维，系统考虑，全力共赢，树立标杆，营造氛围，不断突破。
 </content>
    </entry>
    
     <entry>
        <title>2010</title>
        <url>http://lanlingzi.cn/post/stories/2010/0106_summary/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>总结</tag>
        </tags>
        <content type="html"> 日子就这一样日复一日地消逝着，
在不经意间，
时间滑到2010。
无意与时间赛跑，
在时间面前，
我们永远都是一个输者。
回首2009，
一个充满辛苦的一年，
一个压力倍增的一年。
去了一趟欧洲，
去了一趟南京。
工作走到十字路口，
有更多的人生盲点。
回首2009，
一个没有时间的一年，
一个不懂风情的一年。
当同学渐已结婚，
当朋友比燕双飞。
爱情没有收获秋季，
发现自己不懂恋爱。
展望2010，
将继续在压力中前行，
再大的压力也得扛着。
将持续在学习中历练，
再大的阻碍也得迈过。
不要放弃，
也不要抛弃，
更不要逃避。
展望2010，
从分享快乐开始，
在成长中追逐。
学会懂得珍惜，
学会懂得尊重。
心的方向，
快乐着生活，
享受着快乐。
</content>
    </entry>
    
     <entry>
        <title>秩序</title>
        <url>http://lanlingzi.cn/post/stories/2009/1106_rule/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 昨天下班回来，当过马路时，我一个人在等红绿灯，忽然有一个人在喊我：”走啊，你们这群年轻还没有我们胆子大啊，现在都没有车“，我回头一看，是一个大约40~50岁的人，应该是我们公司供应商的员工。而我，已经习惯了过马路时等红绿灯，在我们公司附近，大家都这样做，即使没有车也会静静地在等着灯亮，这可能是榜样的力量吧。 后来我追上喊我的人，跟他聊起来，我对他说，我刚才是在遵守交通秩序，而不是胆小。他不屑地对我说，都没有什么车穿过，用不着在哪傻等吧。你们这年轻人怎么也爱犯教条主义，那用管这么多的条条框框。
我笑笑了，我知道，我跟他多说无益，因为思想决定境界。在中国传统文化之下，人总喜欢去破坏秩序，并且还自认有理。也有人会说，秩序是死的，人是活的。如果现在年轻人还都这样认为，那中国人的素质还真是没有什么希望。
</content>
    </entry>
    
     <entry>
        <title>青青世界</title>
        <url>http://lanlingzi.cn/post/stories/2009/1004_qingqing/</url>
        <categories>
          <category>杂记</category><category>感想</category>
        </categories>
        <tags>
          <tag>旅游</tag>
        </tags>
        <content type="html"> 少年时，一首青青世界的歌曲在春晚上唱红南北。歌里描绘的是一个梦幻世界，是我一直梦想的世界，一副有山有水的清净世界，歌词的作者天才乔羽现在是否还安好？听我们的老大们讲，乔老创造这首歌时，本来是我们公司请他来为公司写企业主题歌，就他住进了当时公司的培训与生活基地青青世界（那时青青世界刚开没有多久，资金运营上有困难，所以把酒店都包给公司）。精明的青青世界台湾老板自然是不会放过送上门来的文坛泰斗，于是就有了后来的青青世界这着歌，也让青青世界这个旅游景点火一把。 今天，歌声已逝，这首歌也成了记忆中的记忆。同学与我开车再次来到青青世界，重温一下记忆中的记忆。青青世界一直打着城市农夫的定位，虽然景点相对小而且没有新的旅游项目，今天依旧少不了一些童年的元素，80年代人的都玩的滚铁环，滚轮车在这里你可以随处玩。漫步在飘着细雨的雨林，可以忘却一切都市的压力。看着水车，踩在木板路，仿佛又回到了十多年前的那个乡村。我本是一农家仔，看着这些都是那么的亲切，早已厌倦了刚筋水泥墙，能亲近原生的自然多好啊。
</content>
    </entry>
    
     <entry>
        <title>家有老人</title>
        <url>http://lanlingzi.cn/post/stories/2009/0906_grandpa/</url>
        <categories>
          <category>杂记</category>
        </categories>
        <tags>
          <tag>家庭</tag>
        </tags>
        <content type="html"> 昨天去一了趟广州小叔那，我去看爷爷。岁月催人老，一晃我爷爷马上80岁了。我差不多每一年才与他见面一次，主要是回家过年时。每次见到他，都感觉他越来越苍老，不过今年他的身体还不错，希望他能健康百岁。 老人真像小孩一样，有时也会拿我开涮一下，他说他与奶奶在一起有60年了，正好有一花甲了。他说这一次要在广州多呆一段时间，要看广州这边国庆热闹。国庆之后，一定要做飞机回去，说一辈了还没有坐过飞机，总爱喜欢问一些关于飞机上的事，我只得一一回答。这次老人在广州呆着还是很愉快的，说广州比家里热多了，他喜欢天天呆在有空调的房子里不爱出去。他喜欢渴点酒，一天总是端一个杯子，我就劝他少渴点，也总是笑着对我说润润嘴巴。
</content>
    </entry>
    
     <entry>
        <title>读史小记</title>
        <url>http://lanlingzi.cn/post/notes/2009/0822_history_think/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>历史</tag><tag>宗教</tag>
        </tags>
        <content type="html"> 战乱多 自从买了个诺基亚的大E之后，在手机上看书的时间越来越多了，最近一连看了好几本历史相关的书籍。原来中国的历史并非课本上写的那么简单。两千年来，中国历史能值得我们骄傲的并不多，对于普通百姓来说，一直是充满着无知与无奈。对于官员来说，一直是充满着虚伪与争斗，对于帝王来说， 一直是充满着荒唐与淫乱。在历史长河，没有几个太平盛世，没有几个有作为的帝王，没有几个能臣干将。整个中原民族也是不断地受到外族侵略，也不断的融合其它的民族。李世民是鲜卑族，成吉思汗是蒙古族，康熙是满族。强大的政权往往是由外族创建，而后才慢慢融合到汉族中。 杀功臣 一个人一旦成了皇帝，真的成了孤家寡人了，父亲儿子可以杀，那么下面的臣子更不用说了，中国历史上开国皇帝杀功臣的太多了。
汉朝的刘邦怕韩信功高盖主，杀之。唐朝李世民对开国功臣处理比较得当，没有什么杀戮。宋朝赵匡胤对开国功臣采用较和平的方式，让他们回家养老，重文不重武，明朱元璋对开国功臣则是一率的赶尽杀绝，做事做绝。清朝由于前期左右势力均衡，才把顺治推上历史舞台，但其叔父多尔衮却杀了不少他的政敌（也有一些是开国功臣）。
现代企业也普遍存在这种情况，尤其是在国有企业。一个企业的老总，就是这里的皇帝，整一个人太容易。随他一起创业的功臣，老总对他们忌惮太多，这可能也是中国很多企业昙花一现的原因之一。
两极化 中国人的宗教生活不应该分成儒、佛、道三家，更确切地说，应当分成两个等级。即:普通百姓为一个等级，学者(学优而仕，中国古代没有独立的学者，学者即官员)为一个等级。
普通百姓崇拜古代的、佛教的、道教的及其他来源的诸神和自然物。学者们却只信奉皇帝和祖宗，有时也敬奉孔子、佛陀、老子和几位伟大的历史人物，但从不信奉其他神灵。
普通百姓相信占星术，历书、释梦、泥土占卜、巫术、骨相学、手相术、招魂术、各式算命、符咒、魔术以及各种迷信；学者们很少相信这些玩艺。
普通百姓经常出入各类庙宇和神殿；学者们则回避这些地方，只光顾圣堂、孔庙和祠堂，有时也去历史伟人的庙地。
普通百姓认为宗教仪式是神秘的；学者们认为纯属形式而已。
普通百姓多是宿命论者，认为祸福均由神灵直接支配；学者们却不相信命运。
普通百姓敬神，主要是为了求神赐福，尤其是为了求神保佑子女平安，保佑他们生活富裕，长命百岁；学者们的崇拜，并不企求神灵恩赐，只是为了表示敬意。
所以中国不会有绝对的宗教信仰，不会为其献身，宗教对百姓来说只是一时的精神依寄、安慰，学者可能是一种的统治手段、形式。
</content>
    </entry>
    
     <entry>
        <title>性能设计</title>
        <url>http://lanlingzi.cn/post/technical/csdn/perform_design/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>软件设计</tag>
        </tags>
        <content type="html"> 无论Java还是C&#43;&#43;都有不少的性能优化工具。公司曾有人把一个系统从几十TPS优化到上千TPS，真是让人佩服到五体投地。但是由于架构的原因导致性 能问题，那就不好下手优化了。
在软件项目设计前期，不可不能考虑性能设计。要确定好的性能要求，必须识别项目约束、确定软件将执行的服务并指定软件期望的 负载。但也不要过于注重性能设计。太注重往往会陷入设计的误区。有时甚至为了性能而牺牲功能，那是大错特错了。
项目交付时首先是功能是否满足，其它才是性 能。换句话说软件首先要能工作，其次才是否能高效率的工作。性能设计必须依托测试结果。不要我以为这样做法性能会好。而现在很多的所谓的系统分析设计师却 喜欢我以为，爱拿以前的经验做依托，更喜欢拿其它项目成功的性能设计套用，岂知此系统非彼系统。 性能基准测试应尽早开始，以便在问题被引入软件时就将它们识别出来。将后续的基准测试与初始的软件性能基准进行比较，确定性能是进步了还是退步了。执行这样的测试时不要做不必要的改动（如更改硬件），以便可以对 连续测试得出准确的比较结果。同样，性能障碍越早发现改起来越省开销，而且也更容易克服。
当然，要提高性能需付出代价。虽然可以针对任何给定的问题空间生成高性能应用程序，但主要代价是每个事务的成本。有时有必要通过牺牲性能来控制成本。这又说到性能与成本的关系了。性能设计也不可不能权衡提高性能对成本的影响。在成本的约束下确定性能要求。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之名字空间namespace</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_namespace_usage/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> C开发人员会经常使用#define即宏来声明常量，但宏却是全局的，对大的工程来说是很难维护，经常是导致名字冲突。还好，C&#43;&#43;给我们带来了namespace名字空间。它的使用如下，名字空间可以把一组逻辑分组，同时名字空间也是一种作用域。
namespace outspname { const int CVAR1 = 1; const char* const CVAR2 = &amp;quot;33333&amp;quot;; void test(); namespace inspname { enum { A, B, C}; class Klass { }; } }  
但即使一个简单的名字空间，其中也有不少的玄机。
 当某个名字在自己的空间之外使用，在反复地在前面加上名字空间作为限定词， 如:
const int local = outspname::inspname::A  这样写是不是很令人烦。在某个小的局部作用域内，我们可以通过一个使用声明。如:
{ using outspname::inspname::A; const int local = A; }  通过一个使用指令把该名字空间下所有的名字变成可用。
如下所示，与第一点的用法区别，是using 后面有个namespace。同样只在转换时，或者在一个小的局部作用域内使用using namesapce，否则也会带来名字的污染。
{ using namespace outspname; const int local2 = CVAR1; const int local2 = inspname::B; { using namespace inspname; Klass* p = new Klass(); } }  但使用using namespace这种用法时，要注意下面一点，如在某个.h中声明了有testname::test的方法。
namespace testname { void test(int param); }  在其.cpp中，不能使用如下这种方式，test方法只是此编译单元的一个局部方法，并非testname名字空间的test方法实现。
using testname; void test(int param) { }  正确的使用方式是:
namespace testname { void test(int param) { } }  或者是
void testname::test(int param) { }  名字空间的别名，当名字空间很长或嵌套很深时，我们可以使用名字空间别名，用法如下：
namespace oin = outspname::inspname;  无名名字空间，无名名字空间主要是保持代码的局部性，使用如下：
namespace { const int CVAR1 = 1; void test(); }  但一定要注意的一点是，在C&#43;&#43;编译器实现时，无名名字空间其实是有名字的，这个隐含的名字跟它所在编译单元名字相关。所以基于这一点，我们不能跨编译单元使用无名名字空间中的名字。上面的声明等价于:
namespace $$$ { const int CVAR1 = 1; void test(); } using namespace $$$;  其中$$$在其所在的作用域里具有惟一性的名字，每个编译单元里的无名名字空间也是互不相同的，usingnamesapce $$$只是当前的编译单元的隐含名字，所以不能跨编译单元使用无名名字空间中的名字。假设上面的test方法在是a.h与a.cpp中定义与实现的，但在b.h或b.cpp中就不能直接使用test方法或CVAR1。因为在b的这个编译单元中链接的是b这个编译单元中的test符号，并非a编译单元中的test符号，也就会出现未定符号。
 要避免名字空间使用很短的名字，也不能太长，更不能嵌套太深了，个人觉得不要超过4层。
 </content>
    </entry>
    
     <entry>
        <title>面向对象的设计原则</title>
        <url>http://lanlingzi.cn/post/technical/csdn/oo_design_principle/</url>
        <categories>
          <category>笔记</category>
        </categories>
        <tags>
          <tag>软件设计</tag>
        </tags>
        <content type="html"> 如何同时提高一个软件系统的可维护性和可复用性是面向对象的设计要解决的核心问题。
导致一个软件设计的可维护性较低，也就是说会随着性能要求的变化而“腐烂”的真正原因有四个：
 过于僵硬 过于脆弱 复用率低 黏度过高  一个好的系统设计应该有如下的性质，这三条性质就是一个系统设计应当达到的目标。
 可扩展性 灵活性 可插入性   软件的复用的好处有：
 较高的生产效率 较高的软件质量 恰当使用复用可改善系统的可维护性  在面向对象的语言中，数据的抽象化、继承、封装和多态性是几项最重要的语言特性，这些特性使得一个系统可以在更高的层次上提供可复用性。数据的抽象化和继承关系使得概念和定义可以复用；多态性使得实现和应用可以复用；而抽象化和封装可以保持和促进系统的可维护性。
在一个设计得当的系统中，每一个模块都相对于其它模块独立存在，并只保持与其它模块的尽可能少的通信。这样一来，在其中某一个模块发生代码修改的时候，这个修改的压力不会传递到其它的模块。
常见的设计原则有：
 “开闭”原则（Open-Closed Principle）
“开闭”原则讲的是：一个软件实体应当对扩展开放，对修改关闭。其英文原文是：Software entities should be open for extension,but closed for modification.满足开闭原则的设计可以给一个软件系统两个无可比拟的优越性：1.通过扩展已有的软件系统，可以提供新的行为，以满足对软件的新需求，使变化中的软件系统有一定的适应性和灵活必。2.已有的软件模块，特别是最重要的抽象层模块不能再修改，这就使变化中的软件系统有一定的稳定性和延续性。
 里氏代换原则（Liskov Substitution Principle）
里氏代换原则指一个软件实体如果使用的是一个基类的话，那么一定适用于其子类，而且它根本不能察觉出基类和子类对象的区别。里氏代换原则是继承复用的基石。只有当衍生类可以替换掉基类，软件单位的功能不会受到影响时，基类才能真正被复用，而衍生类也才能在基类的基础上增加新的行为。
 依赖倒转原则（Dependency Inversion Principle）
依赖倒转原则要求客户端依赖于抽象耦合，依赖倒转原则的表述是：抽象不应当依赖于细节；细节应当依赖于抽象。（Abstractions should not depend upon details,Details should depend upon abstractions）依赖倒转原则的另一种表达是：要针对接口编程，不要针对实现编程。（Program to an interface, not an implementation）
 接口隔离原则（Interface Segregatioon Principle）
接口隔离原则，指一个类对另外一个类的依赖性应用是建立在最小的接口上的。
 组合／聚合复用原则（Composition/Aggregation Principle）
组合／聚合复用原则，就是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新的对象通过向这些对象的委派达到复用已有功能的目的。另一个更简短的表述：要尽量使用合成／聚合，尽量不要使用继承。
 迪米特法则（Law of Demeter）
迪米特法则又叫做最少知识原则（Least Knowledge Principle），就是说，一个对象应当对其它对象有尽可能少的了解。迪米特法则有很多表达方式，较有代表性的有：只与你直接的朋友们通信（Only talk to your immediate friends）。不要跟“陌生人”说话（Don&amp;rsquo;t talk to strangers）。
   本文上述均节选摘抄自阎宏博士的《Java与模式》一书
</content>
    </entry>
    
     <entry>
        <title>[C&#43;&#43;] STL容器中erase方法的不同陷阱</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_erase_fault/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> STL中的容器都有erase方法，容器的存储分为顺序存储(如vector)与链式存储(如list,map)。先以map为例:
typedef std::map&amp;lt;std::string, std::string&amp;gt; TStrMap; typedef TStrMap::iterator TStrMapIter; TStrMap strmap; TStrMapIter iter = strmap.find(&amp;quot;somekey&amp;quot;); strmap.erase(iter);  这样使用erase方法没有任何问题，删除一个单结节之后，stl中的iterator都是与其中的数据元素关联的，关联的元素删除之后，iter已就失效，iter理解为指向元素的指针，那删除之后可以简单理解为已是一个野指针。 但有时我们一不注意，却会这样使用，这是错误的:
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();&#43;&#43;iter) { if (&amp;quot;somevalue&amp;quot; == iter-&amp;gt;second ) { strmap.erase(iter); } }  iter所指的元素删除之后，&#43;&#43;iter是错误的，会导致程序的未知结果，iter一般是不会移到指向下一个元素。
对于map与list这样的链式存储结构。我们一般可以有两种解决办法:
方法一 使用erase(iter&#43;&#43;)，因为iter2 = iter&#43;&#43;是iter先移到指向下一个节点，而iter2还是指向当前的节点。注意理解iter&#43;&#43;与&#43;&#43;iter的区别。
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();) { if (&amp;quot;somevalue&amp;quot; == iter-&amp;gt;second ) { strmap.erase(iter&#43;&#43;); } else { &#43;&#43;iter; } }  方法二 erase的返回值会指向下一个节点，记把下一节点赋给一个变量。
for(TStrMapIter iter= strmap.begin(); iter!= strmap.end();) { if (&amp;quot;somevalue&amp;quot; == iter-&amp;gt;second ) { iter = strmap.erase(iter); } else { &#43;&#43;iter; } }  但对于顺序存储的vector也可以使用上述两种方法吗？很遗憾，第一种用法却是错误的，但第二种用法是正确的。因为顺序存储的容器一旦erase时，会涉及到数据移动，iterator所指的位置还是那个位置，但元素却移动了，iter&#43;&#43;之后已不再你想要的元素位置了。
void test_vector_erase() { typedef std::vector&amp;lt;int&amp;gt; TIntVec; typedef TIntVec::iterator TIntVecIter; TIntVec vec; vec.push_back(1); vec.push_back(2); vec.push_back(3); vec.push_back(4); for (TIntVecIter iter = vec.begin(); iter != vec.end();) { std::cout &amp;lt;&amp;lt; *iter &amp;lt;&amp;lt; std::endl; if (0 == *iter % 2) { vec.erase(iter&#43;&#43;); } else { &#43;&#43;iter; } } }  它输出的结果却是未知的，我的测试环境为&amp;quot;1，2，4，4&amp;quot;。你可能发现原因，当删除2元素时，3往前移了，而iter&#43;&#43;不是指到3，还是指到4了。当你使用STL容器中erase方法，那是一定要小心再小心，我也是被它戏弄了一下之后，才明白其中容易被忽视的这些细节。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;的仿函数与动态语言的闭包</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_closure_pkg/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 什么是闭包，我们先来用ruby看个例子：
sum = 0 10.times{|n| sum &#43;= n} print sum  其中{}就是闭包的内容，代码看起来是不是很清爽与简单。
我们还来看看Python写的闭包：
def addx(x): return lambda y: x &#43; y add8 = addx(8) print add8(100)  用Python写就没有那么好看。 闭包（Closure）是词法闭包（Lexical Closure）的简称。对闭包的具体定义有很多种说法，这些说法大体可以分为两类：
 一种说法认为闭包是符合一定条件的函数，闭包是在其词法上下文中引用了自由变量的函数。 另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。比如参考资源中就有这样的的定义：在实现深约束时，需要创建一个能显式表示引用环境的东西，并将它与相关的子程序捆绑在一起，这样捆绑起来的整体被称为闭包。  这两种定义在某种意义上是对立的，一个认为闭包是函数，另一个认为闭包是函数和引用环境组成的整体。虽然有些咬文嚼字，但可以肯定第二种说法更确切。闭包只是在形式和表现上像函数，但实际上不是函数。函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。所谓引用环境是指在程序执行中的某个点所有处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。那么为什么要把引用环境与函数组合起来呢？这主要是因为在支持嵌套作用域的语言中，有时不能简单直接地确定函数的引用环境。
什么是仿函数，我们先用C&#43;&#43;来写个例子：
struct comparer { bool operator()(int a, int b) const { return a &amp;gt; b; } }; int main(int, char**) { std::vector&amp;lt;int&amp;gt; vec; std::sort(vec.begin(), vec.end(), comparer()); return 0; }  函数(functor)之所以称为仿函数，是因为这是一种利用某些类对象支持operator()的特性，来达到模拟函数调用效果的技术。从上面你也可以看出来，仿函数实现的内容其实就像动态语言闭包实现的方式差不多，形式不一样，效果是一样的。至于语言本质是什么，就让语言学家去争论吧。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之栈变量的析构应用</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_stack_usage/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 栈变量有一个好处，就是它退栈时会自动析构，并且在栈上对象生成比在堆上分配效率高很多。但每个线程的栈空间是有限的(创建线程时可以设置)，所以一般的临时小对象都会在栈上分配。 struct Test {}; void test() { Test stack_var; // a stack var; Test stack_var2; //a stack var; int *heap_var = new int; // a heap var }  上述的例子，stack_var与stack_var2都是一个栈变量，当然stack_var与stack_var2谁先从栈中分配，不的操作系统，内存管理方式也略有区别。更深一点讲，heap_var这个指针值也是一个栈变量承载，但heap_var所指的地址内容才是从堆上分配的内存空间。当退出test这个函数时，stack_var与stack_var2都会先调用Test的析构，再把其所在的内存空间回收到线程栈中。
在一些场景下，我们可以利用栈变量当退栈时会自动析构这特性，下面我将举两个应用例子。
析构方法释放内存 从堆上面new出来的对象，在一个方法条件分支比较多的情况下，很容易在某个分支少写delete，就会造成内存的泄漏。于是我们可写一个这样的类，在它的析构方法中调用delete回收内存。
template &amp;lt;typename T&amp;gt; class ScopePtr { public: ScopePtr(T *&amp;amp; pT) : m_pT(pT) { } ~ScopePtr() { if ( NULL != m_pT ) { delete m_pT; m_pT = NULL; } } private: typedef ScopePtr&amp;lt;T&amp;gt; TScopePtr; ScopePtr(const TScopePtr &amp;amp;) {} TScopePtr&amp;amp; operator = (const TScopePtr &amp;amp;) {} T *&amp;amp; m_pT; }; // 使用方式如下： void test_scope() { Test* p = new Test; ScopePtr&amp;lt;Test&amp;gt; tempScopePtr(p); }  析构方法打印日志 做软件，写debug日志是一个好的习惯，出问题时可以方便定位问题的发生源。下面的例子是实现是能记录函数在哪一行进入，在哪一行退出。如果函数某个地方抛异常了，则可以根据进入行与退出行相同一看便知。没有抛异常，也很方便查出是在哪个分支退出的。
#define LOG(fmt, ...) printf(fmt, __VA_ARGS__) #define __FUNC_TRACE__ class FuncTracer { public: FuncTracer(const char* func, const char* file, const int line) : m_func(func), m_file(file), m_line(line) { LOG(&amp;quot;Enter [%s][%d][%s]./n&amp;quot;, m_file, m_line, m_func); } ~FuncTracer() { LOG(&amp;quot;Exit [%s][%d][%s]./n&amp;quot;, m_file, m_line, m_func); } inline void updateLine(const int line) { m_line = line; } private: const char* m_func; const char* m_file; int m_line; }; #ifdef __FUNC_TRACE__ #define FUNC_TRACER() FuncTracer __oFuncTracer(__FUNCTION__, __FILE__, __LINE__) #define FUNC_RET(retVal) do { __oFuncTracer.updateLine(__LINE__); return retVal; } while(0) #define FUNC_RET_VOID() do { __oFuncTracer.updateLine(__LINE__); return; } while(0) #else #define FUNC_TRACER() #define FUNC_RET(retVal) return retVal; #define FUNC_RET_VOID() return; #endif  上述的__FUNCTION__，__FILE__与__LINE__是编译期间的宏，是一个字符串常量，分别表示函数名，文件名与当前行数。但__FUNCTION__并非标准中定义的，各个编译器命名不同，更通用的宏可以使用boost中BOOST_CURRENT_FUNCTION。其中的__FUNC_TRACE__宏开关表示是否编译时开启函数跟踪。使用方式如下：
int test_trace() { FUNC_TRACER(); if(...) { switch(...) case 1: FUNC_RET(1); defualt: FUNC_RET(0); .... } FUNC_RET(1); } </content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之operator操作符</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_operator/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 这篇博文是以前很久写的，贴在我的早期一个blog中，今天google一下，发现还真有不少人转载，可惜并不注明出处。那时觉得operator比较好玩。C&#43;&#43;有时它的确是个耐玩的东东。operator它有两种用法，一种是operator overloading（操作符重载），一种是operator casting（操作隐式转换）。 operator overloading C&#43;&#43;可以通过operator 重载操作符，格式如下：类型T operator 操作符 ()，如比重载&#43;，如下所示
template&amp;lt;typename T&amp;gt; class A { public: const T operator &#43; (const T&amp;amp; rhs) { return this-&amp;gt;m_ &#43; rhs; } private: T m_; };  又比如STL中的函数对象，重载()，这是C&#43;&#43;中较推荐的写法，功能与函数指针类似，如下所示
template&amp;lt;typename T&amp;gt; struct A { T operator()(const T&amp;amp; lhs, const T&amp;amp; rhs){ return lhs-rhs;} };  operator casting C&#43;&#43;可以通过operator 重载隐式转换，格式如下： operator 类型T ()，如下所示
class A { public: operator B* () { return this-&amp;gt;b_;} operator const B* () const {return this-&amp;gt;b_;} operator B&amp;amp; () { return *this-&amp;gt;b_;} operator const B&amp;amp; () const {return *this-&amp;gt;b_;} private: B* b_; };  A a;当if(a)，编译时转换成if(a.operator B*())，其实也就是判断if(a.b_).
</content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]自己实现的queue</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_self_impl_queue/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 周末在家，自己用C&#43;&#43;练一下手，用顺序存储与链表存储实现了队列queue。queue是一种先进先出的结构，有很多的应用，比如消息队列。 顺序存储实现： template&amp;lt;typename T, size_t SIZE&amp;gt; class Queue { public: Queue() : m_front(0), m_rear(0) { } ~Queue() { } void clear() { m_front = 0; m_rear = 0; } const bool empty() const { return m_front == m_rear; } const int size() const { int s = (m_rear - m_front &#43; (int)SIZE) % (int)SIZE ; return s; } bool push(const T&amp;amp; t) { int pos = (m_rear &#43; 1) % (int)SIZE; //printf(&amp;quot;/n m_rear = %d&amp;quot;, pos); if (pos == m_front) { return false;// it&#39;s full } m_rear = pos; m_data[m_rear] = t; return true; } T&amp;amp; pop() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;quot;Overflow&amp;quot;); } m_front = (m_front &#43; 1) % (int)SIZE; //printf(&amp;quot;/n m_front = %d&amp;quot;, m_front); return m_data[m_front]; } T&amp;amp; getfront() { return m_data[m_front]; } // 遍历所有的节点 void traverse( void (*func)(T&amp;amp;) ) { if ( empty() ) { return;} for (int idx = m_front &#43; 1; idx != m_rear &#43; 1; idx&#43;&#43;) { if ( idx == (int)SIZE) { idx %= (int)SIZE; } //printf(&amp;quot;/n idx = %d&amp;quot;, idx); func(m_data[idx]); } } private: T m_data[SIZE]; int m_front; int m_rear; };  链表存储实现： template&amp;lt;typename T&amp;gt; struct QNode { QNode() : m_pNext(NULL) { } T m_data; QNode* m_pNext; }; template&amp;lt;typename T&amp;gt; class LQueue { typedef QNode&amp;lt;T&amp;gt; TQNode; public: LQueue() { TQNode* pTemp = NULL; NEW(pTemp, TQNode() ); m_pFront = m_pRear = pTemp; m_size = 0; } ~LQueue() { clear(); DELETE(m_pFront); } void clear() { TQNode* pTemp = m_pFront-&amp;gt;m_pNext; while(NULL != pTemp ) { TQNode* pTemp2 = pTemp-&amp;gt;m_pNext; DELETE(pTemp); pTemp = pTemp2; } m_pFront-&amp;gt;m_pNext = NULL; m_size = 0; } const bool empty() const { return m_pFront == m_pRear; } const int size() const { return m_size;} bool push(const T&amp;amp; t) { TQNode* pTemp = NULL; NEW(pTemp, TQNode() ); if ( NULL == pTemp) { return false;} pTemp-&amp;gt;m_data = t; pTemp-&amp;gt;m_pNext = m_pRear-&amp;gt;m_pNext; m_pRear-&amp;gt;m_pNext = pTemp; m_pRear = pTemp; m_size&#43;&#43;; return true; } T pop() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;quot;Overflow&amp;quot;); } TQNode* pTemp = m_pFront-&amp;gt;m_pNext; T t = pTemp-&amp;gt;m_data; m_pFront-&amp;gt;m_pNext = pTemp-&amp;gt;m_pNext; if (NULL == m_pFront-&amp;gt;m_pNext) { m_pRear = m_pFront; } DELETE(pTemp); m_size--; return t; } T&amp;amp; getfront() { if (empty()) { throw Error&amp;lt;T&amp;gt;(&amp;quot;Overflow&amp;quot;); } TQNode* pTemp = m_pFront-&amp;gt;m_pNext; T t = pTemp-&amp;gt;m_data; return t; } // 遍历所有的节点 void traverse( void (*func)(T&amp;amp;) ) { if ( empty() ) { return;} TQNode* pTemp = m_pFront-&amp;gt;m_pNext; while(NULL != pTemp) { func(pTemp-&amp;gt;m_data); pTemp = pTemp-&amp;gt;m_pNext; } } private: TQNode* m_pFront; TQNode* m_pRear; int m_size; };  测试代码： void print_queue(int&amp;amp; a) { printf(&amp;quot;%d/t&amp;quot;, a); } void test_queue() { LQueue&amp;lt;int&amp;gt; queue; //Queue&amp;lt;int, 4&amp;gt; queue; queue.push(1); queue.push(2); queue.push(3); queue.pop(); queue.pop(); queue.pop(); queue.push(1); queue.push(2); queue.push(3); printf(&amp;quot;/n1 : size: %d /n&amp;quot;, queue.size() ); queue.traverse(print_queue); queue.pop(); printf(&amp;quot;/n2 : size: %d /n&amp;quot;, queue.size() ); queue.traverse(print_queue); queue.push(4); printf(&amp;quot;/n3 : size: %d /n&amp;quot;, queue.size() ); queue.traverse(print_queue); queue.clear(); printf(&amp;quot;/n4 : size: %d /n&amp;quot;, queue.size() ); queue.traverse(print_queue); } </content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之断言Assert</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_static_assert/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 断言的应该是一种编程的常见技巧。我所应用的断言有两种，一种是动态断言，即大家所熟知的C标准库的assert()宏，一种是C&#43;&#43;中的静态断言，即在编译期间检查。 动态断言： assert宏的原型定义在中，其作用是如果它的条件返回错误，则终止程序执行，原型定义：
#include &amp;lt;assert.h&amp;gt; void assert( int expression );  assert的作用是先计算表达式expression ，如果其值为假（即为0），那么它先向stderr打印一条出错信息，然后通过调用abort 来终止程序运行。
大家要注意是，其中的表达式为假时，会终止程序运行，包括我在内经常会写错代码，断言一个指针是否为空，往往写成了 assert(!p);其实应该写成assert(p);。
assert是运行期的判断，并且会强制终止程序，一般要求只能用于debug版本中，是为了尽可能快的发现问题。尤其在我所从事的电信软件产品中，assert是要从release版本中去掉。所以一般开发会重新定义assert宏。
静态断言： 在新的C&#43;&#43;标准中C&#43;&#43;0x中，加了对静态断言的支持，引入了新的关键字static_assert来表示静态断言。
使用静态断言，我们可以在程序的编译时期检测一些条件是否成立。但这个关键字太新了，没有几个编译器是支持的(好像VC2008支持，我用VC很少，主要是在linux下C&#43;&#43;编程)。
于是可以使用C&#43;&#43;现有的模板特性来实现静态断言的功能。boost中也已有BOOST_STATIC_ASSERT宏的实现，有兴趣的同学可以down下来仔细研究一下，它的断言信息更丰富，下面为我的简单实现：
// declare a tempalte class StaticAssert. template &amp;lt;bool assertion&amp;gt; struct StaticAssert; // only partial specializate parameter&#39;s value is true. template &amp;lt;&amp;gt; struct StaticAssert&amp;lt;true&amp;gt; { enum { VALUE = 1 }; }; #define STATIC_ASSERT(expression) (void)StaticAssert&amp;lt;expression&amp;gt;::VALUE  原理是，先声明一个模板类，但后面仅仅偏特化参数值为true的类，而为false的类则一个未定义的类，即是一个未完整的类型,编译期间无法找到StaticAssert&amp;lt;false&amp;gt;::VALUE类型。举例如下：
STATIC_ASSERT(4 == sizeof(long) ); //在 32bit机上OK STATIC_ASSERT(4 == sizeof(long) ); //在 64bit机上NG，long为8字节  静态断言在编译时进行处理，不会产生任何运行时刻空间和时间上的开销，这就使得它比assert宏具有更好的效率。另外比较重要的一个特性是如果断言失败，它会产生有意义且充分的诊断信息，帮助程序员快速解决问题。
</content>
    </entry>
    
     <entry>
        <title>C&#43;&#43;技巧之宏Macro应用</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_macro_rule/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html">  宏不要用来定义常量，因为宏变量是没有类型安全，也没有名字空间约束，会造成名字的污染。
 宏的展开是一行，所以宏中的注释不能使用//，只能使用/* */。宏的代码也不能gdb跟踪，宏中代码逻辑要尽量简单。
 宏的参数一般情况下使用时要用()括起来，如: #define MAX(a, b) a /2 &amp;gt; b ? a /2 : b MAX(3,4)使用没有问题，但MAX(3&#43;4, 4)却有问题，因为宏的参数仅为符号替换。 应用定义为#define MAX(a, b) (a) / 2 &amp;gt; (b) ? (a) /2 : (b)  宏的连接符分为#与## #表示一个符号直接转换为字符串，如 #define CAT(x) &amp;quot;First &amp;quot;#x &amp;quot; Third&amp;quot; const char * pszStr = CAT(Second); str的内容就是&amp;rdquo;First Second Third&amp;rdquo;，也就是说#会把其后的符号直接加上双引号。 ##符号会连接两个符号，从而产生新的符号(词法层次)，例如： #define NAME( x ) name_##x char* NAME( szlanny ); 宏被展开后将成为：char* name_szlanny;
 宏中如有存在if等语句产生的分支，要使用do{}while(0)包起来，如 #define TEST(a ) if ( 0 == a ) dosomething() 如果在下面使用是会存在问题
if ( 1 == b) TEST(a ): else { dootherthing(); }  那当代码展开之后，宏中的if与外面的else是一起匹配，而不是else与if ( 1 == b)匹配。 所以上述宏要修改为
#define TEST(a ) do {/ if ( 0 == a ) { dosomething(); } }while(0)  对于可变参宏，可以使用VA_ARGS，GCC支持它，但并非所有的编译器支持，如果你的代码要跨平台，慎用。
#define LOG( format, ... ) printf( format, __VA_ARGS__ ) LOG( &amp;quot;%s %d&amp;quot;, str, count );  __VA_ARGS__被自动替换为参数列表。
 宏不能嵌套使用，如: #define TEST( x ) ( x &#43; TEST( x ) )，编译器展开过程中发现第二个TEST，那么就将这个TEST当作一般的符号。
 当宏的逻辑比较多时，可以考虑宏中使用模板方法来代替宏的逻辑实现。
 </content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]自己实现的stack</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_self_impl_stack/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 还是前一段时间需要任职资格考试，自己练习一下栈stack的简易实现，今天把它贴出来，暴露的接口与STL类似，没有实现iterator迭代器。实现有两种方式， 基于顺序存储与链式存储。栈的特点是“后进先出”，在数学表达式运算，编译语法分析中，程序函数调用时最为常见。 公用的宏与异常类:
#define NEW(var, T) do { / try { / var = new T; / }catch(...) { / var = NULL; / } / }while(0) #define DELETE(var) do { / if(NULL != var) / { / delete var; / var = NULL; / } / }while(0) template&amp;lt;typename T&amp;gt; struct Error { Error(const char* pszInfo = &amp;quot;Overflow&amp;quot;) { printf(&amp;quot;/nThrow a error, Info :%s/n&amp;quot;, pszInfo); } };  顺序存储，模板实现，其中参数T为栈的存储类型，参数SIZE表示最大存储的个数。
template&amp;lt;typename T, size_t SIZE&amp;gt; class Stack { public: Stack() : m_size(0) { } ~Stack() { } bool push(const T&amp;amp; t) { if (m_size == SIZE) { return false; } m_data[m_size] = t; m_size&#43;&#43;; return true; } T&amp;amp; pop() { if (0 == m_size) { throw Error&amp;lt;T&amp;gt; (&amp;quot;Overflow&amp;quot;); } else { T&amp;amp; t = m_data[m_size]; m_size--; return t; } } void clear() { m_size = 0; } const bool empty() const { return 0 == m_size; } const size_t size() const { return m_size; } // 遍历所有的节点 void traverse(void(*func)(T&amp;amp;)) { if (empty()) { return; } for (size_t idx = 0; idx &amp;lt; m_size; &#43;&#43;idx) { func(m_data[idx]); } } private: T m_data[SIZE]; size_t m_size; };  链式存储，也是模板实现，内部结构为一单向链表。入栈的元素加到链表的表头。
template&amp;lt;typename T&amp;gt; struct SNode { T m_data; SNode* m_pNext; SNode() : m_pNext(NULL) { } }; template&amp;lt;typename T&amp;gt; class LStack { typedef SNode&amp;lt;T&amp;gt; TNode; public: LStack() : m_size(0) { NEW(m_pTop, TNode()); if (NULL != m_pTop) { m_pTop-&amp;gt;m_pNext = NULL; } } ~LStack() { clear(); DELETE(m_pTop); } void clear() { if (NULL == m_pTop) { return; } TNode* pTemp = m_pTop-&amp;gt;m_pNext; while (NULL != pTemp) { TNode* pTemp2 = pTemp-&amp;gt;m_pNext; DELETE(pTemp); pTemp = pTemp2; } m_pTop-&amp;gt;m_pNext = NULL; m_size = 0; } const bool empty() const { return (NULL == m_pTop || NULL == m_pTop-&amp;gt;m_pNext) ? true : false; } const size_t size() const { return m_size; } bool push(const T&amp;amp; t) { if (NULL == m_pTop) { return false; } TNode* pTemp = NULL; NEW(pTemp, TNode()); if (NULL == pTemp) { return false; } pTemp-&amp;gt;m_data = t; pTemp-&amp;gt;m_pNext = m_pTop-&amp;gt;m_pNext; m_pTop-&amp;gt;m_pNext = pTemp; m_size&#43;&#43;; return true; } T pop() { TNode* pTemp = m_pTop-&amp;gt;m_pNext; if (NULL == pTemp) { throw Error&amp;lt;T&amp;gt; (&amp;quot;Overflow&amp;quot;); } T t = pTemp-&amp;gt;m_data; m_pTop-&amp;gt;m_pNext = pTemp-&amp;gt;m_pNext; DELETE(pTemp); m_size--; return t; } // 遍历所有的节点 void traverse(void(*func)(T&amp;amp;)) { if (empty()) { return; } TNode* pTemp = m_pTop-&amp;gt;m_pNext; while (NULL != pTemp) { func(pTemp-&amp;gt;m_data); pTemp = pTemp-&amp;gt;m_pNext; } } private: TNode* m_pTop; size_t m_size; };  测试代码：
void print_stack(int&amp;amp; a) { printf(&amp;quot;%d/t&amp;quot;, a); } void test_stack() { printf(&amp;quot;stack test /n&amp;quot;); //Stack&amp;lt;int, 4&amp;gt; stack; LStack&amp;lt;int&amp;gt; stack; stack.push(1); stack.push(2); stack.push(3); stack.pop(); stack.pop(); stack.pop(); stack.push(1); stack.push(2); stack.push(3); printf(&amp;quot;/n1 : size: %d /n&amp;quot;, stack.size()); stack.traverse(print_stack); stack.pop(); printf(&amp;quot;/n2 : size: %d /n&amp;quot;, stack.size()); stack.traverse(print_stack); stack.push(4); printf(&amp;quot;/n3 : size: %d /n&amp;quot;, stack.size()); stack.traverse(print_stack); stack.pop(); printf(&amp;quot;/n4 : size: %d /n&amp;quot;, stack.size()); stack.traverse(print_stack); stack.clear(); printf(&amp;quot;/n5 : size: %d /n&amp;quot;, stack.size()); stack.traverse(print_stack); } </content>
    </entry>
    
     <entry>
        <title>用C&#43;&#43;模板来展示new与delete操作符原理</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_new_delete/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> C&#43;&#43;中的new与delete可以认为是C中的malloc与free的升级版本。new包含两部分:
 第一部分是与malloc功能相同，是从堆上面申请内存块 第二部是调用类的构造方法来初始化刚申请的内存。  delete是new的逆过程，先调用类的析构方法来反初始化，再把刚申请的内存还给堆。
new []与delete []是针对数组操作符，要注意是通过new []分配的对象，不能用delete来释放对象，否则会有内存泄漏。当然通过new分配的对象，不能用delete[]来释放对象。后面我会通过代码来说明为什么。 下面是C&#43;&#43; 中的new与delete函数原型，申请内存失败会抛出异常bad_alloc
void* operator new(std::size_t) throw (std::bad_alloc); void* operator new[](std::size_t) throw (std::bad_alloc); void operator delete(void*) throw(); void operator delete[](void*) throw();  使用举例:
int* p1 = new int(); delete p2; int* p2 = new int[5]; delete [] p2;  终于到了用模板来模拟new与delete操作符，代码中有注释说明，其中对于调用类的构造方法，采用一种C&#43;&#43;标准中称作in-place construtor的方式。使用原型为T* = new(pbuff) T()，直译的话就是在pbuff这块内存构造T类，而不用再去堆上面申请内存。这种技巧大量应用在对象池的实现中，即pbuff这块内存可以挂在链表中反复地使用（这里先不展开说了）。
/** * A simulation of c&#43;&#43; new T() &amp;amp; new T(param) operation */ struct NewObj { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { // allocate memory form heap void * pBuff = malloc(sizeof(T)); // call constructor pObj = new (pBuff) T(); } template &amp;lt;typename T, typename P&amp;gt; inline void operator()(T*&amp;amp; pObj, const P&amp;amp; param) { // allocate memory form heap void * pBuff = malloc(sizeof(T)); // call constructor, pass one param pObj = new(pBuff) T(param); } }; /** * A simulation of c&#43;&#43; delete T operation */ struct DeleteObj { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { if ( NULL == pObj ) { return ;} // call destructor pObj-&amp;gt;~T(); // free memory to heap free((void*)pObj); pObj = NULL; } }; /** * A simulation of c&#43;&#43; new T[N]() operation */ struct NewObjArray { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj, unsigned int size) { // save the number of array elements in the beginning of the space. long * pBuff = (long *) malloc (sizeof(T) * size &#43; sizeof(long)); *((unsigned int *) pBuff) = size; pBuff&#43;&#43;; // change pointer to T type, then can use pT&#43;&#43; T * pT = (T *) pBuff; // save the pointer to the start of the array. pObj = pT; // now iterate and construct every object in place. for (unsigned int i = 0; i &amp;lt; size; i&#43;&#43;) { new((void *) pT) T(); pT&#43;&#43;; } } }; /** * A simulation of c&#43;&#43; delete [] T operation */ struct DeleteObjArray { template &amp;lt;typename T&amp;gt; inline void operator()(T*&amp;amp; pObj) { unsigned int size = *((unsigned int *) ((long *) pObj - 1)); T * pT = pObj; // call destructor on every element in the array. for (unsigned int i = 0; i &amp;lt; size; i&#43;&#43;) { pT-&amp;gt;~T(); pT&#43;&#43;; } // free memory to heap. free ((void *) ((long *) pObj - 1)); pObj = NULL; } };  测试代码:
struct TestClass { TestClass() : mem1(0), mem2(0) {} TestClass(int m) : mem1(m), mem2(0) {} int mem1; long mem2; }; void test_new_delete() { TestClass* p1 = NULL; NewObj()(p1); printf(&amp;quot;%p/n&amp;quot;, p1); DeleteObj()(p1); // TestClass* p2 = NULL; NewObj()(p2, 0); printf(&amp;quot;%p/n&amp;quot;, p2); DeleteObj()(p2); // TestClass* p3 = NULL; NewObjArray()(p3, 5); printf(&amp;quot;%p/n&amp;quot;, p3); DeleteObjArray()(p3); }   测试环境为eclipse&#43;cdt&#43;ubuntu&#43;gcc，注意头文件需要#include&amp;lt;new&amp;gt;，使用#include&amp;lt;stdlib.h&amp;gt;会导致编译不过，因为in-place construtor是C&#43;&#43;中的新玩意。
</content>
    </entry>
    
     <entry>
        <title>[c&#43;&#43;]常见的几个排序算法</title>
        <url>http://lanlingzi.cn/post/technical/csdn/cpp_aglos/</url>
        <categories>
          <category>技术</category>
        </categories>
        <tags>
          <tag>cpp</tag>
        </tags>
        <content type="html"> 前一段时间需要任职资格考试，于是又拿起丢了几年的数据结构书看了看，温习了一下常见的几个排序算法。今天特把我写的学习代码贴了出来。排序的算法常见有插入排序，选择排序与交换排序，较复杂一点还有归并排序与基数排序，概念性的东西我就不多说了，大家可以找一本严老师数据结构书看看。读大学时不觉得怎么样，现在再来看看，又结合这几年的编程经验，通过C&#43;&#43;风格函数子造了一遍轮子。 排序算法  先来一个排序中的比较函数子，实现是左值小于右值。   template&amp;lt;typename T&amp;gt; struct CmpFuctor { bool operator()(const T&amp;amp; lhs, const T&amp;amp; rhs) { return lhs &amp;lt; rhs; } };   交换排序中用到的交换两个元素的函数。  template&amp;lt;typename T&amp;gt; void swap(T* lhs, T* rhs) { T tmp = *lhs; *lhs = *rhs; *rhs = tmp; }   排序前后，我们自然要观察前后元素的顺序，那也少了下面这个函数。即遍历整个数组，再回调函数指针func，把元素通过引用传递出来。  template&amp;lt;typename T&amp;gt; void traverse(T* pArray, const int size, void (*func)(T&amp;amp;) ) { for(int idx =0; idx&amp;lt; size; idx&#43;&#43;) { func(pArray[idx]); } }   我们先来看一个最简单的插入排序。  template&amp;lt;typename T, typename CMP &amp;gt; void insertsort(T* pArray, const int size, CMP cmp) { for(int idx =0; idx&amp;lt; size; idx&#43;&#43;) { T temp = pArray[idx]; int pos = idx -1; while( pos &amp;gt;= 0 &amp;amp;&amp;amp; cmp(temp, pArray[pos]) ) // &amp;lt; { pArray[pos&#43;1] = pArray[pos]; pos--; } pArray[pos&#43;1] = temp; } }   再对上面的插入排序改进，查找为折半插入排序。  template&amp;lt;typename T, typename CMP&amp;gt; void binaryinsertsort(T* pArray, const int size, CMP cmp) { for(int idx = 1; idx &amp;lt; size; idx&#43;&#43;) { int left = 0; int right = idx -1; T temp = pArray[idx]; while( left &amp;lt;= right) { int middle = (left &#43; right) / 2; if ( cmp(temp, pArray[middle] )) // &amp;lt; { right = middle - 1; } else { left = middle &#43; 1; } } int j = idx-1; for(; j &amp;gt;= right&#43;1; j--) { pArray[j&#43;1] = pArray[j]; } pArray[right&#43;1] = temp; } }   再来一个改进版的插入排序。  是希尔排序。希尔排序的基本思想是：先将整个待排记录序列分割成若干小组（子序列），分别在组内进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。
template&amp;lt;typename T, typename CMP&amp;gt; void shellsort(T* pArray, const int size, CMP cmp) { int j = 0; int d = size / 2; // 通过增量控制排序的执行过程 while( d &amp;gt; 0 ) { for(int i = d; i&amp;lt; size;i&#43;&#43;) { j = i - d; while(j &amp;gt;= 0) { // 对各个分组进行处理 if ( cmp(pArray[j&#43;d], pArray[j]) ) { swap(&amp;amp;pArray[j], &amp;amp;pArray[j&#43;d]); j -= d; } else { j = -1; } } } d /= 2; //递减增量d } }   下面是一种简单选择排序算法。  template&amp;lt;typename T, typename CMP&amp;gt; void selectsort(T* pArray, const int size, CMP cmp) { for(int idx = 0; idx &amp;lt; size; idx&#43;&#43;) { for(int pos = idx &#43; 1; pos &amp;lt; size; pos&#43;&#43;) { if( cmp(pArray[pos], pArray[idx]) ) // &amp;lt; { swap(&amp;amp;pArray[pos], &amp;amp;pArray[idx]); } } } }   交换排序中最简单的冒泡排序。   template&amp;lt;typename T, typename CMP&amp;gt; void bubblesort(T* pArray, const int size, CMP cmp) { for(int idx =0; idx &amp;lt; size; idx&#43;&#43;) { for(int pos = 0; pos &amp;lt;= size - idx;pos&#43;&#43;) { if( cmp(pArray[pos&#43;1], pArray[pos]) ) // &amp;lt; { swap(&amp;amp;pArray[pos], &amp;amp;pArray[pos&#43;1]); } } } }   交换排序中最简单的快速排序。  template&amp;lt;typename T, typename CMP&amp;gt; int partition(T* pArray, int p, int r, CMP cmp) { int i = p - 1; int j = 0; for(j = p; j &amp;lt; r; j&#43;&#43;) { if(cmp(pArray[j], pArray[r])) //pArray[j] &amp;gt;= pArray[r] { i&#43;&#43;; swap(&amp;amp;pArray[i], &amp;amp;pArray[j]); } } swap(&amp;amp;pArray[i &#43; 1], &amp;amp;pArray[r]); return i &#43; 1;  测试代码 void print(int&amp;amp; a) { printf(&amp;quot;%d/t&amp;quot;, a); } int genrandom(int min, int max) { return (min &#43; (int)(((float)rand()/RAND_MAX)*(max - min))); } void random(int&amp;amp; a ) { a = genrandom(-50, 100); } void sort_test() { int A[] = {4, 1, 44, -12, 5, 125, 30}; int len = sizeof(A) / sizeof(int); // traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); insertsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); binaryinsertsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); shellsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); bubblesort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); selectsort(A, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); // traverse(A, len, random); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); quicksort(A, 0, len, CmpFuctor&amp;lt;int&amp;gt;() ); traverse(A, len, print); printf(&amp;quot;/n&amp;quot;); }   上面的函数有C风格的函数指针与C&#43;&#43;风格函数子（Functor，有时也叫函数对象），函数使用了C&#43;&#43;中模板的一些特性，测试环境为eclipse&#43;cdt&#43;gcc。
</content>
    </entry>
    
     <entry>
        <title>Posts</title>
        <url>http://lanlingzi.cn/post/</url>
        <categories>
          
        </categories>
        <tags>
          
        </tags>
        <content type="html"> </content>
    </entry>
    
</search>